2023-09-28 08:48:32,078 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.0 (default, Nov  6 2019, 21:49:08) [GCC 7.3.0]
CUDA available: True
GPU 0,1: A100-SXM4-40GB
CUDA_HOME: /usr/local/cuda
NVCC: Build cuda_11.0_bu.TC445_37.28845127_0
GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
PyTorch: 1.9.0+cu111
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.10.0+cu111
OpenCV: 4.8.0
MMCV: 1.4.2
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.1
MMSegmentation: 0.20.2+e1afc82
------------------------------------------------------------

2023-09-28 08:48:32,079 - mmseg - INFO - Distributed training: True
2023-09-28 08:48:33,294 - mmseg - INFO - Config:
num_things_classes = 8
num_stuff_classes = 5
num_classes = 13
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoderMask2Former',
    pretrained='pretrained/beit_large_patch16_224_pt22k_ft22k.pth',
    backbone=dict(
        type='BEiTAdapter',
        patch_size=16,
        embed_dim=1024,
        depth=24,
        num_heads=16,
        mlp_ratio=4,
        qkv_bias=True,
        use_abs_pos_emb=False,
        use_rel_pos_bias=True,
        img_size=896,
        init_values=1e-06,
        drop_path_rate=0.3,
        conv_inplane=64,
        n_points=4,
        deform_num_heads=16,
        cffn_ratio=0.25,
        deform_ratio=0.5,
        with_cp=True,
        interaction_indexes=[[0, 5], [6, 11], [12, 17], [18, 23]]),
    decode_head=dict(
        type='Mask2FormerHead',
        in_channels=[1024, 1024, 1024, 1024],
        feat_channels=1024,
        out_channels=1024,
        in_index=[0, 1, 2, 3],
        num_things_classes=8,
        num_stuff_classes=5,
        num_queries=100,
        num_transformer_feat_level=3,
        pixel_decoder=dict(
            type='MSDeformAttnPixelDecoder',
            num_outs=3,
            norm_cfg=dict(type='GN', num_groups=32),
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                type='DetrTransformerEncoder',
                num_layers=6,
                transformerlayers=dict(
                    type='BaseTransformerLayer',
                    attn_cfgs=dict(
                        type='MultiScaleDeformableAttention',
                        embed_dims=1024,
                        num_heads=32,
                        num_levels=3,
                        num_points=4,
                        im2col_step=64,
                        dropout=0.0,
                        batch_first=False,
                        norm_cfg=None,
                        init_cfg=None),
                    ffn_cfgs=dict(
                        type='FFN',
                        embed_dims=1024,
                        feedforward_channels=4096,
                        num_fcs=2,
                        ffn_drop=0.0,
                        act_cfg=dict(type='ReLU', inplace=True),
                        with_cp=True),
                    operation_order=('self_attn', 'norm', 'ffn', 'norm')),
                init_cfg=None),
            positional_encoding=dict(
                type='SinePositionalEncoding', num_feats=512, normalize=True),
            init_cfg=None),
        enforce_decoder_input_project=False,
        positional_encoding=dict(
            type='SinePositionalEncoding', num_feats=512, normalize=True),
        transformer_decoder=dict(
            type='DetrTransformerDecoder',
            return_intermediate=True,
            num_layers=9,
            transformerlayers=dict(
                type='DetrTransformerDecoderLayer',
                attn_cfgs=dict(
                    type='MultiheadAttention',
                    embed_dims=1024,
                    num_heads=32,
                    attn_drop=0.0,
                    proj_drop=0.0,
                    dropout_layer=None,
                    batch_first=False),
                ffn_cfgs=dict(
                    embed_dims=1024,
                    feedforward_channels=4096,
                    num_fcs=2,
                    act_cfg=dict(type='ReLU', inplace=True),
                    ffn_drop=0.0,
                    dropout_layer=None,
                    add_identity=True,
                    with_cp=True),
                feedforward_channels=4096,
                operation_order=('cross_attn', 'norm', 'self_attn', 'norm',
                                 'ffn', 'norm')),
            init_cfg=None),
        loss_cls=dict(
            type='CrossEntropyLoss',
            use_sigmoid=False,
            loss_weight=2.0,
            reduction='mean',
            class_weight=[
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 0.1
            ]),
        loss_mask=dict(
            type='CrossEntropyLoss',
            use_sigmoid=True,
            reduction='mean',
            loss_weight=5.0),
        loss_dice=dict(
            type='DiceLoss',
            use_sigmoid=True,
            activate=True,
            reduction='mean',
            naive_dice=True,
            eps=1.0,
            loss_weight=5.0)),
    train_cfg=dict(
        num_points=12544,
        oversample_ratio=3.0,
        importance_sample_ratio=0.75,
        assigner=dict(
            type='MaskHungarianAssigner',
            cls_cost=dict(type='ClassificationCost', weight=2.0),
            mask_cost=dict(
                type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),
            dice_cost=dict(
                type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),
        sampler=dict(type='MaskPseudoSampler')),
    test_cfg=dict(
        panoptic_on=True,
        semantic_on=False,
        instance_on=True,
        max_per_image=100,
        iou_thr=0.8,
        filter_low_score=True,
        mode='slide',
        crop_size=(896, 896),
        stride=(512, 512)),
    init_cfg=None)
dataset_type = 'samsung'
data_root = '/raid/hyundai/13class_dataset'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (896, 896)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(896, 896), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(896, 896), pad_val=0, seg_pad_val=255),
    dict(type='ToMask'),
    dict(type='DefaultFormatBundle'),
    dict(
        type='Collect',
        keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 1024),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=2,
    train=dict(
        type='samsung',
        data_root='/raid/hyundai/13class_dataset',
        img_dir='train_img',
        ann_dir='train_img_anno',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(896, 896), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(896, 896), pad_val=0, seg_pad_val=255),
            dict(type='ToMask'),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels'])
        ]),
    val=dict(
        type='samsung',
        data_root='/raid/hyundai/13class_dataset',
        img_dir='valid_img',
        ann_dir='valid_img_anno',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='samsung',
        data_root='/raid/hyundai/13class_dataset',
        img_dir='valid_img',
        ann_dir='valid_img_anno',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='AdamW',
    lr=2e-05,
    betas=(0.9, 0.999),
    weight_decay=0.05,
    constructor='LayerDecayOptimizerConstructor',
    paramwise_cfg=dict(num_layers=24, layer_decay_rate=0.9))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=40000)
checkpoint_config = dict(by_epoch=False, interval=2000, max_keep_ckpts=1)
evaluation = dict(
    interval=2000, metric='mIoU', pre_eval=True, save_best='mIoU')
pretrained = 'pretrained/beit_large_patch16_224_pt22k_ft22k.pth'
work_dir = './work_dirs/vit_13'
gpu_ids = range(0, 2)
auto_resume = False

2023-09-28 08:48:41,159 - mmseg - INFO - Set random seed to 1138738751, deterministic: True
2023-09-28 08:49:04,088 - mmseg - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc_norm.weight, fc_norm.bias, head.weight, head.bias

missing keys in source state_dict: blocks.0.attn.relative_position_index, blocks.1.attn.relative_position_index, blocks.2.attn.relative_position_index, blocks.3.attn.relative_position_index, blocks.4.attn.relative_position_index, blocks.5.attn.relative_position_index, blocks.6.attn.relative_position_index, blocks.7.attn.relative_position_index, blocks.8.attn.relative_position_index, blocks.9.attn.relative_position_index, blocks.10.attn.relative_position_index, blocks.11.attn.relative_position_index, blocks.12.attn.relative_position_index, blocks.13.attn.relative_position_index, blocks.14.attn.relative_position_index, blocks.15.attn.relative_position_index, blocks.16.attn.relative_position_index, blocks.17.attn.relative_position_index, blocks.18.attn.relative_position_index, blocks.19.attn.relative_position_index, blocks.20.attn.relative_position_index, blocks.21.attn.relative_position_index, blocks.22.attn.relative_position_index, blocks.23.attn.relative_position_index

Name of parameter - Initialization information

backbone.cls_token - torch.Size([1, 1, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.level_embed - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.patch_embed.proj.weight - torch.Size([1024, 3, 16, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.patch_embed.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.0.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.0.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.0.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.0.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.0.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.0.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.0.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.0.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.0.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.0.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.0.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.0.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.0.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.0.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.0.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.0.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.1.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.1.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.1.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.1.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.1.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.1.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.1.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.1.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.1.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.1.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.1.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.1.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.1.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.1.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.1.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.1.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.2.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.2.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.2.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.2.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.2.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.2.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.2.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.2.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.2.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.2.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.2.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.2.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.2.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.2.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.2.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.2.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.3.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.3.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.3.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.3.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.3.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.3.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.3.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.3.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.3.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.3.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.3.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.3.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.3.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.3.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.3.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.3.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.4.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.4.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.4.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.4.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.4.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.4.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.4.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.4.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.4.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.4.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.4.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.4.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.4.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.4.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.4.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.4.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.5.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.5.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.5.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.5.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.5.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.5.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.5.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.5.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.5.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.5.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.5.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.5.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.5.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.5.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.5.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.5.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.6.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.6.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.6.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.6.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.6.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.6.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.6.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.6.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.6.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.6.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.6.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.6.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.6.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.6.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.6.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.6.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.7.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.7.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.7.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.7.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.7.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.7.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.7.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.7.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.7.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.7.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.7.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.7.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.7.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.7.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.7.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.7.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.8.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.8.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.8.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.8.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.8.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.8.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.8.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.8.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.8.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.8.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.8.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.8.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.8.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.8.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.8.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.8.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.9.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.9.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.9.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.9.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.9.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.9.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.9.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.9.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.9.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.9.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.9.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.9.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.9.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.9.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.9.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.9.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.10.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.10.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.10.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.10.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.10.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.10.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.10.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.10.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.10.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.10.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.10.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.10.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.10.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.10.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.10.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.10.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.11.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.11.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.11.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.11.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.11.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.11.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.11.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.11.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.11.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.11.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.11.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.11.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.11.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.11.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.11.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.11.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.12.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.12.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.12.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.12.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.12.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.12.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.12.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.12.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.12.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.12.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.12.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.12.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.12.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.12.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.12.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.12.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.13.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.13.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.13.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.13.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.13.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.13.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.13.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.13.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.13.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.13.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.13.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.13.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.13.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.13.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.13.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.13.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.14.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.14.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.14.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.14.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.14.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.14.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.14.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.14.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.14.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.14.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.14.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.14.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.14.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.14.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.14.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.14.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.15.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.15.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.15.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.15.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.15.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.15.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.15.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.15.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.15.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.15.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.15.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.15.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.15.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.15.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.15.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.15.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.16.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.16.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.16.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.16.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.16.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.16.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.16.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.16.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.16.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.16.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.16.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.16.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.16.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.16.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.16.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.16.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.17.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.17.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.17.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.17.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.17.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.17.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.17.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.17.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.17.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.17.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.17.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.17.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.17.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.17.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.17.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.17.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.18.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.18.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.18.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.18.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.18.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.18.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.18.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.18.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.18.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.18.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.18.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.18.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.18.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.18.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.18.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.18.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.19.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.19.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.19.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.19.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.19.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.19.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.19.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.19.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.19.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.19.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.19.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.19.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.19.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.19.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.19.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.19.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.20.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.20.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.20.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.20.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.20.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.20.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.20.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.20.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.20.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.20.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.20.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.20.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.20.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.20.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.20.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.20.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.21.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.21.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.21.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.21.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.21.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.21.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.21.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.21.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.21.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.21.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.21.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.21.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.21.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.21.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.21.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.21.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.22.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.22.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.22.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.22.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.22.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.22.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.22.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.22.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.22.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.22.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.22.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.22.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.22.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.22.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.22.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.22.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.23.gamma_1 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.23.gamma_2 - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.23.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.23.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.23.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.23.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.23.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.23.attn.qkv.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.23.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.23.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.23.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.23.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.23.mlp.fc1.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.23.mlp.fc1.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.23.mlp.fc2.weight - torch.Size([1024, 4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.blocks.23.mlp.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.stem.0.weight - torch.Size([64, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.stem.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.stem.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.stem.3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.stem.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.stem.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.stem.6.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.stem.7.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.stem.7.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.conv2.0.weight - torch.Size([128, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.conv2.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.conv2.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.conv3.0.weight - torch.Size([256, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.conv3.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.conv3.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.conv4.0.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.conv4.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.conv4.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.fc1.weight - torch.Size([1024, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.fc1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.fc2.weight - torch.Size([1024, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.fc3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.fc3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.fc4.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.spm.fc4.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.injector.gamma - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.injector.query_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.injector.query_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.injector.feat_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.injector.feat_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.injector.attn.sampling_offsets.weight - torch.Size([384, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.injector.attn.sampling_offsets.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.injector.attn.attention_weights.weight - torch.Size([192, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.injector.attn.attention_weights.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.injector.attn.value_proj.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.injector.attn.value_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.injector.attn.output_proj.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.injector.attn.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.query_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.query_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.feat_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.feat_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.attn.sampling_offsets.weight - torch.Size([128, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.attn.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.attn.attention_weights.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.attn.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.attn.value_proj.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.attn.value_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.attn.output_proj.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.attn.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.ffn.fc1.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.ffn.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.ffn.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.ffn.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.ffn.fc2.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.ffn.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.ffn_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.0.extractor.ffn_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.injector.gamma - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.injector.query_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.injector.query_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.injector.feat_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.injector.feat_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.injector.attn.sampling_offsets.weight - torch.Size([384, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.injector.attn.sampling_offsets.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.injector.attn.attention_weights.weight - torch.Size([192, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.injector.attn.attention_weights.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.injector.attn.value_proj.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.injector.attn.value_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.injector.attn.output_proj.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.injector.attn.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.query_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.query_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.feat_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.feat_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.attn.sampling_offsets.weight - torch.Size([128, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.attn.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.attn.attention_weights.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.attn.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.attn.value_proj.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.attn.value_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.attn.output_proj.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.attn.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.ffn.fc1.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.ffn.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.ffn.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.ffn.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.ffn.fc2.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.ffn.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.ffn_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.1.extractor.ffn_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.injector.gamma - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.injector.query_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.injector.query_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.injector.feat_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.injector.feat_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.injector.attn.sampling_offsets.weight - torch.Size([384, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.injector.attn.sampling_offsets.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.injector.attn.attention_weights.weight - torch.Size([192, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.injector.attn.attention_weights.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.injector.attn.value_proj.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.injector.attn.value_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.injector.attn.output_proj.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.injector.attn.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.query_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.query_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.feat_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.feat_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.attn.sampling_offsets.weight - torch.Size([128, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.attn.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.attn.attention_weights.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.attn.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.attn.value_proj.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.attn.value_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.attn.output_proj.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.attn.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.ffn.fc1.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.ffn.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.ffn.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.ffn.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.ffn.fc2.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.ffn.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.ffn_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.2.extractor.ffn_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.injector.gamma - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.injector.query_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.injector.query_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.injector.feat_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.injector.feat_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.injector.attn.sampling_offsets.weight - torch.Size([384, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.injector.attn.sampling_offsets.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.injector.attn.attention_weights.weight - torch.Size([192, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.injector.attn.attention_weights.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.injector.attn.value_proj.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.injector.attn.value_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.injector.attn.output_proj.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.injector.attn.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.query_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.query_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.feat_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.feat_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.attn.sampling_offsets.weight - torch.Size([128, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.attn.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.attn.attention_weights.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.attn.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.attn.value_proj.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.attn.value_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.attn.output_proj.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.attn.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.ffn.fc1.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.ffn.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.ffn.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.ffn.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.ffn.fc2.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.ffn.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.ffn_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extractor.ffn_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.query_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.query_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.feat_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.feat_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.attn.sampling_offsets.weight - torch.Size([128, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.attn.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.attn.attention_weights.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.attn.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.attn.value_proj.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.attn.value_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.attn.output_proj.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.attn.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.ffn.fc1.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.ffn.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.ffn.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.ffn.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.ffn.fc2.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.ffn.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.ffn_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.0.ffn_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.query_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.query_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.feat_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.feat_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.attn.sampling_offsets.weight - torch.Size([128, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.attn.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.attn.attention_weights.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.attn.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.attn.value_proj.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.attn.value_proj.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.attn.output_proj.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.attn.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.ffn.fc1.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.ffn.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.ffn.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.ffn.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.ffn.fc2.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.ffn.fc2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.ffn_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.interactions.3.extra_extractors.1.ffn_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.up.weight - torch.Size([1024, 1024, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.up.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.norm3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.norm3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.norm4.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

backbone.norm4.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([1024, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.0.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.0.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([1024, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.1.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.1.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([1024, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.2.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.2.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.weight - torch.Size([768, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.weight - torch.Size([384, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.weight - torch.Size([768, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.weight - torch.Size([384, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.weight - torch.Size([768, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.weight - torch.Size([384, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.weight - torch.Size([768, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.weight - torch.Size([384, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.weight - torch.Size([768, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.weight - torch.Size([384, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.weight - torch.Size([768, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.weight - torch.Size([384, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([1024, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([1024, 1024, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.output_convs.0.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.mask_feature.weight - torch.Size([1024, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.mask_feature.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.post_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.post_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.query_embed.weight - torch.Size([100, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.query_feat.weight - torch.Size([100, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.level_embed.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.cls_embed.weight - torch.Size([14, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.cls_embed.bias - torch.Size([14]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.0.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.2.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.4.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.4.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  
2023-09-28 08:49:11,835 - mmseg - INFO - EncoderDecoderMask2Former(
  (backbone): BEiTAdapter(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.013043479062616825)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.02608695812523365)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.03913043811917305)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.0521739162504673)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.06521739810705185)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.0782608762383461)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.09130435436964035)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.1043478325009346)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.11739131063222885)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.1304347962141037)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.14347827434539795)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (12): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.1565217524766922)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (13): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.16956523060798645)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (14): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.1826087087392807)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (15): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.19565218687057495)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (16): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.2086956650018692)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (17): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.22173914313316345)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (18): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.2347826212644577)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (19): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.24782609939575195)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (20): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.260869562625885)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (21): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.27391305565834045)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (22): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.2869565188884735)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (23): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.30000001192092896)
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (spm): SpatialPriorModule(
      (stem): Sequential(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (7): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): ReLU(inplace=True)
        (9): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      )
      (conv2): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (conv3): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (conv4): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (fc1): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))
      (fc2): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
      (fc3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
      (fc4): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
    )
    (interactions): Sequential(
      (0): InteractionBlockWithCls(
        (injector): Injector(
          (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=1024, out_features=384, bias=True)
            (attention_weights): Linear(in_features=1024, out_features=192, bias=True)
            (value_proj): Linear(in_features=1024, out_features=512, bias=True)
            (output_proj): Linear(in_features=512, out_features=1024, bias=True)
          )
        )
        (extractor): Extractor(
          (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=1024, out_features=128, bias=True)
            (attention_weights): Linear(in_features=1024, out_features=64, bias=True)
            (value_proj): Linear(in_features=1024, out_features=512, bias=True)
            (output_proj): Linear(in_features=512, out_features=1024, bias=True)
          )
          (ffn): ConvFFN(
            (fc1): Linear(in_features=1024, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ffn_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (drop_path): DropPath()
        )
      )
      (1): InteractionBlockWithCls(
        (injector): Injector(
          (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=1024, out_features=384, bias=True)
            (attention_weights): Linear(in_features=1024, out_features=192, bias=True)
            (value_proj): Linear(in_features=1024, out_features=512, bias=True)
            (output_proj): Linear(in_features=512, out_features=1024, bias=True)
          )
        )
        (extractor): Extractor(
          (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=1024, out_features=128, bias=True)
            (attention_weights): Linear(in_features=1024, out_features=64, bias=True)
            (value_proj): Linear(in_features=1024, out_features=512, bias=True)
            (output_proj): Linear(in_features=512, out_features=1024, bias=True)
          )
          (ffn): ConvFFN(
            (fc1): Linear(in_features=1024, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ffn_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (drop_path): DropPath()
        )
      )
      (2): InteractionBlockWithCls(
        (injector): Injector(
          (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=1024, out_features=384, bias=True)
            (attention_weights): Linear(in_features=1024, out_features=192, bias=True)
            (value_proj): Linear(in_features=1024, out_features=512, bias=True)
            (output_proj): Linear(in_features=512, out_features=1024, bias=True)
          )
        )
        (extractor): Extractor(
          (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=1024, out_features=128, bias=True)
            (attention_weights): Linear(in_features=1024, out_features=64, bias=True)
            (value_proj): Linear(in_features=1024, out_features=512, bias=True)
            (output_proj): Linear(in_features=512, out_features=1024, bias=True)
          )
          (ffn): ConvFFN(
            (fc1): Linear(in_features=1024, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ffn_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (drop_path): DropPath()
        )
      )
      (3): InteractionBlockWithCls(
        (injector): Injector(
          (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=1024, out_features=384, bias=True)
            (attention_weights): Linear(in_features=1024, out_features=192, bias=True)
            (value_proj): Linear(in_features=1024, out_features=512, bias=True)
            (output_proj): Linear(in_features=512, out_features=1024, bias=True)
          )
        )
        (extractor): Extractor(
          (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=1024, out_features=128, bias=True)
            (attention_weights): Linear(in_features=1024, out_features=64, bias=True)
            (value_proj): Linear(in_features=1024, out_features=512, bias=True)
            (output_proj): Linear(in_features=512, out_features=1024, bias=True)
          )
          (ffn): ConvFFN(
            (fc1): Linear(in_features=1024, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ffn_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (drop_path): DropPath()
        )
        (extra_extractors): Sequential(
          (0): Extractor(
            (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=1024, out_features=128, bias=True)
              (attention_weights): Linear(in_features=1024, out_features=64, bias=True)
              (value_proj): Linear(in_features=1024, out_features=512, bias=True)
              (output_proj): Linear(in_features=512, out_features=1024, bias=True)
            )
            (ffn): ConvFFN(
              (fc1): Linear(in_features=1024, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (act): GELU()
              (fc2): Linear(in_features=256, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ffn_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (drop_path): DropPath()
          )
          (1): Extractor(
            (query_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (feat_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=1024, out_features=128, bias=True)
              (attention_weights): Linear(in_features=1024, out_features=64, bias=True)
              (value_proj): Linear(in_features=1024, out_features=512, bias=True)
              (output_proj): Linear(in_features=512, out_features=1024, bias=True)
            )
            (ffn): ConvFFN(
              (fc1): Linear(in_features=1024, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (act): GELU()
              (fc2): Linear(in_features=256, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ffn_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (drop_path): DropPath()
          )
        )
      )
    )
    (up): ConvTranspose2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))
    (norm1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm2): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm4): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (decode_head): Mask2FormerHead(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): None
    (dropout): Dropout2d(p=0.1, inplace=False)
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_convs): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
          (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
        )
        (1): ConvModule(
          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
          (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
        )
        (2): ConvModule(
          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
          (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
        )
      )
      (encoder): DetrTransformerEncoder(
        (layers): ModuleList(
          (0): BaseTransformerLayer(
            (attentions): ModuleList(
              (0): MultiScaleDeformableAttention(
                (dropout): Dropout(p=0.0, inplace=False)
                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)
                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)
                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=1024, out_features=4096, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=4096, out_features=1024, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BaseTransformerLayer(
            (attentions): ModuleList(
              (0): MultiScaleDeformableAttention(
                (dropout): Dropout(p=0.0, inplace=False)
                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)
                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)
                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=1024, out_features=4096, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=4096, out_features=1024, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BaseTransformerLayer(
            (attentions): ModuleList(
              (0): MultiScaleDeformableAttention(
                (dropout): Dropout(p=0.0, inplace=False)
                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)
                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)
                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=1024, out_features=4096, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=4096, out_features=1024, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): BaseTransformerLayer(
            (attentions): ModuleList(
              (0): MultiScaleDeformableAttention(
                (dropout): Dropout(p=0.0, inplace=False)
                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)
                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)
                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=1024, out_features=4096, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=4096, out_features=1024, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
          (4): BaseTransformerLayer(
            (attentions): ModuleList(
              (0): MultiScaleDeformableAttention(
                (dropout): Dropout(p=0.0, inplace=False)
                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)
                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)
                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=1024, out_features=4096, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=4096, out_features=1024, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
          (5): BaseTransformerLayer(
            (attentions): ModuleList(
              (0): MultiScaleDeformableAttention(
                (dropout): Dropout(p=0.0, inplace=False)
                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)
                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)
                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=1024, out_features=4096, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=4096, out_features=1024, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (postional_encoding): SinePositionalEncoding(num_feats=512, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
      (level_encoding): Embedding(3, 1024)
      (lateral_convs): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
        )
      )
      (output_convs): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
          (activate): ReLU(inplace=True)
        )
      )
      (mask_feature): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
    )
    (transformer_decoder): DetrTransformerDecoder(
      (layers): ModuleList(
        (0): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (6): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (7): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (8): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (post_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    )
    (decoder_input_projs): ModuleList(
      (0): Identity()
      (1): Identity()
      (2): Identity()
    )
    (decoder_positional_encoding): SinePositionalEncoding(num_feats=512, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
    (query_embed): Embedding(100, 1024)
    (query_feat): Embedding(100, 1024)
    (level_embed): Embedding(3, 1024)
    (cls_embed): Linear(in_features=1024, out_features=14, bias=True)
    (mask_embed): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=1024, bias=True)
      (3): ReLU(inplace=True)
      (4): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (loss_cls): CrossEntropyLoss(avg_non_ignore=False)
    (loss_mask): CrossEntropyLoss(avg_non_ignore=False)
    (loss_dice): DiceLoss()
  )
)
2023-09-28 08:49:11,965 - mmseg - INFO - Loaded 2194 images
2023-09-28 08:49:14,767 - mmseg - INFO - Loaded 466 images
2023-09-28 08:49:14,769 - mmseg - INFO - load checkpoint from local path: /raid/hyundai/ViT-Adapter/segmentation/best_miou_iter_26000.pth
2023-09-28 08:49:20,747 - mmseg - INFO - Start running, host: sw_hdai@a100-n3, work_dir: /raid/hyundai/ViT-Adapter/segmentation/work_dirs/vit_13
2023-09-28 08:49:20,748 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-09-28 08:49:20,748 - mmseg - INFO - workflow: [('train', 1)], max: 40000 iters
2023-09-28 08:49:20,748 - mmseg - INFO - Checkpoints will be saved to /raid/hyundai/ViT-Adapter/segmentation/work_dirs/vit_13 by HardDiskBackend.
2023-09-28 08:51:41,496 - mmseg - INFO - Iter [50/40000]	lr: 4.685e-08, eta: 1 day, 1:58:45, time: 2.341, data_time: 0.041, memory: 21542, decode.loss_cls: 0.1292, decode.loss_mask: 0.5427, decode.loss_dice: 0.7598, decode.d0.loss_cls: 0.3548, decode.d0.loss_mask: 0.5431, decode.d0.loss_dice: 0.7893, decode.d1.loss_cls: 0.1509, decode.d1.loss_mask: 0.5356, decode.d1.loss_dice: 0.7786, decode.d2.loss_cls: 0.1503, decode.d2.loss_mask: 0.5362, decode.d2.loss_dice: 0.7688, decode.d3.loss_cls: 0.1512, decode.d3.loss_mask: 0.5343, decode.d3.loss_dice: 0.7788, decode.d4.loss_cls: 0.1413, decode.d4.loss_mask: 0.5341, decode.d4.loss_dice: 0.7599, decode.d5.loss_cls: 0.1542, decode.d5.loss_mask: 0.5338, decode.d5.loss_dice: 0.7701, decode.d6.loss_cls: 0.1141, decode.d6.loss_mask: 0.5317, decode.d6.loss_dice: 0.7835, decode.d7.loss_cls: 0.1533, decode.d7.loss_mask: 0.5339, decode.d7.loss_dice: 0.7685, decode.d8.loss_cls: 0.1570, decode.d8.loss_mask: 0.5339, decode.d8.loss_dice: 0.7608, loss: 14.7338
2023-09-28 08:53:37,078 - mmseg - INFO - Iter [100/40000]	lr: 9.453e-08, eta: 1 day, 1:47:10, time: 2.312, data_time: 0.028, memory: 21542, decode.loss_cls: 0.1326, decode.loss_mask: 0.4357, decode.loss_dice: 0.7231, decode.d0.loss_cls: 0.3382, decode.d0.loss_mask: 0.4649, decode.d0.loss_dice: 0.7667, decode.d1.loss_cls: 0.1566, decode.d1.loss_mask: 0.4394, decode.d1.loss_dice: 0.7409, decode.d2.loss_cls: 0.1479, decode.d2.loss_mask: 0.4361, decode.d2.loss_dice: 0.7324, decode.d3.loss_cls: 0.1364, decode.d3.loss_mask: 0.4378, decode.d3.loss_dice: 0.7309, decode.d4.loss_cls: 0.1322, decode.d4.loss_mask: 0.4401, decode.d4.loss_dice: 0.7263, decode.d5.loss_cls: 0.1517, decode.d5.loss_mask: 0.4417, decode.d5.loss_dice: 0.7354, decode.d6.loss_cls: 0.1410, decode.d6.loss_mask: 0.4416, decode.d6.loss_dice: 0.7273, decode.d7.loss_cls: 0.1354, decode.d7.loss_mask: 0.4421, decode.d7.loss_dice: 0.7412, decode.d8.loss_cls: 0.1337, decode.d8.loss_mask: 0.4381, decode.d8.loss_dice: 0.7300, loss: 13.3777
2023-09-28 08:55:32,442 - mmseg - INFO - Iter [150/40000]	lr: 1.421e-07, eta: 1 day, 1:41:00, time: 2.307, data_time: 0.035, memory: 21542, decode.loss_cls: 0.0897, decode.loss_mask: 0.4180, decode.loss_dice: 0.7128, decode.d0.loss_cls: 0.3016, decode.d0.loss_mask: 0.4508, decode.d0.loss_dice: 0.7304, decode.d1.loss_cls: 0.1097, decode.d1.loss_mask: 0.4220, decode.d1.loss_dice: 0.7289, decode.d2.loss_cls: 0.0890, decode.d2.loss_mask: 0.4159, decode.d2.loss_dice: 0.7227, decode.d3.loss_cls: 0.0839, decode.d3.loss_mask: 0.4150, decode.d3.loss_dice: 0.7159, decode.d4.loss_cls: 0.1086, decode.d4.loss_mask: 0.4162, decode.d4.loss_dice: 0.7171, decode.d5.loss_cls: 0.0990, decode.d5.loss_mask: 0.4167, decode.d5.loss_dice: 0.7155, decode.d6.loss_cls: 0.0974, decode.d6.loss_mask: 0.4188, decode.d6.loss_dice: 0.7235, decode.d7.loss_cls: 0.0990, decode.d7.loss_mask: 0.4145, decode.d7.loss_dice: 0.7226, decode.d8.loss_cls: 0.1019, decode.d8.loss_mask: 0.4154, decode.d8.loss_dice: 0.7129, loss: 12.5857
2023-09-28 08:57:28,337 - mmseg - INFO - Iter [200/40000]	lr: 1.895e-07, eta: 1 day, 1:38:41, time: 2.318, data_time: 0.029, memory: 21542, decode.loss_cls: 0.1279, decode.loss_mask: 0.3872, decode.loss_dice: 0.7165, decode.d0.loss_cls: 0.3257, decode.d0.loss_mask: 0.4273, decode.d0.loss_dice: 0.7289, decode.d1.loss_cls: 0.1411, decode.d1.loss_mask: 0.3914, decode.d1.loss_dice: 0.7181, decode.d2.loss_cls: 0.1340, decode.d2.loss_mask: 0.3861, decode.d2.loss_dice: 0.7208, decode.d3.loss_cls: 0.1270, decode.d3.loss_mask: 0.3882, decode.d3.loss_dice: 0.7197, decode.d4.loss_cls: 0.1150, decode.d4.loss_mask: 0.3903, decode.d4.loss_dice: 0.7273, decode.d5.loss_cls: 0.1258, decode.d5.loss_mask: 0.3908, decode.d5.loss_dice: 0.7331, decode.d6.loss_cls: 0.1245, decode.d6.loss_mask: 0.3909, decode.d6.loss_dice: 0.7335, decode.d7.loss_cls: 0.1165, decode.d7.loss_mask: 0.3878, decode.d7.loss_dice: 0.7277, decode.d8.loss_cls: 0.1270, decode.d8.loss_mask: 0.3865, decode.d8.loss_dice: 0.7247, loss: 12.6414
2023-09-28 08:59:24,242 - mmseg - INFO - Iter [250/40000]	lr: 2.369e-07, eta: 1 day, 1:36:33, time: 2.318, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0965, decode.loss_mask: 0.3646, decode.loss_dice: 0.6888, decode.d0.loss_cls: 0.2849, decode.d0.loss_mask: 0.4076, decode.d0.loss_dice: 0.7023, decode.d1.loss_cls: 0.1035, decode.d1.loss_mask: 0.3680, decode.d1.loss_dice: 0.6988, decode.d2.loss_cls: 0.1097, decode.d2.loss_mask: 0.3670, decode.d2.loss_dice: 0.7028, decode.d3.loss_cls: 0.0985, decode.d3.loss_mask: 0.3668, decode.d3.loss_dice: 0.6924, decode.d4.loss_cls: 0.1076, decode.d4.loss_mask: 0.3707, decode.d4.loss_dice: 0.6991, decode.d5.loss_cls: 0.0795, decode.d5.loss_mask: 0.3679, decode.d5.loss_dice: 0.7012, decode.d6.loss_cls: 0.0786, decode.d6.loss_mask: 0.3691, decode.d6.loss_dice: 0.7063, decode.d7.loss_cls: 0.0873, decode.d7.loss_mask: 0.3660, decode.d7.loss_dice: 0.7015, decode.d8.loss_cls: 0.0920, decode.d8.loss_mask: 0.3652, decode.d8.loss_dice: 0.6996, loss: 11.8441
2023-09-28 09:01:18,047 - mmseg - INFO - Iter [300/40000]	lr: 2.841e-07, eta: 1 day, 1:29:45, time: 2.275, data_time: 0.028, memory: 21542, decode.loss_cls: 0.1084, decode.loss_mask: 0.3705, decode.loss_dice: 0.6935, decode.d0.loss_cls: 0.2907, decode.d0.loss_mask: 0.4079, decode.d0.loss_dice: 0.6815, decode.d1.loss_cls: 0.1229, decode.d1.loss_mask: 0.3729, decode.d1.loss_dice: 0.6835, decode.d2.loss_cls: 0.1320, decode.d2.loss_mask: 0.3722, decode.d2.loss_dice: 0.6965, decode.d3.loss_cls: 0.1141, decode.d3.loss_mask: 0.3698, decode.d3.loss_dice: 0.6845, decode.d4.loss_cls: 0.1008, decode.d4.loss_mask: 0.3716, decode.d4.loss_dice: 0.6928, decode.d5.loss_cls: 0.1117, decode.d5.loss_mask: 0.3754, decode.d5.loss_dice: 0.6901, decode.d6.loss_cls: 0.1188, decode.d6.loss_mask: 0.3712, decode.d6.loss_dice: 0.6820, decode.d7.loss_cls: 0.1179, decode.d7.loss_mask: 0.3705, decode.d7.loss_dice: 0.6866, decode.d8.loss_cls: 0.1187, decode.d8.loss_mask: 0.3698, decode.d8.loss_dice: 0.6901, loss: 11.9691
2023-09-28 09:03:16,164 - mmseg - INFO - Iter [350/40000]	lr: 3.311e-07, eta: 1 day, 1:32:33, time: 2.362, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0932, decode.loss_mask: 0.3363, decode.loss_dice: 0.6697, decode.d0.loss_cls: 0.3026, decode.d0.loss_mask: 0.3725, decode.d0.loss_dice: 0.6622, decode.d1.loss_cls: 0.0963, decode.d1.loss_mask: 0.3442, decode.d1.loss_dice: 0.6810, decode.d2.loss_cls: 0.0822, decode.d2.loss_mask: 0.3424, decode.d2.loss_dice: 0.6729, decode.d3.loss_cls: 0.0872, decode.d3.loss_mask: 0.3416, decode.d3.loss_dice: 0.6855, decode.d4.loss_cls: 0.1085, decode.d4.loss_mask: 0.3393, decode.d4.loss_dice: 0.6782, decode.d5.loss_cls: 0.1101, decode.d5.loss_mask: 0.3411, decode.d5.loss_dice: 0.6711, decode.d6.loss_cls: 0.1309, decode.d6.loss_mask: 0.3375, decode.d6.loss_dice: 0.6657, decode.d7.loss_cls: 0.0959, decode.d7.loss_mask: 0.3384, decode.d7.loss_dice: 0.6612, decode.d8.loss_cls: 0.1007, decode.d8.loss_mask: 0.3379, decode.d8.loss_dice: 0.6646, loss: 11.3508
2023-09-28 09:05:12,727 - mmseg - INFO - Iter [400/40000]	lr: 3.781e-07, eta: 1 day, 1:31:43, time: 2.332, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0834, decode.loss_mask: 0.3461, decode.loss_dice: 0.7248, decode.d0.loss_cls: 0.2896, decode.d0.loss_mask: 0.3840, decode.d0.loss_dice: 0.7255, decode.d1.loss_cls: 0.0859, decode.d1.loss_mask: 0.3463, decode.d1.loss_dice: 0.7140, decode.d2.loss_cls: 0.0901, decode.d2.loss_mask: 0.3451, decode.d2.loss_dice: 0.7191, decode.d3.loss_cls: 0.0837, decode.d3.loss_mask: 0.3472, decode.d3.loss_dice: 0.7206, decode.d4.loss_cls: 0.0830, decode.d4.loss_mask: 0.3475, decode.d4.loss_dice: 0.7261, decode.d5.loss_cls: 0.0780, decode.d5.loss_mask: 0.3491, decode.d5.loss_dice: 0.7135, decode.d6.loss_cls: 0.0872, decode.d6.loss_mask: 0.3475, decode.d6.loss_dice: 0.7208, decode.d7.loss_cls: 0.0873, decode.d7.loss_mask: 0.3473, decode.d7.loss_dice: 0.7236, decode.d8.loss_cls: 0.0766, decode.d8.loss_mask: 0.3467, decode.d8.loss_dice: 0.7188, loss: 11.7582
2023-09-28 09:07:08,753 - mmseg - INFO - Iter [450/40000]	lr: 4.250e-07, eta: 1 day, 1:29:45, time: 2.320, data_time: 0.030, memory: 21542, decode.loss_cls: 0.1109, decode.loss_mask: 0.3235, decode.loss_dice: 0.6631, decode.d0.loss_cls: 0.3000, decode.d0.loss_mask: 0.3535, decode.d0.loss_dice: 0.6802, decode.d1.loss_cls: 0.1175, decode.d1.loss_mask: 0.3266, decode.d1.loss_dice: 0.6847, decode.d2.loss_cls: 0.1135, decode.d2.loss_mask: 0.3246, decode.d2.loss_dice: 0.6736, decode.d3.loss_cls: 0.1005, decode.d3.loss_mask: 0.3263, decode.d3.loss_dice: 0.6778, decode.d4.loss_cls: 0.0897, decode.d4.loss_mask: 0.3265, decode.d4.loss_dice: 0.6709, decode.d5.loss_cls: 0.0923, decode.d5.loss_mask: 0.3261, decode.d5.loss_dice: 0.6699, decode.d6.loss_cls: 0.0930, decode.d6.loss_mask: 0.3273, decode.d6.loss_dice: 0.6801, decode.d7.loss_cls: 0.0785, decode.d7.loss_mask: 0.3268, decode.d7.loss_dice: 0.6738, decode.d8.loss_cls: 0.1070, decode.d8.loss_mask: 0.3247, decode.d8.loss_dice: 0.6668, loss: 11.2298
2023-09-28 09:08:59,604 - mmseg - INFO - Iter [500/40000]	lr: 4.717e-07, eta: 1 day, 1:21:00, time: 2.217, data_time: 0.024, memory: 21542, decode.loss_cls: 0.0939, decode.loss_mask: 0.3685, decode.loss_dice: 0.6906, decode.d0.loss_cls: 0.2945, decode.d0.loss_mask: 0.4018, decode.d0.loss_dice: 0.6849, decode.d1.loss_cls: 0.0934, decode.d1.loss_mask: 0.3680, decode.d1.loss_dice: 0.6936, decode.d2.loss_cls: 0.1296, decode.d2.loss_mask: 0.3673, decode.d2.loss_dice: 0.6808, decode.d3.loss_cls: 0.0990, decode.d3.loss_mask: 0.3666, decode.d3.loss_dice: 0.6882, decode.d4.loss_cls: 0.1020, decode.d4.loss_mask: 0.3697, decode.d4.loss_dice: 0.6899, decode.d5.loss_cls: 0.0803, decode.d5.loss_mask: 0.3712, decode.d5.loss_dice: 0.6899, decode.d6.loss_cls: 0.0908, decode.d6.loss_mask: 0.3695, decode.d6.loss_dice: 0.6906, decode.d7.loss_cls: 0.0880, decode.d7.loss_mask: 0.3675, decode.d7.loss_dice: 0.6962, decode.d8.loss_cls: 0.0985, decode.d8.loss_mask: 0.3683, decode.d8.loss_dice: 0.6928, loss: 11.7857
2023-09-28 09:10:50,721 - mmseg - INFO - Iter [550/40000]	lr: 5.183e-07, eta: 1 day, 1:13:42, time: 2.220, data_time: 0.031, memory: 21542, decode.loss_cls: 0.1119, decode.loss_mask: 0.3417, decode.loss_dice: 0.6491, decode.d0.loss_cls: 0.3024, decode.d0.loss_mask: 0.3658, decode.d0.loss_dice: 0.6452, decode.d1.loss_cls: 0.1016, decode.d1.loss_mask: 0.3429, decode.d1.loss_dice: 0.6712, decode.d2.loss_cls: 0.1078, decode.d2.loss_mask: 0.3432, decode.d2.loss_dice: 0.6668, decode.d3.loss_cls: 0.1089, decode.d3.loss_mask: 0.3429, decode.d3.loss_dice: 0.6559, decode.d4.loss_cls: 0.1183, decode.d4.loss_mask: 0.3400, decode.d4.loss_dice: 0.6603, decode.d5.loss_cls: 0.1147, decode.d5.loss_mask: 0.3399, decode.d5.loss_dice: 0.6552, decode.d6.loss_cls: 0.1066, decode.d6.loss_mask: 0.3420, decode.d6.loss_dice: 0.6751, decode.d7.loss_cls: 0.1198, decode.d7.loss_mask: 0.3426, decode.d7.loss_dice: 0.6609, decode.d8.loss_cls: 0.1065, decode.d8.loss_mask: 0.3413, decode.d8.loss_dice: 0.6580, loss: 11.3383
2023-09-28 09:12:40,794 - mmseg - INFO - Iter [600/40000]	lr: 5.648e-07, eta: 1 day, 1:06:22, time: 2.203, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0695, decode.loss_mask: 0.3679, decode.loss_dice: 0.6804, decode.d0.loss_cls: 0.3056, decode.d0.loss_mask: 0.3852, decode.d0.loss_dice: 0.6852, decode.d1.loss_cls: 0.0763, decode.d1.loss_mask: 0.3680, decode.d1.loss_dice: 0.7031, decode.d2.loss_cls: 0.0905, decode.d2.loss_mask: 0.3674, decode.d2.loss_dice: 0.6892, decode.d3.loss_cls: 0.0913, decode.d3.loss_mask: 0.3625, decode.d3.loss_dice: 0.6851, decode.d4.loss_cls: 0.0706, decode.d4.loss_mask: 0.3730, decode.d4.loss_dice: 0.6790, decode.d5.loss_cls: 0.0938, decode.d5.loss_mask: 0.3724, decode.d5.loss_dice: 0.6797, decode.d6.loss_cls: 0.0848, decode.d6.loss_mask: 0.3712, decode.d6.loss_dice: 0.6815, decode.d7.loss_cls: 0.0899, decode.d7.loss_mask: 0.3691, decode.d7.loss_dice: 0.6813, decode.d8.loss_cls: 0.0783, decode.d8.loss_mask: 0.3664, decode.d8.loss_dice: 0.6873, loss: 11.6054
2023-09-28 09:14:31,495 - mmseg - INFO - Iter [650/40000]	lr: 6.111e-07, eta: 1 day, 1:00:25, time: 2.214, data_time: 0.031, memory: 21542, decode.loss_cls: 0.1310, decode.loss_mask: 0.3571, decode.loss_dice: 0.6945, decode.d0.loss_cls: 0.3091, decode.d0.loss_mask: 0.3853, decode.d0.loss_dice: 0.6947, decode.d1.loss_cls: 0.1288, decode.d1.loss_mask: 0.3633, decode.d1.loss_dice: 0.7054, decode.d2.loss_cls: 0.1227, decode.d2.loss_mask: 0.3571, decode.d2.loss_dice: 0.7020, decode.d3.loss_cls: 0.1166, decode.d3.loss_mask: 0.3553, decode.d3.loss_dice: 0.6928, decode.d4.loss_cls: 0.1280, decode.d4.loss_mask: 0.3554, decode.d4.loss_dice: 0.6899, decode.d5.loss_cls: 0.1100, decode.d5.loss_mask: 0.3565, decode.d5.loss_dice: 0.7059, decode.d6.loss_cls: 0.1177, decode.d6.loss_mask: 0.3587, decode.d6.loss_dice: 0.7090, decode.d7.loss_cls: 0.1229, decode.d7.loss_mask: 0.3566, decode.d7.loss_dice: 0.7041, decode.d8.loss_cls: 0.1179, decode.d8.loss_mask: 0.3632, decode.d8.loss_dice: 0.6942, loss: 12.0056
2023-09-28 09:16:21,444 - mmseg - INFO - Iter [700/40000]	lr: 6.574e-07, eta: 1 day, 0:54:21, time: 2.199, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0985, decode.loss_mask: 0.2974, decode.loss_dice: 0.6292, decode.d0.loss_cls: 0.2748, decode.d0.loss_mask: 0.3179, decode.d0.loss_dice: 0.6468, decode.d1.loss_cls: 0.0879, decode.d1.loss_mask: 0.2970, decode.d1.loss_dice: 0.6419, decode.d2.loss_cls: 0.1065, decode.d2.loss_mask: 0.2978, decode.d2.loss_dice: 0.6373, decode.d3.loss_cls: 0.1021, decode.d3.loss_mask: 0.2984, decode.d3.loss_dice: 0.6389, decode.d4.loss_cls: 0.1015, decode.d4.loss_mask: 0.2978, decode.d4.loss_dice: 0.6442, decode.d5.loss_cls: 0.0946, decode.d5.loss_mask: 0.2992, decode.d5.loss_dice: 0.6428, decode.d6.loss_cls: 0.0890, decode.d6.loss_mask: 0.2981, decode.d6.loss_dice: 0.6441, decode.d7.loss_cls: 0.0924, decode.d7.loss_mask: 0.2987, decode.d7.loss_dice: 0.6383, decode.d8.loss_cls: 0.0829, decode.d8.loss_mask: 0.3004, decode.d8.loss_dice: 0.6442, loss: 10.5407
2023-09-28 09:18:11,267 - mmseg - INFO - Iter [750/40000]	lr: 7.035e-07, eta: 1 day, 0:48:44, time: 2.196, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0795, decode.loss_mask: 0.3389, decode.loss_dice: 0.6397, decode.d0.loss_cls: 0.2994, decode.d0.loss_mask: 0.3563, decode.d0.loss_dice: 0.6550, decode.d1.loss_cls: 0.1213, decode.d1.loss_mask: 0.3375, decode.d1.loss_dice: 0.6521, decode.d2.loss_cls: 0.0983, decode.d2.loss_mask: 0.3393, decode.d2.loss_dice: 0.6632, decode.d3.loss_cls: 0.0969, decode.d3.loss_mask: 0.3436, decode.d3.loss_dice: 0.6419, decode.d4.loss_cls: 0.0879, decode.d4.loss_mask: 0.3415, decode.d4.loss_dice: 0.6442, decode.d5.loss_cls: 0.0839, decode.d5.loss_mask: 0.3377, decode.d5.loss_dice: 0.6538, decode.d6.loss_cls: 0.0803, decode.d6.loss_mask: 0.3406, decode.d6.loss_dice: 0.6516, decode.d7.loss_cls: 0.0740, decode.d7.loss_mask: 0.3388, decode.d7.loss_dice: 0.6461, decode.d8.loss_cls: 0.0915, decode.d8.loss_mask: 0.3385, decode.d8.loss_dice: 0.6310, loss: 11.0042
2023-09-28 09:20:01,128 - mmseg - INFO - Iter [800/40000]	lr: 7.495e-07, eta: 1 day, 0:43:38, time: 2.197, data_time: 0.036, memory: 21542, decode.loss_cls: 0.0832, decode.loss_mask: 0.3185, decode.loss_dice: 0.6308, decode.d0.loss_cls: 0.3188, decode.d0.loss_mask: 0.3322, decode.d0.loss_dice: 0.6500, decode.d1.loss_cls: 0.0973, decode.d1.loss_mask: 0.3203, decode.d1.loss_dice: 0.6406, decode.d2.loss_cls: 0.0810, decode.d2.loss_mask: 0.3173, decode.d2.loss_dice: 0.6283, decode.d3.loss_cls: 0.1030, decode.d3.loss_mask: 0.3184, decode.d3.loss_dice: 0.6370, decode.d4.loss_cls: 0.0910, decode.d4.loss_mask: 0.3180, decode.d4.loss_dice: 0.6302, decode.d5.loss_cls: 0.0828, decode.d5.loss_mask: 0.3185, decode.d5.loss_dice: 0.6371, decode.d6.loss_cls: 0.0801, decode.d6.loss_mask: 0.3197, decode.d6.loss_dice: 0.6357, decode.d7.loss_cls: 0.0868, decode.d7.loss_mask: 0.3176, decode.d7.loss_dice: 0.6308, decode.d8.loss_cls: 0.0833, decode.d8.loss_mask: 0.3185, decode.d8.loss_dice: 0.6343, loss: 10.6612
2023-09-28 09:21:51,242 - mmseg - INFO - Iter [850/40000]	lr: 7.954e-07, eta: 1 day, 0:39:07, time: 2.202, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0809, decode.loss_mask: 0.3261, decode.loss_dice: 0.6689, decode.d0.loss_cls: 0.3228, decode.d0.loss_mask: 0.3406, decode.d0.loss_dice: 0.6694, decode.d1.loss_cls: 0.1081, decode.d1.loss_mask: 0.3192, decode.d1.loss_dice: 0.6617, decode.d2.loss_cls: 0.1253, decode.d2.loss_mask: 0.3179, decode.d2.loss_dice: 0.6587, decode.d3.loss_cls: 0.0894, decode.d3.loss_mask: 0.3192, decode.d3.loss_dice: 0.6541, decode.d4.loss_cls: 0.0888, decode.d4.loss_mask: 0.3206, decode.d4.loss_dice: 0.6481, decode.d5.loss_cls: 0.1014, decode.d5.loss_mask: 0.3238, decode.d5.loss_dice: 0.6516, decode.d6.loss_cls: 0.0952, decode.d6.loss_mask: 0.3256, decode.d6.loss_dice: 0.6656, decode.d7.loss_cls: 0.0876, decode.d7.loss_mask: 0.3254, decode.d7.loss_dice: 0.6620, decode.d8.loss_cls: 0.0937, decode.d8.loss_mask: 0.3255, decode.d8.loss_dice: 0.6658, loss: 11.0429
2023-09-28 09:23:41,678 - mmseg - INFO - Iter [900/40000]	lr: 8.412e-07, eta: 1 day, 0:35:06, time: 2.208, data_time: 0.033, memory: 21542, decode.loss_cls: 0.1144, decode.loss_mask: 0.3652, decode.loss_dice: 0.7212, decode.d0.loss_cls: 0.3249, decode.d0.loss_mask: 0.3845, decode.d0.loss_dice: 0.7266, decode.d1.loss_cls: 0.1206, decode.d1.loss_mask: 0.3650, decode.d1.loss_dice: 0.7365, decode.d2.loss_cls: 0.1147, decode.d2.loss_mask: 0.3636, decode.d2.loss_dice: 0.7297, decode.d3.loss_cls: 0.1066, decode.d3.loss_mask: 0.3686, decode.d3.loss_dice: 0.7244, decode.d4.loss_cls: 0.1358, decode.d4.loss_mask: 0.3683, decode.d4.loss_dice: 0.7353, decode.d5.loss_cls: 0.1165, decode.d5.loss_mask: 0.3698, decode.d5.loss_dice: 0.7268, decode.d6.loss_cls: 0.1104, decode.d6.loss_mask: 0.3673, decode.d6.loss_dice: 0.7413, decode.d7.loss_cls: 0.1284, decode.d7.loss_mask: 0.3671, decode.d7.loss_dice: 0.7338, decode.d8.loss_cls: 0.1063, decode.d8.loss_mask: 0.3675, decode.d8.loss_dice: 0.7286, loss: 12.3696
2023-09-28 09:25:32,099 - mmseg - INFO - Iter [950/40000]	lr: 8.868e-07, eta: 1 day, 0:31:20, time: 2.209, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0980, decode.loss_mask: 0.3392, decode.loss_dice: 0.6740, decode.d0.loss_cls: 0.3107, decode.d0.loss_mask: 0.3461, decode.d0.loss_dice: 0.6956, decode.d1.loss_cls: 0.0999, decode.d1.loss_mask: 0.3374, decode.d1.loss_dice: 0.6890, decode.d2.loss_cls: 0.1146, decode.d2.loss_mask: 0.3370, decode.d2.loss_dice: 0.6897, decode.d3.loss_cls: 0.1146, decode.d3.loss_mask: 0.3382, decode.d3.loss_dice: 0.6831, decode.d4.loss_cls: 0.1229, decode.d4.loss_mask: 0.3381, decode.d4.loss_dice: 0.6883, decode.d5.loss_cls: 0.1208, decode.d5.loss_mask: 0.3368, decode.d5.loss_dice: 0.6846, decode.d6.loss_cls: 0.1014, decode.d6.loss_mask: 0.3375, decode.d6.loss_dice: 0.6857, decode.d7.loss_cls: 0.1147, decode.d7.loss_mask: 0.3363, decode.d7.loss_dice: 0.6803, decode.d8.loss_cls: 0.0925, decode.d8.loss_mask: 0.3377, decode.d8.loss_dice: 0.6882, loss: 11.5329
2023-09-28 09:27:22,728 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 09:27:22,728 - mmseg - INFO - Iter [1000/40000]	lr: 9.324e-07, eta: 1 day, 0:27:53, time: 2.213, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0432, decode.loss_mask: 0.2971, decode.loss_dice: 0.6153, decode.d0.loss_cls: 0.2763, decode.d0.loss_mask: 0.3056, decode.d0.loss_dice: 0.6204, decode.d1.loss_cls: 0.0433, decode.d1.loss_mask: 0.2982, decode.d1.loss_dice: 0.6154, decode.d2.loss_cls: 0.0608, decode.d2.loss_mask: 0.2992, decode.d2.loss_dice: 0.6160, decode.d3.loss_cls: 0.0468, decode.d3.loss_mask: 0.2987, decode.d3.loss_dice: 0.6197, decode.d4.loss_cls: 0.0618, decode.d4.loss_mask: 0.2968, decode.d4.loss_dice: 0.6156, decode.d5.loss_cls: 0.0491, decode.d5.loss_mask: 0.2986, decode.d5.loss_dice: 0.6176, decode.d6.loss_cls: 0.0622, decode.d6.loss_mask: 0.3000, decode.d6.loss_dice: 0.6315, decode.d7.loss_cls: 0.0610, decode.d7.loss_mask: 0.3001, decode.d7.loss_dice: 0.6146, decode.d8.loss_cls: 0.0776, decode.d8.loss_mask: 0.2974, decode.d8.loss_dice: 0.6155, loss: 9.9555
2023-09-28 09:29:13,299 - mmseg - INFO - Iter [1050/40000]	lr: 9.778e-07, eta: 1 day, 0:24:33, time: 2.211, data_time: 0.034, memory: 21542, decode.loss_cls: 0.1307, decode.loss_mask: 0.3247, decode.loss_dice: 0.6036, decode.d0.loss_cls: 0.3169, decode.d0.loss_mask: 0.3434, decode.d0.loss_dice: 0.6237, decode.d1.loss_cls: 0.1357, decode.d1.loss_mask: 0.3283, decode.d1.loss_dice: 0.6202, decode.d2.loss_cls: 0.1467, decode.d2.loss_mask: 0.3256, decode.d2.loss_dice: 0.6019, decode.d3.loss_cls: 0.1284, decode.d3.loss_mask: 0.3254, decode.d3.loss_dice: 0.6150, decode.d4.loss_cls: 0.1377, decode.d4.loss_mask: 0.3286, decode.d4.loss_dice: 0.6170, decode.d5.loss_cls: 0.1398, decode.d5.loss_mask: 0.3296, decode.d5.loss_dice: 0.6061, decode.d6.loss_cls: 0.1326, decode.d6.loss_mask: 0.3310, decode.d6.loss_dice: 0.6189, decode.d7.loss_cls: 0.1210, decode.d7.loss_mask: 0.3301, decode.d7.loss_dice: 0.6066, decode.d8.loss_cls: 0.1391, decode.d8.loss_mask: 0.3245, decode.d8.loss_dice: 0.6056, loss: 10.9386
2023-09-28 09:31:06,426 - mmseg - INFO - Iter [1100/40000]	lr: 1.023e-06, eta: 1 day, 0:22:52, time: 2.263, data_time: 0.074, memory: 21542, decode.loss_cls: 0.0801, decode.loss_mask: 0.3180, decode.loss_dice: 0.6303, decode.d0.loss_cls: 0.2806, decode.d0.loss_mask: 0.3349, decode.d0.loss_dice: 0.6460, decode.d1.loss_cls: 0.1000, decode.d1.loss_mask: 0.3171, decode.d1.loss_dice: 0.6198, decode.d2.loss_cls: 0.0829, decode.d2.loss_mask: 0.3216, decode.d2.loss_dice: 0.6293, decode.d3.loss_cls: 0.0742, decode.d3.loss_mask: 0.3197, decode.d3.loss_dice: 0.6318, decode.d4.loss_cls: 0.0696, decode.d4.loss_mask: 0.3221, decode.d4.loss_dice: 0.6228, decode.d5.loss_cls: 0.0664, decode.d5.loss_mask: 0.3207, decode.d5.loss_dice: 0.6205, decode.d6.loss_cls: 0.0811, decode.d6.loss_mask: 0.3183, decode.d6.loss_dice: 0.6443, decode.d7.loss_cls: 0.1005, decode.d7.loss_mask: 0.3164, decode.d7.loss_dice: 0.6288, decode.d8.loss_cls: 0.0917, decode.d8.loss_mask: 0.3176, decode.d8.loss_dice: 0.6308, loss: 10.5380
2023-09-28 09:32:56,689 - mmseg - INFO - Iter [1150/40000]	lr: 1.068e-06, eta: 1 day, 0:19:32, time: 2.205, data_time: 0.029, memory: 21542, decode.loss_cls: 0.1145, decode.loss_mask: 0.3420, decode.loss_dice: 0.6662, decode.d0.loss_cls: 0.3051, decode.d0.loss_mask: 0.3569, decode.d0.loss_dice: 0.6716, decode.d1.loss_cls: 0.1168, decode.d1.loss_mask: 0.3438, decode.d1.loss_dice: 0.6771, decode.d2.loss_cls: 0.1153, decode.d2.loss_mask: 0.3455, decode.d2.loss_dice: 0.6747, decode.d3.loss_cls: 0.0909, decode.d3.loss_mask: 0.3438, decode.d3.loss_dice: 0.6531, decode.d4.loss_cls: 0.1214, decode.d4.loss_mask: 0.3474, decode.d4.loss_dice: 0.6624, decode.d5.loss_cls: 0.1182, decode.d5.loss_mask: 0.3471, decode.d5.loss_dice: 0.6600, decode.d6.loss_cls: 0.1042, decode.d6.loss_mask: 0.3434, decode.d6.loss_dice: 0.6741, decode.d7.loss_cls: 0.0994, decode.d7.loss_mask: 0.3453, decode.d7.loss_dice: 0.6506, decode.d8.loss_cls: 0.1032, decode.d8.loss_mask: 0.3417, decode.d8.loss_dice: 0.6661, loss: 11.4018
2023-09-28 09:34:47,781 - mmseg - INFO - Iter [1200/40000]	lr: 1.113e-06, eta: 1 day, 0:16:47, time: 2.222, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0935, decode.loss_mask: 0.3017, decode.loss_dice: 0.6199, decode.d0.loss_cls: 0.3363, decode.d0.loss_mask: 0.3174, decode.d0.loss_dice: 0.6306, decode.d1.loss_cls: 0.1060, decode.d1.loss_mask: 0.3058, decode.d1.loss_dice: 0.6362, decode.d2.loss_cls: 0.0881, decode.d2.loss_mask: 0.3007, decode.d2.loss_dice: 0.6230, decode.d3.loss_cls: 0.0844, decode.d3.loss_mask: 0.3016, decode.d3.loss_dice: 0.6278, decode.d4.loss_cls: 0.0769, decode.d4.loss_mask: 0.3018, decode.d4.loss_dice: 0.6275, decode.d5.loss_cls: 0.0915, decode.d5.loss_mask: 0.3015, decode.d5.loss_dice: 0.6256, decode.d6.loss_cls: 0.1030, decode.d6.loss_mask: 0.2987, decode.d6.loss_dice: 0.6364, decode.d7.loss_cls: 0.0937, decode.d7.loss_mask: 0.3004, decode.d7.loss_dice: 0.6257, decode.d8.loss_cls: 0.1141, decode.d8.loss_mask: 0.3024, decode.d8.loss_dice: 0.6281, loss: 10.5002
2023-09-28 09:36:37,601 - mmseg - INFO - Iter [1250/40000]	lr: 1.158e-06, eta: 1 day, 0:13:28, time: 2.197, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0998, decode.loss_mask: 0.3392, decode.loss_dice: 0.6562, decode.d0.loss_cls: 0.3302, decode.d0.loss_mask: 0.3502, decode.d0.loss_dice: 0.6516, decode.d1.loss_cls: 0.1162, decode.d1.loss_mask: 0.3376, decode.d1.loss_dice: 0.6445, decode.d2.loss_cls: 0.1123, decode.d2.loss_mask: 0.3353, decode.d2.loss_dice: 0.6420, decode.d3.loss_cls: 0.0973, decode.d3.loss_mask: 0.3384, decode.d3.loss_dice: 0.6465, decode.d4.loss_cls: 0.0908, decode.d4.loss_mask: 0.3382, decode.d4.loss_dice: 0.6475, decode.d5.loss_cls: 0.1091, decode.d5.loss_mask: 0.3398, decode.d5.loss_dice: 0.6577, decode.d6.loss_cls: 0.0994, decode.d6.loss_mask: 0.3375, decode.d6.loss_dice: 0.6497, decode.d7.loss_cls: 0.1022, decode.d7.loss_mask: 0.3421, decode.d7.loss_dice: 0.6439, decode.d8.loss_cls: 0.0995, decode.d8.loss_mask: 0.3378, decode.d8.loss_dice: 0.6508, loss: 11.1436
2023-09-28 09:38:28,313 - mmseg - INFO - Iter [1300/40000]	lr: 1.203e-06, eta: 1 day, 0:10:41, time: 2.214, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0841, decode.loss_mask: 0.3629, decode.loss_dice: 0.7001, decode.d0.loss_cls: 0.2892, decode.d0.loss_mask: 0.3842, decode.d0.loss_dice: 0.6779, decode.d1.loss_cls: 0.1040, decode.d1.loss_mask: 0.3655, decode.d1.loss_dice: 0.6895, decode.d2.loss_cls: 0.1046, decode.d2.loss_mask: 0.3632, decode.d2.loss_dice: 0.6928, decode.d3.loss_cls: 0.0856, decode.d3.loss_mask: 0.3642, decode.d3.loss_dice: 0.6856, decode.d4.loss_cls: 0.0923, decode.d4.loss_mask: 0.3642, decode.d4.loss_dice: 0.7006, decode.d5.loss_cls: 0.0820, decode.d5.loss_mask: 0.3660, decode.d5.loss_dice: 0.6971, decode.d6.loss_cls: 0.0990, decode.d6.loss_mask: 0.3652, decode.d6.loss_dice: 0.6892, decode.d7.loss_cls: 0.0898, decode.d7.loss_mask: 0.3648, decode.d7.loss_dice: 0.6918, decode.d8.loss_cls: 0.1046, decode.d8.loss_mask: 0.3637, decode.d8.loss_dice: 0.6917, loss: 11.7152
2023-09-28 09:40:17,998 - mmseg - INFO - Iter [1350/40000]	lr: 1.248e-06, eta: 1 day, 0:07:29, time: 2.194, data_time: 0.033, memory: 21542, decode.loss_cls: 0.1345, decode.loss_mask: 0.3384, decode.loss_dice: 0.6799, decode.d0.loss_cls: 0.3517, decode.d0.loss_mask: 0.3472, decode.d0.loss_dice: 0.6739, decode.d1.loss_cls: 0.1610, decode.d1.loss_mask: 0.3360, decode.d1.loss_dice: 0.6803, decode.d2.loss_cls: 0.1233, decode.d2.loss_mask: 0.3372, decode.d2.loss_dice: 0.6813, decode.d3.loss_cls: 0.1411, decode.d3.loss_mask: 0.3404, decode.d3.loss_dice: 0.6736, decode.d4.loss_cls: 0.1357, decode.d4.loss_mask: 0.3400, decode.d4.loss_dice: 0.6728, decode.d5.loss_cls: 0.1500, decode.d5.loss_mask: 0.3406, decode.d5.loss_dice: 0.6797, decode.d6.loss_cls: 0.1497, decode.d6.loss_mask: 0.3437, decode.d6.loss_dice: 0.6797, decode.d7.loss_cls: 0.1445, decode.d7.loss_mask: 0.3424, decode.d7.loss_dice: 0.6729, decode.d8.loss_cls: 0.1407, decode.d8.loss_mask: 0.3423, decode.d8.loss_dice: 0.6802, loss: 11.8147
2023-09-28 09:42:09,052 - mmseg - INFO - Iter [1400/40000]	lr: 1.292e-06, eta: 1 day, 0:05:01, time: 2.221, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0757, decode.loss_mask: 0.3202, decode.loss_dice: 0.6854, decode.d0.loss_cls: 0.3028, decode.d0.loss_mask: 0.3278, decode.d0.loss_dice: 0.6873, decode.d1.loss_cls: 0.0880, decode.d1.loss_mask: 0.3209, decode.d1.loss_dice: 0.7033, decode.d2.loss_cls: 0.0827, decode.d2.loss_mask: 0.3223, decode.d2.loss_dice: 0.6993, decode.d3.loss_cls: 0.0749, decode.d3.loss_mask: 0.3210, decode.d3.loss_dice: 0.6992, decode.d4.loss_cls: 0.0765, decode.d4.loss_mask: 0.3215, decode.d4.loss_dice: 0.6881, decode.d5.loss_cls: 0.0751, decode.d5.loss_mask: 0.3204, decode.d5.loss_dice: 0.6951, decode.d6.loss_cls: 0.0828, decode.d6.loss_mask: 0.3222, decode.d6.loss_dice: 0.6928, decode.d7.loss_cls: 0.0796, decode.d7.loss_mask: 0.3207, decode.d7.loss_dice: 0.6863, decode.d8.loss_cls: 0.0829, decode.d8.loss_mask: 0.3204, decode.d8.loss_dice: 0.6942, loss: 11.1694
2023-09-28 09:44:00,279 - mmseg - INFO - Iter [1450/40000]	lr: 1.337e-06, eta: 1 day, 0:02:40, time: 2.225, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0746, decode.loss_mask: 0.3185, decode.loss_dice: 0.6205, decode.d0.loss_cls: 0.2655, decode.d0.loss_mask: 0.3300, decode.d0.loss_dice: 0.6275, decode.d1.loss_cls: 0.0958, decode.d1.loss_mask: 0.3233, decode.d1.loss_dice: 0.6238, decode.d2.loss_cls: 0.0610, decode.d2.loss_mask: 0.3212, decode.d2.loss_dice: 0.6277, decode.d3.loss_cls: 0.0658, decode.d3.loss_mask: 0.3215, decode.d3.loss_dice: 0.6175, decode.d4.loss_cls: 0.0732, decode.d4.loss_mask: 0.3192, decode.d4.loss_dice: 0.6213, decode.d5.loss_cls: 0.0562, decode.d5.loss_mask: 0.3201, decode.d5.loss_dice: 0.6313, decode.d6.loss_cls: 0.0650, decode.d6.loss_mask: 0.3211, decode.d6.loss_dice: 0.6260, decode.d7.loss_cls: 0.0449, decode.d7.loss_mask: 0.3196, decode.d7.loss_dice: 0.6196, decode.d8.loss_cls: 0.0537, decode.d8.loss_mask: 0.3208, decode.d8.loss_dice: 0.6231, loss: 10.3100
2023-09-28 09:45:50,253 - mmseg - INFO - Iter [1500/40000]	lr: 1.381e-06, eta: 23:59:49, time: 2.199, data_time: 0.035, memory: 21542, decode.loss_cls: 0.1148, decode.loss_mask: 0.3093, decode.loss_dice: 0.6850, decode.d0.loss_cls: 0.2880, decode.d0.loss_mask: 0.3109, decode.d0.loss_dice: 0.7017, decode.d1.loss_cls: 0.1335, decode.d1.loss_mask: 0.3070, decode.d1.loss_dice: 0.6884, decode.d2.loss_cls: 0.1012, decode.d2.loss_mask: 0.3059, decode.d2.loss_dice: 0.6873, decode.d3.loss_cls: 0.1214, decode.d3.loss_mask: 0.3082, decode.d3.loss_dice: 0.6927, decode.d4.loss_cls: 0.1394, decode.d4.loss_mask: 0.3093, decode.d4.loss_dice: 0.6946, decode.d5.loss_cls: 0.1222, decode.d5.loss_mask: 0.3087, decode.d5.loss_dice: 0.6922, decode.d6.loss_cls: 0.1083, decode.d6.loss_mask: 0.3095, decode.d6.loss_dice: 0.6883, decode.d7.loss_cls: 0.1297, decode.d7.loss_mask: 0.3077, decode.d7.loss_dice: 0.6863, decode.d8.loss_cls: 0.1237, decode.d8.loss_mask: 0.3073, decode.d8.loss_dice: 0.6887, loss: 11.3710
2023-09-28 09:47:40,749 - mmseg - INFO - Iter [1550/40000]	lr: 1.380e-06, eta: 23:57:14, time: 2.209, data_time: 0.027, memory: 21542, decode.loss_cls: 0.1100, decode.loss_mask: 0.3505, decode.loss_dice: 0.6952, decode.d0.loss_cls: 0.2752, decode.d0.loss_mask: 0.3557, decode.d0.loss_dice: 0.7043, decode.d1.loss_cls: 0.1262, decode.d1.loss_mask: 0.3449, decode.d1.loss_dice: 0.6983, decode.d2.loss_cls: 0.1170, decode.d2.loss_mask: 0.3451, decode.d2.loss_dice: 0.6934, decode.d3.loss_cls: 0.1267, decode.d3.loss_mask: 0.3477, decode.d3.loss_dice: 0.6799, decode.d4.loss_cls: 0.1265, decode.d4.loss_mask: 0.3467, decode.d4.loss_dice: 0.6904, decode.d5.loss_cls: 0.1112, decode.d5.loss_mask: 0.3461, decode.d5.loss_dice: 0.6839, decode.d6.loss_cls: 0.1049, decode.d6.loss_mask: 0.3478, decode.d6.loss_dice: 0.6876, decode.d7.loss_cls: 0.1146, decode.d7.loss_mask: 0.3476, decode.d7.loss_dice: 0.6829, decode.d8.loss_cls: 0.0993, decode.d8.loss_mask: 0.3439, decode.d8.loss_dice: 0.6841, loss: 11.6877
2023-09-28 09:49:31,813 - mmseg - INFO - Iter [1600/40000]	lr: 1.378e-06, eta: 23:54:57, time: 2.222, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0926, decode.loss_mask: 0.3287, decode.loss_dice: 0.6606, decode.d0.loss_cls: 0.2796, decode.d0.loss_mask: 0.3409, decode.d0.loss_dice: 0.6832, decode.d1.loss_cls: 0.0992, decode.d1.loss_mask: 0.3331, decode.d1.loss_dice: 0.6704, decode.d2.loss_cls: 0.0988, decode.d2.loss_mask: 0.3330, decode.d2.loss_dice: 0.6694, decode.d3.loss_cls: 0.1143, decode.d3.loss_mask: 0.3328, decode.d3.loss_dice: 0.6670, decode.d4.loss_cls: 0.1244, decode.d4.loss_mask: 0.3305, decode.d4.loss_dice: 0.6621, decode.d5.loss_cls: 0.1020, decode.d5.loss_mask: 0.3320, decode.d5.loss_dice: 0.6472, decode.d6.loss_cls: 0.0865, decode.d6.loss_mask: 0.3329, decode.d6.loss_dice: 0.6693, decode.d7.loss_cls: 0.1096, decode.d7.loss_mask: 0.3308, decode.d7.loss_dice: 0.6437, decode.d8.loss_cls: 0.1133, decode.d8.loss_mask: 0.3311, decode.d8.loss_dice: 0.6652, loss: 11.1840
2023-09-28 09:51:20,988 - mmseg - INFO - Iter [1650/40000]	lr: 1.377e-06, eta: 23:51:56, time: 2.183, data_time: 0.034, memory: 21542, decode.loss_cls: 0.1205, decode.loss_mask: 0.3068, decode.loss_dice: 0.6808, decode.d0.loss_cls: 0.3128, decode.d0.loss_mask: 0.3136, decode.d0.loss_dice: 0.6799, decode.d1.loss_cls: 0.1466, decode.d1.loss_mask: 0.3050, decode.d1.loss_dice: 0.6840, decode.d2.loss_cls: 0.1317, decode.d2.loss_mask: 0.3104, decode.d2.loss_dice: 0.6950, decode.d3.loss_cls: 0.1257, decode.d3.loss_mask: 0.3101, decode.d3.loss_dice: 0.6810, decode.d4.loss_cls: 0.1307, decode.d4.loss_mask: 0.3112, decode.d4.loss_dice: 0.6802, decode.d5.loss_cls: 0.1315, decode.d5.loss_mask: 0.3070, decode.d5.loss_dice: 0.6818, decode.d6.loss_cls: 0.1119, decode.d6.loss_mask: 0.3091, decode.d6.loss_dice: 0.6782, decode.d7.loss_cls: 0.1550, decode.d7.loss_mask: 0.3062, decode.d7.loss_dice: 0.6627, decode.d8.loss_cls: 0.1252, decode.d8.loss_mask: 0.3064, decode.d8.loss_dice: 0.6930, loss: 11.3942
2023-09-28 09:53:11,373 - mmseg - INFO - Iter [1700/40000]	lr: 1.375e-06, eta: 23:49:27, time: 2.208, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0633, decode.loss_mask: 0.3357, decode.loss_dice: 0.6788, decode.d0.loss_cls: 0.2612, decode.d0.loss_mask: 0.3518, decode.d0.loss_dice: 0.6850, decode.d1.loss_cls: 0.0852, decode.d1.loss_mask: 0.3386, decode.d1.loss_dice: 0.6831, decode.d2.loss_cls: 0.0821, decode.d2.loss_mask: 0.3370, decode.d2.loss_dice: 0.6763, decode.d3.loss_cls: 0.0749, decode.d3.loss_mask: 0.3357, decode.d3.loss_dice: 0.6724, decode.d4.loss_cls: 0.0751, decode.d4.loss_mask: 0.3389, decode.d4.loss_dice: 0.6788, decode.d5.loss_cls: 0.0621, decode.d5.loss_mask: 0.3408, decode.d5.loss_dice: 0.6865, decode.d6.loss_cls: 0.0671, decode.d6.loss_mask: 0.3368, decode.d6.loss_dice: 0.6869, decode.d7.loss_cls: 0.0767, decode.d7.loss_mask: 0.3390, decode.d7.loss_dice: 0.6713, decode.d8.loss_cls: 0.0679, decode.d8.loss_mask: 0.3366, decode.d8.loss_dice: 0.6885, loss: 11.1141
2023-09-28 09:55:01,922 - mmseg - INFO - Iter [1750/40000]	lr: 1.373e-06, eta: 23:47:04, time: 2.211, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0909, decode.loss_mask: 0.2988, decode.loss_dice: 0.6789, decode.d0.loss_cls: 0.2871, decode.d0.loss_mask: 0.3054, decode.d0.loss_dice: 0.6929, decode.d1.loss_cls: 0.1175, decode.d1.loss_mask: 0.2983, decode.d1.loss_dice: 0.6820, decode.d2.loss_cls: 0.1014, decode.d2.loss_mask: 0.2994, decode.d2.loss_dice: 0.6767, decode.d3.loss_cls: 0.0981, decode.d3.loss_mask: 0.2956, decode.d3.loss_dice: 0.6760, decode.d4.loss_cls: 0.0991, decode.d4.loss_mask: 0.2933, decode.d4.loss_dice: 0.6724, decode.d5.loss_cls: 0.0862, decode.d5.loss_mask: 0.2957, decode.d5.loss_dice: 0.6793, decode.d6.loss_cls: 0.0847, decode.d6.loss_mask: 0.2977, decode.d6.loss_dice: 0.6801, decode.d7.loss_cls: 0.0938, decode.d7.loss_mask: 0.3005, decode.d7.loss_dice: 0.6665, decode.d8.loss_cls: 0.0872, decode.d8.loss_mask: 0.2984, decode.d8.loss_dice: 0.6663, loss: 10.9002
2023-09-28 09:56:52,612 - mmseg - INFO - Iter [1800/40000]	lr: 1.371e-06, eta: 23:44:46, time: 2.214, data_time: 0.027, memory: 21542, decode.loss_cls: 0.1141, decode.loss_mask: 0.3662, decode.loss_dice: 0.6860, decode.d0.loss_cls: 0.3333, decode.d0.loss_mask: 0.3679, decode.d0.loss_dice: 0.6860, decode.d1.loss_cls: 0.1484, decode.d1.loss_mask: 0.3628, decode.d1.loss_dice: 0.6793, decode.d2.loss_cls: 0.1249, decode.d2.loss_mask: 0.3643, decode.d2.loss_dice: 0.6830, decode.d3.loss_cls: 0.1231, decode.d3.loss_mask: 0.3669, decode.d3.loss_dice: 0.6766, decode.d4.loss_cls: 0.1300, decode.d4.loss_mask: 0.3663, decode.d4.loss_dice: 0.6846, decode.d5.loss_cls: 0.1067, decode.d5.loss_mask: 0.3671, decode.d5.loss_dice: 0.6774, decode.d6.loss_cls: 0.1240, decode.d6.loss_mask: 0.3668, decode.d6.loss_dice: 0.6835, decode.d7.loss_cls: 0.1312, decode.d7.loss_mask: 0.3641, decode.d7.loss_dice: 0.6816, decode.d8.loss_cls: 0.1150, decode.d8.loss_mask: 0.3676, decode.d8.loss_dice: 0.6804, loss: 11.9293
2023-09-28 09:58:43,276 - mmseg - INFO - Iter [1850/40000]	lr: 1.369e-06, eta: 23:42:29, time: 2.213, data_time: 0.032, memory: 21542, decode.loss_cls: 0.1127, decode.loss_mask: 0.3520, decode.loss_dice: 0.6910, decode.d0.loss_cls: 0.2978, decode.d0.loss_mask: 0.3606, decode.d0.loss_dice: 0.7132, decode.d1.loss_cls: 0.1461, decode.d1.loss_mask: 0.3536, decode.d1.loss_dice: 0.6953, decode.d2.loss_cls: 0.1293, decode.d2.loss_mask: 0.3507, decode.d2.loss_dice: 0.6996, decode.d3.loss_cls: 0.1280, decode.d3.loss_mask: 0.3534, decode.d3.loss_dice: 0.6960, decode.d4.loss_cls: 0.1191, decode.d4.loss_mask: 0.3555, decode.d4.loss_dice: 0.7090, decode.d5.loss_cls: 0.1224, decode.d5.loss_mask: 0.3547, decode.d5.loss_dice: 0.7061, decode.d6.loss_cls: 0.1107, decode.d6.loss_mask: 0.3550, decode.d6.loss_dice: 0.7046, decode.d7.loss_cls: 0.1025, decode.d7.loss_mask: 0.3559, decode.d7.loss_dice: 0.6988, decode.d8.loss_cls: 0.1256, decode.d8.loss_mask: 0.3543, decode.d8.loss_dice: 0.7083, loss: 11.9621
2023-09-28 10:00:33,273 - mmseg - INFO - Iter [1900/40000]	lr: 1.368e-06, eta: 23:40:00, time: 2.200, data_time: 0.033, memory: 21542, decode.loss_cls: 0.1086, decode.loss_mask: 0.3407, decode.loss_dice: 0.7044, decode.d0.loss_cls: 0.2958, decode.d0.loss_mask: 0.3404, decode.d0.loss_dice: 0.7317, decode.d1.loss_cls: 0.1250, decode.d1.loss_mask: 0.3397, decode.d1.loss_dice: 0.7128, decode.d2.loss_cls: 0.1332, decode.d2.loss_mask: 0.3372, decode.d2.loss_dice: 0.7249, decode.d3.loss_cls: 0.1202, decode.d3.loss_mask: 0.3432, decode.d3.loss_dice: 0.7168, decode.d4.loss_cls: 0.1035, decode.d4.loss_mask: 0.3377, decode.d4.loss_dice: 0.7234, decode.d5.loss_cls: 0.1228, decode.d5.loss_mask: 0.3411, decode.d5.loss_dice: 0.7189, decode.d6.loss_cls: 0.1154, decode.d6.loss_mask: 0.3388, decode.d6.loss_dice: 0.7204, decode.d7.loss_cls: 0.0939, decode.d7.loss_mask: 0.3376, decode.d7.loss_dice: 0.7282, decode.d8.loss_cls: 0.1236, decode.d8.loss_mask: 0.3429, decode.d8.loss_dice: 0.7034, loss: 11.9264
2023-09-28 10:02:23,410 - mmseg - INFO - Iter [1950/40000]	lr: 1.366e-06, eta: 23:37:35, time: 2.203, data_time: 0.030, memory: 21542, decode.loss_cls: 0.1257, decode.loss_mask: 0.3170, decode.loss_dice: 0.6555, decode.d0.loss_cls: 0.2637, decode.d0.loss_mask: 0.3228, decode.d0.loss_dice: 0.6687, decode.d1.loss_cls: 0.1542, decode.d1.loss_mask: 0.3141, decode.d1.loss_dice: 0.6741, decode.d2.loss_cls: 0.1117, decode.d2.loss_mask: 0.3115, decode.d2.loss_dice: 0.6557, decode.d3.loss_cls: 0.1508, decode.d3.loss_mask: 0.3130, decode.d3.loss_dice: 0.6565, decode.d4.loss_cls: 0.1329, decode.d4.loss_mask: 0.3177, decode.d4.loss_dice: 0.6583, decode.d5.loss_cls: 0.1586, decode.d5.loss_mask: 0.3067, decode.d5.loss_dice: 0.6542, decode.d6.loss_cls: 0.1117, decode.d6.loss_mask: 0.3131, decode.d6.loss_dice: 0.6633, decode.d7.loss_cls: 0.1278, decode.d7.loss_mask: 0.3153, decode.d7.loss_dice: 0.6573, decode.d8.loss_cls: 0.1247, decode.d8.loss_mask: 0.3142, decode.d8.loss_dice: 0.6508, loss: 11.2015
2023-09-28 10:04:14,094 - mmseg - INFO - Saving checkpoint at 2000 iterations
2023-09-28 10:04:37,812 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 10:04:37,813 - mmseg - INFO - Iter [2000/40000]	lr: 1.364e-06, eta: 23:42:54, time: 2.688, data_time: 0.032, memory: 21542, decode.loss_cls: 0.1019, decode.loss_mask: 0.3549, decode.loss_dice: 0.6660, decode.d0.loss_cls: 0.2849, decode.d0.loss_mask: 0.3581, decode.d0.loss_dice: 0.6786, decode.d1.loss_cls: 0.1132, decode.d1.loss_mask: 0.3557, decode.d1.loss_dice: 0.6633, decode.d2.loss_cls: 0.1193, decode.d2.loss_mask: 0.3510, decode.d2.loss_dice: 0.6639, decode.d3.loss_cls: 0.1250, decode.d3.loss_mask: 0.3488, decode.d3.loss_dice: 0.6555, decode.d4.loss_cls: 0.1240, decode.d4.loss_mask: 0.3548, decode.d4.loss_dice: 0.6630, decode.d5.loss_cls: 0.1179, decode.d5.loss_mask: 0.3518, decode.d5.loss_dice: 0.6663, decode.d6.loss_cls: 0.1014, decode.d6.loss_mask: 0.3528, decode.d6.loss_dice: 0.6683, decode.d7.loss_cls: 0.1096, decode.d7.loss_mask: 0.3533, decode.d7.loss_dice: 0.6637, decode.d8.loss_cls: 0.1296, decode.d8.loss_mask: 0.3531, decode.d8.loss_dice: 0.6558, loss: 11.5058
2023-09-28 10:21:49,756 - mmseg - INFO - per class results:
2023-09-28 10:21:49,772 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 92.95 |  96.8 |
|    Sidewalk   | 67.67 | 83.52 |
|  Construction | 81.63 | 93.45 |
|     Fence     | 31.08 | 34.99 |
|      Pole     | 55.33 | 70.49 |
| Traffic Light | 65.48 | 80.14 |
|  Traffic Sign | 71.27 | 80.23 |
|     Nature    | 88.64 | 94.73 |
|      Sky      | 96.51 | 97.73 |
|     Person    | 45.03 | 52.66 |
|     Rider     |  9.09 | 63.61 |
|      Car      |  91.8 | 95.68 |
|   background  | 96.13 | 97.51 |
+---------------+-------+-------+
2023-09-28 10:21:49,772 - mmseg - INFO - Summary:
2023-09-28 10:21:49,773 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.34 | 68.66 | 80.12 |
+-------+-------+-------+
2023-09-28 10:22:09,342 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_2000.pth.
2023-09-28 10:22:09,342 - mmseg - INFO - Best mIoU is 0.6866 at 2000 iter.
2023-09-28 10:22:09,345 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 10:22:09,345 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9434, mIoU: 0.6866, mAcc: 0.8012, IoU.Road: 0.9295, IoU.Sidewalk: 0.6767, IoU.Construction: 0.8163, IoU.Fence: 0.3108, IoU.Pole: 0.5533, IoU.Traffic Light: 0.6548, IoU.Traffic Sign: 0.7127, IoU.Nature: 0.8864, IoU.Sky: 0.9651, IoU.Person: 0.4503, IoU.Rider: 0.0909, IoU.Car: 0.9180, IoU.background: 0.9613, Acc.Road: 0.9680, Acc.Sidewalk: 0.8352, Acc.Construction: 0.9345, Acc.Fence: 0.3499, Acc.Pole: 0.7049, Acc.Traffic Light: 0.8014, Acc.Traffic Sign: 0.8023, Acc.Nature: 0.9473, Acc.Sky: 0.9773, Acc.Person: 0.5266, Acc.Rider: 0.6361, Acc.Car: 0.9568, Acc.background: 0.9751
2023-09-28 10:24:00,103 - mmseg - INFO - Iter [2050/40000]	lr: 1.362e-06, eta: 1 day, 5:04:58, time: 23.246, data_time: 21.061, memory: 21542, decode.loss_cls: 0.0781, decode.loss_mask: 0.2882, decode.loss_dice: 0.6684, decode.d0.loss_cls: 0.2880, decode.d0.loss_mask: 0.2912, decode.d0.loss_dice: 0.6737, decode.d1.loss_cls: 0.1132, decode.d1.loss_mask: 0.2897, decode.d1.loss_dice: 0.6579, decode.d2.loss_cls: 0.1142, decode.d2.loss_mask: 0.2873, decode.d2.loss_dice: 0.6688, decode.d3.loss_cls: 0.0959, decode.d3.loss_mask: 0.2856, decode.d3.loss_dice: 0.6712, decode.d4.loss_cls: 0.0834, decode.d4.loss_mask: 0.2882, decode.d4.loss_dice: 0.6783, decode.d5.loss_cls: 0.1054, decode.d5.loss_mask: 0.2867, decode.d5.loss_dice: 0.6577, decode.d6.loss_cls: 0.1018, decode.d6.loss_mask: 0.2849, decode.d6.loss_dice: 0.6662, decode.d7.loss_cls: 0.0905, decode.d7.loss_mask: 0.2881, decode.d7.loss_dice: 0.6646, decode.d8.loss_cls: 0.1214, decode.d8.loss_mask: 0.2885, decode.d8.loss_dice: 0.6678, loss: 10.7449
2023-09-28 10:25:50,802 - mmseg - INFO - Iter [2100/40000]	lr: 1.360e-06, eta: 1 day, 4:54:28, time: 2.214, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0802, decode.loss_mask: 0.3305, decode.loss_dice: 0.6757, decode.d0.loss_cls: 0.2917, decode.d0.loss_mask: 0.3449, decode.d0.loss_dice: 0.6919, decode.d1.loss_cls: 0.1077, decode.d1.loss_mask: 0.3370, decode.d1.loss_dice: 0.6867, decode.d2.loss_cls: 0.0753, decode.d2.loss_mask: 0.3346, decode.d2.loss_dice: 0.6820, decode.d3.loss_cls: 0.0901, decode.d3.loss_mask: 0.3375, decode.d3.loss_dice: 0.6850, decode.d4.loss_cls: 0.0702, decode.d4.loss_mask: 0.3399, decode.d4.loss_dice: 0.6958, decode.d5.loss_cls: 0.0847, decode.d5.loss_mask: 0.3318, decode.d5.loss_dice: 0.6819, decode.d6.loss_cls: 0.0878, decode.d6.loss_mask: 0.3320, decode.d6.loss_dice: 0.6803, decode.d7.loss_cls: 0.0898, decode.d7.loss_mask: 0.3360, decode.d7.loss_dice: 0.6788, decode.d8.loss_cls: 0.0741, decode.d8.loss_mask: 0.3349, decode.d8.loss_dice: 0.6906, loss: 11.2595
2023-09-28 10:27:40,764 - mmseg - INFO - Iter [2150/40000]	lr: 1.359e-06, eta: 1 day, 4:44:10, time: 2.199, data_time: 0.031, memory: 21542, decode.loss_cls: 0.1129, decode.loss_mask: 0.3013, decode.loss_dice: 0.6193, decode.d0.loss_cls: 0.2564, decode.d0.loss_mask: 0.3075, decode.d0.loss_dice: 0.6478, decode.d1.loss_cls: 0.0944, decode.d1.loss_mask: 0.3005, decode.d1.loss_dice: 0.6431, decode.d2.loss_cls: 0.0899, decode.d2.loss_mask: 0.3033, decode.d2.loss_dice: 0.6336, decode.d3.loss_cls: 0.0805, decode.d3.loss_mask: 0.3042, decode.d3.loss_dice: 0.6310, decode.d4.loss_cls: 0.0879, decode.d4.loss_mask: 0.3012, decode.d4.loss_dice: 0.6280, decode.d5.loss_cls: 0.0935, decode.d5.loss_mask: 0.3035, decode.d5.loss_dice: 0.6293, decode.d6.loss_cls: 0.0901, decode.d6.loss_mask: 0.3015, decode.d6.loss_dice: 0.6328, decode.d7.loss_cls: 0.1002, decode.d7.loss_mask: 0.3010, decode.d7.loss_dice: 0.6234, decode.d8.loss_cls: 0.1036, decode.d8.loss_mask: 0.3006, decode.d8.loss_dice: 0.6300, loss: 10.4524
2023-09-28 10:29:33,293 - mmseg - INFO - Iter [2200/40000]	lr: 1.357e-06, eta: 1 day, 4:34:59, time: 2.251, data_time: 0.078, memory: 21542, decode.loss_cls: 0.0761, decode.loss_mask: 0.3821, decode.loss_dice: 0.6993, decode.d0.loss_cls: 0.2868, decode.d0.loss_mask: 0.3933, decode.d0.loss_dice: 0.6878, decode.d1.loss_cls: 0.0860, decode.d1.loss_mask: 0.3831, decode.d1.loss_dice: 0.6870, decode.d2.loss_cls: 0.0841, decode.d2.loss_mask: 0.3812, decode.d2.loss_dice: 0.6857, decode.d3.loss_cls: 0.0840, decode.d3.loss_mask: 0.3821, decode.d3.loss_dice: 0.6918, decode.d4.loss_cls: 0.0747, decode.d4.loss_mask: 0.3821, decode.d4.loss_dice: 0.6920, decode.d5.loss_cls: 0.0947, decode.d5.loss_mask: 0.3805, decode.d5.loss_dice: 0.7004, decode.d6.loss_cls: 0.1024, decode.d6.loss_mask: 0.3818, decode.d6.loss_dice: 0.6965, decode.d7.loss_cls: 0.0599, decode.d7.loss_mask: 0.3830, decode.d7.loss_dice: 0.7007, decode.d8.loss_cls: 0.0675, decode.d8.loss_mask: 0.3790, decode.d8.loss_dice: 0.6932, loss: 11.7789
2023-09-28 10:31:24,022 - mmseg - INFO - Iter [2250/40000]	lr: 1.355e-06, eta: 1 day, 4:25:37, time: 2.215, data_time: 0.029, memory: 21542, decode.loss_cls: 0.1027, decode.loss_mask: 0.3496, decode.loss_dice: 0.6829, decode.d0.loss_cls: 0.2944, decode.d0.loss_mask: 0.3669, decode.d0.loss_dice: 0.6922, decode.d1.loss_cls: 0.1472, decode.d1.loss_mask: 0.3490, decode.d1.loss_dice: 0.6795, decode.d2.loss_cls: 0.1276, decode.d2.loss_mask: 0.3511, decode.d2.loss_dice: 0.6822, decode.d3.loss_cls: 0.1184, decode.d3.loss_mask: 0.3472, decode.d3.loss_dice: 0.6857, decode.d4.loss_cls: 0.1212, decode.d4.loss_mask: 0.3474, decode.d4.loss_dice: 0.6802, decode.d5.loss_cls: 0.1214, decode.d5.loss_mask: 0.3518, decode.d5.loss_dice: 0.6792, decode.d6.loss_cls: 0.1433, decode.d6.loss_mask: 0.3464, decode.d6.loss_dice: 0.6706, decode.d7.loss_cls: 0.1078, decode.d7.loss_mask: 0.3499, decode.d7.loss_dice: 0.6753, decode.d8.loss_cls: 0.1190, decode.d8.loss_mask: 0.3470, decode.d8.loss_dice: 0.6645, loss: 11.7015
2023-09-28 10:33:14,223 - mmseg - INFO - Iter [2300/40000]	lr: 1.353e-06, eta: 1 day, 4:16:26, time: 2.204, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0751, decode.loss_mask: 0.3363, decode.loss_dice: 0.6151, decode.d0.loss_cls: 0.2867, decode.d0.loss_mask: 0.3407, decode.d0.loss_dice: 0.6294, decode.d1.loss_cls: 0.1059, decode.d1.loss_mask: 0.3360, decode.d1.loss_dice: 0.6249, decode.d2.loss_cls: 0.0965, decode.d2.loss_mask: 0.3363, decode.d2.loss_dice: 0.6224, decode.d3.loss_cls: 0.1010, decode.d3.loss_mask: 0.3346, decode.d3.loss_dice: 0.6231, decode.d4.loss_cls: 0.0984, decode.d4.loss_mask: 0.3353, decode.d4.loss_dice: 0.6253, decode.d5.loss_cls: 0.1039, decode.d5.loss_mask: 0.3343, decode.d5.loss_dice: 0.6134, decode.d6.loss_cls: 0.0926, decode.d6.loss_mask: 0.3363, decode.d6.loss_dice: 0.6208, decode.d7.loss_cls: 0.1013, decode.d7.loss_mask: 0.3396, decode.d7.loss_dice: 0.6202, decode.d8.loss_cls: 0.0838, decode.d8.loss_mask: 0.3388, decode.d8.loss_dice: 0.6179, loss: 10.7259
2023-09-28 10:35:05,645 - mmseg - INFO - Iter [2350/40000]	lr: 1.351e-06, eta: 1 day, 4:07:52, time: 2.227, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0820, decode.loss_mask: 0.2955, decode.loss_dice: 0.6898, decode.d0.loss_cls: 0.2882, decode.d0.loss_mask: 0.3006, decode.d0.loss_dice: 0.6967, decode.d1.loss_cls: 0.0918, decode.d1.loss_mask: 0.2958, decode.d1.loss_dice: 0.7065, decode.d2.loss_cls: 0.1048, decode.d2.loss_mask: 0.2930, decode.d2.loss_dice: 0.7061, decode.d3.loss_cls: 0.0930, decode.d3.loss_mask: 0.2950, decode.d3.loss_dice: 0.6972, decode.d4.loss_cls: 0.0995, decode.d4.loss_mask: 0.2935, decode.d4.loss_dice: 0.6999, decode.d5.loss_cls: 0.0787, decode.d5.loss_mask: 0.2941, decode.d5.loss_dice: 0.7036, decode.d6.loss_cls: 0.0824, decode.d6.loss_mask: 0.2949, decode.d6.loss_dice: 0.6996, decode.d7.loss_cls: 0.0946, decode.d7.loss_mask: 0.2956, decode.d7.loss_dice: 0.7038, decode.d8.loss_cls: 0.0787, decode.d8.loss_mask: 0.2955, decode.d8.loss_dice: 0.6807, loss: 11.0310
2023-09-28 10:36:55,946 - mmseg - INFO - Iter [2400/40000]	lr: 1.350e-06, eta: 1 day, 3:59:20, time: 2.207, data_time: 0.035, memory: 21542, decode.loss_cls: 0.0925, decode.loss_mask: 0.3256, decode.loss_dice: 0.6761, decode.d0.loss_cls: 0.2556, decode.d0.loss_mask: 0.3331, decode.d0.loss_dice: 0.6683, decode.d1.loss_cls: 0.1002, decode.d1.loss_mask: 0.3285, decode.d1.loss_dice: 0.6739, decode.d2.loss_cls: 0.0995, decode.d2.loss_mask: 0.3274, decode.d2.loss_dice: 0.6703, decode.d3.loss_cls: 0.0860, decode.d3.loss_mask: 0.3261, decode.d3.loss_dice: 0.6746, decode.d4.loss_cls: 0.0942, decode.d4.loss_mask: 0.3260, decode.d4.loss_dice: 0.6779, decode.d5.loss_cls: 0.0962, decode.d5.loss_mask: 0.3241, decode.d5.loss_dice: 0.6733, decode.d6.loss_cls: 0.0888, decode.d6.loss_mask: 0.3256, decode.d6.loss_dice: 0.6733, decode.d7.loss_cls: 0.1010, decode.d7.loss_mask: 0.3240, decode.d7.loss_dice: 0.6563, decode.d8.loss_cls: 0.0897, decode.d8.loss_mask: 0.3255, decode.d8.loss_dice: 0.6731, loss: 11.0867
2023-09-28 10:38:45,570 - mmseg - INFO - Iter [2450/40000]	lr: 1.348e-06, eta: 1 day, 3:50:52, time: 2.192, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0755, decode.loss_mask: 0.3200, decode.loss_dice: 0.6613, decode.d0.loss_cls: 0.2506, decode.d0.loss_mask: 0.3292, decode.d0.loss_dice: 0.6789, decode.d1.loss_cls: 0.0947, decode.d1.loss_mask: 0.3258, decode.d1.loss_dice: 0.6768, decode.d2.loss_cls: 0.0927, decode.d2.loss_mask: 0.3218, decode.d2.loss_dice: 0.6807, decode.d3.loss_cls: 0.0928, decode.d3.loss_mask: 0.3224, decode.d3.loss_dice: 0.6795, decode.d4.loss_cls: 0.0922, decode.d4.loss_mask: 0.3207, decode.d4.loss_dice: 0.6668, decode.d5.loss_cls: 0.1195, decode.d5.loss_mask: 0.3210, decode.d5.loss_dice: 0.6728, decode.d6.loss_cls: 0.0770, decode.d6.loss_mask: 0.3226, decode.d6.loss_dice: 0.6677, decode.d7.loss_cls: 0.0807, decode.d7.loss_mask: 0.3205, decode.d7.loss_dice: 0.6671, decode.d8.loss_cls: 0.0958, decode.d8.loss_mask: 0.3259, decode.d8.loss_dice: 0.6670, loss: 11.0203
2023-09-28 10:40:36,103 - mmseg - INFO - Iter [2500/40000]	lr: 1.346e-06, eta: 1 day, 3:42:54, time: 2.211, data_time: 0.032, memory: 21542, decode.loss_cls: 0.1232, decode.loss_mask: 0.3369, decode.loss_dice: 0.6724, decode.d0.loss_cls: 0.3080, decode.d0.loss_mask: 0.3431, decode.d0.loss_dice: 0.7078, decode.d1.loss_cls: 0.1552, decode.d1.loss_mask: 0.3363, decode.d1.loss_dice: 0.6787, decode.d2.loss_cls: 0.1306, decode.d2.loss_mask: 0.3333, decode.d2.loss_dice: 0.6825, decode.d3.loss_cls: 0.1319, decode.d3.loss_mask: 0.3354, decode.d3.loss_dice: 0.6765, decode.d4.loss_cls: 0.1191, decode.d4.loss_mask: 0.3353, decode.d4.loss_dice: 0.6863, decode.d5.loss_cls: 0.1336, decode.d5.loss_mask: 0.3353, decode.d5.loss_dice: 0.6863, decode.d6.loss_cls: 0.1133, decode.d6.loss_mask: 0.3342, decode.d6.loss_dice: 0.6827, decode.d7.loss_cls: 0.1208, decode.d7.loss_mask: 0.3429, decode.d7.loss_dice: 0.6886, decode.d8.loss_cls: 0.1195, decode.d8.loss_mask: 0.3372, decode.d8.loss_dice: 0.6796, loss: 11.6665
2023-09-28 10:42:26,944 - mmseg - INFO - Iter [2550/40000]	lr: 1.344e-06, eta: 1 day, 3:35:15, time: 2.216, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0690, decode.loss_mask: 0.3256, decode.loss_dice: 0.6595, decode.d0.loss_cls: 0.2575, decode.d0.loss_mask: 0.3270, decode.d0.loss_dice: 0.6443, decode.d1.loss_cls: 0.0801, decode.d1.loss_mask: 0.3271, decode.d1.loss_dice: 0.6639, decode.d2.loss_cls: 0.0570, decode.d2.loss_mask: 0.3247, decode.d2.loss_dice: 0.6547, decode.d3.loss_cls: 0.0767, decode.d3.loss_mask: 0.3254, decode.d3.loss_dice: 0.6509, decode.d4.loss_cls: 0.0814, decode.d4.loss_mask: 0.3265, decode.d4.loss_dice: 0.6570, decode.d5.loss_cls: 0.0871, decode.d5.loss_mask: 0.3251, decode.d5.loss_dice: 0.6661, decode.d6.loss_cls: 0.0648, decode.d6.loss_mask: 0.3255, decode.d6.loss_dice: 0.6547, decode.d7.loss_cls: 0.0838, decode.d7.loss_mask: 0.3249, decode.d7.loss_dice: 0.6643, decode.d8.loss_cls: 0.0702, decode.d8.loss_mask: 0.3261, decode.d8.loss_dice: 0.6509, loss: 10.7519
2023-09-28 10:44:17,777 - mmseg - INFO - Iter [2600/40000]	lr: 1.343e-06, eta: 1 day, 3:27:49, time: 2.217, data_time: 0.029, memory: 21542, decode.loss_cls: 0.1432, decode.loss_mask: 0.3384, decode.loss_dice: 0.6675, decode.d0.loss_cls: 0.3315, decode.d0.loss_mask: 0.3393, decode.d0.loss_dice: 0.6701, decode.d1.loss_cls: 0.1681, decode.d1.loss_mask: 0.3348, decode.d1.loss_dice: 0.6611, decode.d2.loss_cls: 0.1652, decode.d2.loss_mask: 0.3363, decode.d2.loss_dice: 0.6562, decode.d3.loss_cls: 0.1466, decode.d3.loss_mask: 0.3442, decode.d3.loss_dice: 0.6601, decode.d4.loss_cls: 0.1595, decode.d4.loss_mask: 0.3428, decode.d4.loss_dice: 0.6587, decode.d5.loss_cls: 0.1344, decode.d5.loss_mask: 0.3437, decode.d5.loss_dice: 0.6615, decode.d6.loss_cls: 0.1211, decode.d6.loss_mask: 0.3449, decode.d6.loss_dice: 0.6595, decode.d7.loss_cls: 0.1487, decode.d7.loss_mask: 0.3379, decode.d7.loss_dice: 0.6524, decode.d8.loss_cls: 0.1412, decode.d8.loss_mask: 0.3441, decode.d8.loss_dice: 0.6487, loss: 11.6618
2023-09-28 10:46:08,319 - mmseg - INFO - Iter [2650/40000]	lr: 1.341e-06, eta: 1 day, 3:20:33, time: 2.211, data_time: 0.032, memory: 21542, decode.loss_cls: 0.1142, decode.loss_mask: 0.3030, decode.loss_dice: 0.6340, decode.d0.loss_cls: 0.2693, decode.d0.loss_mask: 0.3113, decode.d0.loss_dice: 0.6668, decode.d1.loss_cls: 0.1279, decode.d1.loss_mask: 0.3036, decode.d1.loss_dice: 0.6466, decode.d2.loss_cls: 0.1187, decode.d2.loss_mask: 0.3028, decode.d2.loss_dice: 0.6476, decode.d3.loss_cls: 0.1239, decode.d3.loss_mask: 0.3001, decode.d3.loss_dice: 0.6461, decode.d4.loss_cls: 0.1210, decode.d4.loss_mask: 0.3015, decode.d4.loss_dice: 0.6425, decode.d5.loss_cls: 0.1097, decode.d5.loss_mask: 0.3002, decode.d5.loss_dice: 0.6527, decode.d6.loss_cls: 0.0960, decode.d6.loss_mask: 0.3011, decode.d6.loss_dice: 0.6617, decode.d7.loss_cls: 0.1073, decode.d7.loss_mask: 0.3011, decode.d7.loss_dice: 0.6495, decode.d8.loss_cls: 0.1145, decode.d8.loss_mask: 0.3011, decode.d8.loss_dice: 0.6563, loss: 10.8321
2023-09-28 10:47:59,233 - mmseg - INFO - Iter [2700/40000]	lr: 1.339e-06, eta: 1 day, 3:13:33, time: 2.218, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0993, decode.loss_mask: 0.2964, decode.loss_dice: 0.6447, decode.d0.loss_cls: 0.2812, decode.d0.loss_mask: 0.3038, decode.d0.loss_dice: 0.6608, decode.d1.loss_cls: 0.1077, decode.d1.loss_mask: 0.2995, decode.d1.loss_dice: 0.6378, decode.d2.loss_cls: 0.0993, decode.d2.loss_mask: 0.2950, decode.d2.loss_dice: 0.6314, decode.d3.loss_cls: 0.1069, decode.d3.loss_mask: 0.2963, decode.d3.loss_dice: 0.6489, decode.d4.loss_cls: 0.1121, decode.d4.loss_mask: 0.2959, decode.d4.loss_dice: 0.6340, decode.d5.loss_cls: 0.0941, decode.d5.loss_mask: 0.2957, decode.d5.loss_dice: 0.6441, decode.d6.loss_cls: 0.1179, decode.d6.loss_mask: 0.2972, decode.d6.loss_dice: 0.6389, decode.d7.loss_cls: 0.0935, decode.d7.loss_mask: 0.2983, decode.d7.loss_dice: 0.6480, decode.d8.loss_cls: 0.1015, decode.d8.loss_mask: 0.2961, decode.d8.loss_dice: 0.6486, loss: 10.6250
2023-09-28 10:49:49,287 - mmseg - INFO - Iter [2750/40000]	lr: 1.337e-06, eta: 1 day, 3:06:32, time: 2.201, data_time: 0.039, memory: 21542, decode.loss_cls: 0.0989, decode.loss_mask: 0.3197, decode.loss_dice: 0.6165, decode.d0.loss_cls: 0.3283, decode.d0.loss_mask: 0.3263, decode.d0.loss_dice: 0.6152, decode.d1.loss_cls: 0.1359, decode.d1.loss_mask: 0.3186, decode.d1.loss_dice: 0.6175, decode.d2.loss_cls: 0.1192, decode.d2.loss_mask: 0.3204, decode.d2.loss_dice: 0.6176, decode.d3.loss_cls: 0.0950, decode.d3.loss_mask: 0.3263, decode.d3.loss_dice: 0.6255, decode.d4.loss_cls: 0.1131, decode.d4.loss_mask: 0.3196, decode.d4.loss_dice: 0.6215, decode.d5.loss_cls: 0.1047, decode.d5.loss_mask: 0.3206, decode.d5.loss_dice: 0.6176, decode.d6.loss_cls: 0.0868, decode.d6.loss_mask: 0.3231, decode.d6.loss_dice: 0.6194, decode.d7.loss_cls: 0.0980, decode.d7.loss_mask: 0.3224, decode.d7.loss_dice: 0.6155, decode.d8.loss_cls: 0.0955, decode.d8.loss_mask: 0.3190, decode.d8.loss_dice: 0.6187, loss: 10.6765
2023-09-28 10:51:40,469 - mmseg - INFO - Iter [2800/40000]	lr: 1.335e-06, eta: 1 day, 2:59:57, time: 2.223, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0967, decode.loss_mask: 0.3060, decode.loss_dice: 0.6639, decode.d0.loss_cls: 0.2775, decode.d0.loss_mask: 0.3092, decode.d0.loss_dice: 0.6643, decode.d1.loss_cls: 0.1202, decode.d1.loss_mask: 0.3071, decode.d1.loss_dice: 0.6654, decode.d2.loss_cls: 0.1264, decode.d2.loss_mask: 0.3056, decode.d2.loss_dice: 0.6621, decode.d3.loss_cls: 0.0972, decode.d3.loss_mask: 0.3039, decode.d3.loss_dice: 0.6586, decode.d4.loss_cls: 0.0974, decode.d4.loss_mask: 0.3040, decode.d4.loss_dice: 0.6661, decode.d5.loss_cls: 0.1151, decode.d5.loss_mask: 0.3060, decode.d5.loss_dice: 0.6581, decode.d6.loss_cls: 0.1233, decode.d6.loss_mask: 0.3056, decode.d6.loss_dice: 0.6462, decode.d7.loss_cls: 0.1055, decode.d7.loss_mask: 0.3062, decode.d7.loss_dice: 0.6527, decode.d8.loss_cls: 0.1194, decode.d8.loss_mask: 0.3057, decode.d8.loss_dice: 0.6570, loss: 10.9324
2023-09-28 10:53:31,254 - mmseg - INFO - Iter [2850/40000]	lr: 1.334e-06, eta: 1 day, 2:53:29, time: 2.217, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0954, decode.loss_mask: 0.3120, decode.loss_dice: 0.6102, decode.d0.loss_cls: 0.2474, decode.d0.loss_mask: 0.3218, decode.d0.loss_dice: 0.6099, decode.d1.loss_cls: 0.1099, decode.d1.loss_mask: 0.3164, decode.d1.loss_dice: 0.6066, decode.d2.loss_cls: 0.0910, decode.d2.loss_mask: 0.3193, decode.d2.loss_dice: 0.6180, decode.d3.loss_cls: 0.0944, decode.d3.loss_mask: 0.3160, decode.d3.loss_dice: 0.6136, decode.d4.loss_cls: 0.0951, decode.d4.loss_mask: 0.3168, decode.d4.loss_dice: 0.6169, decode.d5.loss_cls: 0.0948, decode.d5.loss_mask: 0.3196, decode.d5.loss_dice: 0.6029, decode.d6.loss_cls: 0.0887, decode.d6.loss_mask: 0.3196, decode.d6.loss_dice: 0.6043, decode.d7.loss_cls: 0.0934, decode.d7.loss_mask: 0.3193, decode.d7.loss_dice: 0.6111, decode.d8.loss_cls: 0.0797, decode.d8.loss_mask: 0.3190, decode.d8.loss_dice: 0.6089, loss: 10.3720
2023-09-28 10:55:20,803 - mmseg - INFO - Iter [2900/40000]	lr: 1.332e-06, eta: 1 day, 2:46:53, time: 2.191, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0965, decode.loss_mask: 0.3215, decode.loss_dice: 0.6702, decode.d0.loss_cls: 0.2643, decode.d0.loss_mask: 0.3357, decode.d0.loss_dice: 0.6741, decode.d1.loss_cls: 0.0962, decode.d1.loss_mask: 0.3251, decode.d1.loss_dice: 0.6807, decode.d2.loss_cls: 0.0982, decode.d2.loss_mask: 0.3202, decode.d2.loss_dice: 0.6774, decode.d3.loss_cls: 0.0985, decode.d3.loss_mask: 0.3237, decode.d3.loss_dice: 0.6666, decode.d4.loss_cls: 0.1004, decode.d4.loss_mask: 0.3231, decode.d4.loss_dice: 0.6627, decode.d5.loss_cls: 0.0971, decode.d5.loss_mask: 0.3245, decode.d5.loss_dice: 0.6768, decode.d6.loss_cls: 0.1179, decode.d6.loss_mask: 0.3236, decode.d6.loss_dice: 0.6650, decode.d7.loss_cls: 0.1122, decode.d7.loss_mask: 0.3212, decode.d7.loss_dice: 0.6681, decode.d8.loss_cls: 0.1022, decode.d8.loss_mask: 0.3229, decode.d8.loss_dice: 0.6693, loss: 11.1359
2023-09-28 10:57:10,693 - mmseg - INFO - Iter [2950/40000]	lr: 1.330e-06, eta: 1 day, 2:40:31, time: 2.197, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0932, decode.loss_mask: 0.3270, decode.loss_dice: 0.6883, decode.d0.loss_cls: 0.2929, decode.d0.loss_mask: 0.3401, decode.d0.loss_dice: 0.6926, decode.d1.loss_cls: 0.1033, decode.d1.loss_mask: 0.3289, decode.d1.loss_dice: 0.6842, decode.d2.loss_cls: 0.0896, decode.d2.loss_mask: 0.3296, decode.d2.loss_dice: 0.6779, decode.d3.loss_cls: 0.0766, decode.d3.loss_mask: 0.3315, decode.d3.loss_dice: 0.6911, decode.d4.loss_cls: 0.0821, decode.d4.loss_mask: 0.3289, decode.d4.loss_dice: 0.6862, decode.d5.loss_cls: 0.0869, decode.d5.loss_mask: 0.3306, decode.d5.loss_dice: 0.6783, decode.d6.loss_cls: 0.0902, decode.d6.loss_mask: 0.3326, decode.d6.loss_dice: 0.6848, decode.d7.loss_cls: 0.0822, decode.d7.loss_mask: 0.3295, decode.d7.loss_dice: 0.6887, decode.d8.loss_cls: 0.1024, decode.d8.loss_mask: 0.3298, decode.d8.loss_dice: 0.6896, loss: 11.2694
2023-09-28 10:59:01,968 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 10:59:01,968 - mmseg - INFO - Iter [3000/40000]	lr: 1.328e-06, eta: 1 day, 2:34:35, time: 2.226, data_time: 0.033, memory: 21542, decode.loss_cls: 0.1200, decode.loss_mask: 0.3366, decode.loss_dice: 0.6946, decode.d0.loss_cls: 0.2963, decode.d0.loss_mask: 0.3443, decode.d0.loss_dice: 0.7097, decode.d1.loss_cls: 0.1276, decode.d1.loss_mask: 0.3393, decode.d1.loss_dice: 0.6988, decode.d2.loss_cls: 0.1263, decode.d2.loss_mask: 0.3380, decode.d2.loss_dice: 0.6977, decode.d3.loss_cls: 0.1304, decode.d3.loss_mask: 0.3383, decode.d3.loss_dice: 0.7037, decode.d4.loss_cls: 0.1298, decode.d4.loss_mask: 0.3387, decode.d4.loss_dice: 0.7082, decode.d5.loss_cls: 0.1420, decode.d5.loss_mask: 0.3377, decode.d5.loss_dice: 0.6940, decode.d6.loss_cls: 0.1348, decode.d6.loss_mask: 0.3406, decode.d6.loss_dice: 0.7094, decode.d7.loss_cls: 0.1194, decode.d7.loss_mask: 0.3393, decode.d7.loss_dice: 0.6923, decode.d8.loss_cls: 0.1118, decode.d8.loss_mask: 0.3370, decode.d8.loss_dice: 0.6977, loss: 11.8341
2023-09-28 11:00:51,732 - mmseg - INFO - Iter [3050/40000]	lr: 1.326e-06, eta: 1 day, 2:28:30, time: 2.195, data_time: 0.038, memory: 21542, decode.loss_cls: 0.0736, decode.loss_mask: 0.2908, decode.loss_dice: 0.6341, decode.d0.loss_cls: 0.2915, decode.d0.loss_mask: 0.2919, decode.d0.loss_dice: 0.6524, decode.d1.loss_cls: 0.0782, decode.d1.loss_mask: 0.2913, decode.d1.loss_dice: 0.6373, decode.d2.loss_cls: 0.0774, decode.d2.loss_mask: 0.2925, decode.d2.loss_dice: 0.6332, decode.d3.loss_cls: 0.0612, decode.d3.loss_mask: 0.2917, decode.d3.loss_dice: 0.6355, decode.d4.loss_cls: 0.0647, decode.d4.loss_mask: 0.2904, decode.d4.loss_dice: 0.6420, decode.d5.loss_cls: 0.0703, decode.d5.loss_mask: 0.2907, decode.d5.loss_dice: 0.6379, decode.d6.loss_cls: 0.0729, decode.d6.loss_mask: 0.2927, decode.d6.loss_dice: 0.6467, decode.d7.loss_cls: 0.0890, decode.d7.loss_mask: 0.2911, decode.d7.loss_dice: 0.6264, decode.d8.loss_cls: 0.0749, decode.d8.loss_mask: 0.2910, decode.d8.loss_dice: 0.6362, loss: 10.2497
2023-09-28 11:02:42,497 - mmseg - INFO - Iter [3100/40000]	lr: 1.325e-06, eta: 1 day, 2:22:44, time: 2.215, data_time: 0.033, memory: 21542, decode.loss_cls: 0.1125, decode.loss_mask: 0.3547, decode.loss_dice: 0.6628, decode.d0.loss_cls: 0.2689, decode.d0.loss_mask: 0.3633, decode.d0.loss_dice: 0.6690, decode.d1.loss_cls: 0.1074, decode.d1.loss_mask: 0.3535, decode.d1.loss_dice: 0.6685, decode.d2.loss_cls: 0.0921, decode.d2.loss_mask: 0.3535, decode.d2.loss_dice: 0.6709, decode.d3.loss_cls: 0.0939, decode.d3.loss_mask: 0.3554, decode.d3.loss_dice: 0.6554, decode.d4.loss_cls: 0.1020, decode.d4.loss_mask: 0.3530, decode.d4.loss_dice: 0.6658, decode.d5.loss_cls: 0.1108, decode.d5.loss_mask: 0.3541, decode.d5.loss_dice: 0.6566, decode.d6.loss_cls: 0.0882, decode.d6.loss_mask: 0.3547, decode.d6.loss_dice: 0.6623, decode.d7.loss_cls: 0.0915, decode.d7.loss_mask: 0.3528, decode.d7.loss_dice: 0.6630, decode.d8.loss_cls: 0.0910, decode.d8.loss_mask: 0.3541, decode.d8.loss_dice: 0.6628, loss: 11.3447
2023-09-28 11:04:33,524 - mmseg - INFO - Iter [3150/40000]	lr: 1.323e-06, eta: 1 day, 2:17:09, time: 2.221, data_time: 0.030, memory: 21542, decode.loss_cls: 0.1169, decode.loss_mask: 0.3409, decode.loss_dice: 0.6786, decode.d0.loss_cls: 0.2756, decode.d0.loss_mask: 0.3492, decode.d0.loss_dice: 0.6947, decode.d1.loss_cls: 0.1388, decode.d1.loss_mask: 0.3426, decode.d1.loss_dice: 0.6827, decode.d2.loss_cls: 0.1206, decode.d2.loss_mask: 0.3417, decode.d2.loss_dice: 0.6877, decode.d3.loss_cls: 0.1341, decode.d3.loss_mask: 0.3419, decode.d3.loss_dice: 0.6724, decode.d4.loss_cls: 0.1253, decode.d4.loss_mask: 0.3422, decode.d4.loss_dice: 0.6871, decode.d5.loss_cls: 0.1183, decode.d5.loss_mask: 0.3392, decode.d5.loss_dice: 0.6727, decode.d6.loss_cls: 0.1151, decode.d6.loss_mask: 0.3392, decode.d6.loss_dice: 0.6619, decode.d7.loss_cls: 0.1146, decode.d7.loss_mask: 0.3405, decode.d7.loss_dice: 0.6646, decode.d8.loss_cls: 0.1049, decode.d8.loss_mask: 0.3403, decode.d8.loss_dice: 0.6730, loss: 11.5570
2023-09-28 11:06:24,306 - mmseg - INFO - Iter [3200/40000]	lr: 1.321e-06, eta: 1 day, 2:11:38, time: 2.216, data_time: 0.033, memory: 21542, decode.loss_cls: 0.1422, decode.loss_mask: 0.3476, decode.loss_dice: 0.6846, decode.d0.loss_cls: 0.2922, decode.d0.loss_mask: 0.3587, decode.d0.loss_dice: 0.6853, decode.d1.loss_cls: 0.1438, decode.d1.loss_mask: 0.3495, decode.d1.loss_dice: 0.6719, decode.d2.loss_cls: 0.1388, decode.d2.loss_mask: 0.3488, decode.d2.loss_dice: 0.6731, decode.d3.loss_cls: 0.1256, decode.d3.loss_mask: 0.3409, decode.d3.loss_dice: 0.6702, decode.d4.loss_cls: 0.1550, decode.d4.loss_mask: 0.3422, decode.d4.loss_dice: 0.6684, decode.d5.loss_cls: 0.1619, decode.d5.loss_mask: 0.3448, decode.d5.loss_dice: 0.6793, decode.d6.loss_cls: 0.1497, decode.d6.loss_mask: 0.3510, decode.d6.loss_dice: 0.6665, decode.d7.loss_cls: 0.1405, decode.d7.loss_mask: 0.3420, decode.d7.loss_dice: 0.6736, decode.d8.loss_cls: 0.1502, decode.d8.loss_mask: 0.3413, decode.d8.loss_dice: 0.6773, loss: 11.8168
2023-09-28 11:08:14,669 - mmseg - INFO - Iter [3250/40000]	lr: 1.319e-06, eta: 1 day, 2:06:09, time: 2.207, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0825, decode.loss_mask: 0.2954, decode.loss_dice: 0.6285, decode.d0.loss_cls: 0.2796, decode.d0.loss_mask: 0.3021, decode.d0.loss_dice: 0.6296, decode.d1.loss_cls: 0.1037, decode.d1.loss_mask: 0.2968, decode.d1.loss_dice: 0.6287, decode.d2.loss_cls: 0.0947, decode.d2.loss_mask: 0.2949, decode.d2.loss_dice: 0.6230, decode.d3.loss_cls: 0.1102, decode.d3.loss_mask: 0.2923, decode.d3.loss_dice: 0.6332, decode.d4.loss_cls: 0.1033, decode.d4.loss_mask: 0.2982, decode.d4.loss_dice: 0.6154, decode.d5.loss_cls: 0.1074, decode.d5.loss_mask: 0.2965, decode.d5.loss_dice: 0.6187, decode.d6.loss_cls: 0.1138, decode.d6.loss_mask: 0.2981, decode.d6.loss_dice: 0.6257, decode.d7.loss_cls: 0.1076, decode.d7.loss_mask: 0.2954, decode.d7.loss_dice: 0.6193, decode.d8.loss_cls: 0.0738, decode.d8.loss_mask: 0.2978, decode.d8.loss_dice: 0.6308, loss: 10.3969
2023-09-28 11:10:07,033 - mmseg - INFO - Iter [3300/40000]	lr: 1.317e-06, eta: 1 day, 2:01:09, time: 2.247, data_time: 0.080, memory: 21542, decode.loss_cls: 0.1091, decode.loss_mask: 0.3232, decode.loss_dice: 0.6330, decode.d0.loss_cls: 0.2725, decode.d0.loss_mask: 0.3406, decode.d0.loss_dice: 0.6429, decode.d1.loss_cls: 0.1269, decode.d1.loss_mask: 0.3299, decode.d1.loss_dice: 0.6285, decode.d2.loss_cls: 0.1152, decode.d2.loss_mask: 0.3239, decode.d2.loss_dice: 0.6383, decode.d3.loss_cls: 0.1151, decode.d3.loss_mask: 0.3260, decode.d3.loss_dice: 0.6336, decode.d4.loss_cls: 0.1012, decode.d4.loss_mask: 0.3332, decode.d4.loss_dice: 0.6357, decode.d5.loss_cls: 0.0977, decode.d5.loss_mask: 0.3327, decode.d5.loss_dice: 0.6371, decode.d6.loss_cls: 0.1177, decode.d6.loss_mask: 0.3251, decode.d6.loss_dice: 0.6251, decode.d7.loss_cls: 0.1018, decode.d7.loss_mask: 0.3250, decode.d7.loss_dice: 0.6404, decode.d8.loss_cls: 0.0972, decode.d8.loss_mask: 0.3235, decode.d8.loss_dice: 0.6308, loss: 10.8829
2023-09-28 11:11:57,727 - mmseg - INFO - Iter [3350/40000]	lr: 1.316e-06, eta: 1 day, 1:55:56, time: 2.214, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0774, decode.loss_mask: 0.3084, decode.loss_dice: 0.6154, decode.d0.loss_cls: 0.2560, decode.d0.loss_mask: 0.3114, decode.d0.loss_dice: 0.6234, decode.d1.loss_cls: 0.0885, decode.d1.loss_mask: 0.3091, decode.d1.loss_dice: 0.6155, decode.d2.loss_cls: 0.0893, decode.d2.loss_mask: 0.3095, decode.d2.loss_dice: 0.6166, decode.d3.loss_cls: 0.0932, decode.d3.loss_mask: 0.3098, decode.d3.loss_dice: 0.6204, decode.d4.loss_cls: 0.0935, decode.d4.loss_mask: 0.3088, decode.d4.loss_dice: 0.6172, decode.d5.loss_cls: 0.0855, decode.d5.loss_mask: 0.3075, decode.d5.loss_dice: 0.6202, decode.d6.loss_cls: 0.0850, decode.d6.loss_mask: 0.3077, decode.d6.loss_dice: 0.6227, decode.d7.loss_cls: 0.0745, decode.d7.loss_mask: 0.3093, decode.d7.loss_dice: 0.6199, decode.d8.loss_cls: 0.0706, decode.d8.loss_mask: 0.3085, decode.d8.loss_dice: 0.6118, loss: 10.2865
2023-09-28 11:13:47,455 - mmseg - INFO - Iter [3400/40000]	lr: 1.314e-06, eta: 1 day, 1:50:39, time: 2.195, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0915, decode.loss_mask: 0.3290, decode.loss_dice: 0.6844, decode.d0.loss_cls: 0.2469, decode.d0.loss_mask: 0.3345, decode.d0.loss_dice: 0.7021, decode.d1.loss_cls: 0.1268, decode.d1.loss_mask: 0.3286, decode.d1.loss_dice: 0.6936, decode.d2.loss_cls: 0.1125, decode.d2.loss_mask: 0.3266, decode.d2.loss_dice: 0.6812, decode.d3.loss_cls: 0.1110, decode.d3.loss_mask: 0.3253, decode.d3.loss_dice: 0.6835, decode.d4.loss_cls: 0.1209, decode.d4.loss_mask: 0.3284, decode.d4.loss_dice: 0.6728, decode.d5.loss_cls: 0.1097, decode.d5.loss_mask: 0.3280, decode.d5.loss_dice: 0.6885, decode.d6.loss_cls: 0.1046, decode.d6.loss_mask: 0.3281, decode.d6.loss_dice: 0.6860, decode.d7.loss_cls: 0.0803, decode.d7.loss_mask: 0.3275, decode.d7.loss_dice: 0.6909, decode.d8.loss_cls: 0.1073, decode.d8.loss_mask: 0.3286, decode.d8.loss_dice: 0.6794, loss: 11.3583
2023-09-28 11:15:38,598 - mmseg - INFO - Iter [3450/40000]	lr: 1.312e-06, eta: 1 day, 1:45:43, time: 2.223, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0992, decode.loss_mask: 0.3209, decode.loss_dice: 0.6308, decode.d0.loss_cls: 0.2903, decode.d0.loss_mask: 0.3330, decode.d0.loss_dice: 0.6397, decode.d1.loss_cls: 0.1214, decode.d1.loss_mask: 0.3234, decode.d1.loss_dice: 0.6377, decode.d2.loss_cls: 0.1133, decode.d2.loss_mask: 0.3241, decode.d2.loss_dice: 0.6328, decode.d3.loss_cls: 0.1061, decode.d3.loss_mask: 0.3221, decode.d3.loss_dice: 0.6319, decode.d4.loss_cls: 0.1064, decode.d4.loss_mask: 0.3206, decode.d4.loss_dice: 0.6307, decode.d5.loss_cls: 0.1168, decode.d5.loss_mask: 0.3229, decode.d5.loss_dice: 0.6344, decode.d6.loss_cls: 0.1120, decode.d6.loss_mask: 0.3211, decode.d6.loss_dice: 0.6315, decode.d7.loss_cls: 0.0972, decode.d7.loss_mask: 0.3209, decode.d7.loss_dice: 0.6311, decode.d8.loss_cls: 0.0829, decode.d8.loss_mask: 0.3215, decode.d8.loss_dice: 0.6416, loss: 10.8183
2023-09-28 11:17:29,710 - mmseg - INFO - Iter [3500/40000]	lr: 1.310e-06, eta: 1 day, 1:40:51, time: 2.222, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0968, decode.loss_mask: 0.3487, decode.loss_dice: 0.6762, decode.d0.loss_cls: 0.2821, decode.d0.loss_mask: 0.3603, decode.d0.loss_dice: 0.7064, decode.d1.loss_cls: 0.1150, decode.d1.loss_mask: 0.3502, decode.d1.loss_dice: 0.6789, decode.d2.loss_cls: 0.1120, decode.d2.loss_mask: 0.3484, decode.d2.loss_dice: 0.6734, decode.d3.loss_cls: 0.0862, decode.d3.loss_mask: 0.3504, decode.d3.loss_dice: 0.6783, decode.d4.loss_cls: 0.1080, decode.d4.loss_mask: 0.3532, decode.d4.loss_dice: 0.6904, decode.d5.loss_cls: 0.1128, decode.d5.loss_mask: 0.3509, decode.d5.loss_dice: 0.6777, decode.d6.loss_cls: 0.0924, decode.d6.loss_mask: 0.3549, decode.d6.loss_dice: 0.6869, decode.d7.loss_cls: 0.1085, decode.d7.loss_mask: 0.3526, decode.d7.loss_dice: 0.6805, decode.d8.loss_cls: 0.1046, decode.d8.loss_mask: 0.3523, decode.d8.loss_dice: 0.6647, loss: 11.5536
2023-09-28 11:19:20,359 - mmseg - INFO - Iter [3550/40000]	lr: 1.308e-06, eta: 1 day, 1:36:00, time: 2.213, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0756, decode.loss_mask: 0.3431, decode.loss_dice: 0.6858, decode.d0.loss_cls: 0.2864, decode.d0.loss_mask: 0.3502, decode.d0.loss_dice: 0.7141, decode.d1.loss_cls: 0.1211, decode.d1.loss_mask: 0.3364, decode.d1.loss_dice: 0.6957, decode.d2.loss_cls: 0.0955, decode.d2.loss_mask: 0.3412, decode.d2.loss_dice: 0.6926, decode.d3.loss_cls: 0.0851, decode.d3.loss_mask: 0.3352, decode.d3.loss_dice: 0.6899, decode.d4.loss_cls: 0.0742, decode.d4.loss_mask: 0.3431, decode.d4.loss_dice: 0.6836, decode.d5.loss_cls: 0.0912, decode.d5.loss_mask: 0.3413, decode.d5.loss_dice: 0.6938, decode.d6.loss_cls: 0.0911, decode.d6.loss_mask: 0.3414, decode.d6.loss_dice: 0.6901, decode.d7.loss_cls: 0.0665, decode.d7.loss_mask: 0.3429, decode.d7.loss_dice: 0.6890, decode.d8.loss_cls: 0.0802, decode.d8.loss_mask: 0.3416, decode.d8.loss_dice: 0.6917, loss: 11.4097
2023-09-28 11:21:10,877 - mmseg - INFO - Iter [3600/40000]	lr: 1.307e-06, eta: 1 day, 1:31:13, time: 2.211, data_time: 0.034, memory: 21542, decode.loss_cls: 0.1069, decode.loss_mask: 0.3247, decode.loss_dice: 0.6430, decode.d0.loss_cls: 0.2634, decode.d0.loss_mask: 0.3366, decode.d0.loss_dice: 0.6629, decode.d1.loss_cls: 0.1080, decode.d1.loss_mask: 0.3283, decode.d1.loss_dice: 0.6482, decode.d2.loss_cls: 0.1213, decode.d2.loss_mask: 0.3261, decode.d2.loss_dice: 0.6490, decode.d3.loss_cls: 0.1191, decode.d3.loss_mask: 0.3260, decode.d3.loss_dice: 0.6446, decode.d4.loss_cls: 0.1275, decode.d4.loss_mask: 0.3285, decode.d4.loss_dice: 0.6466, decode.d5.loss_cls: 0.1233, decode.d5.loss_mask: 0.3265, decode.d5.loss_dice: 0.6448, decode.d6.loss_cls: 0.1106, decode.d6.loss_mask: 0.3246, decode.d6.loss_dice: 0.6599, decode.d7.loss_cls: 0.1249, decode.d7.loss_mask: 0.3254, decode.d7.loss_dice: 0.6454, decode.d8.loss_cls: 0.1101, decode.d8.loss_mask: 0.3253, decode.d8.loss_dice: 0.6525, loss: 11.0841
2023-09-28 11:23:00,579 - mmseg - INFO - Iter [3650/40000]	lr: 1.305e-06, eta: 1 day, 1:26:23, time: 2.194, data_time: 0.033, memory: 21542, decode.loss_cls: 0.1046, decode.loss_mask: 0.2738, decode.loss_dice: 0.6073, decode.d0.loss_cls: 0.2556, decode.d0.loss_mask: 0.2797, decode.d0.loss_dice: 0.6271, decode.d1.loss_cls: 0.1128, decode.d1.loss_mask: 0.2780, decode.d1.loss_dice: 0.6228, decode.d2.loss_cls: 0.0771, decode.d2.loss_mask: 0.2776, decode.d2.loss_dice: 0.6229, decode.d3.loss_cls: 0.0898, decode.d3.loss_mask: 0.2758, decode.d3.loss_dice: 0.6254, decode.d4.loss_cls: 0.1170, decode.d4.loss_mask: 0.2743, decode.d4.loss_dice: 0.6156, decode.d5.loss_cls: 0.1068, decode.d5.loss_mask: 0.2772, decode.d5.loss_dice: 0.6170, decode.d6.loss_cls: 0.0949, decode.d6.loss_mask: 0.2767, decode.d6.loss_dice: 0.6097, decode.d7.loss_cls: 0.1166, decode.d7.loss_mask: 0.2752, decode.d7.loss_dice: 0.6083, decode.d8.loss_cls: 0.0979, decode.d8.loss_mask: 0.2744, decode.d8.loss_dice: 0.6058, loss: 10.0976
2023-09-28 11:24:51,461 - mmseg - INFO - Iter [3700/40000]	lr: 1.303e-06, eta: 1 day, 1:21:49, time: 2.218, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0745, decode.loss_mask: 0.3027, decode.loss_dice: 0.6434, decode.d0.loss_cls: 0.2481, decode.d0.loss_mask: 0.2995, decode.d0.loss_dice: 0.6512, decode.d1.loss_cls: 0.1079, decode.d1.loss_mask: 0.2959, decode.d1.loss_dice: 0.6511, decode.d2.loss_cls: 0.0876, decode.d2.loss_mask: 0.2954, decode.d2.loss_dice: 0.6400, decode.d3.loss_cls: 0.0773, decode.d3.loss_mask: 0.2981, decode.d3.loss_dice: 0.6306, decode.d4.loss_cls: 0.0796, decode.d4.loss_mask: 0.2993, decode.d4.loss_dice: 0.6434, decode.d5.loss_cls: 0.0771, decode.d5.loss_mask: 0.2929, decode.d5.loss_dice: 0.6520, decode.d6.loss_cls: 0.0937, decode.d6.loss_mask: 0.2922, decode.d6.loss_dice: 0.6466, decode.d7.loss_cls: 0.0783, decode.d7.loss_mask: 0.3018, decode.d7.loss_dice: 0.6427, decode.d8.loss_cls: 0.0668, decode.d8.loss_mask: 0.3000, decode.d8.loss_dice: 0.6499, loss: 10.4195
2023-09-28 11:26:42,037 - mmseg - INFO - Iter [3750/40000]	lr: 1.301e-06, eta: 1 day, 1:17:16, time: 2.211, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0683, decode.loss_mask: 0.3094, decode.loss_dice: 0.6484, decode.d0.loss_cls: 0.2855, decode.d0.loss_mask: 0.3152, decode.d0.loss_dice: 0.6500, decode.d1.loss_cls: 0.0947, decode.d1.loss_mask: 0.3118, decode.d1.loss_dice: 0.6423, decode.d2.loss_cls: 0.0733, decode.d2.loss_mask: 0.3119, decode.d2.loss_dice: 0.6573, decode.d3.loss_cls: 0.0867, decode.d3.loss_mask: 0.3129, decode.d3.loss_dice: 0.6503, decode.d4.loss_cls: 0.1007, decode.d4.loss_mask: 0.3124, decode.d4.loss_dice: 0.6648, decode.d5.loss_cls: 0.1011, decode.d5.loss_mask: 0.3088, decode.d5.loss_dice: 0.6537, decode.d6.loss_cls: 0.0789, decode.d6.loss_mask: 0.3095, decode.d6.loss_dice: 0.6486, decode.d7.loss_cls: 0.0970, decode.d7.loss_mask: 0.3129, decode.d7.loss_dice: 0.6425, decode.d8.loss_cls: 0.0904, decode.d8.loss_mask: 0.3088, decode.d8.loss_dice: 0.6523, loss: 10.7006
2023-09-28 11:28:33,218 - mmseg - INFO - Iter [3800/40000]	lr: 1.299e-06, eta: 1 day, 1:12:53, time: 2.224, data_time: 0.028, memory: 21542, decode.loss_cls: 0.1116, decode.loss_mask: 0.3398, decode.loss_dice: 0.6594, decode.d0.loss_cls: 0.2545, decode.d0.loss_mask: 0.3498, decode.d0.loss_dice: 0.6851, decode.d1.loss_cls: 0.0930, decode.d1.loss_mask: 0.3399, decode.d1.loss_dice: 0.6891, decode.d2.loss_cls: 0.0927, decode.d2.loss_mask: 0.3360, decode.d2.loss_dice: 0.6707, decode.d3.loss_cls: 0.0997, decode.d3.loss_mask: 0.3396, decode.d3.loss_dice: 0.6684, decode.d4.loss_cls: 0.1003, decode.d4.loss_mask: 0.3398, decode.d4.loss_dice: 0.6812, decode.d5.loss_cls: 0.1004, decode.d5.loss_mask: 0.3381, decode.d5.loss_dice: 0.6710, decode.d6.loss_cls: 0.1061, decode.d6.loss_mask: 0.3414, decode.d6.loss_dice: 0.6722, decode.d7.loss_cls: 0.0978, decode.d7.loss_mask: 0.3397, decode.d7.loss_dice: 0.6643, decode.d8.loss_cls: 0.0994, decode.d8.loss_mask: 0.3397, decode.d8.loss_dice: 0.6778, loss: 11.2986
2023-09-28 11:30:23,894 - mmseg - INFO - Iter [3850/40000]	lr: 1.298e-06, eta: 1 day, 1:08:30, time: 2.214, data_time: 0.031, memory: 21542, decode.loss_cls: 0.1027, decode.loss_mask: 0.3231, decode.loss_dice: 0.6600, decode.d0.loss_cls: 0.2454, decode.d0.loss_mask: 0.3342, decode.d0.loss_dice: 0.6751, decode.d1.loss_cls: 0.1250, decode.d1.loss_mask: 0.3228, decode.d1.loss_dice: 0.6595, decode.d2.loss_cls: 0.1075, decode.d2.loss_mask: 0.3226, decode.d2.loss_dice: 0.6617, decode.d3.loss_cls: 0.1239, decode.d3.loss_mask: 0.3225, decode.d3.loss_dice: 0.6571, decode.d4.loss_cls: 0.1310, decode.d4.loss_mask: 0.3222, decode.d4.loss_dice: 0.6559, decode.d5.loss_cls: 0.0980, decode.d5.loss_mask: 0.3239, decode.d5.loss_dice: 0.6680, decode.d6.loss_cls: 0.1070, decode.d6.loss_mask: 0.3239, decode.d6.loss_dice: 0.6586, decode.d7.loss_cls: 0.1220, decode.d7.loss_mask: 0.3215, decode.d7.loss_dice: 0.6685, decode.d8.loss_cls: 0.1212, decode.d8.loss_mask: 0.3208, decode.d8.loss_dice: 0.6595, loss: 11.1449
2023-09-28 11:32:14,982 - mmseg - INFO - Iter [3900/40000]	lr: 1.296e-06, eta: 1 day, 1:04:14, time: 2.222, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0825, decode.loss_mask: 0.3019, decode.loss_dice: 0.6259, decode.d0.loss_cls: 0.2580, decode.d0.loss_mask: 0.3121, decode.d0.loss_dice: 0.6554, decode.d1.loss_cls: 0.1107, decode.d1.loss_mask: 0.3052, decode.d1.loss_dice: 0.6628, decode.d2.loss_cls: 0.1018, decode.d2.loss_mask: 0.3023, decode.d2.loss_dice: 0.6470, decode.d3.loss_cls: 0.1029, decode.d3.loss_mask: 0.3039, decode.d3.loss_dice: 0.6343, decode.d4.loss_cls: 0.0986, decode.d4.loss_mask: 0.3036, decode.d4.loss_dice: 0.6448, decode.d5.loss_cls: 0.0932, decode.d5.loss_mask: 0.3041, decode.d5.loss_dice: 0.6507, decode.d6.loss_cls: 0.0875, decode.d6.loss_mask: 0.3029, decode.d6.loss_dice: 0.6456, decode.d7.loss_cls: 0.1030, decode.d7.loss_mask: 0.3024, decode.d7.loss_dice: 0.6406, decode.d8.loss_cls: 0.0942, decode.d8.loss_mask: 0.3027, decode.d8.loss_dice: 0.6403, loss: 10.6211
2023-09-28 11:34:05,414 - mmseg - INFO - Iter [3950/40000]	lr: 1.294e-06, eta: 1 day, 0:59:56, time: 2.208, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0863, decode.loss_mask: 0.3146, decode.loss_dice: 0.6086, decode.d0.loss_cls: 0.2818, decode.d0.loss_mask: 0.3220, decode.d0.loss_dice: 0.6234, decode.d1.loss_cls: 0.0858, decode.d1.loss_mask: 0.3151, decode.d1.loss_dice: 0.6233, decode.d2.loss_cls: 0.1072, decode.d2.loss_mask: 0.3146, decode.d2.loss_dice: 0.6136, decode.d3.loss_cls: 0.1141, decode.d3.loss_mask: 0.3174, decode.d3.loss_dice: 0.6126, decode.d4.loss_cls: 0.0712, decode.d4.loss_mask: 0.3194, decode.d4.loss_dice: 0.6260, decode.d5.loss_cls: 0.0783, decode.d5.loss_mask: 0.3177, decode.d5.loss_dice: 0.6178, decode.d6.loss_cls: 0.0797, decode.d6.loss_mask: 0.3139, decode.d6.loss_dice: 0.6121, decode.d7.loss_cls: 0.0886, decode.d7.loss_mask: 0.3151, decode.d7.loss_dice: 0.6274, decode.d8.loss_cls: 0.0968, decode.d8.loss_mask: 0.3149, decode.d8.loss_dice: 0.6093, loss: 10.4285
2023-09-28 11:35:56,681 - mmseg - INFO - Saving checkpoint at 4000 iterations
2023-09-28 11:36:16,431 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 11:36:16,432 - mmseg - INFO - Iter [4000/40000]	lr: 1.292e-06, eta: 1 day, 0:58:47, time: 2.621, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0888, decode.loss_mask: 0.3258, decode.loss_dice: 0.6590, decode.d0.loss_cls: 0.2820, decode.d0.loss_mask: 0.3321, decode.d0.loss_dice: 0.6734, decode.d1.loss_cls: 0.1102, decode.d1.loss_mask: 0.3294, decode.d1.loss_dice: 0.6586, decode.d2.loss_cls: 0.1006, decode.d2.loss_mask: 0.3311, decode.d2.loss_dice: 0.6546, decode.d3.loss_cls: 0.1059, decode.d3.loss_mask: 0.3313, decode.d3.loss_dice: 0.6644, decode.d4.loss_cls: 0.1048, decode.d4.loss_mask: 0.3254, decode.d4.loss_dice: 0.6667, decode.d5.loss_cls: 0.1253, decode.d5.loss_mask: 0.3262, decode.d5.loss_dice: 0.6596, decode.d6.loss_cls: 0.1106, decode.d6.loss_mask: 0.3285, decode.d6.loss_dice: 0.6643, decode.d7.loss_cls: 0.0929, decode.d7.loss_mask: 0.3283, decode.d7.loss_dice: 0.6590, decode.d8.loss_cls: 0.0987, decode.d8.loss_mask: 0.3272, decode.d8.loss_dice: 0.6657, loss: 11.1303
2023-09-28 11:53:15,142 - mmseg - INFO - per class results:
2023-09-28 11:53:15,143 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 92.91 | 96.16 |
|    Sidewalk   | 65.81 | 84.17 |
|  Construction | 81.38 | 94.12 |
|     Fence     | 30.27 | 33.43 |
|      Pole     | 54.07 | 72.68 |
| Traffic Light | 67.67 | 78.17 |
|  Traffic Sign | 73.33 |  82.0 |
|     Nature    |  88.4 | 93.96 |
|      Sky      | 96.56 |  97.7 |
|     Person    |  34.2 | 37.46 |
|     Rider     |  9.28 | 71.35 |
|      Car      | 91.78 | 94.87 |
|   background  | 95.64 | 98.22 |
+---------------+-------+-------+
2023-09-28 11:53:15,144 - mmseg - INFO - Summary:
2023-09-28 11:53:15,144 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.25 | 67.79 | 79.56 |
+-------+-------+-------+
2023-09-28 11:53:15,146 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 11:53:15,146 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9425, mIoU: 0.6779, mAcc: 0.7956, IoU.Road: 0.9291, IoU.Sidewalk: 0.6581, IoU.Construction: 0.8138, IoU.Fence: 0.3027, IoU.Pole: 0.5407, IoU.Traffic Light: 0.6767, IoU.Traffic Sign: 0.7333, IoU.Nature: 0.8840, IoU.Sky: 0.9656, IoU.Person: 0.3420, IoU.Rider: 0.0928, IoU.Car: 0.9178, IoU.background: 0.9564, Acc.Road: 0.9616, Acc.Sidewalk: 0.8417, Acc.Construction: 0.9412, Acc.Fence: 0.3343, Acc.Pole: 0.7268, Acc.Traffic Light: 0.7817, Acc.Traffic Sign: 0.8200, Acc.Nature: 0.9396, Acc.Sky: 0.9770, Acc.Person: 0.3746, Acc.Rider: 0.7135, Acc.Car: 0.9487, Acc.background: 0.9822
2023-09-28 11:55:05,858 - mmseg - INFO - Iter [4050/40000]	lr: 1.290e-06, eta: 1 day, 3:25:19, time: 22.588, data_time: 20.408, memory: 21542, decode.loss_cls: 0.0837, decode.loss_mask: 0.3533, decode.loss_dice: 0.6722, decode.d0.loss_cls: 0.2332, decode.d0.loss_mask: 0.3565, decode.d0.loss_dice: 0.6889, decode.d1.loss_cls: 0.1191, decode.d1.loss_mask: 0.3532, decode.d1.loss_dice: 0.6877, decode.d2.loss_cls: 0.0852, decode.d2.loss_mask: 0.3532, decode.d2.loss_dice: 0.6867, decode.d3.loss_cls: 0.1068, decode.d3.loss_mask: 0.3520, decode.d3.loss_dice: 0.6773, decode.d4.loss_cls: 0.0830, decode.d4.loss_mask: 0.3535, decode.d4.loss_dice: 0.6842, decode.d5.loss_cls: 0.0775, decode.d5.loss_mask: 0.3534, decode.d5.loss_dice: 0.6744, decode.d6.loss_cls: 0.0718, decode.d6.loss_mask: 0.3575, decode.d6.loss_dice: 0.6819, decode.d7.loss_cls: 0.0950, decode.d7.loss_mask: 0.3556, decode.d7.loss_dice: 0.6781, decode.d8.loss_cls: 0.1068, decode.d8.loss_mask: 0.3530, decode.d8.loss_dice: 0.6699, loss: 11.4047
2023-09-28 11:56:56,084 - mmseg - INFO - Iter [4100/40000]	lr: 1.289e-06, eta: 1 day, 3:19:05, time: 2.204, data_time: 0.035, memory: 21542, decode.loss_cls: 0.0604, decode.loss_mask: 0.2968, decode.loss_dice: 0.5788, decode.d0.loss_cls: 0.2485, decode.d0.loss_mask: 0.2984, decode.d0.loss_dice: 0.5867, decode.d1.loss_cls: 0.0851, decode.d1.loss_mask: 0.3010, decode.d1.loss_dice: 0.5836, decode.d2.loss_cls: 0.0761, decode.d2.loss_mask: 0.2989, decode.d2.loss_dice: 0.5814, decode.d3.loss_cls: 0.0776, decode.d3.loss_mask: 0.2957, decode.d3.loss_dice: 0.5787, decode.d4.loss_cls: 0.0716, decode.d4.loss_mask: 0.2951, decode.d4.loss_dice: 0.5742, decode.d5.loss_cls: 0.0730, decode.d5.loss_mask: 0.2962, decode.d5.loss_dice: 0.5780, decode.d6.loss_cls: 0.0520, decode.d6.loss_mask: 0.2954, decode.d6.loss_dice: 0.5787, decode.d7.loss_cls: 0.0665, decode.d7.loss_mask: 0.2941, decode.d7.loss_dice: 0.5716, decode.d8.loss_cls: 0.0820, decode.d8.loss_mask: 0.2965, decode.d8.loss_dice: 0.5701, loss: 9.6427
2023-09-28 11:58:45,614 - mmseg - INFO - Iter [4150/40000]	lr: 1.287e-06, eta: 1 day, 3:12:51, time: 2.191, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0688, decode.loss_mask: 0.2972, decode.loss_dice: 0.6338, decode.d0.loss_cls: 0.2581, decode.d0.loss_mask: 0.2985, decode.d0.loss_dice: 0.6370, decode.d1.loss_cls: 0.0786, decode.d1.loss_mask: 0.2967, decode.d1.loss_dice: 0.6442, decode.d2.loss_cls: 0.0590, decode.d2.loss_mask: 0.2955, decode.d2.loss_dice: 0.6385, decode.d3.loss_cls: 0.0946, decode.d3.loss_mask: 0.2963, decode.d3.loss_dice: 0.6375, decode.d4.loss_cls: 0.0779, decode.d4.loss_mask: 0.2994, decode.d4.loss_dice: 0.6459, decode.d5.loss_cls: 0.0665, decode.d5.loss_mask: 0.2956, decode.d5.loss_dice: 0.6466, decode.d6.loss_cls: 0.0849, decode.d6.loss_mask: 0.2958, decode.d6.loss_dice: 0.6336, decode.d7.loss_cls: 0.0719, decode.d7.loss_mask: 0.2962, decode.d7.loss_dice: 0.6457, decode.d8.loss_cls: 0.0780, decode.d8.loss_mask: 0.2962, decode.d8.loss_dice: 0.6376, loss: 10.3060
2023-09-28 12:00:36,659 - mmseg - INFO - Iter [4200/40000]	lr: 1.285e-06, eta: 1 day, 3:06:56, time: 2.221, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0900, decode.loss_mask: 0.3004, decode.loss_dice: 0.5895, decode.d0.loss_cls: 0.2943, decode.d0.loss_mask: 0.3052, decode.d0.loss_dice: 0.5995, decode.d1.loss_cls: 0.0935, decode.d1.loss_mask: 0.3012, decode.d1.loss_dice: 0.6139, decode.d2.loss_cls: 0.0870, decode.d2.loss_mask: 0.3008, decode.d2.loss_dice: 0.6035, decode.d3.loss_cls: 0.0941, decode.d3.loss_mask: 0.2984, decode.d3.loss_dice: 0.5953, decode.d4.loss_cls: 0.0969, decode.d4.loss_mask: 0.3006, decode.d4.loss_dice: 0.6038, decode.d5.loss_cls: 0.0764, decode.d5.loss_mask: 0.3006, decode.d5.loss_dice: 0.5967, decode.d6.loss_cls: 0.0881, decode.d6.loss_mask: 0.3025, decode.d6.loss_dice: 0.6033, decode.d7.loss_cls: 0.0812, decode.d7.loss_mask: 0.3026, decode.d7.loss_dice: 0.5948, decode.d8.loss_cls: 0.0886, decode.d8.loss_mask: 0.3023, decode.d8.loss_dice: 0.6050, loss: 10.1100
2023-09-28 12:02:27,948 - mmseg - INFO - Iter [4250/40000]	lr: 1.283e-06, eta: 1 day, 3:01:08, time: 2.225, data_time: 0.032, memory: 21542, decode.loss_cls: 0.1133, decode.loss_mask: 0.2794, decode.loss_dice: 0.6497, decode.d0.loss_cls: 0.2881, decode.d0.loss_mask: 0.2848, decode.d0.loss_dice: 0.6522, decode.d1.loss_cls: 0.1291, decode.d1.loss_mask: 0.2814, decode.d1.loss_dice: 0.6487, decode.d2.loss_cls: 0.1041, decode.d2.loss_mask: 0.2807, decode.d2.loss_dice: 0.6556, decode.d3.loss_cls: 0.1189, decode.d3.loss_mask: 0.2800, decode.d3.loss_dice: 0.6332, decode.d4.loss_cls: 0.1164, decode.d4.loss_mask: 0.2806, decode.d4.loss_dice: 0.6407, decode.d5.loss_cls: 0.1362, decode.d5.loss_mask: 0.2819, decode.d5.loss_dice: 0.6381, decode.d6.loss_cls: 0.1221, decode.d6.loss_mask: 0.2803, decode.d6.loss_dice: 0.6399, decode.d7.loss_cls: 0.1174, decode.d7.loss_mask: 0.2813, decode.d7.loss_dice: 0.6522, decode.d8.loss_cls: 0.1115, decode.d8.loss_mask: 0.2806, decode.d8.loss_dice: 0.6439, loss: 10.6222
2023-09-28 12:04:18,941 - mmseg - INFO - Iter [4300/40000]	lr: 1.281e-06, eta: 1 day, 2:55:25, time: 2.221, data_time: 0.027, memory: 21542, decode.loss_cls: 0.1034, decode.loss_mask: 0.3112, decode.loss_dice: 0.6670, decode.d0.loss_cls: 0.2799, decode.d0.loss_mask: 0.3174, decode.d0.loss_dice: 0.6806, decode.d1.loss_cls: 0.1260, decode.d1.loss_mask: 0.3083, decode.d1.loss_dice: 0.6736, decode.d2.loss_cls: 0.1120, decode.d2.loss_mask: 0.3106, decode.d2.loss_dice: 0.6737, decode.d3.loss_cls: 0.1259, decode.d3.loss_mask: 0.3096, decode.d3.loss_dice: 0.6661, decode.d4.loss_cls: 0.1408, decode.d4.loss_mask: 0.3106, decode.d4.loss_dice: 0.6583, decode.d5.loss_cls: 0.1345, decode.d5.loss_mask: 0.3094, decode.d5.loss_dice: 0.6560, decode.d6.loss_cls: 0.1363, decode.d6.loss_mask: 0.3092, decode.d6.loss_dice: 0.6673, decode.d7.loss_cls: 0.1217, decode.d7.loss_mask: 0.3090, decode.d7.loss_dice: 0.6766, decode.d8.loss_cls: 0.1126, decode.d8.loss_mask: 0.3106, decode.d8.loss_dice: 0.6699, loss: 11.1880
2023-09-28 12:06:09,176 - mmseg - INFO - Iter [4350/40000]	lr: 1.280e-06, eta: 1 day, 2:49:40, time: 2.205, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0938, decode.loss_mask: 0.3301, decode.loss_dice: 0.6692, decode.d0.loss_cls: 0.2777, decode.d0.loss_mask: 0.3470, decode.d0.loss_dice: 0.6850, decode.d1.loss_cls: 0.1364, decode.d1.loss_mask: 0.3305, decode.d1.loss_dice: 0.6684, decode.d2.loss_cls: 0.1084, decode.d2.loss_mask: 0.3307, decode.d2.loss_dice: 0.6784, decode.d3.loss_cls: 0.0996, decode.d3.loss_mask: 0.3294, decode.d3.loss_dice: 0.6747, decode.d4.loss_cls: 0.1097, decode.d4.loss_mask: 0.3338, decode.d4.loss_dice: 0.6646, decode.d5.loss_cls: 0.0906, decode.d5.loss_mask: 0.3295, decode.d5.loss_dice: 0.6810, decode.d6.loss_cls: 0.0984, decode.d6.loss_mask: 0.3281, decode.d6.loss_dice: 0.6680, decode.d7.loss_cls: 0.1135, decode.d7.loss_mask: 0.3298, decode.d7.loss_dice: 0.6766, decode.d8.loss_cls: 0.0980, decode.d8.loss_mask: 0.3318, decode.d8.loss_dice: 0.6708, loss: 11.2835
2023-09-28 12:08:01,749 - mmseg - INFO - Iter [4400/40000]	lr: 1.278e-06, eta: 1 day, 2:44:19, time: 2.251, data_time: 0.079, memory: 21542, decode.loss_cls: 0.0763, decode.loss_mask: 0.3152, decode.loss_dice: 0.6676, decode.d0.loss_cls: 0.2562, decode.d0.loss_mask: 0.3187, decode.d0.loss_dice: 0.6781, decode.d1.loss_cls: 0.1107, decode.d1.loss_mask: 0.3156, decode.d1.loss_dice: 0.6804, decode.d2.loss_cls: 0.1114, decode.d2.loss_mask: 0.3150, decode.d2.loss_dice: 0.6677, decode.d3.loss_cls: 0.0990, decode.d3.loss_mask: 0.3174, decode.d3.loss_dice: 0.6707, decode.d4.loss_cls: 0.1144, decode.d4.loss_mask: 0.3151, decode.d4.loss_dice: 0.6715, decode.d5.loss_cls: 0.0832, decode.d5.loss_mask: 0.3165, decode.d5.loss_dice: 0.6720, decode.d6.loss_cls: 0.1008, decode.d6.loss_mask: 0.3175, decode.d6.loss_dice: 0.6505, decode.d7.loss_cls: 0.0972, decode.d7.loss_mask: 0.3143, decode.d7.loss_dice: 0.6632, decode.d8.loss_cls: 0.0829, decode.d8.loss_mask: 0.3159, decode.d8.loss_dice: 0.6663, loss: 10.9813
2023-09-28 12:09:52,743 - mmseg - INFO - Iter [4450/40000]	lr: 1.276e-06, eta: 1 day, 2:38:50, time: 2.218, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0561, decode.loss_mask: 0.3057, decode.loss_dice: 0.6039, decode.d0.loss_cls: 0.2735, decode.d0.loss_mask: 0.3182, decode.d0.loss_dice: 0.6275, decode.d1.loss_cls: 0.0964, decode.d1.loss_mask: 0.3090, decode.d1.loss_dice: 0.6159, decode.d2.loss_cls: 0.0868, decode.d2.loss_mask: 0.3080, decode.d2.loss_dice: 0.6138, decode.d3.loss_cls: 0.0865, decode.d3.loss_mask: 0.3063, decode.d3.loss_dice: 0.6159, decode.d4.loss_cls: 0.0870, decode.d4.loss_mask: 0.3081, decode.d4.loss_dice: 0.6045, decode.d5.loss_cls: 0.0889, decode.d5.loss_mask: 0.3068, decode.d5.loss_dice: 0.6094, decode.d6.loss_cls: 0.0777, decode.d6.loss_mask: 0.3062, decode.d6.loss_dice: 0.6109, decode.d7.loss_cls: 0.0556, decode.d7.loss_mask: 0.3060, decode.d7.loss_dice: 0.6024, decode.d8.loss_cls: 0.0883, decode.d8.loss_mask: 0.3045, decode.d8.loss_dice: 0.6132, loss: 10.1928
2023-09-28 12:11:42,985 - mmseg - INFO - Iter [4500/40000]	lr: 1.274e-06, eta: 1 day, 2:33:21, time: 2.207, data_time: 0.034, memory: 21542, decode.loss_cls: 0.1031, decode.loss_mask: 0.3317, decode.loss_dice: 0.6554, decode.d0.loss_cls: 0.2960, decode.d0.loss_mask: 0.3393, decode.d0.loss_dice: 0.6777, decode.d1.loss_cls: 0.1173, decode.d1.loss_mask: 0.3332, decode.d1.loss_dice: 0.6577, decode.d2.loss_cls: 0.1121, decode.d2.loss_mask: 0.3306, decode.d2.loss_dice: 0.6692, decode.d3.loss_cls: 0.1015, decode.d3.loss_mask: 0.3352, decode.d3.loss_dice: 0.6628, decode.d4.loss_cls: 0.1224, decode.d4.loss_mask: 0.3328, decode.d4.loss_dice: 0.6639, decode.d5.loss_cls: 0.0875, decode.d5.loss_mask: 0.3361, decode.d5.loss_dice: 0.6805, decode.d6.loss_cls: 0.1160, decode.d6.loss_mask: 0.3300, decode.d6.loss_dice: 0.6608, decode.d7.loss_cls: 0.1163, decode.d7.loss_mask: 0.3326, decode.d7.loss_dice: 0.6635, decode.d8.loss_cls: 0.1097, decode.d8.loss_mask: 0.3281, decode.d8.loss_dice: 0.6566, loss: 11.2596
2023-09-28 12:13:34,058 - mmseg - INFO - Iter [4550/40000]	lr: 1.273e-06, eta: 1 day, 2:28:03, time: 2.221, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0720, decode.loss_mask: 0.2864, decode.loss_dice: 0.6149, decode.d0.loss_cls: 0.2264, decode.d0.loss_mask: 0.2945, decode.d0.loss_dice: 0.6151, decode.d1.loss_cls: 0.0719, decode.d1.loss_mask: 0.2875, decode.d1.loss_dice: 0.6202, decode.d2.loss_cls: 0.0945, decode.d2.loss_mask: 0.2873, decode.d2.loss_dice: 0.6160, decode.d3.loss_cls: 0.0699, decode.d3.loss_mask: 0.2858, decode.d3.loss_dice: 0.6091, decode.d4.loss_cls: 0.0723, decode.d4.loss_mask: 0.2868, decode.d4.loss_dice: 0.6062, decode.d5.loss_cls: 0.0698, decode.d5.loss_mask: 0.2861, decode.d5.loss_dice: 0.6082, decode.d6.loss_cls: 0.0755, decode.d6.loss_mask: 0.2879, decode.d6.loss_dice: 0.6037, decode.d7.loss_cls: 0.0906, decode.d7.loss_mask: 0.2883, decode.d7.loss_dice: 0.6129, decode.d8.loss_cls: 0.0844, decode.d8.loss_mask: 0.2864, decode.d8.loss_dice: 0.5982, loss: 9.9088
2023-09-28 12:15:24,229 - mmseg - INFO - Iter [4600/40000]	lr: 1.271e-06, eta: 1 day, 2:22:42, time: 2.203, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0808, decode.loss_mask: 0.2932, decode.loss_dice: 0.6361, decode.d0.loss_cls: 0.2548, decode.d0.loss_mask: 0.2978, decode.d0.loss_dice: 0.6512, decode.d1.loss_cls: 0.1215, decode.d1.loss_mask: 0.2967, decode.d1.loss_dice: 0.6443, decode.d2.loss_cls: 0.1011, decode.d2.loss_mask: 0.2966, decode.d2.loss_dice: 0.6460, decode.d3.loss_cls: 0.0981, decode.d3.loss_mask: 0.2944, decode.d3.loss_dice: 0.6344, decode.d4.loss_cls: 0.0929, decode.d4.loss_mask: 0.2938, decode.d4.loss_dice: 0.6412, decode.d5.loss_cls: 0.0813, decode.d5.loss_mask: 0.2932, decode.d5.loss_dice: 0.6348, decode.d6.loss_cls: 0.0833, decode.d6.loss_mask: 0.2940, decode.d6.loss_dice: 0.6405, decode.d7.loss_cls: 0.0962, decode.d7.loss_mask: 0.2908, decode.d7.loss_dice: 0.6368, decode.d8.loss_cls: 0.0687, decode.d8.loss_mask: 0.2925, decode.d8.loss_dice: 0.6410, loss: 10.4281
2023-09-28 12:17:13,984 - mmseg - INFO - Iter [4650/40000]	lr: 1.269e-06, eta: 1 day, 2:17:22, time: 2.195, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0987, decode.loss_mask: 0.3256, decode.loss_dice: 0.6582, decode.d0.loss_cls: 0.2314, decode.d0.loss_mask: 0.3294, decode.d0.loss_dice: 0.6607, decode.d1.loss_cls: 0.0806, decode.d1.loss_mask: 0.3261, decode.d1.loss_dice: 0.6684, decode.d2.loss_cls: 0.0819, decode.d2.loss_mask: 0.3253, decode.d2.loss_dice: 0.6632, decode.d3.loss_cls: 0.1091, decode.d3.loss_mask: 0.3220, decode.d3.loss_dice: 0.6544, decode.d4.loss_cls: 0.0926, decode.d4.loss_mask: 0.3248, decode.d4.loss_dice: 0.6607, decode.d5.loss_cls: 0.0875, decode.d5.loss_mask: 0.3267, decode.d5.loss_dice: 0.6595, decode.d6.loss_cls: 0.0898, decode.d6.loss_mask: 0.3272, decode.d6.loss_dice: 0.6615, decode.d7.loss_cls: 0.1038, decode.d7.loss_mask: 0.3253, decode.d7.loss_dice: 0.6585, decode.d8.loss_cls: 0.0918, decode.d8.loss_mask: 0.3263, decode.d8.loss_dice: 0.6471, loss: 10.9180
2023-09-28 12:19:04,822 - mmseg - INFO - Iter [4700/40000]	lr: 1.267e-06, eta: 1 day, 2:12:16, time: 2.217, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0551, decode.loss_mask: 0.2962, decode.loss_dice: 0.5853, decode.d0.loss_cls: 0.2307, decode.d0.loss_mask: 0.2985, decode.d0.loss_dice: 0.5901, decode.d1.loss_cls: 0.0915, decode.d1.loss_mask: 0.2966, decode.d1.loss_dice: 0.5864, decode.d2.loss_cls: 0.0637, decode.d2.loss_mask: 0.2980, decode.d2.loss_dice: 0.5867, decode.d3.loss_cls: 0.0648, decode.d3.loss_mask: 0.2948, decode.d3.loss_dice: 0.5937, decode.d4.loss_cls: 0.0707, decode.d4.loss_mask: 0.2973, decode.d4.loss_dice: 0.5804, decode.d5.loss_cls: 0.0603, decode.d5.loss_mask: 0.2985, decode.d5.loss_dice: 0.5814, decode.d6.loss_cls: 0.0644, decode.d6.loss_mask: 0.2971, decode.d6.loss_dice: 0.5871, decode.d7.loss_cls: 0.0626, decode.d7.loss_mask: 0.2996, decode.d7.loss_dice: 0.5858, decode.d8.loss_cls: 0.0675, decode.d8.loss_mask: 0.2983, decode.d8.loss_dice: 0.5791, loss: 9.6623
2023-09-28 12:20:54,232 - mmseg - INFO - Iter [4750/40000]	lr: 1.265e-06, eta: 1 day, 2:07:02, time: 2.188, data_time: 0.034, memory: 21542, decode.loss_cls: 0.1131, decode.loss_mask: 0.2971, decode.loss_dice: 0.6503, decode.d0.loss_cls: 0.2808, decode.d0.loss_mask: 0.2982, decode.d0.loss_dice: 0.6723, decode.d1.loss_cls: 0.1094, decode.d1.loss_mask: 0.3007, decode.d1.loss_dice: 0.6558, decode.d2.loss_cls: 0.1407, decode.d2.loss_mask: 0.3008, decode.d2.loss_dice: 0.6492, decode.d3.loss_cls: 0.1035, decode.d3.loss_mask: 0.2990, decode.d3.loss_dice: 0.6507, decode.d4.loss_cls: 0.0962, decode.d4.loss_mask: 0.2996, decode.d4.loss_dice: 0.6483, decode.d5.loss_cls: 0.1096, decode.d5.loss_mask: 0.2990, decode.d5.loss_dice: 0.6533, decode.d6.loss_cls: 0.1034, decode.d6.loss_mask: 0.2981, decode.d6.loss_dice: 0.6551, decode.d7.loss_cls: 0.1065, decode.d7.loss_mask: 0.2999, decode.d7.loss_dice: 0.6491, decode.d8.loss_cls: 0.0880, decode.d8.loss_mask: 0.2992, decode.d8.loss_dice: 0.6458, loss: 10.7725
2023-09-28 12:22:45,405 - mmseg - INFO - Iter [4800/40000]	lr: 1.264e-06, eta: 1 day, 2:02:06, time: 2.223, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0919, decode.loss_mask: 0.3099, decode.loss_dice: 0.6200, decode.d0.loss_cls: 0.2713, decode.d0.loss_mask: 0.3165, decode.d0.loss_dice: 0.6380, decode.d1.loss_cls: 0.1300, decode.d1.loss_mask: 0.3142, decode.d1.loss_dice: 0.6127, decode.d2.loss_cls: 0.0900, decode.d2.loss_mask: 0.3131, decode.d2.loss_dice: 0.6182, decode.d3.loss_cls: 0.0942, decode.d3.loss_mask: 0.3087, decode.d3.loss_dice: 0.6218, decode.d4.loss_cls: 0.0911, decode.d4.loss_mask: 0.3126, decode.d4.loss_dice: 0.6159, decode.d5.loss_cls: 0.1089, decode.d5.loss_mask: 0.3107, decode.d5.loss_dice: 0.6217, decode.d6.loss_cls: 0.0996, decode.d6.loss_mask: 0.3047, decode.d6.loss_dice: 0.6182, decode.d7.loss_cls: 0.0869, decode.d7.loss_mask: 0.3112, decode.d7.loss_dice: 0.6198, decode.d8.loss_cls: 0.1079, decode.d8.loss_mask: 0.3072, decode.d8.loss_dice: 0.6156, loss: 10.4825
2023-09-28 12:24:35,555 - mmseg - INFO - Iter [4850/40000]	lr: 1.262e-06, eta: 1 day, 1:57:07, time: 2.203, data_time: 0.035, memory: 21542, decode.loss_cls: 0.1064, decode.loss_mask: 0.3059, decode.loss_dice: 0.5865, decode.d0.loss_cls: 0.2567, decode.d0.loss_mask: 0.3134, decode.d0.loss_dice: 0.6138, decode.d1.loss_cls: 0.0984, decode.d1.loss_mask: 0.3099, decode.d1.loss_dice: 0.6197, decode.d2.loss_cls: 0.1168, decode.d2.loss_mask: 0.3056, decode.d2.loss_dice: 0.6140, decode.d3.loss_cls: 0.0993, decode.d3.loss_mask: 0.3047, decode.d3.loss_dice: 0.5991, decode.d4.loss_cls: 0.1014, decode.d4.loss_mask: 0.3047, decode.d4.loss_dice: 0.6054, decode.d5.loss_cls: 0.1197, decode.d5.loss_mask: 0.3062, decode.d5.loss_dice: 0.6064, decode.d6.loss_cls: 0.1196, decode.d6.loss_mask: 0.3048, decode.d6.loss_dice: 0.6043, decode.d7.loss_cls: 0.1340, decode.d7.loss_mask: 0.3083, decode.d7.loss_dice: 0.6134, decode.d8.loss_cls: 0.1166, decode.d8.loss_mask: 0.3052, decode.d8.loss_dice: 0.6027, loss: 10.4029
2023-09-28 12:26:26,483 - mmseg - INFO - Iter [4900/40000]	lr: 1.260e-06, eta: 1 day, 1:52:16, time: 2.219, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0905, decode.loss_mask: 0.3444, decode.loss_dice: 0.6859, decode.d0.loss_cls: 0.2433, decode.d0.loss_mask: 0.3521, decode.d0.loss_dice: 0.6673, decode.d1.loss_cls: 0.1087, decode.d1.loss_mask: 0.3470, decode.d1.loss_dice: 0.6807, decode.d2.loss_cls: 0.1103, decode.d2.loss_mask: 0.3446, decode.d2.loss_dice: 0.6765, decode.d3.loss_cls: 0.1017, decode.d3.loss_mask: 0.3475, decode.d3.loss_dice: 0.6809, decode.d4.loss_cls: 0.1065, decode.d4.loss_mask: 0.3449, decode.d4.loss_dice: 0.6802, decode.d5.loss_cls: 0.0931, decode.d5.loss_mask: 0.3415, decode.d5.loss_dice: 0.6869, decode.d6.loss_cls: 0.0828, decode.d6.loss_mask: 0.3509, decode.d6.loss_dice: 0.6926, decode.d7.loss_cls: 0.0938, decode.d7.loss_mask: 0.3428, decode.d7.loss_dice: 0.6778, decode.d8.loss_cls: 0.1029, decode.d8.loss_mask: 0.3502, decode.d8.loss_dice: 0.6957, loss: 11.4239
2023-09-28 12:28:17,464 - mmseg - INFO - Iter [4950/40000]	lr: 1.258e-06, eta: 1 day, 1:47:30, time: 2.218, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0738, decode.loss_mask: 0.3110, decode.loss_dice: 0.6252, decode.d0.loss_cls: 0.2690, decode.d0.loss_mask: 0.3151, decode.d0.loss_dice: 0.6473, decode.d1.loss_cls: 0.0856, decode.d1.loss_mask: 0.3117, decode.d1.loss_dice: 0.6251, decode.d2.loss_cls: 0.0850, decode.d2.loss_mask: 0.3081, decode.d2.loss_dice: 0.6213, decode.d3.loss_cls: 0.0869, decode.d3.loss_mask: 0.3083, decode.d3.loss_dice: 0.6238, decode.d4.loss_cls: 0.1121, decode.d4.loss_mask: 0.3076, decode.d4.loss_dice: 0.6175, decode.d5.loss_cls: 0.0864, decode.d5.loss_mask: 0.3088, decode.d5.loss_dice: 0.6187, decode.d6.loss_cls: 0.0897, decode.d6.loss_mask: 0.3085, decode.d6.loss_dice: 0.6169, decode.d7.loss_cls: 0.0756, decode.d7.loss_mask: 0.3116, decode.d7.loss_dice: 0.6242, decode.d8.loss_cls: 0.0881, decode.d8.loss_mask: 0.3085, decode.d8.loss_dice: 0.6131, loss: 10.3844
2023-09-28 12:30:08,675 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 12:30:08,675 - mmseg - INFO - Iter [5000/40000]	lr: 1.256e-06, eta: 1 day, 1:42:49, time: 2.225, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0788, decode.loss_mask: 0.3026, decode.loss_dice: 0.6437, decode.d0.loss_cls: 0.2656, decode.d0.loss_mask: 0.3047, decode.d0.loss_dice: 0.6516, decode.d1.loss_cls: 0.1172, decode.d1.loss_mask: 0.3008, decode.d1.loss_dice: 0.6528, decode.d2.loss_cls: 0.1025, decode.d2.loss_mask: 0.3038, decode.d2.loss_dice: 0.6388, decode.d3.loss_cls: 0.0881, decode.d3.loss_mask: 0.2967, decode.d3.loss_dice: 0.6351, decode.d4.loss_cls: 0.0771, decode.d4.loss_mask: 0.3035, decode.d4.loss_dice: 0.6386, decode.d5.loss_cls: 0.1092, decode.d5.loss_mask: 0.3056, decode.d5.loss_dice: 0.6513, decode.d6.loss_cls: 0.0902, decode.d6.loss_mask: 0.3045, decode.d6.loss_dice: 0.6420, decode.d7.loss_cls: 0.0858, decode.d7.loss_mask: 0.3077, decode.d7.loss_dice: 0.6458, decode.d8.loss_cls: 0.0826, decode.d8.loss_mask: 0.3021, decode.d8.loss_dice: 0.6385, loss: 10.5671
2023-09-28 12:31:59,916 - mmseg - INFO - Iter [5050/40000]	lr: 1.255e-06, eta: 1 day, 1:38:11, time: 2.225, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0709, decode.loss_mask: 0.3553, decode.loss_dice: 0.6262, decode.d0.loss_cls: 0.2459, decode.d0.loss_mask: 0.3707, decode.d0.loss_dice: 0.6296, decode.d1.loss_cls: 0.0942, decode.d1.loss_mask: 0.3522, decode.d1.loss_dice: 0.6272, decode.d2.loss_cls: 0.0906, decode.d2.loss_mask: 0.3510, decode.d2.loss_dice: 0.6228, decode.d3.loss_cls: 0.1037, decode.d3.loss_mask: 0.3584, decode.d3.loss_dice: 0.6174, decode.d4.loss_cls: 0.0888, decode.d4.loss_mask: 0.3575, decode.d4.loss_dice: 0.6230, decode.d5.loss_cls: 0.0953, decode.d5.loss_mask: 0.3575, decode.d5.loss_dice: 0.6141, decode.d6.loss_cls: 0.0890, decode.d6.loss_mask: 0.3565, decode.d6.loss_dice: 0.6220, decode.d7.loss_cls: 0.0689, decode.d7.loss_mask: 0.3567, decode.d7.loss_dice: 0.6218, decode.d8.loss_cls: 0.0657, decode.d8.loss_mask: 0.3575, decode.d8.loss_dice: 0.6167, loss: 10.8070
2023-09-28 12:33:51,031 - mmseg - INFO - Iter [5100/40000]	lr: 1.253e-06, eta: 1 day, 1:33:36, time: 2.222, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0873, decode.loss_mask: 0.3041, decode.loss_dice: 0.6374, decode.d0.loss_cls: 0.2434, decode.d0.loss_mask: 0.3167, decode.d0.loss_dice: 0.6651, decode.d1.loss_cls: 0.0932, decode.d1.loss_mask: 0.3053, decode.d1.loss_dice: 0.6377, decode.d2.loss_cls: 0.0877, decode.d2.loss_mask: 0.3033, decode.d2.loss_dice: 0.6406, decode.d3.loss_cls: 0.0972, decode.d3.loss_mask: 0.3047, decode.d3.loss_dice: 0.6425, decode.d4.loss_cls: 0.0789, decode.d4.loss_mask: 0.3042, decode.d4.loss_dice: 0.6531, decode.d5.loss_cls: 0.0731, decode.d5.loss_mask: 0.3039, decode.d5.loss_dice: 0.6486, decode.d6.loss_cls: 0.1081, decode.d6.loss_mask: 0.3040, decode.d6.loss_dice: 0.6411, decode.d7.loss_cls: 0.1197, decode.d7.loss_mask: 0.3047, decode.d7.loss_dice: 0.6394, decode.d8.loss_cls: 0.1154, decode.d8.loss_mask: 0.3045, decode.d8.loss_dice: 0.6304, loss: 10.5950
2023-09-28 12:35:41,820 - mmseg - INFO - Iter [5150/40000]	lr: 1.251e-06, eta: 1 day, 1:29:02, time: 2.216, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0753, decode.loss_mask: 0.2900, decode.loss_dice: 0.5828, decode.d0.loss_cls: 0.2329, decode.d0.loss_mask: 0.3087, decode.d0.loss_dice: 0.6086, decode.d1.loss_cls: 0.1022, decode.d1.loss_mask: 0.2938, decode.d1.loss_dice: 0.5807, decode.d2.loss_cls: 0.0658, decode.d2.loss_mask: 0.2978, decode.d2.loss_dice: 0.5931, decode.d3.loss_cls: 0.0645, decode.d3.loss_mask: 0.2978, decode.d3.loss_dice: 0.6032, decode.d4.loss_cls: 0.0700, decode.d4.loss_mask: 0.2963, decode.d4.loss_dice: 0.5819, decode.d5.loss_cls: 0.0625, decode.d5.loss_mask: 0.2973, decode.d5.loss_dice: 0.5958, decode.d6.loss_cls: 0.1073, decode.d6.loss_mask: 0.2909, decode.d6.loss_dice: 0.5790, decode.d7.loss_cls: 0.1070, decode.d7.loss_mask: 0.2915, decode.d7.loss_dice: 0.5801, decode.d8.loss_cls: 0.0699, decode.d8.loss_mask: 0.2921, decode.d8.loss_dice: 0.5784, loss: 9.7972
2023-09-28 12:37:33,182 - mmseg - INFO - Iter [5200/40000]	lr: 1.249e-06, eta: 1 day, 1:24:35, time: 2.227, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0734, decode.loss_mask: 0.2997, decode.loss_dice: 0.5857, decode.d0.loss_cls: 0.2400, decode.d0.loss_mask: 0.2935, decode.d0.loss_dice: 0.5836, decode.d1.loss_cls: 0.1053, decode.d1.loss_mask: 0.3040, decode.d1.loss_dice: 0.5920, decode.d2.loss_cls: 0.0885, decode.d2.loss_mask: 0.2929, decode.d2.loss_dice: 0.5836, decode.d3.loss_cls: 0.0742, decode.d3.loss_mask: 0.2995, decode.d3.loss_dice: 0.5912, decode.d4.loss_cls: 0.0760, decode.d4.loss_mask: 0.2965, decode.d4.loss_dice: 0.5856, decode.d5.loss_cls: 0.0808, decode.d5.loss_mask: 0.2953, decode.d5.loss_dice: 0.6001, decode.d6.loss_cls: 0.1026, decode.d6.loss_mask: 0.2971, decode.d6.loss_dice: 0.5815, decode.d7.loss_cls: 0.0812, decode.d7.loss_mask: 0.3002, decode.d7.loss_dice: 0.5799, decode.d8.loss_cls: 0.0934, decode.d8.loss_mask: 0.2992, decode.d8.loss_dice: 0.5855, loss: 9.8619
2023-09-28 12:39:23,719 - mmseg - INFO - Iter [5250/40000]	lr: 1.247e-06, eta: 1 day, 1:20:05, time: 2.211, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0683, decode.loss_mask: 0.3087, decode.loss_dice: 0.6325, decode.d0.loss_cls: 0.2370, decode.d0.loss_mask: 0.3135, decode.d0.loss_dice: 0.6355, decode.d1.loss_cls: 0.0913, decode.d1.loss_mask: 0.3109, decode.d1.loss_dice: 0.6251, decode.d2.loss_cls: 0.0813, decode.d2.loss_mask: 0.3078, decode.d2.loss_dice: 0.6365, decode.d3.loss_cls: 0.0768, decode.d3.loss_mask: 0.3085, decode.d3.loss_dice: 0.6310, decode.d4.loss_cls: 0.0970, decode.d4.loss_mask: 0.3094, decode.d4.loss_dice: 0.6305, decode.d5.loss_cls: 0.0831, decode.d5.loss_mask: 0.3090, decode.d5.loss_dice: 0.6323, decode.d6.loss_cls: 0.0827, decode.d6.loss_mask: 0.3085, decode.d6.loss_dice: 0.6251, decode.d7.loss_cls: 0.0865, decode.d7.loss_mask: 0.3083, decode.d7.loss_dice: 0.6330, decode.d8.loss_cls: 0.0641, decode.d8.loss_mask: 0.3042, decode.d8.loss_dice: 0.6368, loss: 10.3751
2023-09-28 12:41:14,383 - mmseg - INFO - Iter [5300/40000]	lr: 1.246e-06, eta: 1 day, 1:15:39, time: 2.213, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0811, decode.loss_mask: 0.3100, decode.loss_dice: 0.6254, decode.d0.loss_cls: 0.2521, decode.d0.loss_mask: 0.3169, decode.d0.loss_dice: 0.6423, decode.d1.loss_cls: 0.1112, decode.d1.loss_mask: 0.3084, decode.d1.loss_dice: 0.6338, decode.d2.loss_cls: 0.1285, decode.d2.loss_mask: 0.3085, decode.d2.loss_dice: 0.6246, decode.d3.loss_cls: 0.0908, decode.d3.loss_mask: 0.3089, decode.d3.loss_dice: 0.6358, decode.d4.loss_cls: 0.0952, decode.d4.loss_mask: 0.3092, decode.d4.loss_dice: 0.6312, decode.d5.loss_cls: 0.0925, decode.d5.loss_mask: 0.3104, decode.d5.loss_dice: 0.6358, decode.d6.loss_cls: 0.0933, decode.d6.loss_mask: 0.3076, decode.d6.loss_dice: 0.6205, decode.d7.loss_cls: 0.0982, decode.d7.loss_mask: 0.3075, decode.d7.loss_dice: 0.6241, decode.d8.loss_cls: 0.0941, decode.d8.loss_mask: 0.3096, decode.d8.loss_dice: 0.6297, loss: 10.5373
2023-09-28 12:43:05,066 - mmseg - INFO - Iter [5350/40000]	lr: 1.244e-06, eta: 1 day, 1:11:16, time: 2.213, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0986, decode.loss_mask: 0.3059, decode.loss_dice: 0.6469, decode.d0.loss_cls: 0.2623, decode.d0.loss_mask: 0.3121, decode.d0.loss_dice: 0.6448, decode.d1.loss_cls: 0.1370, decode.d1.loss_mask: 0.3054, decode.d1.loss_dice: 0.6490, decode.d2.loss_cls: 0.1094, decode.d2.loss_mask: 0.3080, decode.d2.loss_dice: 0.6557, decode.d3.loss_cls: 0.1277, decode.d3.loss_mask: 0.3076, decode.d3.loss_dice: 0.6428, decode.d4.loss_cls: 0.1157, decode.d4.loss_mask: 0.3069, decode.d4.loss_dice: 0.6491, decode.d5.loss_cls: 0.1190, decode.d5.loss_mask: 0.3076, decode.d5.loss_dice: 0.6374, decode.d6.loss_cls: 0.1238, decode.d6.loss_mask: 0.3079, decode.d6.loss_dice: 0.6452, decode.d7.loss_cls: 0.1062, decode.d7.loss_mask: 0.3058, decode.d7.loss_dice: 0.6349, decode.d8.loss_cls: 0.0991, decode.d8.loss_mask: 0.3080, decode.d8.loss_dice: 0.6426, loss: 10.8224
2023-09-28 12:44:55,286 - mmseg - INFO - Iter [5400/40000]	lr: 1.242e-06, eta: 1 day, 1:06:53, time: 2.205, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0738, decode.loss_mask: 0.3189, decode.loss_dice: 0.6595, decode.d0.loss_cls: 0.2510, decode.d0.loss_mask: 0.3268, decode.d0.loss_dice: 0.6483, decode.d1.loss_cls: 0.0877, decode.d1.loss_mask: 0.3199, decode.d1.loss_dice: 0.6794, decode.d2.loss_cls: 0.0623, decode.d2.loss_mask: 0.3197, decode.d2.loss_dice: 0.6626, decode.d3.loss_cls: 0.0699, decode.d3.loss_mask: 0.3175, decode.d3.loss_dice: 0.6513, decode.d4.loss_cls: 0.0692, decode.d4.loss_mask: 0.3194, decode.d4.loss_dice: 0.6513, decode.d5.loss_cls: 0.0809, decode.d5.loss_mask: 0.3182, decode.d5.loss_dice: 0.6509, decode.d6.loss_cls: 0.0981, decode.d6.loss_mask: 0.3180, decode.d6.loss_dice: 0.6414, decode.d7.loss_cls: 0.0753, decode.d7.loss_mask: 0.3178, decode.d7.loss_dice: 0.6480, decode.d8.loss_cls: 0.0852, decode.d8.loss_mask: 0.3178, decode.d8.loss_dice: 0.6470, loss: 10.6871
2023-09-28 12:46:44,910 - mmseg - INFO - Iter [5450/40000]	lr: 1.240e-06, eta: 1 day, 1:02:29, time: 2.193, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0712, decode.loss_mask: 0.3178, decode.loss_dice: 0.6003, decode.d0.loss_cls: 0.2526, decode.d0.loss_mask: 0.3253, decode.d0.loss_dice: 0.6192, decode.d1.loss_cls: 0.0959, decode.d1.loss_mask: 0.3118, decode.d1.loss_dice: 0.5942, decode.d2.loss_cls: 0.0834, decode.d2.loss_mask: 0.3130, decode.d2.loss_dice: 0.6107, decode.d3.loss_cls: 0.0771, decode.d3.loss_mask: 0.3247, decode.d3.loss_dice: 0.6038, decode.d4.loss_cls: 0.0729, decode.d4.loss_mask: 0.3179, decode.d4.loss_dice: 0.5999, decode.d5.loss_cls: 0.1010, decode.d5.loss_mask: 0.3167, decode.d5.loss_dice: 0.5978, decode.d6.loss_cls: 0.0933, decode.d6.loss_mask: 0.3190, decode.d6.loss_dice: 0.5914, decode.d7.loss_cls: 0.0895, decode.d7.loss_mask: 0.3181, decode.d7.loss_dice: 0.5973, decode.d8.loss_cls: 0.0709, decode.d8.loss_mask: 0.3182, decode.d8.loss_dice: 0.5960, loss: 10.2010
2023-09-28 12:48:37,142 - mmseg - INFO - Iter [5500/40000]	lr: 1.238e-06, eta: 1 day, 0:58:24, time: 2.245, data_time: 0.086, memory: 21542, decode.loss_cls: 0.1128, decode.loss_mask: 0.3380, decode.loss_dice: 0.6652, decode.d0.loss_cls: 0.3128, decode.d0.loss_mask: 0.3448, decode.d0.loss_dice: 0.6795, decode.d1.loss_cls: 0.1317, decode.d1.loss_mask: 0.3437, decode.d1.loss_dice: 0.6546, decode.d2.loss_cls: 0.1244, decode.d2.loss_mask: 0.3448, decode.d2.loss_dice: 0.6664, decode.d3.loss_cls: 0.1261, decode.d3.loss_mask: 0.3420, decode.d3.loss_dice: 0.6662, decode.d4.loss_cls: 0.1045, decode.d4.loss_mask: 0.3419, decode.d4.loss_dice: 0.6567, decode.d5.loss_cls: 0.1206, decode.d5.loss_mask: 0.3434, decode.d5.loss_dice: 0.6749, decode.d6.loss_cls: 0.1162, decode.d6.loss_mask: 0.3404, decode.d6.loss_dice: 0.6623, decode.d7.loss_cls: 0.1293, decode.d7.loss_mask: 0.3430, decode.d7.loss_dice: 0.6602, decode.d8.loss_cls: 0.1246, decode.d8.loss_mask: 0.3410, decode.d8.loss_dice: 0.6617, loss: 11.4736
2023-09-28 12:50:27,767 - mmseg - INFO - Iter [5550/40000]	lr: 1.237e-06, eta: 1 day, 0:54:12, time: 2.212, data_time: 0.035, memory: 21542, decode.loss_cls: 0.0766, decode.loss_mask: 0.3225, decode.loss_dice: 0.6310, decode.d0.loss_cls: 0.2314, decode.d0.loss_mask: 0.3192, decode.d0.loss_dice: 0.6471, decode.d1.loss_cls: 0.0955, decode.d1.loss_mask: 0.3224, decode.d1.loss_dice: 0.6569, decode.d2.loss_cls: 0.0866, decode.d2.loss_mask: 0.3213, decode.d2.loss_dice: 0.6241, decode.d3.loss_cls: 0.1168, decode.d3.loss_mask: 0.3270, decode.d3.loss_dice: 0.6353, decode.d4.loss_cls: 0.0940, decode.d4.loss_mask: 0.3302, decode.d4.loss_dice: 0.6232, decode.d5.loss_cls: 0.0886, decode.d5.loss_mask: 0.3169, decode.d5.loss_dice: 0.6366, decode.d6.loss_cls: 0.0923, decode.d6.loss_mask: 0.3187, decode.d6.loss_dice: 0.6337, decode.d7.loss_cls: 0.1000, decode.d7.loss_mask: 0.3187, decode.d7.loss_dice: 0.6303, decode.d8.loss_cls: 0.0959, decode.d8.loss_mask: 0.3183, decode.d8.loss_dice: 0.6325, loss: 10.6439
2023-09-28 12:52:18,475 - mmseg - INFO - Iter [5600/40000]	lr: 1.235e-06, eta: 1 day, 0:50:02, time: 2.213, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0745, decode.loss_mask: 0.2912, decode.loss_dice: 0.5971, decode.d0.loss_cls: 0.2394, decode.d0.loss_mask: 0.2928, decode.d0.loss_dice: 0.5844, decode.d1.loss_cls: 0.0864, decode.d1.loss_mask: 0.2893, decode.d1.loss_dice: 0.5937, decode.d2.loss_cls: 0.0734, decode.d2.loss_mask: 0.2871, decode.d2.loss_dice: 0.5995, decode.d3.loss_cls: 0.0786, decode.d3.loss_mask: 0.2931, decode.d3.loss_dice: 0.6037, decode.d4.loss_cls: 0.0796, decode.d4.loss_mask: 0.2875, decode.d4.loss_dice: 0.5939, decode.d5.loss_cls: 0.0672, decode.d5.loss_mask: 0.2905, decode.d5.loss_dice: 0.5976, decode.d6.loss_cls: 0.0735, decode.d6.loss_mask: 0.2895, decode.d6.loss_dice: 0.6031, decode.d7.loss_cls: 0.0700, decode.d7.loss_mask: 0.2925, decode.d7.loss_dice: 0.5997, decode.d8.loss_cls: 0.0689, decode.d8.loss_mask: 0.2920, decode.d8.loss_dice: 0.5977, loss: 9.7872
2023-09-28 12:54:08,903 - mmseg - INFO - Iter [5650/40000]	lr: 1.233e-06, eta: 1 day, 0:45:54, time: 2.210, data_time: 0.035, memory: 21542, decode.loss_cls: 0.1046, decode.loss_mask: 0.3299, decode.loss_dice: 0.6372, decode.d0.loss_cls: 0.2622, decode.d0.loss_mask: 0.3202, decode.d0.loss_dice: 0.6423, decode.d1.loss_cls: 0.1157, decode.d1.loss_mask: 0.3158, decode.d1.loss_dice: 0.6391, decode.d2.loss_cls: 0.0811, decode.d2.loss_mask: 0.3299, decode.d2.loss_dice: 0.6500, decode.d3.loss_cls: 0.0694, decode.d3.loss_mask: 0.3292, decode.d3.loss_dice: 0.6392, decode.d4.loss_cls: 0.1062, decode.d4.loss_mask: 0.3293, decode.d4.loss_dice: 0.6414, decode.d5.loss_cls: 0.0755, decode.d5.loss_mask: 0.3283, decode.d5.loss_dice: 0.6378, decode.d6.loss_cls: 0.0919, decode.d6.loss_mask: 0.3276, decode.d6.loss_dice: 0.6385, decode.d7.loss_cls: 0.0997, decode.d7.loss_mask: 0.3277, decode.d7.loss_dice: 0.6389, decode.d8.loss_cls: 0.1056, decode.d8.loss_mask: 0.3308, decode.d8.loss_dice: 0.6431, loss: 10.7881
2023-09-28 12:55:59,462 - mmseg - INFO - Iter [5700/40000]	lr: 1.231e-06, eta: 1 day, 0:41:49, time: 2.211, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0579, decode.loss_mask: 0.3263, decode.loss_dice: 0.5890, decode.d0.loss_cls: 0.2422, decode.d0.loss_mask: 0.3327, decode.d0.loss_dice: 0.5956, decode.d1.loss_cls: 0.0814, decode.d1.loss_mask: 0.3276, decode.d1.loss_dice: 0.5904, decode.d2.loss_cls: 0.0978, decode.d2.loss_mask: 0.3187, decode.d2.loss_dice: 0.5937, decode.d3.loss_cls: 0.0595, decode.d3.loss_mask: 0.3273, decode.d3.loss_dice: 0.5889, decode.d4.loss_cls: 0.0643, decode.d4.loss_mask: 0.3246, decode.d4.loss_dice: 0.5896, decode.d5.loss_cls: 0.0824, decode.d5.loss_mask: 0.3261, decode.d5.loss_dice: 0.5929, decode.d6.loss_cls: 0.0679, decode.d6.loss_mask: 0.3248, decode.d6.loss_dice: 0.5805, decode.d7.loss_cls: 0.0754, decode.d7.loss_mask: 0.3284, decode.d7.loss_dice: 0.5853, decode.d8.loss_cls: 0.0881, decode.d8.loss_mask: 0.3264, decode.d8.loss_dice: 0.5813, loss: 10.0673
2023-09-28 12:57:51,165 - mmseg - INFO - Iter [5750/40000]	lr: 1.229e-06, eta: 1 day, 0:37:52, time: 2.233, data_time: 0.035, memory: 21542, decode.loss_cls: 0.0846, decode.loss_mask: 0.3270, decode.loss_dice: 0.6569, decode.d0.loss_cls: 0.2437, decode.d0.loss_mask: 0.3343, decode.d0.loss_dice: 0.6586, decode.d1.loss_cls: 0.1063, decode.d1.loss_mask: 0.3290, decode.d1.loss_dice: 0.6614, decode.d2.loss_cls: 0.1021, decode.d2.loss_mask: 0.3315, decode.d2.loss_dice: 0.6728, decode.d3.loss_cls: 0.1143, decode.d3.loss_mask: 0.3271, decode.d3.loss_dice: 0.6594, decode.d4.loss_cls: 0.1016, decode.d4.loss_mask: 0.3287, decode.d4.loss_dice: 0.6603, decode.d5.loss_cls: 0.1058, decode.d5.loss_mask: 0.3281, decode.d5.loss_dice: 0.6552, decode.d6.loss_cls: 0.0998, decode.d6.loss_mask: 0.3251, decode.d6.loss_dice: 0.6524, decode.d7.loss_cls: 0.1021, decode.d7.loss_mask: 0.3264, decode.d7.loss_dice: 0.6642, decode.d8.loss_cls: 0.0989, decode.d8.loss_mask: 0.3256, decode.d8.loss_dice: 0.6610, loss: 11.0441
2023-09-28 12:59:41,178 - mmseg - INFO - Iter [5800/40000]	lr: 1.228e-06, eta: 1 day, 0:33:48, time: 2.201, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0823, decode.loss_mask: 0.3182, decode.loss_dice: 0.6384, decode.d0.loss_cls: 0.2729, decode.d0.loss_mask: 0.3243, decode.d0.loss_dice: 0.6469, decode.d1.loss_cls: 0.1080, decode.d1.loss_mask: 0.3124, decode.d1.loss_dice: 0.6275, decode.d2.loss_cls: 0.1182, decode.d2.loss_mask: 0.3158, decode.d2.loss_dice: 0.6500, decode.d3.loss_cls: 0.1186, decode.d3.loss_mask: 0.3127, decode.d3.loss_dice: 0.6333, decode.d4.loss_cls: 0.0954, decode.d4.loss_mask: 0.3179, decode.d4.loss_dice: 0.6403, decode.d5.loss_cls: 0.1044, decode.d5.loss_mask: 0.3169, decode.d5.loss_dice: 0.6557, decode.d6.loss_cls: 0.0976, decode.d6.loss_mask: 0.3108, decode.d6.loss_dice: 0.6386, decode.d7.loss_cls: 0.0935, decode.d7.loss_mask: 0.3195, decode.d7.loss_dice: 0.6316, decode.d8.loss_cls: 0.0841, decode.d8.loss_mask: 0.3175, decode.d8.loss_dice: 0.6407, loss: 10.7439
2023-09-28 13:01:31,831 - mmseg - INFO - Iter [5850/40000]	lr: 1.226e-06, eta: 1 day, 0:29:50, time: 2.213, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0761, decode.loss_mask: 0.3066, decode.loss_dice: 0.6290, decode.d0.loss_cls: 0.2513, decode.d0.loss_mask: 0.3000, decode.d0.loss_dice: 0.6235, decode.d1.loss_cls: 0.1055, decode.d1.loss_mask: 0.3005, decode.d1.loss_dice: 0.6351, decode.d2.loss_cls: 0.0760, decode.d2.loss_mask: 0.3065, decode.d2.loss_dice: 0.6367, decode.d3.loss_cls: 0.0748, decode.d3.loss_mask: 0.3066, decode.d3.loss_dice: 0.6324, decode.d4.loss_cls: 0.0777, decode.d4.loss_mask: 0.3080, decode.d4.loss_dice: 0.6385, decode.d5.loss_cls: 0.0792, decode.d5.loss_mask: 0.3076, decode.d5.loss_dice: 0.6344, decode.d6.loss_cls: 0.0754, decode.d6.loss_mask: 0.3076, decode.d6.loss_dice: 0.6414, decode.d7.loss_cls: 0.0901, decode.d7.loss_mask: 0.3072, decode.d7.loss_dice: 0.6306, decode.d8.loss_cls: 0.0833, decode.d8.loss_mask: 0.3076, decode.d8.loss_dice: 0.6241, loss: 10.3733
2023-09-28 13:03:22,302 - mmseg - INFO - Iter [5900/40000]	lr: 1.224e-06, eta: 1 day, 0:25:53, time: 2.209, data_time: 0.031, memory: 21542, decode.loss_cls: 0.1045, decode.loss_mask: 0.2818, decode.loss_dice: 0.6061, decode.d0.loss_cls: 0.2532, decode.d0.loss_mask: 0.2851, decode.d0.loss_dice: 0.6195, decode.d1.loss_cls: 0.1208, decode.d1.loss_mask: 0.2813, decode.d1.loss_dice: 0.6185, decode.d2.loss_cls: 0.1069, decode.d2.loss_mask: 0.2784, decode.d2.loss_dice: 0.6071, decode.d3.loss_cls: 0.0948, decode.d3.loss_mask: 0.2816, decode.d3.loss_dice: 0.6105, decode.d4.loss_cls: 0.0742, decode.d4.loss_mask: 0.2797, decode.d4.loss_dice: 0.6125, decode.d5.loss_cls: 0.0915, decode.d5.loss_mask: 0.2823, decode.d5.loss_dice: 0.6022, decode.d6.loss_cls: 0.0863, decode.d6.loss_mask: 0.2811, decode.d6.loss_dice: 0.6086, decode.d7.loss_cls: 0.1021, decode.d7.loss_mask: 0.2815, decode.d7.loss_dice: 0.6093, decode.d8.loss_cls: 0.1007, decode.d8.loss_mask: 0.2804, decode.d8.loss_dice: 0.6206, loss: 10.0633
2023-09-28 13:05:12,710 - mmseg - INFO - Iter [5950/40000]	lr: 1.222e-06, eta: 1 day, 0:21:58, time: 2.208, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0974, decode.loss_mask: 0.3211, decode.loss_dice: 0.6368, decode.d0.loss_cls: 0.2379, decode.d0.loss_mask: 0.3285, decode.d0.loss_dice: 0.6281, decode.d1.loss_cls: 0.0890, decode.d1.loss_mask: 0.3267, decode.d1.loss_dice: 0.6390, decode.d2.loss_cls: 0.0816, decode.d2.loss_mask: 0.3269, decode.d2.loss_dice: 0.6387, decode.d3.loss_cls: 0.0896, decode.d3.loss_mask: 0.3250, decode.d3.loss_dice: 0.6433, decode.d4.loss_cls: 0.1078, decode.d4.loss_mask: 0.3227, decode.d4.loss_dice: 0.6382, decode.d5.loss_cls: 0.1112, decode.d5.loss_mask: 0.3263, decode.d5.loss_dice: 0.6347, decode.d6.loss_cls: 0.0952, decode.d6.loss_mask: 0.3219, decode.d6.loss_dice: 0.6406, decode.d7.loss_cls: 0.1041, decode.d7.loss_mask: 0.3269, decode.d7.loss_dice: 0.6382, decode.d8.loss_cls: 0.0973, decode.d8.loss_mask: 0.3236, decode.d8.loss_dice: 0.6409, loss: 10.7391
2023-09-28 13:07:04,435 - mmseg - INFO - Saving checkpoint at 6000 iterations
2023-09-28 13:07:24,360 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 13:07:24,360 - mmseg - INFO - Iter [6000/40000]	lr: 1.220e-06, eta: 1 day, 0:20:05, time: 2.633, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0726, decode.loss_mask: 0.2757, decode.loss_dice: 0.5390, decode.d0.loss_cls: 0.2694, decode.d0.loss_mask: 0.2752, decode.d0.loss_dice: 0.5516, decode.d1.loss_cls: 0.1057, decode.d1.loss_mask: 0.2729, decode.d1.loss_dice: 0.5383, decode.d2.loss_cls: 0.0917, decode.d2.loss_mask: 0.2759, decode.d2.loss_dice: 0.5406, decode.d3.loss_cls: 0.0699, decode.d3.loss_mask: 0.2773, decode.d3.loss_dice: 0.5388, decode.d4.loss_cls: 0.0796, decode.d4.loss_mask: 0.2765, decode.d4.loss_dice: 0.5359, decode.d5.loss_cls: 0.0816, decode.d5.loss_mask: 0.2763, decode.d5.loss_dice: 0.5417, decode.d6.loss_cls: 0.0693, decode.d6.loss_mask: 0.2732, decode.d6.loss_dice: 0.5388, decode.d7.loss_cls: 0.0782, decode.d7.loss_mask: 0.2738, decode.d7.loss_dice: 0.5305, decode.d8.loss_cls: 0.0710, decode.d8.loss_mask: 0.2780, decode.d8.loss_dice: 0.5406, loss: 9.1394
2023-09-28 13:24:21,726 - mmseg - INFO - per class results:
2023-09-28 13:24:21,727 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 93.16 | 96.93 |
|    Sidewalk   | 68.13 | 82.76 |
|  Construction | 81.97 | 93.91 |
|     Fence     | 31.72 | 35.68 |
|      Pole     | 55.02 | 70.93 |
| Traffic Light | 67.86 | 78.63 |
|  Traffic Sign |  72.3 | 81.34 |
|     Nature    | 88.76 | 94.12 |
|      Sky      | 96.68 |  98.0 |
|     Person    | 32.59 | 34.67 |
|     Rider     |  9.67 | 69.96 |
|      Car      | 91.71 | 94.66 |
|   background  | 96.52 |  98.2 |
+---------------+-------+-------+
2023-09-28 13:24:21,727 - mmseg - INFO - Summary:
2023-09-28 13:24:21,728 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.47 | 68.16 | 79.21 |
+-------+-------+-------+
2023-09-28 13:24:21,729 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 13:24:21,729 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9447, mIoU: 0.6816, mAcc: 0.7921, IoU.Road: 0.9316, IoU.Sidewalk: 0.6813, IoU.Construction: 0.8197, IoU.Fence: 0.3172, IoU.Pole: 0.5502, IoU.Traffic Light: 0.6786, IoU.Traffic Sign: 0.7230, IoU.Nature: 0.8876, IoU.Sky: 0.9668, IoU.Person: 0.3259, IoU.Rider: 0.0967, IoU.Car: 0.9171, IoU.background: 0.9652, Acc.Road: 0.9693, Acc.Sidewalk: 0.8276, Acc.Construction: 0.9391, Acc.Fence: 0.3568, Acc.Pole: 0.7093, Acc.Traffic Light: 0.7863, Acc.Traffic Sign: 0.8134, Acc.Nature: 0.9412, Acc.Sky: 0.9800, Acc.Person: 0.3467, Acc.Rider: 0.6996, Acc.Car: 0.9466, Acc.background: 0.9820
2023-09-28 13:26:12,823 - mmseg - INFO - Iter [6050/40000]	lr: 1.219e-06, eta: 1 day, 1:51:26, time: 22.569, data_time: 20.378, memory: 21542, decode.loss_cls: 0.1193, decode.loss_mask: 0.3208, decode.loss_dice: 0.6547, decode.d0.loss_cls: 0.2590, decode.d0.loss_mask: 0.3245, decode.d0.loss_dice: 0.6670, decode.d1.loss_cls: 0.1123, decode.d1.loss_mask: 0.3231, decode.d1.loss_dice: 0.6560, decode.d2.loss_cls: 0.1308, decode.d2.loss_mask: 0.3231, decode.d2.loss_dice: 0.6598, decode.d3.loss_cls: 0.1112, decode.d3.loss_mask: 0.3205, decode.d3.loss_dice: 0.6524, decode.d4.loss_cls: 0.1197, decode.d4.loss_mask: 0.3200, decode.d4.loss_dice: 0.6513, decode.d5.loss_cls: 0.1104, decode.d5.loss_mask: 0.3222, decode.d5.loss_dice: 0.6497, decode.d6.loss_cls: 0.1160, decode.d6.loss_mask: 0.3230, decode.d6.loss_dice: 0.6510, decode.d7.loss_cls: 0.1122, decode.d7.loss_mask: 0.3216, decode.d7.loss_dice: 0.6421, decode.d8.loss_cls: 0.0978, decode.d8.loss_mask: 0.3221, decode.d8.loss_dice: 0.6519, loss: 11.0455
2023-09-28 13:28:03,398 - mmseg - INFO - Iter [6100/40000]	lr: 1.217e-06, eta: 1 day, 1:46:42, time: 2.212, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0983, decode.loss_mask: 0.3232, decode.loss_dice: 0.6478, decode.d0.loss_cls: 0.2877, decode.d0.loss_mask: 0.3361, decode.d0.loss_dice: 0.6442, decode.d1.loss_cls: 0.1504, decode.d1.loss_mask: 0.3182, decode.d1.loss_dice: 0.6396, decode.d2.loss_cls: 0.1213, decode.d2.loss_mask: 0.3235, decode.d2.loss_dice: 0.6351, decode.d3.loss_cls: 0.1117, decode.d3.loss_mask: 0.3193, decode.d3.loss_dice: 0.6395, decode.d4.loss_cls: 0.1079, decode.d4.loss_mask: 0.3220, decode.d4.loss_dice: 0.6334, decode.d5.loss_cls: 0.1139, decode.d5.loss_mask: 0.3226, decode.d5.loss_dice: 0.6309, decode.d6.loss_cls: 0.0970, decode.d6.loss_mask: 0.3228, decode.d6.loss_dice: 0.6439, decode.d7.loss_cls: 0.0963, decode.d7.loss_mask: 0.3223, decode.d7.loss_dice: 0.6393, decode.d8.loss_cls: 0.1029, decode.d8.loss_mask: 0.3210, decode.d8.loss_dice: 0.6441, loss: 10.9162
2023-09-28 13:29:53,702 - mmseg - INFO - Iter [6150/40000]	lr: 1.215e-06, eta: 1 day, 1:41:58, time: 2.206, data_time: 0.025, memory: 21542, decode.loss_cls: 0.1124, decode.loss_mask: 0.3082, decode.loss_dice: 0.6725, decode.d0.loss_cls: 0.2408, decode.d0.loss_mask: 0.3001, decode.d0.loss_dice: 0.7088, decode.d1.loss_cls: 0.1246, decode.d1.loss_mask: 0.3102, decode.d1.loss_dice: 0.6844, decode.d2.loss_cls: 0.1138, decode.d2.loss_mask: 0.3056, decode.d2.loss_dice: 0.6778, decode.d3.loss_cls: 0.1049, decode.d3.loss_mask: 0.3053, decode.d3.loss_dice: 0.6772, decode.d4.loss_cls: 0.1201, decode.d4.loss_mask: 0.3070, decode.d4.loss_dice: 0.6773, decode.d5.loss_cls: 0.1440, decode.d5.loss_mask: 0.3104, decode.d5.loss_dice: 0.6905, decode.d6.loss_cls: 0.1105, decode.d6.loss_mask: 0.3088, decode.d6.loss_dice: 0.6787, decode.d7.loss_cls: 0.1255, decode.d7.loss_mask: 0.3102, decode.d7.loss_dice: 0.6826, decode.d8.loss_cls: 0.1161, decode.d8.loss_mask: 0.3096, decode.d8.loss_dice: 0.6782, loss: 11.2163
2023-09-28 13:31:44,234 - mmseg - INFO - Iter [6200/40000]	lr: 1.213e-06, eta: 1 day, 1:37:19, time: 2.211, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0729, decode.loss_mask: 0.3280, decode.loss_dice: 0.6490, decode.d0.loss_cls: 0.2439, decode.d0.loss_mask: 0.3245, decode.d0.loss_dice: 0.6514, decode.d1.loss_cls: 0.0879, decode.d1.loss_mask: 0.3258, decode.d1.loss_dice: 0.6424, decode.d2.loss_cls: 0.0722, decode.d2.loss_mask: 0.3291, decode.d2.loss_dice: 0.6401, decode.d3.loss_cls: 0.0885, decode.d3.loss_mask: 0.3307, decode.d3.loss_dice: 0.6496, decode.d4.loss_cls: 0.0892, decode.d4.loss_mask: 0.3292, decode.d4.loss_dice: 0.6342, decode.d5.loss_cls: 0.0811, decode.d5.loss_mask: 0.3265, decode.d5.loss_dice: 0.6395, decode.d6.loss_cls: 0.0842, decode.d6.loss_mask: 0.3283, decode.d6.loss_dice: 0.6455, decode.d7.loss_cls: 0.0784, decode.d7.loss_mask: 0.3272, decode.d7.loss_dice: 0.6471, decode.d8.loss_cls: 0.0733, decode.d8.loss_mask: 0.3273, decode.d8.loss_dice: 0.6457, loss: 10.6927
2023-09-28 13:33:35,529 - mmseg - INFO - Iter [6250/40000]	lr: 1.211e-06, eta: 1 day, 1:32:47, time: 2.226, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0692, decode.loss_mask: 0.3256, decode.loss_dice: 0.6095, decode.d0.loss_cls: 0.2441, decode.d0.loss_mask: 0.3264, decode.d0.loss_dice: 0.6156, decode.d1.loss_cls: 0.0925, decode.d1.loss_mask: 0.3248, decode.d1.loss_dice: 0.6167, decode.d2.loss_cls: 0.0758, decode.d2.loss_mask: 0.3278, decode.d2.loss_dice: 0.6092, decode.d3.loss_cls: 0.0905, decode.d3.loss_mask: 0.3261, decode.d3.loss_dice: 0.6068, decode.d4.loss_cls: 0.0837, decode.d4.loss_mask: 0.3271, decode.d4.loss_dice: 0.6123, decode.d5.loss_cls: 0.0709, decode.d5.loss_mask: 0.3280, decode.d5.loss_dice: 0.6040, decode.d6.loss_cls: 0.0726, decode.d6.loss_mask: 0.3293, decode.d6.loss_dice: 0.5943, decode.d7.loss_cls: 0.0584, decode.d7.loss_mask: 0.3262, decode.d7.loss_dice: 0.6060, decode.d8.loss_cls: 0.0669, decode.d8.loss_mask: 0.3274, decode.d8.loss_dice: 0.6112, loss: 10.2790
2023-09-28 13:35:26,049 - mmseg - INFO - Iter [6300/40000]	lr: 1.210e-06, eta: 1 day, 1:28:13, time: 2.209, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0857, decode.loss_mask: 0.2916, decode.loss_dice: 0.6600, decode.d0.loss_cls: 0.2364, decode.d0.loss_mask: 0.2957, decode.d0.loss_dice: 0.6842, decode.d1.loss_cls: 0.0991, decode.d1.loss_mask: 0.2949, decode.d1.loss_dice: 0.6784, decode.d2.loss_cls: 0.0940, decode.d2.loss_mask: 0.2925, decode.d2.loss_dice: 0.6627, decode.d3.loss_cls: 0.0929, decode.d3.loss_mask: 0.2926, decode.d3.loss_dice: 0.6580, decode.d4.loss_cls: 0.1096, decode.d4.loss_mask: 0.2940, decode.d4.loss_dice: 0.6638, decode.d5.loss_cls: 0.1012, decode.d5.loss_mask: 0.2940, decode.d5.loss_dice: 0.6680, decode.d6.loss_cls: 0.1105, decode.d6.loss_mask: 0.2933, decode.d6.loss_dice: 0.6737, decode.d7.loss_cls: 0.0839, decode.d7.loss_mask: 0.2922, decode.d7.loss_dice: 0.6702, decode.d8.loss_cls: 0.1245, decode.d8.loss_mask: 0.2935, decode.d8.loss_dice: 0.6723, loss: 10.7635
2023-09-28 13:37:17,328 - mmseg - INFO - Iter [6350/40000]	lr: 1.208e-06, eta: 1 day, 1:23:46, time: 2.225, data_time: 0.031, memory: 21542, decode.loss_cls: 0.1096, decode.loss_mask: 0.3134, decode.loss_dice: 0.6264, decode.d0.loss_cls: 0.2330, decode.d0.loss_mask: 0.3195, decode.d0.loss_dice: 0.6418, decode.d1.loss_cls: 0.1300, decode.d1.loss_mask: 0.3105, decode.d1.loss_dice: 0.6340, decode.d2.loss_cls: 0.1000, decode.d2.loss_mask: 0.3116, decode.d2.loss_dice: 0.6311, decode.d3.loss_cls: 0.0999, decode.d3.loss_mask: 0.3109, decode.d3.loss_dice: 0.6294, decode.d4.loss_cls: 0.0959, decode.d4.loss_mask: 0.3130, decode.d4.loss_dice: 0.6279, decode.d5.loss_cls: 0.1043, decode.d5.loss_mask: 0.3121, decode.d5.loss_dice: 0.6306, decode.d6.loss_cls: 0.0881, decode.d6.loss_mask: 0.3128, decode.d6.loss_dice: 0.6320, decode.d7.loss_cls: 0.0973, decode.d7.loss_mask: 0.3132, decode.d7.loss_dice: 0.6305, decode.d8.loss_cls: 0.1069, decode.d8.loss_mask: 0.3084, decode.d8.loss_dice: 0.6203, loss: 10.5946
2023-09-28 13:39:08,395 - mmseg - INFO - Iter [6400/40000]	lr: 1.206e-06, eta: 1 day, 1:19:20, time: 2.222, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0607, decode.loss_mask: 0.2831, decode.loss_dice: 0.6002, decode.d0.loss_cls: 0.2320, decode.d0.loss_mask: 0.2848, decode.d0.loss_dice: 0.6010, decode.d1.loss_cls: 0.0720, decode.d1.loss_mask: 0.2819, decode.d1.loss_dice: 0.6046, decode.d2.loss_cls: 0.0806, decode.d2.loss_mask: 0.2830, decode.d2.loss_dice: 0.6100, decode.d3.loss_cls: 0.0818, decode.d3.loss_mask: 0.2829, decode.d3.loss_dice: 0.5946, decode.d4.loss_cls: 0.0618, decode.d4.loss_mask: 0.2829, decode.d4.loss_dice: 0.6041, decode.d5.loss_cls: 0.0647, decode.d5.loss_mask: 0.2839, decode.d5.loss_dice: 0.6091, decode.d6.loss_cls: 0.0719, decode.d6.loss_mask: 0.2842, decode.d6.loss_dice: 0.5956, decode.d7.loss_cls: 0.0786, decode.d7.loss_mask: 0.2839, decode.d7.loss_dice: 0.6040, decode.d8.loss_cls: 0.0765, decode.d8.loss_mask: 0.2845, decode.d8.loss_dice: 0.5992, loss: 9.7382
2023-09-28 13:40:59,112 - mmseg - INFO - Iter [6450/40000]	lr: 1.204e-06, eta: 1 day, 1:14:55, time: 2.215, data_time: 0.029, memory: 21542, decode.loss_cls: 0.1282, decode.loss_mask: 0.2934, decode.loss_dice: 0.6346, decode.d0.loss_cls: 0.2814, decode.d0.loss_mask: 0.2956, decode.d0.loss_dice: 0.6442, decode.d1.loss_cls: 0.1581, decode.d1.loss_mask: 0.2817, decode.d1.loss_dice: 0.6440, decode.d2.loss_cls: 0.1422, decode.d2.loss_mask: 0.2921, decode.d2.loss_dice: 0.6387, decode.d3.loss_cls: 0.1164, decode.d3.loss_mask: 0.2900, decode.d3.loss_dice: 0.6388, decode.d4.loss_cls: 0.1339, decode.d4.loss_mask: 0.2931, decode.d4.loss_dice: 0.6317, decode.d5.loss_cls: 0.1167, decode.d5.loss_mask: 0.2903, decode.d5.loss_dice: 0.6331, decode.d6.loss_cls: 0.1373, decode.d6.loss_mask: 0.2849, decode.d6.loss_dice: 0.6320, decode.d7.loss_cls: 0.1419, decode.d7.loss_mask: 0.2783, decode.d7.loss_dice: 0.6326, decode.d8.loss_cls: 0.1535, decode.d8.loss_mask: 0.2784, decode.d8.loss_dice: 0.6282, loss: 10.7455
2023-09-28 13:42:51,141 - mmseg - INFO - Iter [6500/40000]	lr: 1.203e-06, eta: 1 day, 1:10:38, time: 2.240, data_time: 0.031, memory: 21542, decode.loss_cls: 0.1051, decode.loss_mask: 0.3288, decode.loss_dice: 0.6658, decode.d0.loss_cls: 0.2570, decode.d0.loss_mask: 0.3362, decode.d0.loss_dice: 0.6849, decode.d1.loss_cls: 0.1069, decode.d1.loss_mask: 0.3303, decode.d1.loss_dice: 0.6690, decode.d2.loss_cls: 0.1352, decode.d2.loss_mask: 0.3287, decode.d2.loss_dice: 0.6685, decode.d3.loss_cls: 0.1126, decode.d3.loss_mask: 0.3280, decode.d3.loss_dice: 0.6687, decode.d4.loss_cls: 0.0828, decode.d4.loss_mask: 0.3295, decode.d4.loss_dice: 0.6759, decode.d5.loss_cls: 0.0906, decode.d5.loss_mask: 0.3309, decode.d5.loss_dice: 0.6726, decode.d6.loss_cls: 0.0844, decode.d6.loss_mask: 0.3304, decode.d6.loss_dice: 0.6655, decode.d7.loss_cls: 0.0840, decode.d7.loss_mask: 0.3300, decode.d7.loss_dice: 0.6662, decode.d8.loss_cls: 0.0864, decode.d8.loss_mask: 0.3286, decode.d8.loss_dice: 0.6698, loss: 11.1534
2023-09-28 13:44:42,090 - mmseg - INFO - Iter [6550/40000]	lr: 1.201e-06, eta: 1 day, 1:06:19, time: 2.219, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0981, decode.loss_mask: 0.3150, decode.loss_dice: 0.6711, decode.d0.loss_cls: 0.2847, decode.d0.loss_mask: 0.3202, decode.d0.loss_dice: 0.6810, decode.d1.loss_cls: 0.1107, decode.d1.loss_mask: 0.3154, decode.d1.loss_dice: 0.6773, decode.d2.loss_cls: 0.1026, decode.d2.loss_mask: 0.3190, decode.d2.loss_dice: 0.6632, decode.d3.loss_cls: 0.1004, decode.d3.loss_mask: 0.3142, decode.d3.loss_dice: 0.6790, decode.d4.loss_cls: 0.0918, decode.d4.loss_mask: 0.3152, decode.d4.loss_dice: 0.6821, decode.d5.loss_cls: 0.1163, decode.d5.loss_mask: 0.3150, decode.d5.loss_dice: 0.6801, decode.d6.loss_cls: 0.0903, decode.d6.loss_mask: 0.3154, decode.d6.loss_dice: 0.6760, decode.d7.loss_cls: 0.0836, decode.d7.loss_mask: 0.3154, decode.d7.loss_dice: 0.6725, decode.d8.loss_cls: 0.0943, decode.d8.loss_mask: 0.3148, decode.d8.loss_dice: 0.6727, loss: 11.0872
2023-09-28 13:46:34,876 - mmseg - INFO - Iter [6600/40000]	lr: 1.199e-06, eta: 1 day, 1:02:11, time: 2.256, data_time: 0.080, memory: 21542, decode.loss_cls: 0.0917, decode.loss_mask: 0.2975, decode.loss_dice: 0.6412, decode.d0.loss_cls: 0.2436, decode.d0.loss_mask: 0.3026, decode.d0.loss_dice: 0.6417, decode.d1.loss_cls: 0.0997, decode.d1.loss_mask: 0.3001, decode.d1.loss_dice: 0.6350, decode.d2.loss_cls: 0.0884, decode.d2.loss_mask: 0.3013, decode.d2.loss_dice: 0.6349, decode.d3.loss_cls: 0.0857, decode.d3.loss_mask: 0.2997, decode.d3.loss_dice: 0.6354, decode.d4.loss_cls: 0.1008, decode.d4.loss_mask: 0.2997, decode.d4.loss_dice: 0.6358, decode.d5.loss_cls: 0.1021, decode.d5.loss_mask: 0.2994, decode.d5.loss_dice: 0.6406, decode.d6.loss_cls: 0.0967, decode.d6.loss_mask: 0.2989, decode.d6.loss_dice: 0.6330, decode.d7.loss_cls: 0.0809, decode.d7.loss_mask: 0.3011, decode.d7.loss_dice: 0.6474, decode.d8.loss_cls: 0.0977, decode.d8.loss_mask: 0.3001, decode.d8.loss_dice: 0.6343, loss: 10.4666
2023-09-28 13:48:25,165 - mmseg - INFO - Iter [6650/40000]	lr: 1.197e-06, eta: 1 day, 0:57:52, time: 2.206, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0643, decode.loss_mask: 0.2835, decode.loss_dice: 0.5705, decode.d0.loss_cls: 0.2459, decode.d0.loss_mask: 0.2870, decode.d0.loss_dice: 0.5901, decode.d1.loss_cls: 0.0729, decode.d1.loss_mask: 0.2846, decode.d1.loss_dice: 0.5648, decode.d2.loss_cls: 0.0751, decode.d2.loss_mask: 0.2832, decode.d2.loss_dice: 0.5679, decode.d3.loss_cls: 0.0798, decode.d3.loss_mask: 0.2845, decode.d3.loss_dice: 0.5640, decode.d4.loss_cls: 0.0957, decode.d4.loss_mask: 0.2846, decode.d4.loss_dice: 0.5783, decode.d5.loss_cls: 0.0844, decode.d5.loss_mask: 0.2814, decode.d5.loss_dice: 0.5674, decode.d6.loss_cls: 0.0669, decode.d6.loss_mask: 0.2821, decode.d6.loss_dice: 0.5722, decode.d7.loss_cls: 0.0782, decode.d7.loss_mask: 0.2833, decode.d7.loss_dice: 0.5833, decode.d8.loss_cls: 0.0862, decode.d8.loss_mask: 0.2824, decode.d8.loss_dice: 0.5654, loss: 9.5099
2023-09-28 13:50:16,106 - mmseg - INFO - Iter [6700/40000]	lr: 1.195e-06, eta: 1 day, 0:53:39, time: 2.219, data_time: 0.031, memory: 21542, decode.loss_cls: 0.1039, decode.loss_mask: 0.2992, decode.loss_dice: 0.6973, decode.d0.loss_cls: 0.2402, decode.d0.loss_mask: 0.3096, decode.d0.loss_dice: 0.7131, decode.d1.loss_cls: 0.1192, decode.d1.loss_mask: 0.3029, decode.d1.loss_dice: 0.7021, decode.d2.loss_cls: 0.1049, decode.d2.loss_mask: 0.3042, decode.d2.loss_dice: 0.6981, decode.d3.loss_cls: 0.1140, decode.d3.loss_mask: 0.2991, decode.d3.loss_dice: 0.6929, decode.d4.loss_cls: 0.1076, decode.d4.loss_mask: 0.3041, decode.d4.loss_dice: 0.6918, decode.d5.loss_cls: 0.1091, decode.d5.loss_mask: 0.3046, decode.d5.loss_dice: 0.7048, decode.d6.loss_cls: 0.1151, decode.d6.loss_mask: 0.3014, decode.d6.loss_dice: 0.6930, decode.d7.loss_cls: 0.0915, decode.d7.loss_mask: 0.3033, decode.d7.loss_dice: 0.6963, decode.d8.loss_cls: 0.1092, decode.d8.loss_mask: 0.3023, decode.d8.loss_dice: 0.6900, loss: 11.2250
2023-09-28 13:52:07,062 - mmseg - INFO - Iter [6750/40000]	lr: 1.194e-06, eta: 1 day, 0:49:28, time: 2.218, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0552, decode.loss_mask: 0.2820, decode.loss_dice: 0.5814, decode.d0.loss_cls: 0.2474, decode.d0.loss_mask: 0.2879, decode.d0.loss_dice: 0.6023, decode.d1.loss_cls: 0.0708, decode.d1.loss_mask: 0.2813, decode.d1.loss_dice: 0.5969, decode.d2.loss_cls: 0.0707, decode.d2.loss_mask: 0.2830, decode.d2.loss_dice: 0.5920, decode.d3.loss_cls: 0.0475, decode.d3.loss_mask: 0.2837, decode.d3.loss_dice: 0.5878, decode.d4.loss_cls: 0.0479, decode.d4.loss_mask: 0.2845, decode.d4.loss_dice: 0.5857, decode.d5.loss_cls: 0.0762, decode.d5.loss_mask: 0.2815, decode.d5.loss_dice: 0.5806, decode.d6.loss_cls: 0.0522, decode.d6.loss_mask: 0.2787, decode.d6.loss_dice: 0.5797, decode.d7.loss_cls: 0.0590, decode.d7.loss_mask: 0.2823, decode.d7.loss_dice: 0.5913, decode.d8.loss_cls: 0.0480, decode.d8.loss_mask: 0.2816, decode.d8.loss_dice: 0.5935, loss: 9.4925
2023-09-28 13:53:58,394 - mmseg - INFO - Iter [6800/40000]	lr: 1.192e-06, eta: 1 day, 0:45:21, time: 2.227, data_time: 0.030, memory: 21542, decode.loss_cls: 0.1085, decode.loss_mask: 0.3130, decode.loss_dice: 0.6283, decode.d0.loss_cls: 0.2971, decode.d0.loss_mask: 0.3184, decode.d0.loss_dice: 0.6356, decode.d1.loss_cls: 0.1576, decode.d1.loss_mask: 0.3089, decode.d1.loss_dice: 0.6464, decode.d2.loss_cls: 0.1206, decode.d2.loss_mask: 0.3072, decode.d2.loss_dice: 0.6299, decode.d3.loss_cls: 0.1439, decode.d3.loss_mask: 0.3041, decode.d3.loss_dice: 0.6234, decode.d4.loss_cls: 0.1370, decode.d4.loss_mask: 0.3143, decode.d4.loss_dice: 0.6262, decode.d5.loss_cls: 0.1243, decode.d5.loss_mask: 0.3150, decode.d5.loss_dice: 0.6293, decode.d6.loss_cls: 0.1085, decode.d6.loss_mask: 0.3140, decode.d6.loss_dice: 0.6243, decode.d7.loss_cls: 0.1267, decode.d7.loss_mask: 0.3138, decode.d7.loss_dice: 0.6225, decode.d8.loss_cls: 0.1028, decode.d8.loss_mask: 0.3129, decode.d8.loss_dice: 0.6258, loss: 10.8402
2023-09-28 13:55:49,180 - mmseg - INFO - Iter [6850/40000]	lr: 1.190e-06, eta: 1 day, 0:41:14, time: 2.216, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0691, decode.loss_mask: 0.2984, decode.loss_dice: 0.5511, decode.d0.loss_cls: 0.2282, decode.d0.loss_mask: 0.3014, decode.d0.loss_dice: 0.5565, decode.d1.loss_cls: 0.0957, decode.d1.loss_mask: 0.2998, decode.d1.loss_dice: 0.5520, decode.d2.loss_cls: 0.0706, decode.d2.loss_mask: 0.3014, decode.d2.loss_dice: 0.5515, decode.d3.loss_cls: 0.0523, decode.d3.loss_mask: 0.3004, decode.d3.loss_dice: 0.5555, decode.d4.loss_cls: 0.0616, decode.d4.loss_mask: 0.2990, decode.d4.loss_dice: 0.5518, decode.d5.loss_cls: 0.0507, decode.d5.loss_mask: 0.2986, decode.d5.loss_dice: 0.5524, decode.d6.loss_cls: 0.0476, decode.d6.loss_mask: 0.2992, decode.d6.loss_dice: 0.5576, decode.d7.loss_cls: 0.0543, decode.d7.loss_mask: 0.3000, decode.d7.loss_dice: 0.5574, decode.d8.loss_cls: 0.0469, decode.d8.loss_mask: 0.3017, decode.d8.loss_dice: 0.5594, loss: 9.3221
2023-09-28 13:57:39,528 - mmseg - INFO - Iter [6900/40000]	lr: 1.188e-06, eta: 1 day, 0:37:06, time: 2.207, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0867, decode.loss_mask: 0.3085, decode.loss_dice: 0.6004, decode.d0.loss_cls: 0.2604, decode.d0.loss_mask: 0.3148, decode.d0.loss_dice: 0.6085, decode.d1.loss_cls: 0.1037, decode.d1.loss_mask: 0.3097, decode.d1.loss_dice: 0.6114, decode.d2.loss_cls: 0.0964, decode.d2.loss_mask: 0.3103, decode.d2.loss_dice: 0.6000, decode.d3.loss_cls: 0.0924, decode.d3.loss_mask: 0.3093, decode.d3.loss_dice: 0.6075, decode.d4.loss_cls: 0.1121, decode.d4.loss_mask: 0.3098, decode.d4.loss_dice: 0.6109, decode.d5.loss_cls: 0.1063, decode.d5.loss_mask: 0.3084, decode.d5.loss_dice: 0.5993, decode.d6.loss_cls: 0.0943, decode.d6.loss_mask: 0.3086, decode.d6.loss_dice: 0.5939, decode.d7.loss_cls: 0.0994, decode.d7.loss_mask: 0.3086, decode.d7.loss_dice: 0.5996, decode.d8.loss_cls: 0.0794, decode.d8.loss_mask: 0.3099, decode.d8.loss_dice: 0.5955, loss: 10.2561
2023-09-28 13:59:30,512 - mmseg - INFO - Iter [6950/40000]	lr: 1.186e-06, eta: 1 day, 0:33:03, time: 2.220, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0877, decode.loss_mask: 0.2852, decode.loss_dice: 0.5757, decode.d0.loss_cls: 0.2143, decode.d0.loss_mask: 0.2939, decode.d0.loss_dice: 0.5955, decode.d1.loss_cls: 0.0778, decode.d1.loss_mask: 0.2878, decode.d1.loss_dice: 0.5759, decode.d2.loss_cls: 0.0648, decode.d2.loss_mask: 0.2851, decode.d2.loss_dice: 0.5712, decode.d3.loss_cls: 0.0751, decode.d3.loss_mask: 0.2849, decode.d3.loss_dice: 0.5738, decode.d4.loss_cls: 0.0829, decode.d4.loss_mask: 0.2870, decode.d4.loss_dice: 0.5822, decode.d5.loss_cls: 0.0795, decode.d5.loss_mask: 0.2873, decode.d5.loss_dice: 0.5718, decode.d6.loss_cls: 0.0802, decode.d6.loss_mask: 0.2856, decode.d6.loss_dice: 0.5590, decode.d7.loss_cls: 0.0721, decode.d7.loss_mask: 0.2855, decode.d7.loss_dice: 0.5714, decode.d8.loss_cls: 0.0876, decode.d8.loss_mask: 0.2853, decode.d8.loss_dice: 0.5801, loss: 9.5462
2023-09-28 14:01:20,737 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 14:01:20,737 - mmseg - INFO - Iter [7000/40000]	lr: 1.185e-06, eta: 1 day, 0:28:59, time: 2.205, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0587, decode.loss_mask: 0.3286, decode.loss_dice: 0.5752, decode.d0.loss_cls: 0.2289, decode.d0.loss_mask: 0.3350, decode.d0.loss_dice: 0.6067, decode.d1.loss_cls: 0.0773, decode.d1.loss_mask: 0.3319, decode.d1.loss_dice: 0.5991, decode.d2.loss_cls: 0.0670, decode.d2.loss_mask: 0.3306, decode.d2.loss_dice: 0.5999, decode.d3.loss_cls: 0.0777, decode.d3.loss_mask: 0.3280, decode.d3.loss_dice: 0.5872, decode.d4.loss_cls: 0.0728, decode.d4.loss_mask: 0.3272, decode.d4.loss_dice: 0.5865, decode.d5.loss_cls: 0.0682, decode.d5.loss_mask: 0.3287, decode.d5.loss_dice: 0.5929, decode.d6.loss_cls: 0.0665, decode.d6.loss_mask: 0.3301, decode.d6.loss_dice: 0.5916, decode.d7.loss_cls: 0.0645, decode.d7.loss_mask: 0.3273, decode.d7.loss_dice: 0.5885, decode.d8.loss_cls: 0.0634, decode.d8.loss_mask: 0.3295, decode.d8.loss_dice: 0.5872, loss: 10.0570
2023-09-28 14:03:12,224 - mmseg - INFO - Iter [7050/40000]	lr: 1.183e-06, eta: 1 day, 0:25:02, time: 2.230, data_time: 0.032, memory: 21542, decode.loss_cls: 0.1027, decode.loss_mask: 0.2941, decode.loss_dice: 0.6114, decode.d0.loss_cls: 0.2378, decode.d0.loss_mask: 0.2992, decode.d0.loss_dice: 0.6150, decode.d1.loss_cls: 0.1121, decode.d1.loss_mask: 0.2945, decode.d1.loss_dice: 0.6207, decode.d2.loss_cls: 0.1128, decode.d2.loss_mask: 0.2931, decode.d2.loss_dice: 0.6147, decode.d3.loss_cls: 0.0942, decode.d3.loss_mask: 0.2943, decode.d3.loss_dice: 0.6140, decode.d4.loss_cls: 0.0857, decode.d4.loss_mask: 0.2952, decode.d4.loss_dice: 0.6112, decode.d5.loss_cls: 0.1156, decode.d5.loss_mask: 0.2933, decode.d5.loss_dice: 0.6211, decode.d6.loss_cls: 0.0945, decode.d6.loss_mask: 0.2954, decode.d6.loss_dice: 0.6219, decode.d7.loss_cls: 0.0965, decode.d7.loss_mask: 0.2958, decode.d7.loss_dice: 0.6256, decode.d8.loss_cls: 0.1148, decode.d8.loss_mask: 0.2944, decode.d8.loss_dice: 0.6203, loss: 10.2919
2023-09-28 14:05:03,708 - mmseg - INFO - Iter [7100/40000]	lr: 1.181e-06, eta: 1 day, 0:21:07, time: 2.230, data_time: 0.029, memory: 21542, decode.loss_cls: 0.1034, decode.loss_mask: 0.3133, decode.loss_dice: 0.6301, decode.d0.loss_cls: 0.2518, decode.d0.loss_mask: 0.3153, decode.d0.loss_dice: 0.6428, decode.d1.loss_cls: 0.1055, decode.d1.loss_mask: 0.3121, decode.d1.loss_dice: 0.6267, decode.d2.loss_cls: 0.0975, decode.d2.loss_mask: 0.3129, decode.d2.loss_dice: 0.6311, decode.d3.loss_cls: 0.1094, decode.d3.loss_mask: 0.3106, decode.d3.loss_dice: 0.6261, decode.d4.loss_cls: 0.0968, decode.d4.loss_mask: 0.3135, decode.d4.loss_dice: 0.6368, decode.d5.loss_cls: 0.1108, decode.d5.loss_mask: 0.3133, decode.d5.loss_dice: 0.6272, decode.d6.loss_cls: 0.0881, decode.d6.loss_mask: 0.3127, decode.d6.loss_dice: 0.6328, decode.d7.loss_cls: 0.1100, decode.d7.loss_mask: 0.3127, decode.d7.loss_dice: 0.6381, decode.d8.loss_cls: 0.1138, decode.d8.loss_mask: 0.3121, decode.d8.loss_dice: 0.6373, loss: 10.6446
2023-09-28 14:06:55,046 - mmseg - INFO - Iter [7150/40000]	lr: 1.179e-06, eta: 1 day, 0:17:14, time: 2.227, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0853, decode.loss_mask: 0.2916, decode.loss_dice: 0.6230, decode.d0.loss_cls: 0.2448, decode.d0.loss_mask: 0.2995, decode.d0.loss_dice: 0.6319, decode.d1.loss_cls: 0.1235, decode.d1.loss_mask: 0.2937, decode.d1.loss_dice: 0.6310, decode.d2.loss_cls: 0.1003, decode.d2.loss_mask: 0.2921, decode.d2.loss_dice: 0.6170, decode.d3.loss_cls: 0.0805, decode.d3.loss_mask: 0.2939, decode.d3.loss_dice: 0.6208, decode.d4.loss_cls: 0.0794, decode.d4.loss_mask: 0.2914, decode.d4.loss_dice: 0.6117, decode.d5.loss_cls: 0.0984, decode.d5.loss_mask: 0.2921, decode.d5.loss_dice: 0.6286, decode.d6.loss_cls: 0.0947, decode.d6.loss_mask: 0.2934, decode.d6.loss_dice: 0.6224, decode.d7.loss_cls: 0.0882, decode.d7.loss_mask: 0.2909, decode.d7.loss_dice: 0.6170, decode.d8.loss_cls: 0.0766, decode.d8.loss_mask: 0.2930, decode.d8.loss_dice: 0.6257, loss: 10.2325
2023-09-28 14:08:46,326 - mmseg - INFO - Iter [7200/40000]	lr: 1.177e-06, eta: 1 day, 0:13:21, time: 2.226, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0970, decode.loss_mask: 0.2768, decode.loss_dice: 0.6258, decode.d0.loss_cls: 0.2544, decode.d0.loss_mask: 0.2840, decode.d0.loss_dice: 0.6325, decode.d1.loss_cls: 0.1345, decode.d1.loss_mask: 0.2763, decode.d1.loss_dice: 0.6210, decode.d2.loss_cls: 0.1217, decode.d2.loss_mask: 0.2740, decode.d2.loss_dice: 0.6256, decode.d3.loss_cls: 0.1229, decode.d3.loss_mask: 0.2738, decode.d3.loss_dice: 0.6182, decode.d4.loss_cls: 0.1135, decode.d4.loss_mask: 0.2739, decode.d4.loss_dice: 0.6279, decode.d5.loss_cls: 0.0966, decode.d5.loss_mask: 0.2790, decode.d5.loss_dice: 0.6289, decode.d6.loss_cls: 0.1081, decode.d6.loss_mask: 0.2795, decode.d6.loss_dice: 0.6152, decode.d7.loss_cls: 0.0839, decode.d7.loss_mask: 0.2797, decode.d7.loss_dice: 0.6218, decode.d8.loss_cls: 0.1165, decode.d8.loss_mask: 0.2791, decode.d8.loss_dice: 0.6269, loss: 10.2690
2023-09-28 14:10:37,484 - mmseg - INFO - Iter [7250/40000]	lr: 1.176e-06, eta: 1 day, 0:09:30, time: 2.223, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0982, decode.loss_mask: 0.2983, decode.loss_dice: 0.6389, decode.d0.loss_cls: 0.2710, decode.d0.loss_mask: 0.3036, decode.d0.loss_dice: 0.6425, decode.d1.loss_cls: 0.1076, decode.d1.loss_mask: 0.3016, decode.d1.loss_dice: 0.6370, decode.d2.loss_cls: 0.0910, decode.d2.loss_mask: 0.2987, decode.d2.loss_dice: 0.6376, decode.d3.loss_cls: 0.0959, decode.d3.loss_mask: 0.2987, decode.d3.loss_dice: 0.6253, decode.d4.loss_cls: 0.0953, decode.d4.loss_mask: 0.3022, decode.d4.loss_dice: 0.6437, decode.d5.loss_cls: 0.0979, decode.d5.loss_mask: 0.2991, decode.d5.loss_dice: 0.6336, decode.d6.loss_cls: 0.1039, decode.d6.loss_mask: 0.3008, decode.d6.loss_dice: 0.6324, decode.d7.loss_cls: 0.0944, decode.d7.loss_mask: 0.3012, decode.d7.loss_dice: 0.6345, decode.d8.loss_cls: 0.0897, decode.d8.loss_mask: 0.3010, decode.d8.loss_dice: 0.6250, loss: 10.5005
2023-09-28 14:12:28,260 - mmseg - INFO - Iter [7300/40000]	lr: 1.174e-06, eta: 1 day, 0:05:38, time: 2.215, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0731, decode.loss_mask: 0.2615, decode.loss_dice: 0.5723, decode.d0.loss_cls: 0.2262, decode.d0.loss_mask: 0.2674, decode.d0.loss_dice: 0.5798, decode.d1.loss_cls: 0.0833, decode.d1.loss_mask: 0.2627, decode.d1.loss_dice: 0.5751, decode.d2.loss_cls: 0.0837, decode.d2.loss_mask: 0.2625, decode.d2.loss_dice: 0.5875, decode.d3.loss_cls: 0.0882, decode.d3.loss_mask: 0.2615, decode.d3.loss_dice: 0.5837, decode.d4.loss_cls: 0.0918, decode.d4.loss_mask: 0.2621, decode.d4.loss_dice: 0.5899, decode.d5.loss_cls: 0.0884, decode.d5.loss_mask: 0.2631, decode.d5.loss_dice: 0.5849, decode.d6.loss_cls: 0.0753, decode.d6.loss_mask: 0.2630, decode.d6.loss_dice: 0.5882, decode.d7.loss_cls: 0.0836, decode.d7.loss_mask: 0.2622, decode.d7.loss_dice: 0.5774, decode.d8.loss_cls: 0.0836, decode.d8.loss_mask: 0.2627, decode.d8.loss_dice: 0.5769, loss: 9.4218
2023-09-28 14:14:19,880 - mmseg - INFO - Iter [7350/40000]	lr: 1.172e-06, eta: 1 day, 0:01:53, time: 2.233, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0868, decode.loss_mask: 0.2856, decode.loss_dice: 0.5707, decode.d0.loss_cls: 0.2568, decode.d0.loss_mask: 0.2893, decode.d0.loss_dice: 0.5689, decode.d1.loss_cls: 0.0960, decode.d1.loss_mask: 0.2825, decode.d1.loss_dice: 0.5695, decode.d2.loss_cls: 0.0959, decode.d2.loss_mask: 0.2823, decode.d2.loss_dice: 0.5539, decode.d3.loss_cls: 0.0755, decode.d3.loss_mask: 0.2874, decode.d3.loss_dice: 0.5609, decode.d4.loss_cls: 0.1004, decode.d4.loss_mask: 0.2874, decode.d4.loss_dice: 0.5670, decode.d5.loss_cls: 0.0717, decode.d5.loss_mask: 0.2865, decode.d5.loss_dice: 0.5667, decode.d6.loss_cls: 0.0874, decode.d6.loss_mask: 0.2858, decode.d6.loss_dice: 0.5515, decode.d7.loss_cls: 0.0805, decode.d7.loss_mask: 0.2872, decode.d7.loss_dice: 0.5567, decode.d8.loss_cls: 0.0815, decode.d8.loss_mask: 0.2874, decode.d8.loss_dice: 0.5548, loss: 9.5145
2023-09-28 14:16:10,229 - mmseg - INFO - Iter [7400/40000]	lr: 1.170e-06, eta: 23:58:03, time: 2.207, data_time: 0.035, memory: 21542, decode.loss_cls: 0.0973, decode.loss_mask: 0.3051, decode.loss_dice: 0.6489, decode.d0.loss_cls: 0.2504, decode.d0.loss_mask: 0.3168, decode.d0.loss_dice: 0.6581, decode.d1.loss_cls: 0.1459, decode.d1.loss_mask: 0.3100, decode.d1.loss_dice: 0.6619, decode.d2.loss_cls: 0.1358, decode.d2.loss_mask: 0.3086, decode.d2.loss_dice: 0.6387, decode.d3.loss_cls: 0.1184, decode.d3.loss_mask: 0.3066, decode.d3.loss_dice: 0.6353, decode.d4.loss_cls: 0.1226, decode.d4.loss_mask: 0.3075, decode.d4.loss_dice: 0.6463, decode.d5.loss_cls: 0.0927, decode.d5.loss_mask: 0.3068, decode.d5.loss_dice: 0.6463, decode.d6.loss_cls: 0.1080, decode.d6.loss_mask: 0.3050, decode.d6.loss_dice: 0.6292, decode.d7.loss_cls: 0.1194, decode.d7.loss_mask: 0.3060, decode.d7.loss_dice: 0.6448, decode.d8.loss_cls: 0.0954, decode.d8.loss_mask: 0.3064, decode.d8.loss_dice: 0.6446, loss: 10.8189
2023-09-28 14:18:01,475 - mmseg - INFO - Iter [7450/40000]	lr: 1.168e-06, eta: 23:54:18, time: 2.225, data_time: 0.037, memory: 21542, decode.loss_cls: 0.0959, decode.loss_mask: 0.3140, decode.loss_dice: 0.6302, decode.d0.loss_cls: 0.2520, decode.d0.loss_mask: 0.3287, decode.d0.loss_dice: 0.6523, decode.d1.loss_cls: 0.0988, decode.d1.loss_mask: 0.3186, decode.d1.loss_dice: 0.6522, decode.d2.loss_cls: 0.1190, decode.d2.loss_mask: 0.3127, decode.d2.loss_dice: 0.6344, decode.d3.loss_cls: 0.1013, decode.d3.loss_mask: 0.3109, decode.d3.loss_dice: 0.6275, decode.d4.loss_cls: 0.1087, decode.d4.loss_mask: 0.3135, decode.d4.loss_dice: 0.6272, decode.d5.loss_cls: 0.1097, decode.d5.loss_mask: 0.3113, decode.d5.loss_dice: 0.6294, decode.d6.loss_cls: 0.1197, decode.d6.loss_mask: 0.3120, decode.d6.loss_dice: 0.6215, decode.d7.loss_cls: 0.1268, decode.d7.loss_mask: 0.3132, decode.d7.loss_dice: 0.6293, decode.d8.loss_cls: 0.1166, decode.d8.loss_mask: 0.3136, decode.d8.loss_dice: 0.6240, loss: 10.7246
2023-09-28 14:19:51,342 - mmseg - INFO - Iter [7500/40000]	lr: 1.167e-06, eta: 23:50:29, time: 2.197, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0837, decode.loss_mask: 0.2833, decode.loss_dice: 0.6172, decode.d0.loss_cls: 0.2297, decode.d0.loss_mask: 0.2840, decode.d0.loss_dice: 0.6312, decode.d1.loss_cls: 0.1164, decode.d1.loss_mask: 0.2822, decode.d1.loss_dice: 0.6441, decode.d2.loss_cls: 0.0919, decode.d2.loss_mask: 0.2812, decode.d2.loss_dice: 0.6238, decode.d3.loss_cls: 0.0874, decode.d3.loss_mask: 0.2825, decode.d3.loss_dice: 0.6278, decode.d4.loss_cls: 0.1090, decode.d4.loss_mask: 0.2825, decode.d4.loss_dice: 0.6240, decode.d5.loss_cls: 0.1142, decode.d5.loss_mask: 0.2829, decode.d5.loss_dice: 0.6343, decode.d6.loss_cls: 0.0926, decode.d6.loss_mask: 0.2822, decode.d6.loss_dice: 0.6312, decode.d7.loss_cls: 0.0927, decode.d7.loss_mask: 0.2833, decode.d7.loss_dice: 0.6141, decode.d8.loss_cls: 0.0975, decode.d8.loss_mask: 0.2820, decode.d8.loss_dice: 0.6071, loss: 10.1960
2023-09-28 14:21:41,264 - mmseg - INFO - Iter [7550/40000]	lr: 1.165e-06, eta: 23:46:42, time: 2.197, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0728, decode.loss_mask: 0.3024, decode.loss_dice: 0.6068, decode.d0.loss_cls: 0.2542, decode.d0.loss_mask: 0.3090, decode.d0.loss_dice: 0.6076, decode.d1.loss_cls: 0.0721, decode.d1.loss_mask: 0.3018, decode.d1.loss_dice: 0.6049, decode.d2.loss_cls: 0.0681, decode.d2.loss_mask: 0.3004, decode.d2.loss_dice: 0.5946, decode.d3.loss_cls: 0.0584, decode.d3.loss_mask: 0.3016, decode.d3.loss_dice: 0.5926, decode.d4.loss_cls: 0.0829, decode.d4.loss_mask: 0.3006, decode.d4.loss_dice: 0.5932, decode.d5.loss_cls: 0.0604, decode.d5.loss_mask: 0.3033, decode.d5.loss_dice: 0.5921, decode.d6.loss_cls: 0.0430, decode.d6.loss_mask: 0.3036, decode.d6.loss_dice: 0.6063, decode.d7.loss_cls: 0.0603, decode.d7.loss_mask: 0.3038, decode.d7.loss_dice: 0.5999, decode.d8.loss_cls: 0.0658, decode.d8.loss_mask: 0.3015, decode.d8.loss_dice: 0.5929, loss: 9.8568
2023-09-28 14:23:31,799 - mmseg - INFO - Iter [7600/40000]	lr: 1.163e-06, eta: 23:42:59, time: 2.212, data_time: 0.035, memory: 21542, decode.loss_cls: 0.0810, decode.loss_mask: 0.3208, decode.loss_dice: 0.6262, decode.d0.loss_cls: 0.2513, decode.d0.loss_mask: 0.3341, decode.d0.loss_dice: 0.6331, decode.d1.loss_cls: 0.1288, decode.d1.loss_mask: 0.3218, decode.d1.loss_dice: 0.6227, decode.d2.loss_cls: 0.1005, decode.d2.loss_mask: 0.3213, decode.d2.loss_dice: 0.6197, decode.d3.loss_cls: 0.0995, decode.d3.loss_mask: 0.3206, decode.d3.loss_dice: 0.6235, decode.d4.loss_cls: 0.1188, decode.d4.loss_mask: 0.3193, decode.d4.loss_dice: 0.6193, decode.d5.loss_cls: 0.1162, decode.d5.loss_mask: 0.3214, decode.d5.loss_dice: 0.6237, decode.d6.loss_cls: 0.1005, decode.d6.loss_mask: 0.3194, decode.d6.loss_dice: 0.6244, decode.d7.loss_cls: 0.1045, decode.d7.loss_mask: 0.3211, decode.d7.loss_dice: 0.6176, decode.d8.loss_cls: 0.1120, decode.d8.loss_mask: 0.3223, decode.d8.loss_dice: 0.6216, loss: 10.6669
2023-09-28 14:25:22,865 - mmseg - INFO - Iter [7650/40000]	lr: 1.161e-06, eta: 23:39:20, time: 2.221, data_time: 0.032, memory: 21542, decode.loss_cls: 0.1066, decode.loss_mask: 0.3226, decode.loss_dice: 0.6641, decode.d0.loss_cls: 0.2868, decode.d0.loss_mask: 0.3316, decode.d0.loss_dice: 0.6885, decode.d1.loss_cls: 0.1731, decode.d1.loss_mask: 0.3264, decode.d1.loss_dice: 0.6816, decode.d2.loss_cls: 0.1188, decode.d2.loss_mask: 0.3269, decode.d2.loss_dice: 0.6594, decode.d3.loss_cls: 0.1233, decode.d3.loss_mask: 0.3250, decode.d3.loss_dice: 0.6647, decode.d4.loss_cls: 0.1186, decode.d4.loss_mask: 0.3238, decode.d4.loss_dice: 0.6753, decode.d5.loss_cls: 0.1203, decode.d5.loss_mask: 0.3249, decode.d5.loss_dice: 0.6798, decode.d6.loss_cls: 0.1349, decode.d6.loss_mask: 0.3225, decode.d6.loss_dice: 0.6728, decode.d7.loss_cls: 0.1215, decode.d7.loss_mask: 0.3237, decode.d7.loss_dice: 0.6665, decode.d8.loss_cls: 0.1284, decode.d8.loss_mask: 0.3257, decode.d8.loss_dice: 0.6703, loss: 11.4082
2023-09-28 14:27:15,937 - mmseg - INFO - Iter [7700/40000]	lr: 1.159e-06, eta: 23:35:50, time: 2.262, data_time: 0.083, memory: 21542, decode.loss_cls: 0.0620, decode.loss_mask: 0.3008, decode.loss_dice: 0.6462, decode.d0.loss_cls: 0.2344, decode.d0.loss_mask: 0.3023, decode.d0.loss_dice: 0.6420, decode.d1.loss_cls: 0.0793, decode.d1.loss_mask: 0.3016, decode.d1.loss_dice: 0.6478, decode.d2.loss_cls: 0.0710, decode.d2.loss_mask: 0.3007, decode.d2.loss_dice: 0.6291, decode.d3.loss_cls: 0.0622, decode.d3.loss_mask: 0.3016, decode.d3.loss_dice: 0.6430, decode.d4.loss_cls: 0.0728, decode.d4.loss_mask: 0.3034, decode.d4.loss_dice: 0.6461, decode.d5.loss_cls: 0.0758, decode.d5.loss_mask: 0.3009, decode.d5.loss_dice: 0.6438, decode.d6.loss_cls: 0.0737, decode.d6.loss_mask: 0.3008, decode.d6.loss_dice: 0.6342, decode.d7.loss_cls: 0.0681, decode.d7.loss_mask: 0.3033, decode.d7.loss_dice: 0.6495, decode.d8.loss_cls: 0.0801, decode.d8.loss_mask: 0.3027, decode.d8.loss_dice: 0.6403, loss: 10.3194
2023-09-28 14:29:06,973 - mmseg - INFO - Iter [7750/40000]	lr: 1.158e-06, eta: 23:32:14, time: 2.221, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0898, decode.loss_mask: 0.3027, decode.loss_dice: 0.6074, decode.d0.loss_cls: 0.2123, decode.d0.loss_mask: 0.3126, decode.d0.loss_dice: 0.6056, decode.d1.loss_cls: 0.0878, decode.d1.loss_mask: 0.3018, decode.d1.loss_dice: 0.6138, decode.d2.loss_cls: 0.0806, decode.d2.loss_mask: 0.3062, decode.d2.loss_dice: 0.6099, decode.d3.loss_cls: 0.1136, decode.d3.loss_mask: 0.2984, decode.d3.loss_dice: 0.6074, decode.d4.loss_cls: 0.0941, decode.d4.loss_mask: 0.3017, decode.d4.loss_dice: 0.6130, decode.d5.loss_cls: 0.0950, decode.d5.loss_mask: 0.3004, decode.d5.loss_dice: 0.6081, decode.d6.loss_cls: 0.0901, decode.d6.loss_mask: 0.3010, decode.d6.loss_dice: 0.6080, decode.d7.loss_cls: 0.0812, decode.d7.loss_mask: 0.3041, decode.d7.loss_dice: 0.6176, decode.d8.loss_cls: 0.0808, decode.d8.loss_mask: 0.3041, decode.d8.loss_dice: 0.6169, loss: 10.1659
2023-09-28 14:30:58,290 - mmseg - INFO - Iter [7800/40000]	lr: 1.156e-06, eta: 23:28:39, time: 2.226, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0905, decode.loss_mask: 0.3229, decode.loss_dice: 0.6282, decode.d0.loss_cls: 0.2535, decode.d0.loss_mask: 0.3293, decode.d0.loss_dice: 0.6187, decode.d1.loss_cls: 0.1064, decode.d1.loss_mask: 0.3212, decode.d1.loss_dice: 0.6219, decode.d2.loss_cls: 0.1030, decode.d2.loss_mask: 0.3209, decode.d2.loss_dice: 0.6061, decode.d3.loss_cls: 0.0732, decode.d3.loss_mask: 0.3215, decode.d3.loss_dice: 0.6121, decode.d4.loss_cls: 0.1059, decode.d4.loss_mask: 0.3213, decode.d4.loss_dice: 0.6082, decode.d5.loss_cls: 0.0944, decode.d5.loss_mask: 0.3219, decode.d5.loss_dice: 0.6125, decode.d6.loss_cls: 0.0728, decode.d6.loss_mask: 0.3235, decode.d6.loss_dice: 0.6212, decode.d7.loss_cls: 0.0906, decode.d7.loss_mask: 0.3224, decode.d7.loss_dice: 0.6218, decode.d8.loss_cls: 0.0967, decode.d8.loss_mask: 0.3210, decode.d8.loss_dice: 0.6048, loss: 10.4685
2023-09-28 14:32:48,325 - mmseg - INFO - Iter [7850/40000]	lr: 1.154e-06, eta: 23:25:01, time: 2.201, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0685, decode.loss_mask: 0.2908, decode.loss_dice: 0.6293, decode.d0.loss_cls: 0.2417, decode.d0.loss_mask: 0.2927, decode.d0.loss_dice: 0.6479, decode.d1.loss_cls: 0.1026, decode.d1.loss_mask: 0.2893, decode.d1.loss_dice: 0.6445, decode.d2.loss_cls: 0.0973, decode.d2.loss_mask: 0.2933, decode.d2.loss_dice: 0.6310, decode.d3.loss_cls: 0.0791, decode.d3.loss_mask: 0.2936, decode.d3.loss_dice: 0.6262, decode.d4.loss_cls: 0.0903, decode.d4.loss_mask: 0.2946, decode.d4.loss_dice: 0.6260, decode.d5.loss_cls: 0.0956, decode.d5.loss_mask: 0.2915, decode.d5.loss_dice: 0.6267, decode.d6.loss_cls: 0.0834, decode.d6.loss_mask: 0.2919, decode.d6.loss_dice: 0.6251, decode.d7.loss_cls: 0.1040, decode.d7.loss_mask: 0.2911, decode.d7.loss_dice: 0.6292, decode.d8.loss_cls: 0.0949, decode.d8.loss_mask: 0.2914, decode.d8.loss_dice: 0.6314, loss: 10.2946
2023-09-28 14:34:39,307 - mmseg - INFO - Iter [7900/40000]	lr: 1.152e-06, eta: 23:21:28, time: 2.220, data_time: 0.031, memory: 21542, decode.loss_cls: 0.1335, decode.loss_mask: 0.3012, decode.loss_dice: 0.5966, decode.d0.loss_cls: 0.2614, decode.d0.loss_mask: 0.3043, decode.d0.loss_dice: 0.5845, decode.d1.loss_cls: 0.1149, decode.d1.loss_mask: 0.3001, decode.d1.loss_dice: 0.5775, decode.d2.loss_cls: 0.1316, decode.d2.loss_mask: 0.3008, decode.d2.loss_dice: 0.5703, decode.d3.loss_cls: 0.1076, decode.d3.loss_mask: 0.3042, decode.d3.loss_dice: 0.5762, decode.d4.loss_cls: 0.1381, decode.d4.loss_mask: 0.3035, decode.d4.loss_dice: 0.5706, decode.d5.loss_cls: 0.0973, decode.d5.loss_mask: 0.3041, decode.d5.loss_dice: 0.5788, decode.d6.loss_cls: 0.0997, decode.d6.loss_mask: 0.3069, decode.d6.loss_dice: 0.5824, decode.d7.loss_cls: 0.1096, decode.d7.loss_mask: 0.3016, decode.d7.loss_dice: 0.5836, decode.d8.loss_cls: 0.0972, decode.d8.loss_mask: 0.3018, decode.d8.loss_dice: 0.5842, loss: 10.1241
2023-09-28 14:36:29,027 - mmseg - INFO - Iter [7950/40000]	lr: 1.150e-06, eta: 23:17:52, time: 2.194, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0609, decode.loss_mask: 0.3395, decode.loss_dice: 0.6204, decode.d0.loss_cls: 0.2446, decode.d0.loss_mask: 0.3580, decode.d0.loss_dice: 0.6256, decode.d1.loss_cls: 0.0911, decode.d1.loss_mask: 0.3404, decode.d1.loss_dice: 0.6268, decode.d2.loss_cls: 0.1125, decode.d2.loss_mask: 0.3381, decode.d2.loss_dice: 0.6225, decode.d3.loss_cls: 0.0922, decode.d3.loss_mask: 0.3373, decode.d3.loss_dice: 0.6275, decode.d4.loss_cls: 0.0805, decode.d4.loss_mask: 0.3377, decode.d4.loss_dice: 0.6343, decode.d5.loss_cls: 0.0830, decode.d5.loss_mask: 0.3347, decode.d5.loss_dice: 0.6251, decode.d6.loss_cls: 0.1031, decode.d6.loss_mask: 0.3312, decode.d6.loss_dice: 0.6088, decode.d7.loss_cls: 0.0926, decode.d7.loss_mask: 0.3395, decode.d7.loss_dice: 0.6152, decode.d8.loss_cls: 0.0930, decode.d8.loss_mask: 0.3387, decode.d8.loss_dice: 0.6167, loss: 10.6715
2023-09-28 14:38:19,468 - mmseg - INFO - Saving checkpoint at 8000 iterations
2023-09-28 14:38:39,566 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 14:38:39,566 - mmseg - INFO - Iter [8000/40000]	lr: 1.149e-06, eta: 23:15:40, time: 2.611, data_time: 0.033, memory: 21542, decode.loss_cls: 0.1211, decode.loss_mask: 0.2961, decode.loss_dice: 0.6041, decode.d0.loss_cls: 0.2399, decode.d0.loss_mask: 0.3055, decode.d0.loss_dice: 0.6282, decode.d1.loss_cls: 0.1074, decode.d1.loss_mask: 0.3017, decode.d1.loss_dice: 0.6244, decode.d2.loss_cls: 0.1103, decode.d2.loss_mask: 0.3000, decode.d2.loss_dice: 0.6232, decode.d3.loss_cls: 0.1052, decode.d3.loss_mask: 0.2999, decode.d3.loss_dice: 0.6097, decode.d4.loss_cls: 0.1180, decode.d4.loss_mask: 0.2988, decode.d4.loss_dice: 0.6111, decode.d5.loss_cls: 0.1193, decode.d5.loss_mask: 0.2991, decode.d5.loss_dice: 0.6146, decode.d6.loss_cls: 0.1172, decode.d6.loss_mask: 0.2991, decode.d6.loss_dice: 0.6176, decode.d7.loss_cls: 0.1287, decode.d7.loss_mask: 0.2971, decode.d7.loss_dice: 0.6101, decode.d8.loss_cls: 0.1012, decode.d8.loss_mask: 0.2987, decode.d8.loss_dice: 0.6235, loss: 10.4308
2023-09-28 14:55:39,404 - mmseg - INFO - per class results:
2023-09-28 14:55:39,406 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 92.98 |  97.2 |
|    Sidewalk   | 68.28 | 83.49 |
|  Construction | 81.99 | 94.67 |
|     Fence     | 30.11 | 32.39 |
|      Pole     | 55.41 | 71.95 |
| Traffic Light | 67.31 | 79.47 |
|  Traffic Sign | 71.35 | 80.79 |
|     Nature    | 88.59 | 93.49 |
|      Sky      | 96.64 | 98.03 |
|     Person    | 35.74 |  39.0 |
|     Rider     |  9.21 | 69.69 |
|      Car      | 92.04 | 95.05 |
|   background  | 96.35 | 97.63 |
+---------------+-------+-------+
2023-09-28 14:55:39,406 - mmseg - INFO - Summary:
2023-09-28 14:55:39,406 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.44 | 68.15 | 79.45 |
+-------+-------+-------+
2023-09-28 14:55:39,408 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 14:55:39,408 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9444, mIoU: 0.6815, mAcc: 0.7945, IoU.Road: 0.9298, IoU.Sidewalk: 0.6828, IoU.Construction: 0.8199, IoU.Fence: 0.3011, IoU.Pole: 0.5541, IoU.Traffic Light: 0.6731, IoU.Traffic Sign: 0.7135, IoU.Nature: 0.8859, IoU.Sky: 0.9664, IoU.Person: 0.3574, IoU.Rider: 0.0921, IoU.Car: 0.9204, IoU.background: 0.9635, Acc.Road: 0.9720, Acc.Sidewalk: 0.8349, Acc.Construction: 0.9467, Acc.Fence: 0.3239, Acc.Pole: 0.7195, Acc.Traffic Light: 0.7947, Acc.Traffic Sign: 0.8079, Acc.Nature: 0.9349, Acc.Sky: 0.9803, Acc.Person: 0.3900, Acc.Rider: 0.6969, Acc.Car: 0.9505, Acc.background: 0.9763
2023-09-28 14:57:29,767 - mmseg - INFO - Iter [8050/40000]	lr: 1.147e-06, eta: 1 day, 0:19:35, time: 22.604, data_time: 20.432, memory: 21542, decode.loss_cls: 0.0865, decode.loss_mask: 0.3273, decode.loss_dice: 0.6170, decode.d0.loss_cls: 0.2262, decode.d0.loss_mask: 0.3348, decode.d0.loss_dice: 0.6399, decode.d1.loss_cls: 0.1065, decode.d1.loss_mask: 0.3254, decode.d1.loss_dice: 0.6159, decode.d2.loss_cls: 0.1122, decode.d2.loss_mask: 0.3279, decode.d2.loss_dice: 0.6096, decode.d3.loss_cls: 0.1041, decode.d3.loss_mask: 0.3294, decode.d3.loss_dice: 0.6130, decode.d4.loss_cls: 0.1124, decode.d4.loss_mask: 0.3280, decode.d4.loss_dice: 0.6117, decode.d5.loss_cls: 0.0917, decode.d5.loss_mask: 0.3292, decode.d5.loss_dice: 0.6120, decode.d6.loss_cls: 0.0936, decode.d6.loss_mask: 0.3264, decode.d6.loss_dice: 0.6047, decode.d7.loss_cls: 0.0960, decode.d7.loss_mask: 0.3238, decode.d7.loss_dice: 0.6057, decode.d8.loss_cls: 0.1005, decode.d8.loss_mask: 0.3277, decode.d8.loss_dice: 0.6225, loss: 10.5616
2023-09-28 14:59:20,727 - mmseg - INFO - Iter [8100/40000]	lr: 1.145e-06, eta: 1 day, 0:15:35, time: 2.219, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0941, decode.loss_mask: 0.3123, decode.loss_dice: 0.6351, decode.d0.loss_cls: 0.2258, decode.d0.loss_mask: 0.3194, decode.d0.loss_dice: 0.6618, decode.d1.loss_cls: 0.1164, decode.d1.loss_mask: 0.3131, decode.d1.loss_dice: 0.6579, decode.d2.loss_cls: 0.1009, decode.d2.loss_mask: 0.3110, decode.d2.loss_dice: 0.6469, decode.d3.loss_cls: 0.0818, decode.d3.loss_mask: 0.3124, decode.d3.loss_dice: 0.6410, decode.d4.loss_cls: 0.0942, decode.d4.loss_mask: 0.3112, decode.d4.loss_dice: 0.6479, decode.d5.loss_cls: 0.0775, decode.d5.loss_mask: 0.3142, decode.d5.loss_dice: 0.6564, decode.d6.loss_cls: 0.0901, decode.d6.loss_mask: 0.3115, decode.d6.loss_dice: 0.6413, decode.d7.loss_cls: 0.0948, decode.d7.loss_mask: 0.3108, decode.d7.loss_dice: 0.6445, decode.d8.loss_cls: 0.0921, decode.d8.loss_mask: 0.3133, decode.d8.loss_dice: 0.6539, loss: 10.6833
2023-09-28 15:01:11,771 - mmseg - INFO - Iter [8150/40000]	lr: 1.143e-06, eta: 1 day, 0:11:38, time: 2.221, data_time: 0.028, memory: 21542, decode.loss_cls: 0.1104, decode.loss_mask: 0.2901, decode.loss_dice: 0.5775, decode.d0.loss_cls: 0.2403, decode.d0.loss_mask: 0.2919, decode.d0.loss_dice: 0.5915, decode.d1.loss_cls: 0.1325, decode.d1.loss_mask: 0.2923, decode.d1.loss_dice: 0.5768, decode.d2.loss_cls: 0.1195, decode.d2.loss_mask: 0.2920, decode.d2.loss_dice: 0.5650, decode.d3.loss_cls: 0.1104, decode.d3.loss_mask: 0.2876, decode.d3.loss_dice: 0.5742, decode.d4.loss_cls: 0.1134, decode.d4.loss_mask: 0.2892, decode.d4.loss_dice: 0.5845, decode.d5.loss_cls: 0.1000, decode.d5.loss_mask: 0.2927, decode.d5.loss_dice: 0.5820, decode.d6.loss_cls: 0.1021, decode.d6.loss_mask: 0.2872, decode.d6.loss_dice: 0.5710, decode.d7.loss_cls: 0.1150, decode.d7.loss_mask: 0.2881, decode.d7.loss_dice: 0.5714, decode.d8.loss_cls: 0.1014, decode.d8.loss_mask: 0.2896, decode.d8.loss_dice: 0.5807, loss: 9.9199
2023-09-28 15:03:02,015 - mmseg - INFO - Iter [8200/40000]	lr: 1.141e-06, eta: 1 day, 0:07:38, time: 2.204, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0715, decode.loss_mask: 0.2721, decode.loss_dice: 0.5788, decode.d0.loss_cls: 0.2324, decode.d0.loss_mask: 0.2745, decode.d0.loss_dice: 0.5873, decode.d1.loss_cls: 0.0918, decode.d1.loss_mask: 0.2728, decode.d1.loss_dice: 0.5719, decode.d2.loss_cls: 0.0880, decode.d2.loss_mask: 0.2733, decode.d2.loss_dice: 0.5808, decode.d3.loss_cls: 0.0680, decode.d3.loss_mask: 0.2747, decode.d3.loss_dice: 0.5801, decode.d4.loss_cls: 0.0860, decode.d4.loss_mask: 0.2732, decode.d4.loss_dice: 0.5801, decode.d5.loss_cls: 0.0868, decode.d5.loss_mask: 0.2718, decode.d5.loss_dice: 0.5699, decode.d6.loss_cls: 0.0864, decode.d6.loss_mask: 0.2716, decode.d6.loss_dice: 0.5715, decode.d7.loss_cls: 0.0811, decode.d7.loss_mask: 0.2726, decode.d7.loss_dice: 0.5707, decode.d8.loss_cls: 0.1043, decode.d8.loss_mask: 0.2741, decode.d8.loss_dice: 0.5716, loss: 9.4895
2023-09-28 15:04:51,437 - mmseg - INFO - Iter [8250/40000]	lr: 1.140e-06, eta: 1 day, 0:03:37, time: 2.189, data_time: 0.033, memory: 21542, decode.loss_cls: 0.1008, decode.loss_mask: 0.2999, decode.loss_dice: 0.6136, decode.d0.loss_cls: 0.2413, decode.d0.loss_mask: 0.3059, decode.d0.loss_dice: 0.6306, decode.d1.loss_cls: 0.1181, decode.d1.loss_mask: 0.2992, decode.d1.loss_dice: 0.6101, decode.d2.loss_cls: 0.0961, decode.d2.loss_mask: 0.3001, decode.d2.loss_dice: 0.6273, decode.d3.loss_cls: 0.1247, decode.d3.loss_mask: 0.3001, decode.d3.loss_dice: 0.6278, decode.d4.loss_cls: 0.0926, decode.d4.loss_mask: 0.2999, decode.d4.loss_dice: 0.6333, decode.d5.loss_cls: 0.0953, decode.d5.loss_mask: 0.2992, decode.d5.loss_dice: 0.6324, decode.d6.loss_cls: 0.0829, decode.d6.loss_mask: 0.2964, decode.d6.loss_dice: 0.6345, decode.d7.loss_cls: 0.1311, decode.d7.loss_mask: 0.2993, decode.d7.loss_dice: 0.6239, decode.d8.loss_cls: 0.0855, decode.d8.loss_mask: 0.2993, decode.d8.loss_dice: 0.6302, loss: 10.4315
2023-09-28 15:06:42,045 - mmseg - INFO - Iter [8300/40000]	lr: 1.138e-06, eta: 23:59:42, time: 2.212, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0750, decode.loss_mask: 0.2707, decode.loss_dice: 0.5625, decode.d0.loss_cls: 0.2073, decode.d0.loss_mask: 0.2713, decode.d0.loss_dice: 0.5778, decode.d1.loss_cls: 0.0806, decode.d1.loss_mask: 0.2709, decode.d1.loss_dice: 0.5634, decode.d2.loss_cls: 0.0640, decode.d2.loss_mask: 0.2697, decode.d2.loss_dice: 0.5678, decode.d3.loss_cls: 0.0630, decode.d3.loss_mask: 0.2707, decode.d3.loss_dice: 0.5643, decode.d4.loss_cls: 0.0869, decode.d4.loss_mask: 0.2700, decode.d4.loss_dice: 0.5643, decode.d5.loss_cls: 0.0782, decode.d5.loss_mask: 0.2681, decode.d5.loss_dice: 0.5599, decode.d6.loss_cls: 0.0901, decode.d6.loss_mask: 0.2692, decode.d6.loss_dice: 0.5587, decode.d7.loss_cls: 0.0769, decode.d7.loss_mask: 0.2703, decode.d7.loss_dice: 0.5655, decode.d8.loss_cls: 0.0951, decode.d8.loss_mask: 0.2691, decode.d8.loss_dice: 0.5666, loss: 9.2676
2023-09-28 15:08:33,574 - mmseg - INFO - Iter [8350/40000]	lr: 1.136e-06, eta: 23:55:52, time: 2.231, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0806, decode.loss_mask: 0.3147, decode.loss_dice: 0.6442, decode.d0.loss_cls: 0.2736, decode.d0.loss_mask: 0.3228, decode.d0.loss_dice: 0.6316, decode.d1.loss_cls: 0.1247, decode.d1.loss_mask: 0.3151, decode.d1.loss_dice: 0.6421, decode.d2.loss_cls: 0.1034, decode.d2.loss_mask: 0.3158, decode.d2.loss_dice: 0.6390, decode.d3.loss_cls: 0.1090, decode.d3.loss_mask: 0.3187, decode.d3.loss_dice: 0.6434, decode.d4.loss_cls: 0.1096, decode.d4.loss_mask: 0.3162, decode.d4.loss_dice: 0.6467, decode.d5.loss_cls: 0.0937, decode.d5.loss_mask: 0.3157, decode.d5.loss_dice: 0.6430, decode.d6.loss_cls: 0.1041, decode.d6.loss_mask: 0.3152, decode.d6.loss_dice: 0.6553, decode.d7.loss_cls: 0.1040, decode.d7.loss_mask: 0.3136, decode.d7.loss_dice: 0.6324, decode.d8.loss_cls: 0.0900, decode.d8.loss_mask: 0.3130, decode.d8.loss_dice: 0.6373, loss: 10.7685
2023-09-28 15:10:24,785 - mmseg - INFO - Iter [8400/40000]	lr: 1.134e-06, eta: 23:52:02, time: 2.224, data_time: 0.033, memory: 21542, decode.loss_cls: 0.1407, decode.loss_mask: 0.3161, decode.loss_dice: 0.6519, decode.d0.loss_cls: 0.2440, decode.d0.loss_mask: 0.3261, decode.d0.loss_dice: 0.6596, decode.d1.loss_cls: 0.1353, decode.d1.loss_mask: 0.3203, decode.d1.loss_dice: 0.6518, decode.d2.loss_cls: 0.1158, decode.d2.loss_mask: 0.3209, decode.d2.loss_dice: 0.6616, decode.d3.loss_cls: 0.1210, decode.d3.loss_mask: 0.3188, decode.d3.loss_dice: 0.6560, decode.d4.loss_cls: 0.1208, decode.d4.loss_mask: 0.3168, decode.d4.loss_dice: 0.6508, decode.d5.loss_cls: 0.1285, decode.d5.loss_mask: 0.3162, decode.d5.loss_dice: 0.6449, decode.d6.loss_cls: 0.1321, decode.d6.loss_mask: 0.3162, decode.d6.loss_dice: 0.6317, decode.d7.loss_cls: 0.1322, decode.d7.loss_mask: 0.3172, decode.d7.loss_dice: 0.6557, decode.d8.loss_cls: 0.1466, decode.d8.loss_mask: 0.3147, decode.d8.loss_dice: 0.6529, loss: 11.1173
2023-09-28 15:12:15,135 - mmseg - INFO - Iter [8450/40000]	lr: 1.133e-06, eta: 23:48:11, time: 2.207, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0849, decode.loss_mask: 0.2975, decode.loss_dice: 0.6048, decode.d0.loss_cls: 0.2410, decode.d0.loss_mask: 0.3030, decode.d0.loss_dice: 0.6269, decode.d1.loss_cls: 0.0865, decode.d1.loss_mask: 0.3004, decode.d1.loss_dice: 0.6054, decode.d2.loss_cls: 0.0837, decode.d2.loss_mask: 0.3009, decode.d2.loss_dice: 0.6067, decode.d3.loss_cls: 0.0960, decode.d3.loss_mask: 0.2997, decode.d3.loss_dice: 0.6024, decode.d4.loss_cls: 0.0771, decode.d4.loss_mask: 0.3005, decode.d4.loss_dice: 0.6132, decode.d5.loss_cls: 0.1013, decode.d5.loss_mask: 0.2963, decode.d5.loss_dice: 0.6043, decode.d6.loss_cls: 0.0822, decode.d6.loss_mask: 0.3001, decode.d6.loss_dice: 0.5981, decode.d7.loss_cls: 0.0803, decode.d7.loss_mask: 0.2984, decode.d7.loss_dice: 0.6076, decode.d8.loss_cls: 0.0891, decode.d8.loss_mask: 0.2989, decode.d8.loss_dice: 0.6011, loss: 10.0881
2023-09-28 15:14:05,633 - mmseg - INFO - Iter [8500/40000]	lr: 1.131e-06, eta: 23:44:21, time: 2.210, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0478, decode.loss_mask: 0.2727, decode.loss_dice: 0.5464, decode.d0.loss_cls: 0.2064, decode.d0.loss_mask: 0.2745, decode.d0.loss_dice: 0.5632, decode.d1.loss_cls: 0.0793, decode.d1.loss_mask: 0.2764, decode.d1.loss_dice: 0.5658, decode.d2.loss_cls: 0.0609, decode.d2.loss_mask: 0.2755, decode.d2.loss_dice: 0.5562, decode.d3.loss_cls: 0.0501, decode.d3.loss_mask: 0.2750, decode.d3.loss_dice: 0.5549, decode.d4.loss_cls: 0.0470, decode.d4.loss_mask: 0.2755, decode.d4.loss_dice: 0.5612, decode.d5.loss_cls: 0.0639, decode.d5.loss_mask: 0.2751, decode.d5.loss_dice: 0.5598, decode.d6.loss_cls: 0.0758, decode.d6.loss_mask: 0.2759, decode.d6.loss_dice: 0.5543, decode.d7.loss_cls: 0.0588, decode.d7.loss_mask: 0.2753, decode.d7.loss_dice: 0.5536, decode.d8.loss_cls: 0.0538, decode.d8.loss_mask: 0.2735, decode.d8.loss_dice: 0.5510, loss: 9.0595
2023-09-28 15:15:55,185 - mmseg - INFO - Iter [8550/40000]	lr: 1.129e-06, eta: 23:40:30, time: 2.191, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0729, decode.loss_mask: 0.3427, decode.loss_dice: 0.6450, decode.d0.loss_cls: 0.2882, decode.d0.loss_mask: 0.3504, decode.d0.loss_dice: 0.6457, decode.d1.loss_cls: 0.0926, decode.d1.loss_mask: 0.3450, decode.d1.loss_dice: 0.6552, decode.d2.loss_cls: 0.0972, decode.d2.loss_mask: 0.3433, decode.d2.loss_dice: 0.6516, decode.d3.loss_cls: 0.0777, decode.d3.loss_mask: 0.3419, decode.d3.loss_dice: 0.6362, decode.d4.loss_cls: 0.0881, decode.d4.loss_mask: 0.3436, decode.d4.loss_dice: 0.6551, decode.d5.loss_cls: 0.0811, decode.d5.loss_mask: 0.3423, decode.d5.loss_dice: 0.6395, decode.d6.loss_cls: 0.0943, decode.d6.loss_mask: 0.3444, decode.d6.loss_dice: 0.6387, decode.d7.loss_cls: 0.1059, decode.d7.loss_mask: 0.3430, decode.d7.loss_dice: 0.6356, decode.d8.loss_cls: 0.0891, decode.d8.loss_mask: 0.3418, decode.d8.loss_dice: 0.6357, loss: 10.9639
2023-09-28 15:17:45,671 - mmseg - INFO - Iter [8600/40000]	lr: 1.127e-06, eta: 23:36:43, time: 2.210, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0620, decode.loss_mask: 0.3302, decode.loss_dice: 0.5666, decode.d0.loss_cls: 0.2357, decode.d0.loss_mask: 0.3240, decode.d0.loss_dice: 0.5824, decode.d1.loss_cls: 0.0675, decode.d1.loss_mask: 0.3216, decode.d1.loss_dice: 0.5749, decode.d2.loss_cls: 0.0587, decode.d2.loss_mask: 0.3256, decode.d2.loss_dice: 0.5765, decode.d3.loss_cls: 0.0947, decode.d3.loss_mask: 0.3286, decode.d3.loss_dice: 0.5781, decode.d4.loss_cls: 0.0677, decode.d4.loss_mask: 0.3275, decode.d4.loss_dice: 0.5796, decode.d5.loss_cls: 0.0602, decode.d5.loss_mask: 0.3299, decode.d5.loss_dice: 0.5804, decode.d6.loss_cls: 0.0681, decode.d6.loss_mask: 0.3311, decode.d6.loss_dice: 0.5821, decode.d7.loss_cls: 0.0731, decode.d7.loss_mask: 0.3288, decode.d7.loss_dice: 0.5723, decode.d8.loss_cls: 0.0694, decode.d8.loss_mask: 0.3302, decode.d8.loss_dice: 0.5739, loss: 9.9015
2023-09-28 15:19:36,492 - mmseg - INFO - Iter [8650/40000]	lr: 1.125e-06, eta: 23:32:58, time: 2.216, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0697, decode.loss_mask: 0.3273, decode.loss_dice: 0.6476, decode.d0.loss_cls: 0.2795, decode.d0.loss_mask: 0.3333, decode.d0.loss_dice: 0.6505, decode.d1.loss_cls: 0.0890, decode.d1.loss_mask: 0.3273, decode.d1.loss_dice: 0.6591, decode.d2.loss_cls: 0.0980, decode.d2.loss_mask: 0.3285, decode.d2.loss_dice: 0.6591, decode.d3.loss_cls: 0.0886, decode.d3.loss_mask: 0.3313, decode.d3.loss_dice: 0.6516, decode.d4.loss_cls: 0.0758, decode.d4.loss_mask: 0.3312, decode.d4.loss_dice: 0.6676, decode.d5.loss_cls: 0.0896, decode.d5.loss_mask: 0.3265, decode.d5.loss_dice: 0.6524, decode.d6.loss_cls: 0.0727, decode.d6.loss_mask: 0.3287, decode.d6.loss_dice: 0.6568, decode.d7.loss_cls: 0.0647, decode.d7.loss_mask: 0.3317, decode.d7.loss_dice: 0.6531, decode.d8.loss_cls: 0.0736, decode.d8.loss_mask: 0.3285, decode.d8.loss_dice: 0.6567, loss: 10.8501
2023-09-28 15:21:27,260 - mmseg - INFO - Iter [8700/40000]	lr: 1.124e-06, eta: 23:29:15, time: 2.214, data_time: 0.033, memory: 21542, decode.loss_cls: 0.1013, decode.loss_mask: 0.2726, decode.loss_dice: 0.5985, decode.d0.loss_cls: 0.2596, decode.d0.loss_mask: 0.2770, decode.d0.loss_dice: 0.6241, decode.d1.loss_cls: 0.1421, decode.d1.loss_mask: 0.2721, decode.d1.loss_dice: 0.5908, decode.d2.loss_cls: 0.0930, decode.d2.loss_mask: 0.2739, decode.d2.loss_dice: 0.6040, decode.d3.loss_cls: 0.1151, decode.d3.loss_mask: 0.2713, decode.d3.loss_dice: 0.5916, decode.d4.loss_cls: 0.1061, decode.d4.loss_mask: 0.2724, decode.d4.loss_dice: 0.5955, decode.d5.loss_cls: 0.0912, decode.d5.loss_mask: 0.2731, decode.d5.loss_dice: 0.6072, decode.d6.loss_cls: 0.1046, decode.d6.loss_mask: 0.2748, decode.d6.loss_dice: 0.6085, decode.d7.loss_cls: 0.0757, decode.d7.loss_mask: 0.2735, decode.d7.loss_dice: 0.5972, decode.d8.loss_cls: 0.0821, decode.d8.loss_mask: 0.2729, decode.d8.loss_dice: 0.6107, loss: 9.9325
2023-09-28 15:23:18,387 - mmseg - INFO - Iter [8750/40000]	lr: 1.122e-06, eta: 23:25:35, time: 2.224, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0673, decode.loss_mask: 0.3078, decode.loss_dice: 0.6682, decode.d0.loss_cls: 0.2146, decode.d0.loss_mask: 0.3134, decode.d0.loss_dice: 0.6668, decode.d1.loss_cls: 0.1120, decode.d1.loss_mask: 0.3114, decode.d1.loss_dice: 0.6543, decode.d2.loss_cls: 0.1028, decode.d2.loss_mask: 0.3082, decode.d2.loss_dice: 0.6615, decode.d3.loss_cls: 0.0940, decode.d3.loss_mask: 0.3071, decode.d3.loss_dice: 0.6583, decode.d4.loss_cls: 0.0889, decode.d4.loss_mask: 0.3099, decode.d4.loss_dice: 0.6678, decode.d5.loss_cls: 0.0706, decode.d5.loss_mask: 0.3094, decode.d5.loss_dice: 0.6710, decode.d6.loss_cls: 0.0690, decode.d6.loss_mask: 0.3084, decode.d6.loss_dice: 0.6707, decode.d7.loss_cls: 0.0793, decode.d7.loss_mask: 0.3077, decode.d7.loss_dice: 0.6557, decode.d8.loss_cls: 0.0808, decode.d8.loss_mask: 0.3073, decode.d8.loss_dice: 0.6574, loss: 10.7015
2023-09-28 15:25:10,938 - mmseg - INFO - Iter [8800/40000]	lr: 1.120e-06, eta: 23:22:00, time: 2.250, data_time: 0.080, memory: 21542, decode.loss_cls: 0.0826, decode.loss_mask: 0.3219, decode.loss_dice: 0.5940, decode.d0.loss_cls: 0.2521, decode.d0.loss_mask: 0.3239, decode.d0.loss_dice: 0.5981, decode.d1.loss_cls: 0.1032, decode.d1.loss_mask: 0.3182, decode.d1.loss_dice: 0.5875, decode.d2.loss_cls: 0.0949, decode.d2.loss_mask: 0.3155, decode.d2.loss_dice: 0.6028, decode.d3.loss_cls: 0.1081, decode.d3.loss_mask: 0.3118, decode.d3.loss_dice: 0.5943, decode.d4.loss_cls: 0.0981, decode.d4.loss_mask: 0.3222, decode.d4.loss_dice: 0.5916, decode.d5.loss_cls: 0.0857, decode.d5.loss_mask: 0.3223, decode.d5.loss_dice: 0.5925, decode.d6.loss_cls: 0.0871, decode.d6.loss_mask: 0.3240, decode.d6.loss_dice: 0.5921, decode.d7.loss_cls: 0.0956, decode.d7.loss_mask: 0.3176, decode.d7.loss_dice: 0.5944, decode.d8.loss_cls: 0.0691, decode.d8.loss_mask: 0.3217, decode.d8.loss_dice: 0.5831, loss: 10.2058
2023-09-28 15:27:01,769 - mmseg - INFO - Iter [8850/40000]	lr: 1.118e-06, eta: 23:18:21, time: 2.218, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0865, decode.loss_mask: 0.2993, decode.loss_dice: 0.6285, decode.d0.loss_cls: 0.2746, decode.d0.loss_mask: 0.3060, decode.d0.loss_dice: 0.6344, decode.d1.loss_cls: 0.1302, decode.d1.loss_mask: 0.2992, decode.d1.loss_dice: 0.6328, decode.d2.loss_cls: 0.1151, decode.d2.loss_mask: 0.2993, decode.d2.loss_dice: 0.6381, decode.d3.loss_cls: 0.1030, decode.d3.loss_mask: 0.2991, decode.d3.loss_dice: 0.6296, decode.d4.loss_cls: 0.1037, decode.d4.loss_mask: 0.2991, decode.d4.loss_dice: 0.6256, decode.d5.loss_cls: 0.0975, decode.d5.loss_mask: 0.2997, decode.d5.loss_dice: 0.6186, decode.d6.loss_cls: 0.0857, decode.d6.loss_mask: 0.2980, decode.d6.loss_dice: 0.6293, decode.d7.loss_cls: 0.0887, decode.d7.loss_mask: 0.2992, decode.d7.loss_dice: 0.6236, decode.d8.loss_cls: 0.0817, decode.d8.loss_mask: 0.2991, decode.d8.loss_dice: 0.6193, loss: 10.4445
2023-09-28 15:28:51,449 - mmseg - INFO - Iter [8900/40000]	lr: 1.116e-06, eta: 23:14:39, time: 2.194, data_time: 0.031, memory: 21542, decode.loss_cls: 0.1063, decode.loss_mask: 0.2978, decode.loss_dice: 0.6120, decode.d0.loss_cls: 0.2432, decode.d0.loss_mask: 0.3014, decode.d0.loss_dice: 0.6167, decode.d1.loss_cls: 0.1172, decode.d1.loss_mask: 0.2986, decode.d1.loss_dice: 0.6128, decode.d2.loss_cls: 0.1094, decode.d2.loss_mask: 0.3010, decode.d2.loss_dice: 0.6036, decode.d3.loss_cls: 0.0906, decode.d3.loss_mask: 0.2994, decode.d3.loss_dice: 0.6146, decode.d4.loss_cls: 0.0960, decode.d4.loss_mask: 0.2984, decode.d4.loss_dice: 0.6093, decode.d5.loss_cls: 0.1062, decode.d5.loss_mask: 0.2974, decode.d5.loss_dice: 0.6185, decode.d6.loss_cls: 0.1220, decode.d6.loss_mask: 0.2970, decode.d6.loss_dice: 0.6145, decode.d7.loss_cls: 0.1127, decode.d7.loss_mask: 0.3002, decode.d7.loss_dice: 0.6126, decode.d8.loss_cls: 0.1031, decode.d8.loss_mask: 0.2998, decode.d8.loss_dice: 0.6148, loss: 10.3272
2023-09-28 15:30:42,463 - mmseg - INFO - Iter [8950/40000]	lr: 1.115e-06, eta: 23:11:03, time: 2.219, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0730, decode.loss_mask: 0.3286, decode.loss_dice: 0.6039, decode.d0.loss_cls: 0.2335, decode.d0.loss_mask: 0.3435, decode.d0.loss_dice: 0.6045, decode.d1.loss_cls: 0.0891, decode.d1.loss_mask: 0.3312, decode.d1.loss_dice: 0.6086, decode.d2.loss_cls: 0.0805, decode.d2.loss_mask: 0.3297, decode.d2.loss_dice: 0.6117, decode.d3.loss_cls: 0.0997, decode.d3.loss_mask: 0.3266, decode.d3.loss_dice: 0.6074, decode.d4.loss_cls: 0.0818, decode.d4.loss_mask: 0.3301, decode.d4.loss_dice: 0.6055, decode.d5.loss_cls: 0.0754, decode.d5.loss_mask: 0.3313, decode.d5.loss_dice: 0.5957, decode.d6.loss_cls: 0.0702, decode.d6.loss_mask: 0.3287, decode.d6.loss_dice: 0.6039, decode.d7.loss_cls: 0.0774, decode.d7.loss_mask: 0.3307, decode.d7.loss_dice: 0.5996, decode.d8.loss_cls: 0.0846, decode.d8.loss_mask: 0.3296, decode.d8.loss_dice: 0.5919, loss: 10.3076
2023-09-28 15:32:32,334 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 15:32:32,335 - mmseg - INFO - Iter [9000/40000]	lr: 1.113e-06, eta: 23:07:24, time: 2.198, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0542, decode.loss_mask: 0.2982, decode.loss_dice: 0.5946, decode.d0.loss_cls: 0.2206, decode.d0.loss_mask: 0.3057, decode.d0.loss_dice: 0.5991, decode.d1.loss_cls: 0.0787, decode.d1.loss_mask: 0.2980, decode.d1.loss_dice: 0.5952, decode.d2.loss_cls: 0.0731, decode.d2.loss_mask: 0.2970, decode.d2.loss_dice: 0.5918, decode.d3.loss_cls: 0.0645, decode.d3.loss_mask: 0.2991, decode.d3.loss_dice: 0.5997, decode.d4.loss_cls: 0.0767, decode.d4.loss_mask: 0.2998, decode.d4.loss_dice: 0.5988, decode.d5.loss_cls: 0.0661, decode.d5.loss_mask: 0.2977, decode.d5.loss_dice: 0.5958, decode.d6.loss_cls: 0.0733, decode.d6.loss_mask: 0.2978, decode.d6.loss_dice: 0.5935, decode.d7.loss_cls: 0.0645, decode.d7.loss_mask: 0.2985, decode.d7.loss_dice: 0.5920, decode.d8.loss_cls: 0.0525, decode.d8.loss_mask: 0.2991, decode.d8.loss_dice: 0.5983, loss: 9.7738
2023-09-28 15:34:23,693 - mmseg - INFO - Iter [9050/40000]	lr: 1.111e-06, eta: 23:03:52, time: 2.227, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0890, decode.loss_mask: 0.2776, decode.loss_dice: 0.6054, decode.d0.loss_cls: 0.2426, decode.d0.loss_mask: 0.2836, decode.d0.loss_dice: 0.6242, decode.d1.loss_cls: 0.0893, decode.d1.loss_mask: 0.2796, decode.d1.loss_dice: 0.6346, decode.d2.loss_cls: 0.0852, decode.d2.loss_mask: 0.2798, decode.d2.loss_dice: 0.6188, decode.d3.loss_cls: 0.0989, decode.d3.loss_mask: 0.2785, decode.d3.loss_dice: 0.6178, decode.d4.loss_cls: 0.0863, decode.d4.loss_mask: 0.2787, decode.d4.loss_dice: 0.6180, decode.d5.loss_cls: 0.0819, decode.d5.loss_mask: 0.2790, decode.d5.loss_dice: 0.6319, decode.d6.loss_cls: 0.0676, decode.d6.loss_mask: 0.2775, decode.d6.loss_dice: 0.6263, decode.d7.loss_cls: 0.0670, decode.d7.loss_mask: 0.2779, decode.d7.loss_dice: 0.6295, decode.d8.loss_cls: 0.1016, decode.d8.loss_mask: 0.2779, decode.d8.loss_dice: 0.6221, loss: 10.0282
2023-09-28 15:36:15,510 - mmseg - INFO - Iter [9100/40000]	lr: 1.109e-06, eta: 23:00:22, time: 2.236, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0904, decode.loss_mask: 0.3211, decode.loss_dice: 0.6424, decode.d0.loss_cls: 0.2460, decode.d0.loss_mask: 0.3307, decode.d0.loss_dice: 0.6479, decode.d1.loss_cls: 0.0849, decode.d1.loss_mask: 0.3215, decode.d1.loss_dice: 0.6339, decode.d2.loss_cls: 0.0952, decode.d2.loss_mask: 0.3204, decode.d2.loss_dice: 0.6416, decode.d3.loss_cls: 0.1093, decode.d3.loss_mask: 0.3207, decode.d3.loss_dice: 0.6423, decode.d4.loss_cls: 0.0788, decode.d4.loss_mask: 0.3198, decode.d4.loss_dice: 0.6532, decode.d5.loss_cls: 0.0725, decode.d5.loss_mask: 0.3220, decode.d5.loss_dice: 0.6447, decode.d6.loss_cls: 0.0962, decode.d6.loss_mask: 0.3215, decode.d6.loss_dice: 0.6310, decode.d7.loss_cls: 0.0987, decode.d7.loss_mask: 0.3201, decode.d7.loss_dice: 0.6364, decode.d8.loss_cls: 0.0844, decode.d8.loss_mask: 0.3210, decode.d8.loss_dice: 0.6441, loss: 10.6929
2023-09-28 15:38:06,498 - mmseg - INFO - Iter [9150/40000]	lr: 1.107e-06, eta: 22:56:50, time: 2.220, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0707, decode.loss_mask: 0.3124, decode.loss_dice: 0.6121, decode.d0.loss_cls: 0.2367, decode.d0.loss_mask: 0.3182, decode.d0.loss_dice: 0.6321, decode.d1.loss_cls: 0.0977, decode.d1.loss_mask: 0.3136, decode.d1.loss_dice: 0.6172, decode.d2.loss_cls: 0.0844, decode.d2.loss_mask: 0.3146, decode.d2.loss_dice: 0.6108, decode.d3.loss_cls: 0.0903, decode.d3.loss_mask: 0.3143, decode.d3.loss_dice: 0.6217, decode.d4.loss_cls: 0.0831, decode.d4.loss_mask: 0.3117, decode.d4.loss_dice: 0.6069, decode.d5.loss_cls: 0.0749, decode.d5.loss_mask: 0.3126, decode.d5.loss_dice: 0.6238, decode.d6.loss_cls: 0.0524, decode.d6.loss_mask: 0.3143, decode.d6.loss_dice: 0.6199, decode.d7.loss_cls: 0.0681, decode.d7.loss_mask: 0.3132, decode.d7.loss_dice: 0.6100, decode.d8.loss_cls: 0.0676, decode.d8.loss_mask: 0.3128, decode.d8.loss_dice: 0.6224, loss: 10.2407
2023-09-28 15:39:57,082 - mmseg - INFO - Iter [9200/40000]	lr: 1.106e-06, eta: 22:53:18, time: 2.212, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0571, decode.loss_mask: 0.3579, decode.loss_dice: 0.6413, decode.d0.loss_cls: 0.2508, decode.d0.loss_mask: 0.3678, decode.d0.loss_dice: 0.6325, decode.d1.loss_cls: 0.0842, decode.d1.loss_mask: 0.3584, decode.d1.loss_dice: 0.6371, decode.d2.loss_cls: 0.0672, decode.d2.loss_mask: 0.3612, decode.d2.loss_dice: 0.6416, decode.d3.loss_cls: 0.0849, decode.d3.loss_mask: 0.3613, decode.d3.loss_dice: 0.6265, decode.d4.loss_cls: 0.0727, decode.d4.loss_mask: 0.3602, decode.d4.loss_dice: 0.6330, decode.d5.loss_cls: 0.0742, decode.d5.loss_mask: 0.3613, decode.d5.loss_dice: 0.6319, decode.d6.loss_cls: 0.0490, decode.d6.loss_mask: 0.3597, decode.d6.loss_dice: 0.6269, decode.d7.loss_cls: 0.0728, decode.d7.loss_mask: 0.3550, decode.d7.loss_dice: 0.6301, decode.d8.loss_cls: 0.0528, decode.d8.loss_mask: 0.3586, decode.d8.loss_dice: 0.6343, loss: 10.8025
2023-09-28 15:41:48,858 - mmseg - INFO - Iter [9250/40000]	lr: 1.104e-06, eta: 22:49:51, time: 2.236, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0736, decode.loss_mask: 0.3247, decode.loss_dice: 0.6052, decode.d0.loss_cls: 0.2686, decode.d0.loss_mask: 0.3291, decode.d0.loss_dice: 0.6114, decode.d1.loss_cls: 0.1200, decode.d1.loss_mask: 0.3238, decode.d1.loss_dice: 0.6202, decode.d2.loss_cls: 0.1407, decode.d2.loss_mask: 0.3191, decode.d2.loss_dice: 0.6195, decode.d3.loss_cls: 0.0677, decode.d3.loss_mask: 0.3260, decode.d3.loss_dice: 0.6206, decode.d4.loss_cls: 0.0904, decode.d4.loss_mask: 0.3242, decode.d4.loss_dice: 0.6178, decode.d5.loss_cls: 0.1012, decode.d5.loss_mask: 0.3203, decode.d5.loss_dice: 0.6040, decode.d6.loss_cls: 0.0958, decode.d6.loss_mask: 0.3249, decode.d6.loss_dice: 0.6149, decode.d7.loss_cls: 0.0991, decode.d7.loss_mask: 0.3249, decode.d7.loss_dice: 0.6048, decode.d8.loss_cls: 0.0874, decode.d8.loss_mask: 0.3241, decode.d8.loss_dice: 0.6031, loss: 10.5070
2023-09-28 15:43:38,992 - mmseg - INFO - Iter [9300/40000]	lr: 1.102e-06, eta: 22:46:20, time: 2.203, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0891, decode.loss_mask: 0.2908, decode.loss_dice: 0.5914, decode.d0.loss_cls: 0.2512, decode.d0.loss_mask: 0.2971, decode.d0.loss_dice: 0.5947, decode.d1.loss_cls: 0.0875, decode.d1.loss_mask: 0.2950, decode.d1.loss_dice: 0.6001, decode.d2.loss_cls: 0.0889, decode.d2.loss_mask: 0.2898, decode.d2.loss_dice: 0.5900, decode.d3.loss_cls: 0.1123, decode.d3.loss_mask: 0.2926, decode.d3.loss_dice: 0.5946, decode.d4.loss_cls: 0.0832, decode.d4.loss_mask: 0.2956, decode.d4.loss_dice: 0.6089, decode.d5.loss_cls: 0.0984, decode.d5.loss_mask: 0.2941, decode.d5.loss_dice: 0.5967, decode.d6.loss_cls: 0.1015, decode.d6.loss_mask: 0.2923, decode.d6.loss_dice: 0.5852, decode.d7.loss_cls: 0.0873, decode.d7.loss_mask: 0.2922, decode.d7.loss_dice: 0.5895, decode.d8.loss_cls: 0.0676, decode.d8.loss_mask: 0.2938, decode.d8.loss_dice: 0.6015, loss: 9.9528
2023-09-28 15:45:29,722 - mmseg - INFO - Iter [9350/40000]	lr: 1.100e-06, eta: 22:42:52, time: 2.215, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0839, decode.loss_mask: 0.2857, decode.loss_dice: 0.6034, decode.d0.loss_cls: 0.2571, decode.d0.loss_mask: 0.2873, decode.d0.loss_dice: 0.6133, decode.d1.loss_cls: 0.1139, decode.d1.loss_mask: 0.2832, decode.d1.loss_dice: 0.6074, decode.d2.loss_cls: 0.0871, decode.d2.loss_mask: 0.2867, decode.d2.loss_dice: 0.6242, decode.d3.loss_cls: 0.0863, decode.d3.loss_mask: 0.2866, decode.d3.loss_dice: 0.6128, decode.d4.loss_cls: 0.0851, decode.d4.loss_mask: 0.2855, decode.d4.loss_dice: 0.6081, decode.d5.loss_cls: 0.0840, decode.d5.loss_mask: 0.2852, decode.d5.loss_dice: 0.6167, decode.d6.loss_cls: 0.0718, decode.d6.loss_mask: 0.2857, decode.d6.loss_dice: 0.6094, decode.d7.loss_cls: 0.0869, decode.d7.loss_mask: 0.2860, decode.d7.loss_dice: 0.6003, decode.d8.loss_cls: 0.0913, decode.d8.loss_mask: 0.2863, decode.d8.loss_dice: 0.6197, loss: 10.0207
2023-09-28 15:47:20,587 - mmseg - INFO - Iter [9400/40000]	lr: 1.098e-06, eta: 22:39:25, time: 2.217, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0630, decode.loss_mask: 0.2619, decode.loss_dice: 0.5805, decode.d0.loss_cls: 0.2085, decode.d0.loss_mask: 0.2647, decode.d0.loss_dice: 0.5822, decode.d1.loss_cls: 0.0661, decode.d1.loss_mask: 0.2622, decode.d1.loss_dice: 0.5843, decode.d2.loss_cls: 0.0664, decode.d2.loss_mask: 0.2615, decode.d2.loss_dice: 0.5863, decode.d3.loss_cls: 0.0655, decode.d3.loss_mask: 0.2604, decode.d3.loss_dice: 0.5822, decode.d4.loss_cls: 0.0485, decode.d4.loss_mask: 0.2621, decode.d4.loss_dice: 0.5954, decode.d5.loss_cls: 0.0573, decode.d5.loss_mask: 0.2616, decode.d5.loss_dice: 0.5737, decode.d6.loss_cls: 0.0612, decode.d6.loss_mask: 0.2623, decode.d6.loss_dice: 0.5795, decode.d7.loss_cls: 0.0473, decode.d7.loss_mask: 0.2629, decode.d7.loss_dice: 0.5745, decode.d8.loss_cls: 0.0495, decode.d8.loss_mask: 0.2615, decode.d8.loss_dice: 0.5902, loss: 9.1834
2023-09-28 15:49:10,278 - mmseg - INFO - Iter [9450/40000]	lr: 1.097e-06, eta: 22:35:55, time: 2.194, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0926, decode.loss_mask: 0.2980, decode.loss_dice: 0.5988, decode.d0.loss_cls: 0.2404, decode.d0.loss_mask: 0.2970, decode.d0.loss_dice: 0.6071, decode.d1.loss_cls: 0.1130, decode.d1.loss_mask: 0.2965, decode.d1.loss_dice: 0.6111, decode.d2.loss_cls: 0.0924, decode.d2.loss_mask: 0.2963, decode.d2.loss_dice: 0.6051, decode.d3.loss_cls: 0.0738, decode.d3.loss_mask: 0.2989, decode.d3.loss_dice: 0.5956, decode.d4.loss_cls: 0.0796, decode.d4.loss_mask: 0.2968, decode.d4.loss_dice: 0.5982, decode.d5.loss_cls: 0.0869, decode.d5.loss_mask: 0.2980, decode.d5.loss_dice: 0.6013, decode.d6.loss_cls: 0.0876, decode.d6.loss_mask: 0.2960, decode.d6.loss_dice: 0.6045, decode.d7.loss_cls: 0.0934, decode.d7.loss_mask: 0.2995, decode.d7.loss_dice: 0.5926, decode.d8.loss_cls: 0.0867, decode.d8.loss_mask: 0.2971, decode.d8.loss_dice: 0.5982, loss: 10.0330
2023-09-28 15:51:01,236 - mmseg - INFO - Iter [9500/40000]	lr: 1.095e-06, eta: 22:32:31, time: 2.219, data_time: 0.030, memory: 21542, decode.loss_cls: 0.1080, decode.loss_mask: 0.2817, decode.loss_dice: 0.6187, decode.d0.loss_cls: 0.2212, decode.d0.loss_mask: 0.2809, decode.d0.loss_dice: 0.6303, decode.d1.loss_cls: 0.0998, decode.d1.loss_mask: 0.2794, decode.d1.loss_dice: 0.6222, decode.d2.loss_cls: 0.1035, decode.d2.loss_mask: 0.2803, decode.d2.loss_dice: 0.6361, decode.d3.loss_cls: 0.1154, decode.d3.loss_mask: 0.2781, decode.d3.loss_dice: 0.6288, decode.d4.loss_cls: 0.1095, decode.d4.loss_mask: 0.2832, decode.d4.loss_dice: 0.6233, decode.d5.loss_cls: 0.0854, decode.d5.loss_mask: 0.2814, decode.d5.loss_dice: 0.6286, decode.d6.loss_cls: 0.0927, decode.d6.loss_mask: 0.2810, decode.d6.loss_dice: 0.6250, decode.d7.loss_cls: 0.1239, decode.d7.loss_mask: 0.2803, decode.d7.loss_dice: 0.6150, decode.d8.loss_cls: 0.0924, decode.d8.loss_mask: 0.2843, decode.d8.loss_dice: 0.6276, loss: 10.2178
2023-09-28 15:52:51,684 - mmseg - INFO - Iter [9550/40000]	lr: 1.093e-06, eta: 22:29:06, time: 2.209, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0929, decode.loss_mask: 0.2897, decode.loss_dice: 0.5949, decode.d0.loss_cls: 0.2610, decode.d0.loss_mask: 0.2942, decode.d0.loss_dice: 0.5896, decode.d1.loss_cls: 0.1025, decode.d1.loss_mask: 0.2912, decode.d1.loss_dice: 0.5861, decode.d2.loss_cls: 0.0861, decode.d2.loss_mask: 0.2888, decode.d2.loss_dice: 0.5890, decode.d3.loss_cls: 0.1143, decode.d3.loss_mask: 0.2878, decode.d3.loss_dice: 0.5902, decode.d4.loss_cls: 0.0943, decode.d4.loss_mask: 0.2891, decode.d4.loss_dice: 0.5958, decode.d5.loss_cls: 0.1020, decode.d5.loss_mask: 0.2883, decode.d5.loss_dice: 0.5920, decode.d6.loss_cls: 0.1056, decode.d6.loss_mask: 0.2900, decode.d6.loss_dice: 0.5921, decode.d7.loss_cls: 0.1068, decode.d7.loss_mask: 0.2879, decode.d7.loss_dice: 0.5882, decode.d8.loss_cls: 0.0899, decode.d8.loss_mask: 0.2883, decode.d8.loss_dice: 0.5940, loss: 9.9626
2023-09-28 15:54:43,020 - mmseg - INFO - Iter [9600/40000]	lr: 1.091e-06, eta: 22:25:45, time: 2.227, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0622, decode.loss_mask: 0.2924, decode.loss_dice: 0.5794, decode.d0.loss_cls: 0.2269, decode.d0.loss_mask: 0.2959, decode.d0.loss_dice: 0.5961, decode.d1.loss_cls: 0.0885, decode.d1.loss_mask: 0.2874, decode.d1.loss_dice: 0.5918, decode.d2.loss_cls: 0.0661, decode.d2.loss_mask: 0.2880, decode.d2.loss_dice: 0.5841, decode.d3.loss_cls: 0.0740, decode.d3.loss_mask: 0.2850, decode.d3.loss_dice: 0.5800, decode.d4.loss_cls: 0.0720, decode.d4.loss_mask: 0.2828, decode.d4.loss_dice: 0.5826, decode.d5.loss_cls: 0.0755, decode.d5.loss_mask: 0.2839, decode.d5.loss_dice: 0.5850, decode.d6.loss_cls: 0.0689, decode.d6.loss_mask: 0.2849, decode.d6.loss_dice: 0.5788, decode.d7.loss_cls: 0.0768, decode.d7.loss_mask: 0.2852, decode.d7.loss_dice: 0.5812, decode.d8.loss_cls: 0.0961, decode.d8.loss_mask: 0.2861, decode.d8.loss_dice: 0.5820, loss: 9.6196
2023-09-28 15:56:34,344 - mmseg - INFO - Iter [9650/40000]	lr: 1.089e-06, eta: 22:22:24, time: 2.226, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0802, decode.loss_mask: 0.3055, decode.loss_dice: 0.6637, decode.d0.loss_cls: 0.2155, decode.d0.loss_mask: 0.3090, decode.d0.loss_dice: 0.6871, decode.d1.loss_cls: 0.1000, decode.d1.loss_mask: 0.3107, decode.d1.loss_dice: 0.6689, decode.d2.loss_cls: 0.0928, decode.d2.loss_mask: 0.3056, decode.d2.loss_dice: 0.6653, decode.d3.loss_cls: 0.0854, decode.d3.loss_mask: 0.3066, decode.d3.loss_dice: 0.6649, decode.d4.loss_cls: 0.0988, decode.d4.loss_mask: 0.3062, decode.d4.loss_dice: 0.6594, decode.d5.loss_cls: 0.0891, decode.d5.loss_mask: 0.3057, decode.d5.loss_dice: 0.6618, decode.d6.loss_cls: 0.0792, decode.d6.loss_mask: 0.3062, decode.d6.loss_dice: 0.6591, decode.d7.loss_cls: 0.0981, decode.d7.loss_mask: 0.3068, decode.d7.loss_dice: 0.6700, decode.d8.loss_cls: 0.0753, decode.d8.loss_mask: 0.3069, decode.d8.loss_dice: 0.6581, loss: 10.7416
2023-09-28 15:58:25,334 - mmseg - INFO - Iter [9700/40000]	lr: 1.088e-06, eta: 22:19:04, time: 2.220, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0605, decode.loss_mask: 0.3013, decode.loss_dice: 0.6275, decode.d0.loss_cls: 0.2150, decode.d0.loss_mask: 0.2998, decode.d0.loss_dice: 0.6346, decode.d1.loss_cls: 0.0663, decode.d1.loss_mask: 0.3003, decode.d1.loss_dice: 0.6353, decode.d2.loss_cls: 0.0714, decode.d2.loss_mask: 0.3001, decode.d2.loss_dice: 0.6248, decode.d3.loss_cls: 0.0802, decode.d3.loss_mask: 0.3008, decode.d3.loss_dice: 0.6225, decode.d4.loss_cls: 0.0744, decode.d4.loss_mask: 0.3016, decode.d4.loss_dice: 0.6359, decode.d5.loss_cls: 0.0593, decode.d5.loss_mask: 0.3012, decode.d5.loss_dice: 0.6152, decode.d6.loss_cls: 0.0777, decode.d6.loss_mask: 0.2990, decode.d6.loss_dice: 0.6305, decode.d7.loss_cls: 0.0700, decode.d7.loss_mask: 0.2990, decode.d7.loss_dice: 0.6235, decode.d8.loss_cls: 0.0810, decode.d8.loss_mask: 0.3016, decode.d8.loss_dice: 0.6209, loss: 10.1308
2023-09-28 16:00:15,549 - mmseg - INFO - Iter [9750/40000]	lr: 1.086e-06, eta: 22:15:42, time: 2.204, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0896, decode.loss_mask: 0.3113, decode.loss_dice: 0.6254, decode.d0.loss_cls: 0.2459, decode.d0.loss_mask: 0.3154, decode.d0.loss_dice: 0.6346, decode.d1.loss_cls: 0.1090, decode.d1.loss_mask: 0.3131, decode.d1.loss_dice: 0.6181, decode.d2.loss_cls: 0.0766, decode.d2.loss_mask: 0.3128, decode.d2.loss_dice: 0.6305, decode.d3.loss_cls: 0.1128, decode.d3.loss_mask: 0.3119, decode.d3.loss_dice: 0.6217, decode.d4.loss_cls: 0.0929, decode.d4.loss_mask: 0.3103, decode.d4.loss_dice: 0.6332, decode.d5.loss_cls: 0.0828, decode.d5.loss_mask: 0.3123, decode.d5.loss_dice: 0.6227, decode.d6.loss_cls: 0.0915, decode.d6.loss_mask: 0.3144, decode.d6.loss_dice: 0.6291, decode.d7.loss_cls: 0.0707, decode.d7.loss_mask: 0.3141, decode.d7.loss_dice: 0.6235, decode.d8.loss_cls: 0.0760, decode.d8.loss_mask: 0.3117, decode.d8.loss_dice: 0.6277, loss: 10.4414
2023-09-28 16:02:06,098 - mmseg - INFO - Iter [9800/40000]	lr: 1.084e-06, eta: 22:12:22, time: 2.211, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0574, decode.loss_mask: 0.2862, decode.loss_dice: 0.5972, decode.d0.loss_cls: 0.2164, decode.d0.loss_mask: 0.2835, decode.d0.loss_dice: 0.5924, decode.d1.loss_cls: 0.0589, decode.d1.loss_mask: 0.2866, decode.d1.loss_dice: 0.5903, decode.d2.loss_cls: 0.0670, decode.d2.loss_mask: 0.2875, decode.d2.loss_dice: 0.5914, decode.d3.loss_cls: 0.0627, decode.d3.loss_mask: 0.2862, decode.d3.loss_dice: 0.6049, decode.d4.loss_cls: 0.0504, decode.d4.loss_mask: 0.2862, decode.d4.loss_dice: 0.5941, decode.d5.loss_cls: 0.0572, decode.d5.loss_mask: 0.2853, decode.d5.loss_dice: 0.5853, decode.d6.loss_cls: 0.0599, decode.d6.loss_mask: 0.2858, decode.d6.loss_dice: 0.5861, decode.d7.loss_cls: 0.0648, decode.d7.loss_mask: 0.2858, decode.d7.loss_dice: 0.5856, decode.d8.loss_cls: 0.0722, decode.d8.loss_mask: 0.2864, decode.d8.loss_dice: 0.5917, loss: 9.5454
2023-09-28 16:03:56,039 - mmseg - INFO - Iter [9850/40000]	lr: 1.082e-06, eta: 22:09:01, time: 2.199, data_time: 0.035, memory: 21542, decode.loss_cls: 0.0893, decode.loss_mask: 0.2813, decode.loss_dice: 0.5778, decode.d0.loss_cls: 0.2195, decode.d0.loss_mask: 0.2857, decode.d0.loss_dice: 0.5931, decode.d1.loss_cls: 0.0824, decode.d1.loss_mask: 0.2827, decode.d1.loss_dice: 0.5810, decode.d2.loss_cls: 0.0791, decode.d2.loss_mask: 0.2812, decode.d2.loss_dice: 0.5768, decode.d3.loss_cls: 0.0793, decode.d3.loss_mask: 0.2836, decode.d3.loss_dice: 0.5789, decode.d4.loss_cls: 0.0706, decode.d4.loss_mask: 0.2821, decode.d4.loss_dice: 0.5795, decode.d5.loss_cls: 0.0849, decode.d5.loss_mask: 0.2835, decode.d5.loss_dice: 0.5848, decode.d6.loss_cls: 0.0788, decode.d6.loss_mask: 0.2803, decode.d6.loss_dice: 0.5795, decode.d7.loss_cls: 0.0737, decode.d7.loss_mask: 0.2794, decode.d7.loss_dice: 0.5724, decode.d8.loss_cls: 0.0797, decode.d8.loss_mask: 0.2819, decode.d8.loss_dice: 0.5746, loss: 9.5574
2023-09-28 16:05:49,447 - mmseg - INFO - Iter [9900/40000]	lr: 1.080e-06, eta: 22:05:51, time: 2.268, data_time: 0.077, memory: 21542, decode.loss_cls: 0.0858, decode.loss_mask: 0.2827, decode.loss_dice: 0.5861, decode.d0.loss_cls: 0.2487, decode.d0.loss_mask: 0.2848, decode.d0.loss_dice: 0.6028, decode.d1.loss_cls: 0.0845, decode.d1.loss_mask: 0.2830, decode.d1.loss_dice: 0.6009, decode.d2.loss_cls: 0.0671, decode.d2.loss_mask: 0.2810, decode.d2.loss_dice: 0.5963, decode.d3.loss_cls: 0.1083, decode.d3.loss_mask: 0.2826, decode.d3.loss_dice: 0.5976, decode.d4.loss_cls: 0.0795, decode.d4.loss_mask: 0.2824, decode.d4.loss_dice: 0.6011, decode.d5.loss_cls: 0.0848, decode.d5.loss_mask: 0.2800, decode.d5.loss_dice: 0.5957, decode.d6.loss_cls: 0.0846, decode.d6.loss_mask: 0.2824, decode.d6.loss_dice: 0.5830, decode.d7.loss_cls: 0.0973, decode.d7.loss_mask: 0.2822, decode.d7.loss_dice: 0.5843, decode.d8.loss_cls: 0.0859, decode.d8.loss_mask: 0.2817, decode.d8.loss_dice: 0.5832, loss: 9.7800
2023-09-28 16:07:40,747 - mmseg - INFO - Iter [9950/40000]	lr: 1.079e-06, eta: 22:02:36, time: 2.226, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0814, decode.loss_mask: 0.2829, decode.loss_dice: 0.5978, decode.d0.loss_cls: 0.2336, decode.d0.loss_mask: 0.2836, decode.d0.loss_dice: 0.5985, decode.d1.loss_cls: 0.0954, decode.d1.loss_mask: 0.2766, decode.d1.loss_dice: 0.5947, decode.d2.loss_cls: 0.0880, decode.d2.loss_mask: 0.2824, decode.d2.loss_dice: 0.5979, decode.d3.loss_cls: 0.0712, decode.d3.loss_mask: 0.2834, decode.d3.loss_dice: 0.5880, decode.d4.loss_cls: 0.0867, decode.d4.loss_mask: 0.2827, decode.d4.loss_dice: 0.5941, decode.d5.loss_cls: 0.1025, decode.d5.loss_mask: 0.2829, decode.d5.loss_dice: 0.6015, decode.d6.loss_cls: 0.0782, decode.d6.loss_mask: 0.2828, decode.d6.loss_dice: 0.5913, decode.d7.loss_cls: 0.0688, decode.d7.loss_mask: 0.2840, decode.d7.loss_dice: 0.5996, decode.d8.loss_cls: 0.0969, decode.d8.loss_mask: 0.2835, decode.d8.loss_dice: 0.5897, loss: 9.7805
2023-09-28 16:09:31,372 - mmseg - INFO - Saving checkpoint at 10000 iterations
2023-09-28 16:09:51,257 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 16:09:51,258 - mmseg - INFO - Iter [10000/40000]	lr: 1.077e-06, eta: 22:00:20, time: 2.610, data_time: 0.036, memory: 21542, decode.loss_cls: 0.0632, decode.loss_mask: 0.2819, decode.loss_dice: 0.5729, decode.d0.loss_cls: 0.2186, decode.d0.loss_mask: 0.2905, decode.d0.loss_dice: 0.5931, decode.d1.loss_cls: 0.0653, decode.d1.loss_mask: 0.2888, decode.d1.loss_dice: 0.5731, decode.d2.loss_cls: 0.0781, decode.d2.loss_mask: 0.2840, decode.d2.loss_dice: 0.5753, decode.d3.loss_cls: 0.0510, decode.d3.loss_mask: 0.2831, decode.d3.loss_dice: 0.5722, decode.d4.loss_cls: 0.0611, decode.d4.loss_mask: 0.2869, decode.d4.loss_dice: 0.5811, decode.d5.loss_cls: 0.0498, decode.d5.loss_mask: 0.2890, decode.d5.loss_dice: 0.5956, decode.d6.loss_cls: 0.0464, decode.d6.loss_mask: 0.2870, decode.d6.loss_dice: 0.5794, decode.d7.loss_cls: 0.0472, decode.d7.loss_mask: 0.2859, decode.d7.loss_dice: 0.5821, decode.d8.loss_cls: 0.0636, decode.d8.loss_mask: 0.2854, decode.d8.loss_dice: 0.5746, loss: 9.4064
2023-09-28 16:26:48,685 - mmseg - INFO - per class results:
2023-09-28 16:26:48,687 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 92.79 |  97.3 |
|    Sidewalk   | 68.76 | 84.22 |
|  Construction | 81.99 | 93.54 |
|     Fence     |  34.2 | 38.71 |
|      Pole     | 56.06 | 72.93 |
| Traffic Light | 66.86 | 79.94 |
|  Traffic Sign | 72.07 | 81.84 |
|     Nature    | 88.59 |  94.3 |
|      Sky      | 96.57 | 97.92 |
|     Person    | 39.99 |  44.9 |
|     Rider     |  7.36 |  47.9 |
|      Car      | 91.59 | 94.67 |
|   background  | 96.08 | 96.98 |
+---------------+-------+-------+
2023-09-28 16:26:48,687 - mmseg - INFO - Summary:
2023-09-28 16:26:48,687 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.41 | 68.69 | 78.86 |
+-------+-------+-------+
2023-09-28 16:26:49,795 - mmseg - INFO - The previous best checkpoint /raid/hyundai/ViT-Adapter/segmentation/work_dirs/vit_13/best_mIoU_iter_2000.pth was removed
2023-09-28 16:27:08,689 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_10000.pth.
2023-09-28 16:27:08,689 - mmseg - INFO - Best mIoU is 0.6869 at 10000 iter.
2023-09-28 16:27:08,692 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 16:27:08,692 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9441, mIoU: 0.6869, mAcc: 0.7886, IoU.Road: 0.9279, IoU.Sidewalk: 0.6876, IoU.Construction: 0.8199, IoU.Fence: 0.3420, IoU.Pole: 0.5606, IoU.Traffic Light: 0.6686, IoU.Traffic Sign: 0.7207, IoU.Nature: 0.8859, IoU.Sky: 0.9657, IoU.Person: 0.3999, IoU.Rider: 0.0736, IoU.Car: 0.9159, IoU.background: 0.9608, Acc.Road: 0.9730, Acc.Sidewalk: 0.8422, Acc.Construction: 0.9354, Acc.Fence: 0.3871, Acc.Pole: 0.7293, Acc.Traffic Light: 0.7994, Acc.Traffic Sign: 0.8184, Acc.Nature: 0.9430, Acc.Sky: 0.9792, Acc.Person: 0.4490, Acc.Rider: 0.4790, Acc.Car: 0.9467, Acc.background: 0.9698
2023-09-28 16:29:00,081 - mmseg - INFO - Iter [10050/40000]	lr: 1.075e-06, eta: 22:48:38, time: 22.976, data_time: 20.780, memory: 21542, decode.loss_cls: 0.1281, decode.loss_mask: 0.2994, decode.loss_dice: 0.6385, decode.d0.loss_cls: 0.2770, decode.d0.loss_mask: 0.2971, decode.d0.loss_dice: 0.6614, decode.d1.loss_cls: 0.1290, decode.d1.loss_mask: 0.2931, decode.d1.loss_dice: 0.6312, decode.d2.loss_cls: 0.1237, decode.d2.loss_mask: 0.2896, decode.d2.loss_dice: 0.6427, decode.d3.loss_cls: 0.1420, decode.d3.loss_mask: 0.2921, decode.d3.loss_dice: 0.6363, decode.d4.loss_cls: 0.0919, decode.d4.loss_mask: 0.3028, decode.d4.loss_dice: 0.6425, decode.d5.loss_cls: 0.1277, decode.d5.loss_mask: 0.2905, decode.d5.loss_dice: 0.6327, decode.d6.loss_cls: 0.1246, decode.d6.loss_mask: 0.2877, decode.d6.loss_dice: 0.6401, decode.d7.loss_cls: 0.1201, decode.d7.loss_mask: 0.2920, decode.d7.loss_dice: 0.6433, decode.d8.loss_cls: 0.1234, decode.d8.loss_mask: 0.2956, decode.d8.loss_dice: 0.6427, loss: 10.7387
2023-09-28 16:30:50,628 - mmseg - INFO - Iter [10100/40000]	lr: 1.073e-06, eta: 22:45:02, time: 2.211, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0907, decode.loss_mask: 0.3216, decode.loss_dice: 0.6115, decode.d0.loss_cls: 0.2532, decode.d0.loss_mask: 0.3373, decode.d0.loss_dice: 0.6215, decode.d1.loss_cls: 0.0861, decode.d1.loss_mask: 0.3255, decode.d1.loss_dice: 0.6026, decode.d2.loss_cls: 0.0931, decode.d2.loss_mask: 0.3254, decode.d2.loss_dice: 0.6088, decode.d3.loss_cls: 0.0795, decode.d3.loss_mask: 0.3213, decode.d3.loss_dice: 0.6079, decode.d4.loss_cls: 0.0850, decode.d4.loss_mask: 0.3238, decode.d4.loss_dice: 0.6064, decode.d5.loss_cls: 0.0777, decode.d5.loss_mask: 0.3245, decode.d5.loss_dice: 0.6085, decode.d6.loss_cls: 0.0833, decode.d6.loss_mask: 0.3259, decode.d6.loss_dice: 0.6094, decode.d7.loss_cls: 0.0770, decode.d7.loss_mask: 0.3256, decode.d7.loss_dice: 0.6110, decode.d8.loss_cls: 0.0743, decode.d8.loss_mask: 0.3245, decode.d8.loss_dice: 0.6089, loss: 10.3521
2023-09-28 16:32:41,457 - mmseg - INFO - Iter [10150/40000]	lr: 1.071e-06, eta: 22:41:28, time: 2.216, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0914, decode.loss_mask: 0.3252, decode.loss_dice: 0.6384, decode.d0.loss_cls: 0.2200, decode.d0.loss_mask: 0.3354, decode.d0.loss_dice: 0.6605, decode.d1.loss_cls: 0.0729, decode.d1.loss_mask: 0.3323, decode.d1.loss_dice: 0.6539, decode.d2.loss_cls: 0.0885, decode.d2.loss_mask: 0.3275, decode.d2.loss_dice: 0.6621, decode.d3.loss_cls: 0.0852, decode.d3.loss_mask: 0.3242, decode.d3.loss_dice: 0.6437, decode.d4.loss_cls: 0.0996, decode.d4.loss_mask: 0.3264, decode.d4.loss_dice: 0.6453, decode.d5.loss_cls: 0.0885, decode.d5.loss_mask: 0.3273, decode.d5.loss_dice: 0.6523, decode.d6.loss_cls: 0.0778, decode.d6.loss_mask: 0.3262, decode.d6.loss_dice: 0.6452, decode.d7.loss_cls: 0.0711, decode.d7.loss_mask: 0.3262, decode.d7.loss_dice: 0.6560, decode.d8.loss_cls: 0.1011, decode.d8.loss_mask: 0.3278, decode.d8.loss_dice: 0.6629, loss: 10.7948
2023-09-28 16:34:32,173 - mmseg - INFO - Iter [10200/40000]	lr: 1.070e-06, eta: 22:37:55, time: 2.214, data_time: 0.035, memory: 21542, decode.loss_cls: 0.0647, decode.loss_mask: 0.2643, decode.loss_dice: 0.6095, decode.d0.loss_cls: 0.2319, decode.d0.loss_mask: 0.2654, decode.d0.loss_dice: 0.6261, decode.d1.loss_cls: 0.0828, decode.d1.loss_mask: 0.2661, decode.d1.loss_dice: 0.6119, decode.d2.loss_cls: 0.0445, decode.d2.loss_mask: 0.2651, decode.d2.loss_dice: 0.6303, decode.d3.loss_cls: 0.0543, decode.d3.loss_mask: 0.2644, decode.d3.loss_dice: 0.6033, decode.d4.loss_cls: 0.0511, decode.d4.loss_mask: 0.2648, decode.d4.loss_dice: 0.6105, decode.d5.loss_cls: 0.0535, decode.d5.loss_mask: 0.2641, decode.d5.loss_dice: 0.6083, decode.d6.loss_cls: 0.0410, decode.d6.loss_mask: 0.2637, decode.d6.loss_dice: 0.6127, decode.d7.loss_cls: 0.0490, decode.d7.loss_mask: 0.2641, decode.d7.loss_dice: 0.6184, decode.d8.loss_cls: 0.0509, decode.d8.loss_mask: 0.2634, decode.d8.loss_dice: 0.6043, loss: 9.5045
2023-09-28 16:36:22,962 - mmseg - INFO - Iter [10250/40000]	lr: 1.068e-06, eta: 22:34:23, time: 2.216, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0960, decode.loss_mask: 0.3491, decode.loss_dice: 0.6834, decode.d0.loss_cls: 0.2357, decode.d0.loss_mask: 0.3546, decode.d0.loss_dice: 0.6920, decode.d1.loss_cls: 0.1099, decode.d1.loss_mask: 0.3517, decode.d1.loss_dice: 0.6910, decode.d2.loss_cls: 0.1250, decode.d2.loss_mask: 0.3496, decode.d2.loss_dice: 0.6799, decode.d3.loss_cls: 0.1166, decode.d3.loss_mask: 0.3486, decode.d3.loss_dice: 0.6761, decode.d4.loss_cls: 0.1201, decode.d4.loss_mask: 0.3477, decode.d4.loss_dice: 0.6892, decode.d5.loss_cls: 0.0894, decode.d5.loss_mask: 0.3496, decode.d5.loss_dice: 0.6877, decode.d6.loss_cls: 0.1035, decode.d6.loss_mask: 0.3486, decode.d6.loss_dice: 0.6858, decode.d7.loss_cls: 0.1037, decode.d7.loss_mask: 0.3483, decode.d7.loss_dice: 0.6805, decode.d8.loss_cls: 0.1353, decode.d8.loss_mask: 0.3483, decode.d8.loss_dice: 0.6888, loss: 11.5860
2023-09-28 16:38:13,712 - mmseg - INFO - Iter [10300/40000]	lr: 1.066e-06, eta: 22:30:52, time: 2.215, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0635, decode.loss_mask: 0.3127, decode.loss_dice: 0.5872, decode.d0.loss_cls: 0.2389, decode.d0.loss_mask: 0.3171, decode.d0.loss_dice: 0.5962, decode.d1.loss_cls: 0.1212, decode.d1.loss_mask: 0.3088, decode.d1.loss_dice: 0.6011, decode.d2.loss_cls: 0.0642, decode.d2.loss_mask: 0.3108, decode.d2.loss_dice: 0.5983, decode.d3.loss_cls: 0.0828, decode.d3.loss_mask: 0.3114, decode.d3.loss_dice: 0.6047, decode.d4.loss_cls: 0.0999, decode.d4.loss_mask: 0.3116, decode.d4.loss_dice: 0.6034, decode.d5.loss_cls: 0.0724, decode.d5.loss_mask: 0.3113, decode.d5.loss_dice: 0.5967, decode.d6.loss_cls: 0.0589, decode.d6.loss_mask: 0.3132, decode.d6.loss_dice: 0.5880, decode.d7.loss_cls: 0.0788, decode.d7.loss_mask: 0.3114, decode.d7.loss_dice: 0.5915, decode.d8.loss_cls: 0.0725, decode.d8.loss_mask: 0.3145, decode.d8.loss_dice: 0.5951, loss: 10.0383
2023-09-28 16:40:04,996 - mmseg - INFO - Iter [10350/40000]	lr: 1.064e-06, eta: 22:27:24, time: 2.226, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0613, decode.loss_mask: 0.2842, decode.loss_dice: 0.5601, decode.d0.loss_cls: 0.2297, decode.d0.loss_mask: 0.2913, decode.d0.loss_dice: 0.5733, decode.d1.loss_cls: 0.0829, decode.d1.loss_mask: 0.2864, decode.d1.loss_dice: 0.5598, decode.d2.loss_cls: 0.0678, decode.d2.loss_mask: 0.2856, decode.d2.loss_dice: 0.5652, decode.d3.loss_cls: 0.0659, decode.d3.loss_mask: 0.2841, decode.d3.loss_dice: 0.5586, decode.d4.loss_cls: 0.0643, decode.d4.loss_mask: 0.2844, decode.d4.loss_dice: 0.5591, decode.d5.loss_cls: 0.0732, decode.d5.loss_mask: 0.2845, decode.d5.loss_dice: 0.5510, decode.d6.loss_cls: 0.0679, decode.d6.loss_mask: 0.2854, decode.d6.loss_dice: 0.5622, decode.d7.loss_cls: 0.0776, decode.d7.loss_mask: 0.2845, decode.d7.loss_dice: 0.5619, decode.d8.loss_cls: 0.0653, decode.d8.loss_mask: 0.2854, decode.d8.loss_dice: 0.5561, loss: 9.3191
2023-09-28 16:41:55,495 - mmseg - INFO - Iter [10400/40000]	lr: 1.063e-06, eta: 22:23:54, time: 2.210, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0736, decode.loss_mask: 0.2834, decode.loss_dice: 0.6049, decode.d0.loss_cls: 0.2424, decode.d0.loss_mask: 0.2880, decode.d0.loss_dice: 0.5988, decode.d1.loss_cls: 0.1261, decode.d1.loss_mask: 0.2851, decode.d1.loss_dice: 0.6004, decode.d2.loss_cls: 0.1044, decode.d2.loss_mask: 0.2834, decode.d2.loss_dice: 0.5846, decode.d3.loss_cls: 0.0759, decode.d3.loss_mask: 0.2850, decode.d3.loss_dice: 0.5978, decode.d4.loss_cls: 0.1083, decode.d4.loss_mask: 0.2844, decode.d4.loss_dice: 0.5929, decode.d5.loss_cls: 0.0910, decode.d5.loss_mask: 0.2832, decode.d5.loss_dice: 0.5951, decode.d6.loss_cls: 0.1070, decode.d6.loss_mask: 0.2836, decode.d6.loss_dice: 0.5922, decode.d7.loss_cls: 0.0879, decode.d7.loss_mask: 0.2842, decode.d7.loss_dice: 0.6066, decode.d8.loss_cls: 0.1083, decode.d8.loss_mask: 0.2834, decode.d8.loss_dice: 0.5897, loss: 9.9317
2023-09-28 16:43:46,622 - mmseg - INFO - Iter [10450/40000]	lr: 1.061e-06, eta: 22:20:27, time: 2.223, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0735, decode.loss_mask: 0.2878, decode.loss_dice: 0.5795, decode.d0.loss_cls: 0.2203, decode.d0.loss_mask: 0.2940, decode.d0.loss_dice: 0.6044, decode.d1.loss_cls: 0.0941, decode.d1.loss_mask: 0.2923, decode.d1.loss_dice: 0.5897, decode.d2.loss_cls: 0.0764, decode.d2.loss_mask: 0.2909, decode.d2.loss_dice: 0.5883, decode.d3.loss_cls: 0.0995, decode.d3.loss_mask: 0.2897, decode.d3.loss_dice: 0.5833, decode.d4.loss_cls: 0.0885, decode.d4.loss_mask: 0.2890, decode.d4.loss_dice: 0.5916, decode.d5.loss_cls: 0.0987, decode.d5.loss_mask: 0.2907, decode.d5.loss_dice: 0.5886, decode.d6.loss_cls: 0.0660, decode.d6.loss_mask: 0.2893, decode.d6.loss_dice: 0.5923, decode.d7.loss_cls: 0.0820, decode.d7.loss_mask: 0.2899, decode.d7.loss_dice: 0.5934, decode.d8.loss_cls: 0.0881, decode.d8.loss_mask: 0.2882, decode.d8.loss_dice: 0.5788, loss: 9.7789
2023-09-28 16:45:37,374 - mmseg - INFO - Iter [10500/40000]	lr: 1.059e-06, eta: 22:16:59, time: 2.215, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0643, decode.loss_mask: 0.2767, decode.loss_dice: 0.5860, decode.d0.loss_cls: 0.2074, decode.d0.loss_mask: 0.2805, decode.d0.loss_dice: 0.5949, decode.d1.loss_cls: 0.0704, decode.d1.loss_mask: 0.2784, decode.d1.loss_dice: 0.5985, decode.d2.loss_cls: 0.0682, decode.d2.loss_mask: 0.2773, decode.d2.loss_dice: 0.5944, decode.d3.loss_cls: 0.0555, decode.d3.loss_mask: 0.2787, decode.d3.loss_dice: 0.5824, decode.d4.loss_cls: 0.0634, decode.d4.loss_mask: 0.2788, decode.d4.loss_dice: 0.5878, decode.d5.loss_cls: 0.0591, decode.d5.loss_mask: 0.2777, decode.d5.loss_dice: 0.5925, decode.d6.loss_cls: 0.0469, decode.d6.loss_mask: 0.2774, decode.d6.loss_dice: 0.5929, decode.d7.loss_cls: 0.0645, decode.d7.loss_mask: 0.2778, decode.d7.loss_dice: 0.5885, decode.d8.loss_cls: 0.0556, decode.d8.loss_mask: 0.2785, decode.d8.loss_dice: 0.5815, loss: 9.4364
2023-09-28 16:47:27,737 - mmseg - INFO - Iter [10550/40000]	lr: 1.057e-06, eta: 22:13:32, time: 2.207, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0649, decode.loss_mask: 0.2812, decode.loss_dice: 0.6116, decode.d0.loss_cls: 0.2379, decode.d0.loss_mask: 0.2824, decode.d0.loss_dice: 0.6114, decode.d1.loss_cls: 0.0818, decode.d1.loss_mask: 0.2815, decode.d1.loss_dice: 0.6224, decode.d2.loss_cls: 0.0929, decode.d2.loss_mask: 0.2812, decode.d2.loss_dice: 0.6169, decode.d3.loss_cls: 0.0936, decode.d3.loss_mask: 0.2802, decode.d3.loss_dice: 0.6141, decode.d4.loss_cls: 0.0682, decode.d4.loss_mask: 0.2812, decode.d4.loss_dice: 0.6143, decode.d5.loss_cls: 0.0707, decode.d5.loss_mask: 0.2819, decode.d5.loss_dice: 0.6131, decode.d6.loss_cls: 0.0849, decode.d6.loss_mask: 0.2817, decode.d6.loss_dice: 0.6100, decode.d7.loss_cls: 0.0683, decode.d7.loss_mask: 0.2826, decode.d7.loss_dice: 0.6194, decode.d8.loss_cls: 0.0771, decode.d8.loss_mask: 0.2834, decode.d8.loss_dice: 0.6059, loss: 9.8970
2023-09-28 16:49:19,220 - mmseg - INFO - Iter [10600/40000]	lr: 1.055e-06, eta: 22:10:08, time: 2.230, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0768, decode.loss_mask: 0.2929, decode.loss_dice: 0.5794, decode.d0.loss_cls: 0.2269, decode.d0.loss_mask: 0.2993, decode.d0.loss_dice: 0.5929, decode.d1.loss_cls: 0.0968, decode.d1.loss_mask: 0.2933, decode.d1.loss_dice: 0.5771, decode.d2.loss_cls: 0.0945, decode.d2.loss_mask: 0.2933, decode.d2.loss_dice: 0.5772, decode.d3.loss_cls: 0.0688, decode.d3.loss_mask: 0.2942, decode.d3.loss_dice: 0.5820, decode.d4.loss_cls: 0.0702, decode.d4.loss_mask: 0.2939, decode.d4.loss_dice: 0.5924, decode.d5.loss_cls: 0.0765, decode.d5.loss_mask: 0.2939, decode.d5.loss_dice: 0.5775, decode.d6.loss_cls: 0.0769, decode.d6.loss_mask: 0.2944, decode.d6.loss_dice: 0.5781, decode.d7.loss_cls: 0.0790, decode.d7.loss_mask: 0.2942, decode.d7.loss_dice: 0.5788, decode.d8.loss_cls: 0.0847, decode.d8.loss_mask: 0.2937, decode.d8.loss_dice: 0.5780, loss: 9.7076
2023-09-28 16:51:09,565 - mmseg - INFO - Iter [10650/40000]	lr: 1.054e-06, eta: 22:06:42, time: 2.205, data_time: 0.032, memory: 21542, decode.loss_cls: 0.1161, decode.loss_mask: 0.2982, decode.loss_dice: 0.6215, decode.d0.loss_cls: 0.2531, decode.d0.loss_mask: 0.3071, decode.d0.loss_dice: 0.6389, decode.d1.loss_cls: 0.1004, decode.d1.loss_mask: 0.3010, decode.d1.loss_dice: 0.6428, decode.d2.loss_cls: 0.1212, decode.d2.loss_mask: 0.2998, decode.d2.loss_dice: 0.6229, decode.d3.loss_cls: 0.1159, decode.d3.loss_mask: 0.2993, decode.d3.loss_dice: 0.6271, decode.d4.loss_cls: 0.0971, decode.d4.loss_mask: 0.3005, decode.d4.loss_dice: 0.6209, decode.d5.loss_cls: 0.1216, decode.d5.loss_mask: 0.3030, decode.d5.loss_dice: 0.6329, decode.d6.loss_cls: 0.1138, decode.d6.loss_mask: 0.3009, decode.d6.loss_dice: 0.6266, decode.d7.loss_cls: 0.0833, decode.d7.loss_mask: 0.3015, decode.d7.loss_dice: 0.6326, decode.d8.loss_cls: 0.1131, decode.d8.loss_mask: 0.2992, decode.d8.loss_dice: 0.6288, loss: 10.5409
2023-09-28 16:53:00,886 - mmseg - INFO - Iter [10700/40000]	lr: 1.052e-06, eta: 22:03:21, time: 2.228, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0772, decode.loss_mask: 0.2873, decode.loss_dice: 0.5650, decode.d0.loss_cls: 0.2271, decode.d0.loss_mask: 0.2893, decode.d0.loss_dice: 0.5670, decode.d1.loss_cls: 0.0883, decode.d1.loss_mask: 0.2868, decode.d1.loss_dice: 0.5740, decode.d2.loss_cls: 0.0732, decode.d2.loss_mask: 0.2882, decode.d2.loss_dice: 0.5657, decode.d3.loss_cls: 0.0891, decode.d3.loss_mask: 0.2870, decode.d3.loss_dice: 0.5635, decode.d4.loss_cls: 0.0712, decode.d4.loss_mask: 0.2864, decode.d4.loss_dice: 0.5592, decode.d5.loss_cls: 0.0668, decode.d5.loss_mask: 0.2867, decode.d5.loss_dice: 0.5725, decode.d6.loss_cls: 0.0753, decode.d6.loss_mask: 0.2862, decode.d6.loss_dice: 0.5598, decode.d7.loss_cls: 0.0810, decode.d7.loss_mask: 0.2854, decode.d7.loss_dice: 0.5685, decode.d8.loss_cls: 0.0941, decode.d8.loss_mask: 0.2861, decode.d8.loss_dice: 0.5668, loss: 9.4745
2023-09-28 16:54:51,654 - mmseg - INFO - Iter [10750/40000]	lr: 1.050e-06, eta: 21:59:58, time: 2.215, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0542, decode.loss_mask: 0.3077, decode.loss_dice: 0.5958, decode.d0.loss_cls: 0.2312, decode.d0.loss_mask: 0.3083, decode.d0.loss_dice: 0.5804, decode.d1.loss_cls: 0.0786, decode.d1.loss_mask: 0.3018, decode.d1.loss_dice: 0.6034, decode.d2.loss_cls: 0.0795, decode.d2.loss_mask: 0.3035, decode.d2.loss_dice: 0.5999, decode.d3.loss_cls: 0.0614, decode.d3.loss_mask: 0.3090, decode.d3.loss_dice: 0.6003, decode.d4.loss_cls: 0.0637, decode.d4.loss_mask: 0.3082, decode.d4.loss_dice: 0.5988, decode.d5.loss_cls: 0.0622, decode.d5.loss_mask: 0.3083, decode.d5.loss_dice: 0.5983, decode.d6.loss_cls: 0.0610, decode.d6.loss_mask: 0.3072, decode.d6.loss_dice: 0.5872, decode.d7.loss_cls: 0.0435, decode.d7.loss_mask: 0.3092, decode.d7.loss_dice: 0.5958, decode.d8.loss_cls: 0.0498, decode.d8.loss_mask: 0.3095, decode.d8.loss_dice: 0.6031, loss: 9.8208
2023-09-28 16:56:41,792 - mmseg - INFO - Iter [10800/40000]	lr: 1.048e-06, eta: 21:56:34, time: 2.203, data_time: 0.031, memory: 21542, decode.loss_cls: 0.1163, decode.loss_mask: 0.3102, decode.loss_dice: 0.5963, decode.d0.loss_cls: 0.2764, decode.d0.loss_mask: 0.3155, decode.d0.loss_dice: 0.6301, decode.d1.loss_cls: 0.1230, decode.d1.loss_mask: 0.3119, decode.d1.loss_dice: 0.6102, decode.d2.loss_cls: 0.1319, decode.d2.loss_mask: 0.3071, decode.d2.loss_dice: 0.5915, decode.d3.loss_cls: 0.1232, decode.d3.loss_mask: 0.3093, decode.d3.loss_dice: 0.6073, decode.d4.loss_cls: 0.1148, decode.d4.loss_mask: 0.3120, decode.d4.loss_dice: 0.6089, decode.d5.loss_cls: 0.1154, decode.d5.loss_mask: 0.3123, decode.d5.loss_dice: 0.6147, decode.d6.loss_cls: 0.1253, decode.d6.loss_mask: 0.3107, decode.d6.loss_dice: 0.6013, decode.d7.loss_cls: 0.1115, decode.d7.loss_mask: 0.3115, decode.d7.loss_dice: 0.5933, decode.d8.loss_cls: 0.1400, decode.d8.loss_mask: 0.3095, decode.d8.loss_dice: 0.5959, loss: 10.5371
2023-09-28 16:58:31,559 - mmseg - INFO - Iter [10850/40000]	lr: 1.046e-06, eta: 21:53:10, time: 2.194, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0612, decode.loss_mask: 0.2706, decode.loss_dice: 0.5523, decode.d0.loss_cls: 0.2302, decode.d0.loss_mask: 0.2721, decode.d0.loss_dice: 0.5538, decode.d1.loss_cls: 0.0878, decode.d1.loss_mask: 0.2706, decode.d1.loss_dice: 0.5482, decode.d2.loss_cls: 0.0966, decode.d2.loss_mask: 0.2692, decode.d2.loss_dice: 0.5507, decode.d3.loss_cls: 0.0805, decode.d3.loss_mask: 0.2712, decode.d3.loss_dice: 0.5475, decode.d4.loss_cls: 0.0804, decode.d4.loss_mask: 0.2694, decode.d4.loss_dice: 0.5471, decode.d5.loss_cls: 0.0856, decode.d5.loss_mask: 0.2699, decode.d5.loss_dice: 0.5456, decode.d6.loss_cls: 0.0901, decode.d6.loss_mask: 0.2718, decode.d6.loss_dice: 0.5422, decode.d7.loss_cls: 0.0867, decode.d7.loss_mask: 0.2702, decode.d7.loss_dice: 0.5525, decode.d8.loss_cls: 0.0736, decode.d8.loss_mask: 0.2706, decode.d8.loss_dice: 0.5528, loss: 9.1711
2023-09-28 17:00:22,299 - mmseg - INFO - Iter [10900/40000]	lr: 1.045e-06, eta: 21:49:50, time: 2.215, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0630, decode.loss_mask: 0.2736, decode.loss_dice: 0.5588, decode.d0.loss_cls: 0.2144, decode.d0.loss_mask: 0.2778, decode.d0.loss_dice: 0.5535, decode.d1.loss_cls: 0.0873, decode.d1.loss_mask: 0.2724, decode.d1.loss_dice: 0.5556, decode.d2.loss_cls: 0.0630, decode.d2.loss_mask: 0.2737, decode.d2.loss_dice: 0.5650, decode.d3.loss_cls: 0.0761, decode.d3.loss_mask: 0.2741, decode.d3.loss_dice: 0.5569, decode.d4.loss_cls: 0.0766, decode.d4.loss_mask: 0.2753, decode.d4.loss_dice: 0.5612, decode.d5.loss_cls: 0.0714, decode.d5.loss_mask: 0.2742, decode.d5.loss_dice: 0.5551, decode.d6.loss_cls: 0.0728, decode.d6.loss_mask: 0.2736, decode.d6.loss_dice: 0.5526, decode.d7.loss_cls: 0.0674, decode.d7.loss_mask: 0.2736, decode.d7.loss_dice: 0.5561, decode.d8.loss_cls: 0.0550, decode.d8.loss_mask: 0.2750, decode.d8.loss_dice: 0.5734, loss: 9.1783
2023-09-28 17:02:13,875 - mmseg - INFO - Iter [10950/40000]	lr: 1.043e-06, eta: 21:46:33, time: 2.232, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0549, decode.loss_mask: 0.2748, decode.loss_dice: 0.6250, decode.d0.loss_cls: 0.2238, decode.d0.loss_mask: 0.2818, decode.d0.loss_dice: 0.6319, decode.d1.loss_cls: 0.1078, decode.d1.loss_mask: 0.2783, decode.d1.loss_dice: 0.6419, decode.d2.loss_cls: 0.0747, decode.d2.loss_mask: 0.2744, decode.d2.loss_dice: 0.6386, decode.d3.loss_cls: 0.0567, decode.d3.loss_mask: 0.2740, decode.d3.loss_dice: 0.6357, decode.d4.loss_cls: 0.0639, decode.d4.loss_mask: 0.2762, decode.d4.loss_dice: 0.6389, decode.d5.loss_cls: 0.0415, decode.d5.loss_mask: 0.2766, decode.d5.loss_dice: 0.6396, decode.d6.loss_cls: 0.0597, decode.d6.loss_mask: 0.2749, decode.d6.loss_dice: 0.6291, decode.d7.loss_cls: 0.0679, decode.d7.loss_mask: 0.2762, decode.d7.loss_dice: 0.6240, decode.d8.loss_cls: 0.0523, decode.d8.loss_mask: 0.2766, decode.d8.loss_dice: 0.6317, loss: 9.9034
2023-09-28 17:04:06,750 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 17:04:06,750 - mmseg - INFO - Iter [11000/40000]	lr: 1.041e-06, eta: 21:43:20, time: 2.258, data_time: 0.081, memory: 21542, decode.loss_cls: 0.0647, decode.loss_mask: 0.3298, decode.loss_dice: 0.5875, decode.d0.loss_cls: 0.2486, decode.d0.loss_mask: 0.3464, decode.d0.loss_dice: 0.5896, decode.d1.loss_cls: 0.0739, decode.d1.loss_mask: 0.3329, decode.d1.loss_dice: 0.6033, decode.d2.loss_cls: 0.0848, decode.d2.loss_mask: 0.3308, decode.d2.loss_dice: 0.5875, decode.d3.loss_cls: 0.0769, decode.d3.loss_mask: 0.3304, decode.d3.loss_dice: 0.5810, decode.d4.loss_cls: 0.0830, decode.d4.loss_mask: 0.3304, decode.d4.loss_dice: 0.5993, decode.d5.loss_cls: 0.0825, decode.d5.loss_mask: 0.3312, decode.d5.loss_dice: 0.5906, decode.d6.loss_cls: 0.0705, decode.d6.loss_mask: 0.3290, decode.d6.loss_dice: 0.5846, decode.d7.loss_cls: 0.0696, decode.d7.loss_mask: 0.3304, decode.d7.loss_dice: 0.5859, decode.d8.loss_cls: 0.0770, decode.d8.loss_mask: 0.3297, decode.d8.loss_dice: 0.5910, loss: 10.1527
2023-09-28 17:05:56,954 - mmseg - INFO - Iter [11050/40000]	lr: 1.039e-06, eta: 21:40:00, time: 2.204, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0937, decode.loss_mask: 0.2912, decode.loss_dice: 0.6286, decode.d0.loss_cls: 0.2476, decode.d0.loss_mask: 0.2961, decode.d0.loss_dice: 0.6292, decode.d1.loss_cls: 0.1307, decode.d1.loss_mask: 0.2917, decode.d1.loss_dice: 0.6318, decode.d2.loss_cls: 0.1450, decode.d2.loss_mask: 0.2917, decode.d2.loss_dice: 0.6235, decode.d3.loss_cls: 0.0994, decode.d3.loss_mask: 0.2911, decode.d3.loss_dice: 0.6183, decode.d4.loss_cls: 0.1137, decode.d4.loss_mask: 0.2909, decode.d4.loss_dice: 0.6286, decode.d5.loss_cls: 0.0976, decode.d5.loss_mask: 0.2889, decode.d5.loss_dice: 0.6397, decode.d6.loss_cls: 0.1203, decode.d6.loss_mask: 0.2876, decode.d6.loss_dice: 0.6253, decode.d7.loss_cls: 0.0962, decode.d7.loss_mask: 0.2901, decode.d7.loss_dice: 0.6302, decode.d8.loss_cls: 0.1234, decode.d8.loss_mask: 0.2893, decode.d8.loss_dice: 0.6297, loss: 10.4608
2023-09-28 17:07:47,451 - mmseg - INFO - Iter [11100/40000]	lr: 1.037e-06, eta: 21:36:43, time: 2.210, data_time: 0.034, memory: 21542, decode.loss_cls: 0.1135, decode.loss_mask: 0.2557, decode.loss_dice: 0.5530, decode.d0.loss_cls: 0.2441, decode.d0.loss_mask: 0.2631, decode.d0.loss_dice: 0.5720, decode.d1.loss_cls: 0.0864, decode.d1.loss_mask: 0.2670, decode.d1.loss_dice: 0.5707, decode.d2.loss_cls: 0.1017, decode.d2.loss_mask: 0.2650, decode.d2.loss_dice: 0.5711, decode.d3.loss_cls: 0.0943, decode.d3.loss_mask: 0.2655, decode.d3.loss_dice: 0.5699, decode.d4.loss_cls: 0.0938, decode.d4.loss_mask: 0.2649, decode.d4.loss_dice: 0.5606, decode.d5.loss_cls: 0.1024, decode.d5.loss_mask: 0.2580, decode.d5.loss_dice: 0.5662, decode.d6.loss_cls: 0.0991, decode.d6.loss_mask: 0.2560, decode.d6.loss_dice: 0.5473, decode.d7.loss_cls: 0.0877, decode.d7.loss_mask: 0.2672, decode.d7.loss_dice: 0.5625, decode.d8.loss_cls: 0.1020, decode.d8.loss_mask: 0.2563, decode.d8.loss_dice: 0.5656, loss: 9.3824
2023-09-28 17:09:37,728 - mmseg - INFO - Iter [11150/40000]	lr: 1.036e-06, eta: 21:33:25, time: 2.206, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0726, decode.loss_mask: 0.2996, decode.loss_dice: 0.5714, decode.d0.loss_cls: 0.2281, decode.d0.loss_mask: 0.3047, decode.d0.loss_dice: 0.5689, decode.d1.loss_cls: 0.0848, decode.d1.loss_mask: 0.2999, decode.d1.loss_dice: 0.5782, decode.d2.loss_cls: 0.0867, decode.d2.loss_mask: 0.3000, decode.d2.loss_dice: 0.5791, decode.d3.loss_cls: 0.0682, decode.d3.loss_mask: 0.3002, decode.d3.loss_dice: 0.5804, decode.d4.loss_cls: 0.0733, decode.d4.loss_mask: 0.2995, decode.d4.loss_dice: 0.5836, decode.d5.loss_cls: 0.0769, decode.d5.loss_mask: 0.3002, decode.d5.loss_dice: 0.5792, decode.d6.loss_cls: 0.0785, decode.d6.loss_mask: 0.3002, decode.d6.loss_dice: 0.5696, decode.d7.loss_cls: 0.0949, decode.d7.loss_mask: 0.2980, decode.d7.loss_dice: 0.5759, decode.d8.loss_cls: 0.0706, decode.d8.loss_mask: 0.2994, decode.d8.loss_dice: 0.5698, loss: 9.6924
2023-09-28 17:11:28,747 - mmseg - INFO - Iter [11200/40000]	lr: 1.034e-06, eta: 21:30:10, time: 2.220, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0753, decode.loss_mask: 0.2813, decode.loss_dice: 0.6372, decode.d0.loss_cls: 0.2182, decode.d0.loss_mask: 0.2859, decode.d0.loss_dice: 0.6508, decode.d1.loss_cls: 0.1225, decode.d1.loss_mask: 0.2835, decode.d1.loss_dice: 0.6485, decode.d2.loss_cls: 0.0937, decode.d2.loss_mask: 0.2819, decode.d2.loss_dice: 0.6346, decode.d3.loss_cls: 0.1184, decode.d3.loss_mask: 0.2814, decode.d3.loss_dice: 0.6342, decode.d4.loss_cls: 0.1123, decode.d4.loss_mask: 0.2815, decode.d4.loss_dice: 0.6436, decode.d5.loss_cls: 0.1002, decode.d5.loss_mask: 0.2822, decode.d5.loss_dice: 0.6433, decode.d6.loss_cls: 0.0827, decode.d6.loss_mask: 0.2826, decode.d6.loss_dice: 0.6364, decode.d7.loss_cls: 0.0744, decode.d7.loss_mask: 0.2828, decode.d7.loss_dice: 0.6364, decode.d8.loss_cls: 0.0997, decode.d8.loss_mask: 0.2820, decode.d8.loss_dice: 0.6434, loss: 10.3312
2023-09-28 17:13:20,394 - mmseg - INFO - Iter [11250/40000]	lr: 1.032e-06, eta: 21:26:57, time: 2.231, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0867, decode.loss_mask: 0.2924, decode.loss_dice: 0.6066, decode.d0.loss_cls: 0.2399, decode.d0.loss_mask: 0.2946, decode.d0.loss_dice: 0.6094, decode.d1.loss_cls: 0.0831, decode.d1.loss_mask: 0.2876, decode.d1.loss_dice: 0.6072, decode.d2.loss_cls: 0.0913, decode.d2.loss_mask: 0.2896, decode.d2.loss_dice: 0.6127, decode.d3.loss_cls: 0.0801, decode.d3.loss_mask: 0.2860, decode.d3.loss_dice: 0.6022, decode.d4.loss_cls: 0.0831, decode.d4.loss_mask: 0.2915, decode.d4.loss_dice: 0.6078, decode.d5.loss_cls: 0.0792, decode.d5.loss_mask: 0.2920, decode.d5.loss_dice: 0.6069, decode.d6.loss_cls: 0.0758, decode.d6.loss_mask: 0.2915, decode.d6.loss_dice: 0.5995, decode.d7.loss_cls: 0.1056, decode.d7.loss_mask: 0.2889, decode.d7.loss_dice: 0.6023, decode.d8.loss_cls: 0.1055, decode.d8.loss_mask: 0.2857, decode.d8.loss_dice: 0.6041, loss: 9.9890
2023-09-28 17:15:10,926 - mmseg - INFO - Iter [11300/40000]	lr: 1.030e-06, eta: 21:23:43, time: 2.212, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0556, decode.loss_mask: 0.3325, decode.loss_dice: 0.6169, decode.d0.loss_cls: 0.2603, decode.d0.loss_mask: 0.3500, decode.d0.loss_dice: 0.6143, decode.d1.loss_cls: 0.1256, decode.d1.loss_mask: 0.3276, decode.d1.loss_dice: 0.6120, decode.d2.loss_cls: 0.0695, decode.d2.loss_mask: 0.3349, decode.d2.loss_dice: 0.6265, decode.d3.loss_cls: 0.0834, decode.d3.loss_mask: 0.3356, decode.d3.loss_dice: 0.6232, decode.d4.loss_cls: 0.0730, decode.d4.loss_mask: 0.3337, decode.d4.loss_dice: 0.6223, decode.d5.loss_cls: 0.0947, decode.d5.loss_mask: 0.3374, decode.d5.loss_dice: 0.6193, decode.d6.loss_cls: 0.0645, decode.d6.loss_mask: 0.3343, decode.d6.loss_dice: 0.6082, decode.d7.loss_cls: 0.0817, decode.d7.loss_mask: 0.3324, decode.d7.loss_dice: 0.6238, decode.d8.loss_cls: 0.0779, decode.d8.loss_mask: 0.3376, decode.d8.loss_dice: 0.6190, loss: 10.5275
2023-09-28 17:17:01,792 - mmseg - INFO - Iter [11350/40000]	lr: 1.028e-06, eta: 21:20:30, time: 2.217, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0741, decode.loss_mask: 0.2744, decode.loss_dice: 0.5807, decode.d0.loss_cls: 0.2305, decode.d0.loss_mask: 0.2787, decode.d0.loss_dice: 0.5862, decode.d1.loss_cls: 0.0988, decode.d1.loss_mask: 0.2740, decode.d1.loss_dice: 0.5822, decode.d2.loss_cls: 0.0895, decode.d2.loss_mask: 0.2749, decode.d2.loss_dice: 0.5839, decode.d3.loss_cls: 0.0757, decode.d3.loss_mask: 0.2738, decode.d3.loss_dice: 0.5740, decode.d4.loss_cls: 0.0569, decode.d4.loss_mask: 0.2741, decode.d4.loss_dice: 0.5858, decode.d5.loss_cls: 0.0627, decode.d5.loss_mask: 0.2743, decode.d5.loss_dice: 0.5721, decode.d6.loss_cls: 0.0760, decode.d6.loss_mask: 0.2750, decode.d6.loss_dice: 0.5659, decode.d7.loss_cls: 0.0887, decode.d7.loss_mask: 0.2759, decode.d7.loss_dice: 0.5756, decode.d8.loss_cls: 0.0878, decode.d8.loss_mask: 0.2758, decode.d8.loss_dice: 0.5757, loss: 9.4736
2023-09-28 17:18:53,049 - mmseg - INFO - Iter [11400/40000]	lr: 1.027e-06, eta: 21:17:19, time: 2.225, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0669, decode.loss_mask: 0.2815, decode.loss_dice: 0.5703, decode.d0.loss_cls: 0.2132, decode.d0.loss_mask: 0.2855, decode.d0.loss_dice: 0.5891, decode.d1.loss_cls: 0.1104, decode.d1.loss_mask: 0.2812, decode.d1.loss_dice: 0.5719, decode.d2.loss_cls: 0.0834, decode.d2.loss_mask: 0.2812, decode.d2.loss_dice: 0.5794, decode.d3.loss_cls: 0.0759, decode.d3.loss_mask: 0.2821, decode.d3.loss_dice: 0.5793, decode.d4.loss_cls: 0.0857, decode.d4.loss_mask: 0.2810, decode.d4.loss_dice: 0.5728, decode.d5.loss_cls: 0.0809, decode.d5.loss_mask: 0.2815, decode.d5.loss_dice: 0.5684, decode.d6.loss_cls: 0.0846, decode.d6.loss_mask: 0.2821, decode.d6.loss_dice: 0.5804, decode.d7.loss_cls: 0.0687, decode.d7.loss_mask: 0.2823, decode.d7.loss_dice: 0.5831, decode.d8.loss_cls: 0.0737, decode.d8.loss_mask: 0.2822, decode.d8.loss_dice: 0.5766, loss: 9.5350
2023-09-28 17:20:44,887 - mmseg - INFO - Iter [11450/40000]	lr: 1.025e-06, eta: 21:14:09, time: 2.237, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0705, decode.loss_mask: 0.3195, decode.loss_dice: 0.5853, decode.d0.loss_cls: 0.2452, decode.d0.loss_mask: 0.3256, decode.d0.loss_dice: 0.5796, decode.d1.loss_cls: 0.0843, decode.d1.loss_mask: 0.3215, decode.d1.loss_dice: 0.5748, decode.d2.loss_cls: 0.0760, decode.d2.loss_mask: 0.3203, decode.d2.loss_dice: 0.5869, decode.d3.loss_cls: 0.0476, decode.d3.loss_mask: 0.3206, decode.d3.loss_dice: 0.5898, decode.d4.loss_cls: 0.0725, decode.d4.loss_mask: 0.3188, decode.d4.loss_dice: 0.5900, decode.d5.loss_cls: 0.0744, decode.d5.loss_mask: 0.3215, decode.d5.loss_dice: 0.5866, decode.d6.loss_cls: 0.0717, decode.d6.loss_mask: 0.3186, decode.d6.loss_dice: 0.5766, decode.d7.loss_cls: 0.0824, decode.d7.loss_mask: 0.3174, decode.d7.loss_dice: 0.5861, decode.d8.loss_cls: 0.0767, decode.d8.loss_mask: 0.3185, decode.d8.loss_dice: 0.5888, loss: 9.9483
2023-09-28 17:22:36,429 - mmseg - INFO - Iter [11500/40000]	lr: 1.023e-06, eta: 21:11:00, time: 2.231, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0818, decode.loss_mask: 0.3160, decode.loss_dice: 0.6048, decode.d0.loss_cls: 0.2307, decode.d0.loss_mask: 0.3243, decode.d0.loss_dice: 0.6266, decode.d1.loss_cls: 0.0892, decode.d1.loss_mask: 0.3054, decode.d1.loss_dice: 0.6129, decode.d2.loss_cls: 0.0892, decode.d2.loss_mask: 0.3154, decode.d2.loss_dice: 0.6200, decode.d3.loss_cls: 0.0782, decode.d3.loss_mask: 0.3179, decode.d3.loss_dice: 0.6104, decode.d4.loss_cls: 0.0946, decode.d4.loss_mask: 0.3171, decode.d4.loss_dice: 0.6250, decode.d5.loss_cls: 0.0795, decode.d5.loss_mask: 0.3194, decode.d5.loss_dice: 0.6240, decode.d6.loss_cls: 0.0881, decode.d6.loss_mask: 0.3165, decode.d6.loss_dice: 0.6152, decode.d7.loss_cls: 0.0885, decode.d7.loss_mask: 0.3192, decode.d7.loss_dice: 0.6148, decode.d8.loss_cls: 0.0858, decode.d8.loss_mask: 0.3159, decode.d8.loss_dice: 0.6228, loss: 10.3489
2023-09-28 17:24:27,475 - mmseg - INFO - Iter [11550/40000]	lr: 1.021e-06, eta: 21:07:50, time: 2.219, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0794, decode.loss_mask: 0.2919, decode.loss_dice: 0.5766, decode.d0.loss_cls: 0.2412, decode.d0.loss_mask: 0.2963, decode.d0.loss_dice: 0.5998, decode.d1.loss_cls: 0.0962, decode.d1.loss_mask: 0.2870, decode.d1.loss_dice: 0.5790, decode.d2.loss_cls: 0.0881, decode.d2.loss_mask: 0.2851, decode.d2.loss_dice: 0.5786, decode.d3.loss_cls: 0.0860, decode.d3.loss_mask: 0.2909, decode.d3.loss_dice: 0.5903, decode.d4.loss_cls: 0.0637, decode.d4.loss_mask: 0.2944, decode.d4.loss_dice: 0.5834, decode.d5.loss_cls: 0.0708, decode.d5.loss_mask: 0.2972, decode.d5.loss_dice: 0.5883, decode.d6.loss_cls: 0.0744, decode.d6.loss_mask: 0.2913, decode.d6.loss_dice: 0.5886, decode.d7.loss_cls: 0.0824, decode.d7.loss_mask: 0.2916, decode.d7.loss_dice: 0.5817, decode.d8.loss_cls: 0.1194, decode.d8.loss_mask: 0.2924, decode.d8.loss_dice: 0.5818, loss: 9.7677
2023-09-28 17:26:18,977 - mmseg - INFO - Iter [11600/40000]	lr: 1.019e-06, eta: 21:04:42, time: 2.232, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0876, decode.loss_mask: 0.2655, decode.loss_dice: 0.6046, decode.d0.loss_cls: 0.2112, decode.d0.loss_mask: 0.2736, decode.d0.loss_dice: 0.6201, decode.d1.loss_cls: 0.1227, decode.d1.loss_mask: 0.2683, decode.d1.loss_dice: 0.6081, decode.d2.loss_cls: 0.0953, decode.d2.loss_mask: 0.2683, decode.d2.loss_dice: 0.6134, decode.d3.loss_cls: 0.0824, decode.d3.loss_mask: 0.2672, decode.d3.loss_dice: 0.6089, decode.d4.loss_cls: 0.0734, decode.d4.loss_mask: 0.2666, decode.d4.loss_dice: 0.6132, decode.d5.loss_cls: 0.0863, decode.d5.loss_mask: 0.2659, decode.d5.loss_dice: 0.6137, decode.d6.loss_cls: 0.0779, decode.d6.loss_mask: 0.2667, decode.d6.loss_dice: 0.6053, decode.d7.loss_cls: 0.0861, decode.d7.loss_mask: 0.2674, decode.d7.loss_dice: 0.6089, decode.d8.loss_cls: 0.0822, decode.d8.loss_mask: 0.2664, decode.d8.loss_dice: 0.6039, loss: 9.7814
2023-09-28 17:28:10,798 - mmseg - INFO - Iter [11650/40000]	lr: 1.018e-06, eta: 21:01:36, time: 2.236, data_time: 0.028, memory: 21542, decode.loss_cls: 0.1085, decode.loss_mask: 0.2968, decode.loss_dice: 0.6188, decode.d0.loss_cls: 0.2353, decode.d0.loss_mask: 0.3047, decode.d0.loss_dice: 0.6395, decode.d1.loss_cls: 0.0988, decode.d1.loss_mask: 0.3001, decode.d1.loss_dice: 0.6278, decode.d2.loss_cls: 0.1239, decode.d2.loss_mask: 0.2969, decode.d2.loss_dice: 0.6202, decode.d3.loss_cls: 0.1273, decode.d3.loss_mask: 0.2972, decode.d3.loss_dice: 0.6143, decode.d4.loss_cls: 0.1138, decode.d4.loss_mask: 0.3017, decode.d4.loss_dice: 0.6311, decode.d5.loss_cls: 0.1143, decode.d5.loss_mask: 0.3008, decode.d5.loss_dice: 0.6248, decode.d6.loss_cls: 0.0999, decode.d6.loss_mask: 0.2981, decode.d6.loss_dice: 0.6258, decode.d7.loss_cls: 0.1016, decode.d7.loss_mask: 0.2980, decode.d7.loss_dice: 0.6231, decode.d8.loss_cls: 0.1313, decode.d8.loss_mask: 0.2964, decode.d8.loss_dice: 0.6141, loss: 10.4848
2023-09-28 17:30:01,912 - mmseg - INFO - Iter [11700/40000]	lr: 1.016e-06, eta: 20:58:28, time: 2.222, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0959, decode.loss_mask: 0.3240, decode.loss_dice: 0.6529, decode.d0.loss_cls: 0.2708, decode.d0.loss_mask: 0.3229, decode.d0.loss_dice: 0.6704, decode.d1.loss_cls: 0.1306, decode.d1.loss_mask: 0.3249, decode.d1.loss_dice: 0.6541, decode.d2.loss_cls: 0.1248, decode.d2.loss_mask: 0.3233, decode.d2.loss_dice: 0.6586, decode.d3.loss_cls: 0.1028, decode.d3.loss_mask: 0.3230, decode.d3.loss_dice: 0.6623, decode.d4.loss_cls: 0.1018, decode.d4.loss_mask: 0.3240, decode.d4.loss_dice: 0.6616, decode.d5.loss_cls: 0.0795, decode.d5.loss_mask: 0.3231, decode.d5.loss_dice: 0.6602, decode.d6.loss_cls: 0.0856, decode.d6.loss_mask: 0.3211, decode.d6.loss_dice: 0.6670, decode.d7.loss_cls: 0.0779, decode.d7.loss_mask: 0.3261, decode.d7.loss_dice: 0.6629, decode.d8.loss_cls: 0.0904, decode.d8.loss_mask: 0.3244, decode.d8.loss_dice: 0.6658, loss: 11.0127
2023-09-28 17:31:52,572 - mmseg - INFO - Iter [11750/40000]	lr: 1.014e-06, eta: 20:55:20, time: 2.213, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0860, decode.loss_mask: 0.3005, decode.loss_dice: 0.6264, decode.d0.loss_cls: 0.2330, decode.d0.loss_mask: 0.3065, decode.d0.loss_dice: 0.6436, decode.d1.loss_cls: 0.0931, decode.d1.loss_mask: 0.3014, decode.d1.loss_dice: 0.6299, decode.d2.loss_cls: 0.1060, decode.d2.loss_mask: 0.3020, decode.d2.loss_dice: 0.6352, decode.d3.loss_cls: 0.0926, decode.d3.loss_mask: 0.2996, decode.d3.loss_dice: 0.6335, decode.d4.loss_cls: 0.0795, decode.d4.loss_mask: 0.3012, decode.d4.loss_dice: 0.6452, decode.d5.loss_cls: 0.0839, decode.d5.loss_mask: 0.3007, decode.d5.loss_dice: 0.6259, decode.d6.loss_cls: 0.0689, decode.d6.loss_mask: 0.3007, decode.d6.loss_dice: 0.6274, decode.d7.loss_cls: 0.1039, decode.d7.loss_mask: 0.3011, decode.d7.loss_dice: 0.6321, decode.d8.loss_cls: 0.0924, decode.d8.loss_mask: 0.3003, decode.d8.loss_dice: 0.6390, loss: 10.3915
2023-09-28 17:33:43,363 - mmseg - INFO - Iter [11800/40000]	lr: 1.012e-06, eta: 20:52:13, time: 2.216, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0748, decode.loss_mask: 0.3074, decode.loss_dice: 0.6554, decode.d0.loss_cls: 0.2447, decode.d0.loss_mask: 0.3138, decode.d0.loss_dice: 0.6513, decode.d1.loss_cls: 0.1077, decode.d1.loss_mask: 0.3091, decode.d1.loss_dice: 0.6631, decode.d2.loss_cls: 0.0886, decode.d2.loss_mask: 0.3084, decode.d2.loss_dice: 0.6495, decode.d3.loss_cls: 0.0738, decode.d3.loss_mask: 0.3083, decode.d3.loss_dice: 0.6511, decode.d4.loss_cls: 0.1093, decode.d4.loss_mask: 0.3085, decode.d4.loss_dice: 0.6604, decode.d5.loss_cls: 0.0837, decode.d5.loss_mask: 0.3080, decode.d5.loss_dice: 0.6515, decode.d6.loss_cls: 0.0722, decode.d6.loss_mask: 0.3103, decode.d6.loss_dice: 0.6616, decode.d7.loss_cls: 0.0706, decode.d7.loss_mask: 0.3091, decode.d7.loss_dice: 0.6597, decode.d8.loss_cls: 0.0670, decode.d8.loss_mask: 0.3077, decode.d8.loss_dice: 0.6545, loss: 10.6410
2023-09-28 17:35:33,743 - mmseg - INFO - Iter [11850/40000]	lr: 1.010e-06, eta: 20:49:05, time: 2.208, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0736, decode.loss_mask: 0.3271, decode.loss_dice: 0.6465, decode.d0.loss_cls: 0.2192, decode.d0.loss_mask: 0.3342, decode.d0.loss_dice: 0.6479, decode.d1.loss_cls: 0.0867, decode.d1.loss_mask: 0.3280, decode.d1.loss_dice: 0.6404, decode.d2.loss_cls: 0.0859, decode.d2.loss_mask: 0.3277, decode.d2.loss_dice: 0.6431, decode.d3.loss_cls: 0.0785, decode.d3.loss_mask: 0.3256, decode.d3.loss_dice: 0.6452, decode.d4.loss_cls: 0.0821, decode.d4.loss_mask: 0.3263, decode.d4.loss_dice: 0.6492, decode.d5.loss_cls: 0.0799, decode.d5.loss_mask: 0.3266, decode.d5.loss_dice: 0.6425, decode.d6.loss_cls: 0.0901, decode.d6.loss_mask: 0.3257, decode.d6.loss_dice: 0.6425, decode.d7.loss_cls: 0.0854, decode.d7.loss_mask: 0.3266, decode.d7.loss_dice: 0.6405, decode.d8.loss_cls: 0.0883, decode.d8.loss_mask: 0.3284, decode.d8.loss_dice: 0.6422, loss: 10.6860
2023-09-28 17:37:25,858 - mmseg - INFO - Iter [11900/40000]	lr: 1.009e-06, eta: 20:46:03, time: 2.242, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0675, decode.loss_mask: 0.2872, decode.loss_dice: 0.6189, decode.d0.loss_cls: 0.2398, decode.d0.loss_mask: 0.2936, decode.d0.loss_dice: 0.6526, decode.d1.loss_cls: 0.0979, decode.d1.loss_mask: 0.2889, decode.d1.loss_dice: 0.6370, decode.d2.loss_cls: 0.0828, decode.d2.loss_mask: 0.2884, decode.d2.loss_dice: 0.6159, decode.d3.loss_cls: 0.0921, decode.d3.loss_mask: 0.2876, decode.d3.loss_dice: 0.6122, decode.d4.loss_cls: 0.1053, decode.d4.loss_mask: 0.2875, decode.d4.loss_dice: 0.6205, decode.d5.loss_cls: 0.0789, decode.d5.loss_mask: 0.2879, decode.d5.loss_dice: 0.6192, decode.d6.loss_cls: 0.0754, decode.d6.loss_mask: 0.2889, decode.d6.loss_dice: 0.6099, decode.d7.loss_cls: 0.0732, decode.d7.loss_mask: 0.2890, decode.d7.loss_dice: 0.6216, decode.d8.loss_cls: 0.0665, decode.d8.loss_mask: 0.2864, decode.d8.loss_dice: 0.6124, loss: 10.0848
2023-09-28 17:39:17,749 - mmseg - INFO - Iter [11950/40000]	lr: 1.007e-06, eta: 20:43:00, time: 2.238, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0946, decode.loss_mask: 0.2797, decode.loss_dice: 0.6402, decode.d0.loss_cls: 0.2565, decode.d0.loss_mask: 0.2812, decode.d0.loss_dice: 0.6380, decode.d1.loss_cls: 0.0886, decode.d1.loss_mask: 0.2810, decode.d1.loss_dice: 0.6476, decode.d2.loss_cls: 0.1107, decode.d2.loss_mask: 0.2795, decode.d2.loss_dice: 0.6412, decode.d3.loss_cls: 0.0850, decode.d3.loss_mask: 0.2824, decode.d3.loss_dice: 0.6431, decode.d4.loss_cls: 0.0869, decode.d4.loss_mask: 0.2833, decode.d4.loss_dice: 0.6473, decode.d5.loss_cls: 0.1055, decode.d5.loss_mask: 0.2803, decode.d5.loss_dice: 0.6499, decode.d6.loss_cls: 0.0881, decode.d6.loss_mask: 0.2810, decode.d6.loss_dice: 0.6415, decode.d7.loss_cls: 0.0932, decode.d7.loss_mask: 0.2821, decode.d7.loss_dice: 0.6401, decode.d8.loss_cls: 0.0978, decode.d8.loss_mask: 0.2813, decode.d8.loss_dice: 0.6397, loss: 10.3473
2023-09-28 17:41:08,401 - mmseg - INFO - Saving checkpoint at 12000 iterations
2023-09-28 17:41:28,429 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 17:41:28,430 - mmseg - INFO - Iter [12000/40000]	lr: 1.005e-06, eta: 20:40:42, time: 2.614, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0676, decode.loss_mask: 0.2750, decode.loss_dice: 0.5271, decode.d0.loss_cls: 0.2350, decode.d0.loss_mask: 0.2784, decode.d0.loss_dice: 0.5463, decode.d1.loss_cls: 0.0931, decode.d1.loss_mask: 0.2743, decode.d1.loss_dice: 0.5408, decode.d2.loss_cls: 0.0768, decode.d2.loss_mask: 0.2755, decode.d2.loss_dice: 0.5332, decode.d3.loss_cls: 0.0726, decode.d3.loss_mask: 0.2758, decode.d3.loss_dice: 0.5474, decode.d4.loss_cls: 0.0645, decode.d4.loss_mask: 0.2757, decode.d4.loss_dice: 0.5412, decode.d5.loss_cls: 0.0809, decode.d5.loss_mask: 0.2752, decode.d5.loss_dice: 0.5550, decode.d6.loss_cls: 0.0780, decode.d6.loss_mask: 0.2748, decode.d6.loss_dice: 0.5405, decode.d7.loss_cls: 0.0697, decode.d7.loss_mask: 0.2747, decode.d7.loss_dice: 0.5462, decode.d8.loss_cls: 0.0924, decode.d8.loss_mask: 0.2764, decode.d8.loss_dice: 0.5515, loss: 9.1158
2023-09-28 17:58:27,287 - mmseg - INFO - per class results:
2023-09-28 17:58:27,289 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 92.72 | 96.92 |
|    Sidewalk   |  69.8 | 82.17 |
|  Construction | 81.21 | 94.28 |
|     Fence     |  28.8 | 32.45 |
|      Pole     | 56.22 | 71.17 |
| Traffic Light | 67.31 | 79.04 |
|  Traffic Sign | 72.05 | 81.72 |
|     Nature    | 88.48 | 93.88 |
|      Sky      | 96.61 | 97.77 |
|     Person    | 31.44 | 33.26 |
|     Rider     |  9.35 | 66.26 |
|      Car      | 91.45 | 94.87 |
|   background  | 96.14 | 97.21 |
+---------------+-------+-------+
2023-09-28 17:58:27,289 - mmseg - INFO - Summary:
2023-09-28 17:58:27,289 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.23 | 67.81 | 78.54 |
+-------+-------+-------+
2023-09-28 17:58:27,291 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 17:58:27,292 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9423, mIoU: 0.6781, mAcc: 0.7854, IoU.Road: 0.9272, IoU.Sidewalk: 0.6980, IoU.Construction: 0.8121, IoU.Fence: 0.2880, IoU.Pole: 0.5622, IoU.Traffic Light: 0.6731, IoU.Traffic Sign: 0.7205, IoU.Nature: 0.8848, IoU.Sky: 0.9661, IoU.Person: 0.3144, IoU.Rider: 0.0935, IoU.Car: 0.9145, IoU.background: 0.9614, Acc.Road: 0.9692, Acc.Sidewalk: 0.8217, Acc.Construction: 0.9428, Acc.Fence: 0.3245, Acc.Pole: 0.7117, Acc.Traffic Light: 0.7904, Acc.Traffic Sign: 0.8172, Acc.Nature: 0.9388, Acc.Sky: 0.9777, Acc.Person: 0.3326, Acc.Rider: 0.6626, Acc.Car: 0.9487, Acc.background: 0.9721
2023-09-28 18:00:18,067 - mmseg - INFO - Iter [12050/40000]	lr: 1.003e-06, eta: 21:17:01, time: 22.592, data_time: 20.407, memory: 21542, decode.loss_cls: 0.0912, decode.loss_mask: 0.2735, decode.loss_dice: 0.5861, decode.d0.loss_cls: 0.2465, decode.d0.loss_mask: 0.2788, decode.d0.loss_dice: 0.6042, decode.d1.loss_cls: 0.1000, decode.d1.loss_mask: 0.2734, decode.d1.loss_dice: 0.5962, decode.d2.loss_cls: 0.0839, decode.d2.loss_mask: 0.2735, decode.d2.loss_dice: 0.5877, decode.d3.loss_cls: 0.0873, decode.d3.loss_mask: 0.2736, decode.d3.loss_dice: 0.5951, decode.d4.loss_cls: 0.1045, decode.d4.loss_mask: 0.2711, decode.d4.loss_dice: 0.5944, decode.d5.loss_cls: 0.1055, decode.d5.loss_mask: 0.2696, decode.d5.loss_dice: 0.5891, decode.d6.loss_cls: 0.0780, decode.d6.loss_mask: 0.2711, decode.d6.loss_dice: 0.5858, decode.d7.loss_cls: 0.0867, decode.d7.loss_mask: 0.2719, decode.d7.loss_dice: 0.5944, decode.d8.loss_cls: 0.1038, decode.d8.loss_mask: 0.2734, decode.d8.loss_dice: 0.5837, loss: 9.7338
2023-09-28 18:02:11,453 - mmseg - INFO - Iter [12100/40000]	lr: 1.002e-06, eta: 21:13:49, time: 2.268, data_time: 0.079, memory: 21542, decode.loss_cls: 0.0752, decode.loss_mask: 0.2832, decode.loss_dice: 0.6010, decode.d0.loss_cls: 0.2145, decode.d0.loss_mask: 0.2852, decode.d0.loss_dice: 0.6097, decode.d1.loss_cls: 0.1023, decode.d1.loss_mask: 0.2852, decode.d1.loss_dice: 0.5888, decode.d2.loss_cls: 0.0867, decode.d2.loss_mask: 0.2847, decode.d2.loss_dice: 0.5943, decode.d3.loss_cls: 0.0890, decode.d3.loss_mask: 0.2850, decode.d3.loss_dice: 0.5852, decode.d4.loss_cls: 0.1062, decode.d4.loss_mask: 0.2836, decode.d4.loss_dice: 0.6083, decode.d5.loss_cls: 0.0618, decode.d5.loss_mask: 0.2844, decode.d5.loss_dice: 0.5971, decode.d6.loss_cls: 0.0772, decode.d6.loss_mask: 0.2845, decode.d6.loss_dice: 0.5830, decode.d7.loss_cls: 0.0655, decode.d7.loss_mask: 0.2848, decode.d7.loss_dice: 0.6024, decode.d8.loss_cls: 0.0695, decode.d8.loss_mask: 0.2835, decode.d8.loss_dice: 0.5854, loss: 9.7468
2023-09-28 18:04:02,906 - mmseg - INFO - Iter [12150/40000]	lr: 9.997e-07, eta: 21:10:34, time: 2.229, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0711, decode.loss_mask: 0.3060, decode.loss_dice: 0.5888, decode.d0.loss_cls: 0.2388, decode.d0.loss_mask: 0.3138, decode.d0.loss_dice: 0.5704, decode.d1.loss_cls: 0.1009, decode.d1.loss_mask: 0.3066, decode.d1.loss_dice: 0.5841, decode.d2.loss_cls: 0.0788, decode.d2.loss_mask: 0.3033, decode.d2.loss_dice: 0.5592, decode.d3.loss_cls: 0.0842, decode.d3.loss_mask: 0.3054, decode.d3.loss_dice: 0.5803, decode.d4.loss_cls: 0.0928, decode.d4.loss_mask: 0.3083, decode.d4.loss_dice: 0.5731, decode.d5.loss_cls: 0.0870, decode.d5.loss_mask: 0.3062, decode.d5.loss_dice: 0.5744, decode.d6.loss_cls: 0.0769, decode.d6.loss_mask: 0.3060, decode.d6.loss_dice: 0.5798, decode.d7.loss_cls: 0.0893, decode.d7.loss_mask: 0.3085, decode.d7.loss_dice: 0.5742, decode.d8.loss_cls: 0.0929, decode.d8.loss_mask: 0.3066, decode.d8.loss_dice: 0.5776, loss: 9.8453
2023-09-28 18:05:54,218 - mmseg - INFO - Iter [12200/40000]	lr: 9.979e-07, eta: 21:07:18, time: 2.226, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0914, decode.loss_mask: 0.2757, decode.loss_dice: 0.6068, decode.d0.loss_cls: 0.2112, decode.d0.loss_mask: 0.2804, decode.d0.loss_dice: 0.6167, decode.d1.loss_cls: 0.1008, decode.d1.loss_mask: 0.2791, decode.d1.loss_dice: 0.6052, decode.d2.loss_cls: 0.0932, decode.d2.loss_mask: 0.2790, decode.d2.loss_dice: 0.6131, decode.d3.loss_cls: 0.0784, decode.d3.loss_mask: 0.2766, decode.d3.loss_dice: 0.6084, decode.d4.loss_cls: 0.0942, decode.d4.loss_mask: 0.2764, decode.d4.loss_dice: 0.6011, decode.d5.loss_cls: 0.0922, decode.d5.loss_mask: 0.2769, decode.d5.loss_dice: 0.6045, decode.d6.loss_cls: 0.0772, decode.d6.loss_mask: 0.2779, decode.d6.loss_dice: 0.6092, decode.d7.loss_cls: 0.0790, decode.d7.loss_mask: 0.2752, decode.d7.loss_dice: 0.6136, decode.d8.loss_cls: 0.0840, decode.d8.loss_mask: 0.2768, decode.d8.loss_dice: 0.6190, loss: 9.8732
2023-09-28 18:07:45,387 - mmseg - INFO - Iter [12250/40000]	lr: 9.961e-07, eta: 21:04:04, time: 2.222, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0568, decode.loss_mask: 0.2977, decode.loss_dice: 0.6085, decode.d0.loss_cls: 0.2569, decode.d0.loss_mask: 0.3151, decode.d0.loss_dice: 0.6050, decode.d1.loss_cls: 0.0821, decode.d1.loss_mask: 0.3050, decode.d1.loss_dice: 0.5964, decode.d2.loss_cls: 0.0690, decode.d2.loss_mask: 0.3064, decode.d2.loss_dice: 0.6083, decode.d3.loss_cls: 0.0504, decode.d3.loss_mask: 0.3135, decode.d3.loss_dice: 0.6036, decode.d4.loss_cls: 0.0710, decode.d4.loss_mask: 0.3119, decode.d4.loss_dice: 0.6143, decode.d5.loss_cls: 0.0552, decode.d5.loss_mask: 0.3050, decode.d5.loss_dice: 0.6078, decode.d6.loss_cls: 0.0634, decode.d6.loss_mask: 0.3111, decode.d6.loss_dice: 0.6039, decode.d7.loss_cls: 0.0657, decode.d7.loss_mask: 0.3117, decode.d7.loss_dice: 0.6142, decode.d8.loss_cls: 0.0477, decode.d8.loss_mask: 0.3124, decode.d8.loss_dice: 0.6110, loss: 9.9812
2023-09-28 18:09:36,517 - mmseg - INFO - Iter [12300/40000]	lr: 9.943e-07, eta: 21:00:49, time: 2.222, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0663, decode.loss_mask: 0.3043, decode.loss_dice: 0.6055, decode.d0.loss_cls: 0.2312, decode.d0.loss_mask: 0.3091, decode.d0.loss_dice: 0.6088, decode.d1.loss_cls: 0.0867, decode.d1.loss_mask: 0.3018, decode.d1.loss_dice: 0.5975, decode.d2.loss_cls: 0.0930, decode.d2.loss_mask: 0.3018, decode.d2.loss_dice: 0.5967, decode.d3.loss_cls: 0.0966, decode.d3.loss_mask: 0.2996, decode.d3.loss_dice: 0.6014, decode.d4.loss_cls: 0.0909, decode.d4.loss_mask: 0.3037, decode.d4.loss_dice: 0.5972, decode.d5.loss_cls: 0.0709, decode.d5.loss_mask: 0.3044, decode.d5.loss_dice: 0.6073, decode.d6.loss_cls: 0.0818, decode.d6.loss_mask: 0.3027, decode.d6.loss_dice: 0.6010, decode.d7.loss_cls: 0.0889, decode.d7.loss_mask: 0.3031, decode.d7.loss_dice: 0.5944, decode.d8.loss_cls: 0.0712, decode.d8.loss_mask: 0.3046, decode.d8.loss_dice: 0.6057, loss: 10.0281
2023-09-28 18:11:26,922 - mmseg - INFO - Iter [12350/40000]	lr: 9.925e-07, eta: 20:57:35, time: 2.209, data_time: 0.033, memory: 21542, decode.loss_cls: 0.1093, decode.loss_mask: 0.2913, decode.loss_dice: 0.6252, decode.d0.loss_cls: 0.2205, decode.d0.loss_mask: 0.2975, decode.d0.loss_dice: 0.6378, decode.d1.loss_cls: 0.0986, decode.d1.loss_mask: 0.2897, decode.d1.loss_dice: 0.6341, decode.d2.loss_cls: 0.0975, decode.d2.loss_mask: 0.2900, decode.d2.loss_dice: 0.6368, decode.d3.loss_cls: 0.0989, decode.d3.loss_mask: 0.2937, decode.d3.loss_dice: 0.6345, decode.d4.loss_cls: 0.1122, decode.d4.loss_mask: 0.2931, decode.d4.loss_dice: 0.6414, decode.d5.loss_cls: 0.0921, decode.d5.loss_mask: 0.2930, decode.d5.loss_dice: 0.6246, decode.d6.loss_cls: 0.0981, decode.d6.loss_mask: 0.2935, decode.d6.loss_dice: 0.6305, decode.d7.loss_cls: 0.1019, decode.d7.loss_mask: 0.2925, decode.d7.loss_dice: 0.6297, decode.d8.loss_cls: 0.1089, decode.d8.loss_mask: 0.2927, decode.d8.loss_dice: 0.6325, loss: 10.3920
2023-09-28 18:13:18,037 - mmseg - INFO - Iter [12400/40000]	lr: 9.907e-07, eta: 20:54:22, time: 2.222, data_time: 0.027, memory: 21542, decode.loss_cls: 0.1200, decode.loss_mask: 0.3020, decode.loss_dice: 0.6129, decode.d0.loss_cls: 0.2635, decode.d0.loss_mask: 0.3059, decode.d0.loss_dice: 0.6273, decode.d1.loss_cls: 0.1307, decode.d1.loss_mask: 0.3039, decode.d1.loss_dice: 0.6231, decode.d2.loss_cls: 0.1033, decode.d2.loss_mask: 0.3016, decode.d2.loss_dice: 0.6214, decode.d3.loss_cls: 0.0962, decode.d3.loss_mask: 0.3030, decode.d3.loss_dice: 0.6133, decode.d4.loss_cls: 0.1129, decode.d4.loss_mask: 0.3028, decode.d4.loss_dice: 0.6164, decode.d5.loss_cls: 0.1247, decode.d5.loss_mask: 0.3017, decode.d5.loss_dice: 0.6111, decode.d6.loss_cls: 0.0951, decode.d6.loss_mask: 0.2995, decode.d6.loss_dice: 0.6198, decode.d7.loss_cls: 0.1207, decode.d7.loss_mask: 0.3024, decode.d7.loss_dice: 0.6118, decode.d8.loss_cls: 0.1094, decode.d8.loss_mask: 0.3025, decode.d8.loss_dice: 0.5947, loss: 10.4536
2023-09-28 18:15:09,343 - mmseg - INFO - Iter [12450/40000]	lr: 9.889e-07, eta: 20:51:10, time: 2.226, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0936, decode.loss_mask: 0.2916, decode.loss_dice: 0.5904, decode.d0.loss_cls: 0.2421, decode.d0.loss_mask: 0.2992, decode.d0.loss_dice: 0.6092, decode.d1.loss_cls: 0.0986, decode.d1.loss_mask: 0.2974, decode.d1.loss_dice: 0.6004, decode.d2.loss_cls: 0.0880, decode.d2.loss_mask: 0.2954, decode.d2.loss_dice: 0.5959, decode.d3.loss_cls: 0.0755, decode.d3.loss_mask: 0.2945, decode.d3.loss_dice: 0.5921, decode.d4.loss_cls: 0.0897, decode.d4.loss_mask: 0.2916, decode.d4.loss_dice: 0.5935, decode.d5.loss_cls: 0.0996, decode.d5.loss_mask: 0.2942, decode.d5.loss_dice: 0.5862, decode.d6.loss_cls: 0.1150, decode.d6.loss_mask: 0.2911, decode.d6.loss_dice: 0.5787, decode.d7.loss_cls: 0.0974, decode.d7.loss_mask: 0.2910, decode.d7.loss_dice: 0.6035, decode.d8.loss_cls: 0.0907, decode.d8.loss_mask: 0.2900, decode.d8.loss_dice: 0.5908, loss: 9.9671
2023-09-28 18:17:00,667 - mmseg - INFO - Iter [12500/40000]	lr: 9.871e-07, eta: 20:47:59, time: 2.226, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0797, decode.loss_mask: 0.2985, decode.loss_dice: 0.5819, decode.d0.loss_cls: 0.2286, decode.d0.loss_mask: 0.2983, decode.d0.loss_dice: 0.6033, decode.d1.loss_cls: 0.1154, decode.d1.loss_mask: 0.2923, decode.d1.loss_dice: 0.5830, decode.d2.loss_cls: 0.1119, decode.d2.loss_mask: 0.2900, decode.d2.loss_dice: 0.5822, decode.d3.loss_cls: 0.0980, decode.d3.loss_mask: 0.2917, decode.d3.loss_dice: 0.5810, decode.d4.loss_cls: 0.0897, decode.d4.loss_mask: 0.3007, decode.d4.loss_dice: 0.5880, decode.d5.loss_cls: 0.1000, decode.d5.loss_mask: 0.2992, decode.d5.loss_dice: 0.5829, decode.d6.loss_cls: 0.0996, decode.d6.loss_mask: 0.2961, decode.d6.loss_dice: 0.5863, decode.d7.loss_cls: 0.0952, decode.d7.loss_mask: 0.2936, decode.d7.loss_dice: 0.5827, decode.d8.loss_cls: 0.1047, decode.d8.loss_mask: 0.2917, decode.d8.loss_dice: 0.5855, loss: 9.9315
2023-09-28 18:18:52,055 - mmseg - INFO - Iter [12550/40000]	lr: 9.854e-07, eta: 20:44:49, time: 2.228, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0822, decode.loss_mask: 0.3310, decode.loss_dice: 0.6316, decode.d0.loss_cls: 0.2145, decode.d0.loss_mask: 0.3401, decode.d0.loss_dice: 0.6586, decode.d1.loss_cls: 0.1095, decode.d1.loss_mask: 0.3300, decode.d1.loss_dice: 0.6305, decode.d2.loss_cls: 0.0932, decode.d2.loss_mask: 0.3307, decode.d2.loss_dice: 0.6373, decode.d3.loss_cls: 0.1036, decode.d3.loss_mask: 0.3300, decode.d3.loss_dice: 0.6401, decode.d4.loss_cls: 0.0965, decode.d4.loss_mask: 0.3290, decode.d4.loss_dice: 0.6402, decode.d5.loss_cls: 0.0793, decode.d5.loss_mask: 0.3332, decode.d5.loss_dice: 0.6473, decode.d6.loss_cls: 0.0870, decode.d6.loss_mask: 0.3295, decode.d6.loss_dice: 0.6463, decode.d7.loss_cls: 0.0945, decode.d7.loss_mask: 0.3304, decode.d7.loss_dice: 0.6505, decode.d8.loss_cls: 0.0892, decode.d8.loss_mask: 0.3289, decode.d8.loss_dice: 0.6378, loss: 10.7824
2023-09-28 18:20:43,234 - mmseg - INFO - Iter [12600/40000]	lr: 9.836e-07, eta: 20:41:38, time: 2.224, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0744, decode.loss_mask: 0.2734, decode.loss_dice: 0.5497, decode.d0.loss_cls: 0.2179, decode.d0.loss_mask: 0.2813, decode.d0.loss_dice: 0.5529, decode.d1.loss_cls: 0.0759, decode.d1.loss_mask: 0.2761, decode.d1.loss_dice: 0.5540, decode.d2.loss_cls: 0.0884, decode.d2.loss_mask: 0.2725, decode.d2.loss_dice: 0.5439, decode.d3.loss_cls: 0.0745, decode.d3.loss_mask: 0.2720, decode.d3.loss_dice: 0.5534, decode.d4.loss_cls: 0.0800, decode.d4.loss_mask: 0.2738, decode.d4.loss_dice: 0.5477, decode.d5.loss_cls: 0.0851, decode.d5.loss_mask: 0.2751, decode.d5.loss_dice: 0.5498, decode.d6.loss_cls: 0.0619, decode.d6.loss_mask: 0.2744, decode.d6.loss_dice: 0.5586, decode.d7.loss_cls: 0.0833, decode.d7.loss_mask: 0.2736, decode.d7.loss_dice: 0.5413, decode.d8.loss_cls: 0.0817, decode.d8.loss_mask: 0.2734, decode.d8.loss_dice: 0.5454, loss: 9.1653
2023-09-28 18:22:34,818 - mmseg - INFO - Iter [12650/40000]	lr: 9.818e-07, eta: 20:38:30, time: 2.232, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0559, decode.loss_mask: 0.2672, decode.loss_dice: 0.5732, decode.d0.loss_cls: 0.1969, decode.d0.loss_mask: 0.2760, decode.d0.loss_dice: 0.5873, decode.d1.loss_cls: 0.0800, decode.d1.loss_mask: 0.2669, decode.d1.loss_dice: 0.5761, decode.d2.loss_cls: 0.0751, decode.d2.loss_mask: 0.2649, decode.d2.loss_dice: 0.5775, decode.d3.loss_cls: 0.0707, decode.d3.loss_mask: 0.2667, decode.d3.loss_dice: 0.5700, decode.d4.loss_cls: 0.0775, decode.d4.loss_mask: 0.2677, decode.d4.loss_dice: 0.5796, decode.d5.loss_cls: 0.0786, decode.d5.loss_mask: 0.2662, decode.d5.loss_dice: 0.5728, decode.d6.loss_cls: 0.0760, decode.d6.loss_mask: 0.2671, decode.d6.loss_dice: 0.5768, decode.d7.loss_cls: 0.0531, decode.d7.loss_mask: 0.2667, decode.d7.loss_dice: 0.5789, decode.d8.loss_cls: 0.0632, decode.d8.loss_mask: 0.2666, decode.d8.loss_dice: 0.5818, loss: 9.2771
2023-09-28 18:24:26,622 - mmseg - INFO - Iter [12700/40000]	lr: 9.800e-07, eta: 20:35:22, time: 2.236, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0869, decode.loss_mask: 0.2953, decode.loss_dice: 0.6423, decode.d0.loss_cls: 0.2406, decode.d0.loss_mask: 0.3005, decode.d0.loss_dice: 0.6647, decode.d1.loss_cls: 0.0809, decode.d1.loss_mask: 0.2962, decode.d1.loss_dice: 0.6575, decode.d2.loss_cls: 0.0819, decode.d2.loss_mask: 0.2950, decode.d2.loss_dice: 0.6443, decode.d3.loss_cls: 0.0749, decode.d3.loss_mask: 0.2961, decode.d3.loss_dice: 0.6505, decode.d4.loss_cls: 0.0756, decode.d4.loss_mask: 0.2963, decode.d4.loss_dice: 0.6530, decode.d5.loss_cls: 0.0847, decode.d5.loss_mask: 0.2951, decode.d5.loss_dice: 0.6480, decode.d6.loss_cls: 0.1087, decode.d6.loss_mask: 0.2947, decode.d6.loss_dice: 0.6484, decode.d7.loss_cls: 0.0752, decode.d7.loss_mask: 0.2953, decode.d7.loss_dice: 0.6594, decode.d8.loss_cls: 0.0772, decode.d8.loss_mask: 0.2966, decode.d8.loss_dice: 0.6544, loss: 10.4707
2023-09-28 18:26:17,964 - mmseg - INFO - Iter [12750/40000]	lr: 9.782e-07, eta: 20:32:14, time: 2.227, data_time: 0.026, memory: 21542, decode.loss_cls: 0.0991, decode.loss_mask: 0.2977, decode.loss_dice: 0.6234, decode.d0.loss_cls: 0.2491, decode.d0.loss_mask: 0.3004, decode.d0.loss_dice: 0.6252, decode.d1.loss_cls: 0.1073, decode.d1.loss_mask: 0.2972, decode.d1.loss_dice: 0.6369, decode.d2.loss_cls: 0.0947, decode.d2.loss_mask: 0.2977, decode.d2.loss_dice: 0.6279, decode.d3.loss_cls: 0.1069, decode.d3.loss_mask: 0.2988, decode.d3.loss_dice: 0.6288, decode.d4.loss_cls: 0.0896, decode.d4.loss_mask: 0.3008, decode.d4.loss_dice: 0.6326, decode.d5.loss_cls: 0.1065, decode.d5.loss_mask: 0.2981, decode.d5.loss_dice: 0.6197, decode.d6.loss_cls: 0.0904, decode.d6.loss_mask: 0.2992, decode.d6.loss_dice: 0.6178, decode.d7.loss_cls: 0.1016, decode.d7.loss_mask: 0.2964, decode.d7.loss_dice: 0.6258, decode.d8.loss_cls: 0.1112, decode.d8.loss_mask: 0.2968, decode.d8.loss_dice: 0.6229, loss: 10.4005
2023-09-28 18:28:09,866 - mmseg - INFO - Iter [12800/40000]	lr: 9.764e-07, eta: 20:29:08, time: 2.238, data_time: 0.033, memory: 21542, decode.loss_cls: 0.1125, decode.loss_mask: 0.2908, decode.loss_dice: 0.6259, decode.d0.loss_cls: 0.2299, decode.d0.loss_mask: 0.3032, decode.d0.loss_dice: 0.6433, decode.d1.loss_cls: 0.1133, decode.d1.loss_mask: 0.2909, decode.d1.loss_dice: 0.6339, decode.d2.loss_cls: 0.1005, decode.d2.loss_mask: 0.2918, decode.d2.loss_dice: 0.6431, decode.d3.loss_cls: 0.0938, decode.d3.loss_mask: 0.2925, decode.d3.loss_dice: 0.6391, decode.d4.loss_cls: 0.0989, decode.d4.loss_mask: 0.2913, decode.d4.loss_dice: 0.6256, decode.d5.loss_cls: 0.0880, decode.d5.loss_mask: 0.2910, decode.d5.loss_dice: 0.6292, decode.d6.loss_cls: 0.0828, decode.d6.loss_mask: 0.2934, decode.d6.loss_dice: 0.6293, decode.d7.loss_cls: 0.0967, decode.d7.loss_mask: 0.2887, decode.d7.loss_dice: 0.6158, decode.d8.loss_cls: 0.0920, decode.d8.loss_mask: 0.2903, decode.d8.loss_dice: 0.6255, loss: 10.3428
2023-09-28 18:30:01,965 - mmseg - INFO - Iter [12850/40000]	lr: 9.746e-07, eta: 20:26:03, time: 2.242, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0959, decode.loss_mask: 0.2853, decode.loss_dice: 0.6036, decode.d0.loss_cls: 0.2157, decode.d0.loss_mask: 0.2902, decode.d0.loss_dice: 0.6292, decode.d1.loss_cls: 0.1093, decode.d1.loss_mask: 0.2868, decode.d1.loss_dice: 0.6084, decode.d2.loss_cls: 0.0762, decode.d2.loss_mask: 0.2872, decode.d2.loss_dice: 0.6179, decode.d3.loss_cls: 0.0757, decode.d3.loss_mask: 0.2862, decode.d3.loss_dice: 0.6025, decode.d4.loss_cls: 0.1043, decode.d4.loss_mask: 0.2871, decode.d4.loss_dice: 0.6101, decode.d5.loss_cls: 0.1002, decode.d5.loss_mask: 0.2857, decode.d5.loss_dice: 0.6083, decode.d6.loss_cls: 0.0939, decode.d6.loss_mask: 0.2869, decode.d6.loss_dice: 0.6034, decode.d7.loss_cls: 0.0922, decode.d7.loss_mask: 0.2858, decode.d7.loss_dice: 0.6084, decode.d8.loss_cls: 0.0973, decode.d8.loss_mask: 0.2855, decode.d8.loss_dice: 0.6088, loss: 10.0279
2023-09-28 18:31:53,079 - mmseg - INFO - Iter [12900/40000]	lr: 9.728e-07, eta: 20:22:56, time: 2.222, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0934, decode.loss_mask: 0.2679, decode.loss_dice: 0.6124, decode.d0.loss_cls: 0.2414, decode.d0.loss_mask: 0.2688, decode.d0.loss_dice: 0.6355, decode.d1.loss_cls: 0.1102, decode.d1.loss_mask: 0.2675, decode.d1.loss_dice: 0.6269, decode.d2.loss_cls: 0.0920, decode.d2.loss_mask: 0.2671, decode.d2.loss_dice: 0.6203, decode.d3.loss_cls: 0.0910, decode.d3.loss_mask: 0.2666, decode.d3.loss_dice: 0.6099, decode.d4.loss_cls: 0.0739, decode.d4.loss_mask: 0.2665, decode.d4.loss_dice: 0.6212, decode.d5.loss_cls: 0.0827, decode.d5.loss_mask: 0.2664, decode.d5.loss_dice: 0.6315, decode.d6.loss_cls: 0.0988, decode.d6.loss_mask: 0.2673, decode.d6.loss_dice: 0.6249, decode.d7.loss_cls: 0.1060, decode.d7.loss_mask: 0.2669, decode.d7.loss_dice: 0.6219, decode.d8.loss_cls: 0.0692, decode.d8.loss_mask: 0.2661, decode.d8.loss_dice: 0.6178, loss: 9.9520
2023-09-28 18:33:43,578 - mmseg - INFO - Iter [12950/40000]	lr: 9.710e-07, eta: 20:19:49, time: 2.210, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0716, decode.loss_mask: 0.2971, decode.loss_dice: 0.5932, decode.d0.loss_cls: 0.2266, decode.d0.loss_mask: 0.3067, decode.d0.loss_dice: 0.5907, decode.d1.loss_cls: 0.0837, decode.d1.loss_mask: 0.2970, decode.d1.loss_dice: 0.5851, decode.d2.loss_cls: 0.0777, decode.d2.loss_mask: 0.2979, decode.d2.loss_dice: 0.5929, decode.d3.loss_cls: 0.0668, decode.d3.loss_mask: 0.3056, decode.d3.loss_dice: 0.5897, decode.d4.loss_cls: 0.0718, decode.d4.loss_mask: 0.3047, decode.d4.loss_dice: 0.5971, decode.d5.loss_cls: 0.0683, decode.d5.loss_mask: 0.2972, decode.d5.loss_dice: 0.5953, decode.d6.loss_cls: 0.0808, decode.d6.loss_mask: 0.2984, decode.d6.loss_dice: 0.5845, decode.d7.loss_cls: 0.0587, decode.d7.loss_mask: 0.3049, decode.d7.loss_dice: 0.5926, decode.d8.loss_cls: 0.0569, decode.d8.loss_mask: 0.3062, decode.d8.loss_dice: 0.5965, loss: 9.7961
2023-09-28 18:35:34,896 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 18:35:34,896 - mmseg - INFO - Iter [13000/40000]	lr: 9.692e-07, eta: 20:16:44, time: 2.226, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0730, decode.loss_mask: 0.2760, decode.loss_dice: 0.6047, decode.d0.loss_cls: 0.2150, decode.d0.loss_mask: 0.2850, decode.d0.loss_dice: 0.6158, decode.d1.loss_cls: 0.1018, decode.d1.loss_mask: 0.2803, decode.d1.loss_dice: 0.6113, decode.d2.loss_cls: 0.0727, decode.d2.loss_mask: 0.2797, decode.d2.loss_dice: 0.6085, decode.d3.loss_cls: 0.0798, decode.d3.loss_mask: 0.2766, decode.d3.loss_dice: 0.6021, decode.d4.loss_cls: 0.0827, decode.d4.loss_mask: 0.2796, decode.d4.loss_dice: 0.6098, decode.d5.loss_cls: 0.0685, decode.d5.loss_mask: 0.2796, decode.d5.loss_dice: 0.6171, decode.d6.loss_cls: 0.0711, decode.d6.loss_mask: 0.2788, decode.d6.loss_dice: 0.6091, decode.d7.loss_cls: 0.0974, decode.d7.loss_mask: 0.2784, decode.d7.loss_dice: 0.6095, decode.d8.loss_cls: 0.0846, decode.d8.loss_mask: 0.2781, decode.d8.loss_dice: 0.6022, loss: 9.8290
2023-09-28 18:37:25,234 - mmseg - INFO - Iter [13050/40000]	lr: 9.674e-07, eta: 20:13:37, time: 2.207, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0724, decode.loss_mask: 0.2793, decode.loss_dice: 0.5498, decode.d0.loss_cls: 0.2217, decode.d0.loss_mask: 0.2849, decode.d0.loss_dice: 0.5628, decode.d1.loss_cls: 0.0848, decode.d1.loss_mask: 0.2806, decode.d1.loss_dice: 0.5674, decode.d2.loss_cls: 0.0749, decode.d2.loss_mask: 0.2790, decode.d2.loss_dice: 0.5606, decode.d3.loss_cls: 0.0654, decode.d3.loss_mask: 0.2788, decode.d3.loss_dice: 0.5529, decode.d4.loss_cls: 0.0876, decode.d4.loss_mask: 0.2795, decode.d4.loss_dice: 0.5630, decode.d5.loss_cls: 0.0732, decode.d5.loss_mask: 0.2799, decode.d5.loss_dice: 0.5619, decode.d6.loss_cls: 0.0756, decode.d6.loss_mask: 0.2801, decode.d6.loss_dice: 0.5667, decode.d7.loss_cls: 0.0814, decode.d7.loss_mask: 0.2792, decode.d7.loss_dice: 0.5671, decode.d8.loss_cls: 0.0726, decode.d8.loss_mask: 0.2797, decode.d8.loss_dice: 0.5632, loss: 9.3262
2023-09-28 18:39:16,955 - mmseg - INFO - Iter [13100/40000]	lr: 9.656e-07, eta: 20:10:34, time: 2.235, data_time: 0.031, memory: 21542, decode.loss_cls: 0.1008, decode.loss_mask: 0.2706, decode.loss_dice: 0.5869, decode.d0.loss_cls: 0.2450, decode.d0.loss_mask: 0.2738, decode.d0.loss_dice: 0.5862, decode.d1.loss_cls: 0.1156, decode.d1.loss_mask: 0.2755, decode.d1.loss_dice: 0.5905, decode.d2.loss_cls: 0.1164, decode.d2.loss_mask: 0.2728, decode.d2.loss_dice: 0.5833, decode.d3.loss_cls: 0.1031, decode.d3.loss_mask: 0.2742, decode.d3.loss_dice: 0.5950, decode.d4.loss_cls: 0.1032, decode.d4.loss_mask: 0.2739, decode.d4.loss_dice: 0.5837, decode.d5.loss_cls: 0.0838, decode.d5.loss_mask: 0.2746, decode.d5.loss_dice: 0.5895, decode.d6.loss_cls: 0.0844, decode.d6.loss_mask: 0.2729, decode.d6.loss_dice: 0.5873, decode.d7.loss_cls: 0.0857, decode.d7.loss_mask: 0.2722, decode.d7.loss_dice: 0.5844, decode.d8.loss_cls: 0.0781, decode.d8.loss_mask: 0.2720, decode.d8.loss_dice: 0.5864, loss: 9.7215
2023-09-28 18:41:07,742 - mmseg - INFO - Iter [13150/40000]	lr: 9.638e-07, eta: 20:07:30, time: 2.216, data_time: 0.035, memory: 21542, decode.loss_cls: 0.0792, decode.loss_mask: 0.3067, decode.loss_dice: 0.6051, decode.d0.loss_cls: 0.2434, decode.d0.loss_mask: 0.3087, decode.d0.loss_dice: 0.6286, decode.d1.loss_cls: 0.0873, decode.d1.loss_mask: 0.3047, decode.d1.loss_dice: 0.6010, decode.d2.loss_cls: 0.1088, decode.d2.loss_mask: 0.3039, decode.d2.loss_dice: 0.6053, decode.d3.loss_cls: 0.0872, decode.d3.loss_mask: 0.3067, decode.d3.loss_dice: 0.6007, decode.d4.loss_cls: 0.0976, decode.d4.loss_mask: 0.3083, decode.d4.loss_dice: 0.6072, decode.d5.loss_cls: 0.1012, decode.d5.loss_mask: 0.3076, decode.d5.loss_dice: 0.5830, decode.d6.loss_cls: 0.0804, decode.d6.loss_mask: 0.3072, decode.d6.loss_dice: 0.6121, decode.d7.loss_cls: 0.0780, decode.d7.loss_mask: 0.3073, decode.d7.loss_dice: 0.5991, decode.d8.loss_cls: 0.1080, decode.d8.loss_mask: 0.3055, decode.d8.loss_dice: 0.6024, loss: 10.1824
2023-09-28 18:43:02,133 - mmseg - INFO - Iter [13200/40000]	lr: 9.620e-07, eta: 20:04:33, time: 2.288, data_time: 0.080, memory: 21542, decode.loss_cls: 0.0616, decode.loss_mask: 0.2843, decode.loss_dice: 0.5910, decode.d0.loss_cls: 0.2260, decode.d0.loss_mask: 0.2881, decode.d0.loss_dice: 0.5803, decode.d1.loss_cls: 0.0633, decode.d1.loss_mask: 0.2888, decode.d1.loss_dice: 0.5876, decode.d2.loss_cls: 0.0544, decode.d2.loss_mask: 0.2873, decode.d2.loss_dice: 0.5786, decode.d3.loss_cls: 0.0680, decode.d3.loss_mask: 0.2861, decode.d3.loss_dice: 0.5806, decode.d4.loss_cls: 0.0565, decode.d4.loss_mask: 0.2870, decode.d4.loss_dice: 0.5833, decode.d5.loss_cls: 0.0638, decode.d5.loss_mask: 0.2869, decode.d5.loss_dice: 0.5807, decode.d6.loss_cls: 0.0931, decode.d6.loss_mask: 0.2846, decode.d6.loss_dice: 0.5923, decode.d7.loss_cls: 0.0582, decode.d7.loss_mask: 0.2846, decode.d7.loss_dice: 0.5805, decode.d8.loss_cls: 0.0525, decode.d8.loss_mask: 0.2860, decode.d8.loss_dice: 0.5871, loss: 9.5031
2023-09-28 18:44:54,372 - mmseg - INFO - Iter [13250/40000]	lr: 9.602e-07, eta: 20:01:33, time: 2.243, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0733, decode.loss_mask: 0.2767, decode.loss_dice: 0.6138, decode.d0.loss_cls: 0.2157, decode.d0.loss_mask: 0.2836, decode.d0.loss_dice: 0.6266, decode.d1.loss_cls: 0.0805, decode.d1.loss_mask: 0.2798, decode.d1.loss_dice: 0.6180, decode.d2.loss_cls: 0.0851, decode.d2.loss_mask: 0.2798, decode.d2.loss_dice: 0.6174, decode.d3.loss_cls: 0.0905, decode.d3.loss_mask: 0.2776, decode.d3.loss_dice: 0.6100, decode.d4.loss_cls: 0.0970, decode.d4.loss_mask: 0.2776, decode.d4.loss_dice: 0.6144, decode.d5.loss_cls: 0.0784, decode.d5.loss_mask: 0.2787, decode.d5.loss_dice: 0.6098, decode.d6.loss_cls: 0.0697, decode.d6.loss_mask: 0.2795, decode.d6.loss_dice: 0.6071, decode.d7.loss_cls: 0.0684, decode.d7.loss_mask: 0.2784, decode.d7.loss_dice: 0.6132, decode.d8.loss_cls: 0.0663, decode.d8.loss_mask: 0.2777, decode.d8.loss_dice: 0.6140, loss: 9.8586
2023-09-28 18:46:45,659 - mmseg - INFO - Iter [13300/40000]	lr: 9.584e-07, eta: 19:58:31, time: 2.227, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0822, decode.loss_mask: 0.2638, decode.loss_dice: 0.5716, decode.d0.loss_cls: 0.2362, decode.d0.loss_mask: 0.2631, decode.d0.loss_dice: 0.5890, decode.d1.loss_cls: 0.0928, decode.d1.loss_mask: 0.2640, decode.d1.loss_dice: 0.5815, decode.d2.loss_cls: 0.0778, decode.d2.loss_mask: 0.2643, decode.d2.loss_dice: 0.5749, decode.d3.loss_cls: 0.0727, decode.d3.loss_mask: 0.2655, decode.d3.loss_dice: 0.5843, decode.d4.loss_cls: 0.0925, decode.d4.loss_mask: 0.2658, decode.d4.loss_dice: 0.5886, decode.d5.loss_cls: 0.0915, decode.d5.loss_mask: 0.2641, decode.d5.loss_dice: 0.5712, decode.d6.loss_cls: 0.0812, decode.d6.loss_mask: 0.2648, decode.d6.loss_dice: 0.5758, decode.d7.loss_cls: 0.0869, decode.d7.loss_mask: 0.2650, decode.d7.loss_dice: 0.5629, decode.d8.loss_cls: 0.0815, decode.d8.loss_mask: 0.2657, decode.d8.loss_dice: 0.5755, loss: 9.4166
2023-09-28 18:48:36,437 - mmseg - INFO - Iter [13350/40000]	lr: 9.566e-07, eta: 19:55:28, time: 2.215, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0654, decode.loss_mask: 0.2691, decode.loss_dice: 0.6040, decode.d0.loss_cls: 0.2039, decode.d0.loss_mask: 0.2699, decode.d0.loss_dice: 0.6087, decode.d1.loss_cls: 0.0738, decode.d1.loss_mask: 0.2681, decode.d1.loss_dice: 0.5888, decode.d2.loss_cls: 0.0654, decode.d2.loss_mask: 0.2673, decode.d2.loss_dice: 0.5836, decode.d3.loss_cls: 0.0772, decode.d3.loss_mask: 0.2698, decode.d3.loss_dice: 0.5952, decode.d4.loss_cls: 0.1010, decode.d4.loss_mask: 0.2695, decode.d4.loss_dice: 0.5886, decode.d5.loss_cls: 0.0884, decode.d5.loss_mask: 0.2672, decode.d5.loss_dice: 0.5806, decode.d6.loss_cls: 0.0697, decode.d6.loss_mask: 0.2695, decode.d6.loss_dice: 0.5907, decode.d7.loss_cls: 0.0642, decode.d7.loss_mask: 0.2695, decode.d7.loss_dice: 0.5896, decode.d8.loss_cls: 0.0747, decode.d8.loss_mask: 0.2695, decode.d8.loss_dice: 0.5868, loss: 9.4899
2023-09-28 18:50:27,526 - mmseg - INFO - Iter [13400/40000]	lr: 9.548e-07, eta: 19:52:27, time: 2.223, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0852, decode.loss_mask: 0.2927, decode.loss_dice: 0.5879, decode.d0.loss_cls: 0.2257, decode.d0.loss_mask: 0.3020, decode.d0.loss_dice: 0.5989, decode.d1.loss_cls: 0.0842, decode.d1.loss_mask: 0.2970, decode.d1.loss_dice: 0.6078, decode.d2.loss_cls: 0.0727, decode.d2.loss_mask: 0.2952, decode.d2.loss_dice: 0.5977, decode.d3.loss_cls: 0.0625, decode.d3.loss_mask: 0.2962, decode.d3.loss_dice: 0.6031, decode.d4.loss_cls: 0.0782, decode.d4.loss_mask: 0.2977, decode.d4.loss_dice: 0.5997, decode.d5.loss_cls: 0.0621, decode.d5.loss_mask: 0.2949, decode.d5.loss_dice: 0.5940, decode.d6.loss_cls: 0.0631, decode.d6.loss_mask: 0.2942, decode.d6.loss_dice: 0.5922, decode.d7.loss_cls: 0.0708, decode.d7.loss_mask: 0.2958, decode.d7.loss_dice: 0.5936, decode.d8.loss_cls: 0.0791, decode.d8.loss_mask: 0.2947, decode.d8.loss_dice: 0.5911, loss: 9.8100
2023-09-28 18:52:19,475 - mmseg - INFO - Iter [13450/40000]	lr: 9.530e-07, eta: 19:49:28, time: 2.239, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0840, decode.loss_mask: 0.3022, decode.loss_dice: 0.5769, decode.d0.loss_cls: 0.2203, decode.d0.loss_mask: 0.3122, decode.d0.loss_dice: 0.5911, decode.d1.loss_cls: 0.1020, decode.d1.loss_mask: 0.3055, decode.d1.loss_dice: 0.5780, decode.d2.loss_cls: 0.0747, decode.d2.loss_mask: 0.3045, decode.d2.loss_dice: 0.5928, decode.d3.loss_cls: 0.0828, decode.d3.loss_mask: 0.3048, decode.d3.loss_dice: 0.5854, decode.d4.loss_cls: 0.0933, decode.d4.loss_mask: 0.3042, decode.d4.loss_dice: 0.5911, decode.d5.loss_cls: 0.0702, decode.d5.loss_mask: 0.3048, decode.d5.loss_dice: 0.5859, decode.d6.loss_cls: 0.0778, decode.d6.loss_mask: 0.3059, decode.d6.loss_dice: 0.5826, decode.d7.loss_cls: 0.0926, decode.d7.loss_mask: 0.3060, decode.d7.loss_dice: 0.5886, decode.d8.loss_cls: 0.0810, decode.d8.loss_mask: 0.3038, decode.d8.loss_dice: 0.5853, loss: 9.8904
2023-09-28 18:54:10,933 - mmseg - INFO - Iter [13500/40000]	lr: 9.513e-07, eta: 19:46:29, time: 2.230, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0974, decode.loss_mask: 0.3119, decode.loss_dice: 0.6059, decode.d0.loss_cls: 0.2479, decode.d0.loss_mask: 0.3157, decode.d0.loss_dice: 0.6221, decode.d1.loss_cls: 0.1300, decode.d1.loss_mask: 0.3123, decode.d1.loss_dice: 0.6093, decode.d2.loss_cls: 0.1189, decode.d2.loss_mask: 0.3012, decode.d2.loss_dice: 0.6153, decode.d3.loss_cls: 0.0913, decode.d3.loss_mask: 0.3107, decode.d3.loss_dice: 0.6101, decode.d4.loss_cls: 0.0991, decode.d4.loss_mask: 0.3143, decode.d4.loss_dice: 0.6115, decode.d5.loss_cls: 0.1082, decode.d5.loss_mask: 0.3108, decode.d5.loss_dice: 0.6080, decode.d6.loss_cls: 0.1053, decode.d6.loss_mask: 0.3101, decode.d6.loss_dice: 0.6114, decode.d7.loss_cls: 0.0987, decode.d7.loss_mask: 0.3128, decode.d7.loss_dice: 0.6055, decode.d8.loss_cls: 0.1083, decode.d8.loss_mask: 0.3107, decode.d8.loss_dice: 0.6130, loss: 10.4278
2023-09-28 18:56:02,348 - mmseg - INFO - Iter [13550/40000]	lr: 9.495e-07, eta: 19:43:30, time: 2.228, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0495, decode.loss_mask: 0.2831, decode.loss_dice: 0.5680, decode.d0.loss_cls: 0.2381, decode.d0.loss_mask: 0.2859, decode.d0.loss_dice: 0.5794, decode.d1.loss_cls: 0.0685, decode.d1.loss_mask: 0.2848, decode.d1.loss_dice: 0.5845, decode.d2.loss_cls: 0.0503, decode.d2.loss_mask: 0.2825, decode.d2.loss_dice: 0.5781, decode.d3.loss_cls: 0.0638, decode.d3.loss_mask: 0.2841, decode.d3.loss_dice: 0.5741, decode.d4.loss_cls: 0.0490, decode.d4.loss_mask: 0.2832, decode.d4.loss_dice: 0.5694, decode.d5.loss_cls: 0.0598, decode.d5.loss_mask: 0.2826, decode.d5.loss_dice: 0.5703, decode.d6.loss_cls: 0.0465, decode.d6.loss_mask: 0.2832, decode.d6.loss_dice: 0.5586, decode.d7.loss_cls: 0.0501, decode.d7.loss_mask: 0.2828, decode.d7.loss_dice: 0.5801, decode.d8.loss_cls: 0.0571, decode.d8.loss_mask: 0.2811, decode.d8.loss_dice: 0.5683, loss: 9.2968
2023-09-28 18:57:53,686 - mmseg - INFO - Iter [13600/40000]	lr: 9.477e-07, eta: 19:40:31, time: 2.226, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0626, decode.loss_mask: 0.2954, decode.loss_dice: 0.5984, decode.d0.loss_cls: 0.2234, decode.d0.loss_mask: 0.3057, decode.d0.loss_dice: 0.6162, decode.d1.loss_cls: 0.0789, decode.d1.loss_mask: 0.2986, decode.d1.loss_dice: 0.6098, decode.d2.loss_cls: 0.0724, decode.d2.loss_mask: 0.2979, decode.d2.loss_dice: 0.5958, decode.d3.loss_cls: 0.0671, decode.d3.loss_mask: 0.2980, decode.d3.loss_dice: 0.5980, decode.d4.loss_cls: 0.0622, decode.d4.loss_mask: 0.2994, decode.d4.loss_dice: 0.5975, decode.d5.loss_cls: 0.0613, decode.d5.loss_mask: 0.2969, decode.d5.loss_dice: 0.6007, decode.d6.loss_cls: 0.0557, decode.d6.loss_mask: 0.2977, decode.d6.loss_dice: 0.6077, decode.d7.loss_cls: 0.0634, decode.d7.loss_mask: 0.2973, decode.d7.loss_dice: 0.6027, decode.d8.loss_cls: 0.0717, decode.d8.loss_mask: 0.2967, decode.d8.loss_dice: 0.6023, loss: 9.8316
2023-09-28 18:59:45,322 - mmseg - INFO - Iter [13650/40000]	lr: 9.459e-07, eta: 19:37:34, time: 2.233, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0823, decode.loss_mask: 0.2703, decode.loss_dice: 0.5885, decode.d0.loss_cls: 0.2462, decode.d0.loss_mask: 0.2720, decode.d0.loss_dice: 0.5952, decode.d1.loss_cls: 0.0911, decode.d1.loss_mask: 0.2700, decode.d1.loss_dice: 0.5880, decode.d2.loss_cls: 0.0930, decode.d2.loss_mask: 0.2716, decode.d2.loss_dice: 0.5914, decode.d3.loss_cls: 0.0914, decode.d3.loss_mask: 0.2694, decode.d3.loss_dice: 0.5956, decode.d4.loss_cls: 0.0696, decode.d4.loss_mask: 0.2706, decode.d4.loss_dice: 0.5902, decode.d5.loss_cls: 0.0804, decode.d5.loss_mask: 0.2708, decode.d5.loss_dice: 0.5943, decode.d6.loss_cls: 0.0773, decode.d6.loss_mask: 0.2711, decode.d6.loss_dice: 0.5769, decode.d7.loss_cls: 0.0952, decode.d7.loss_mask: 0.2690, decode.d7.loss_dice: 0.5896, decode.d8.loss_cls: 0.0771, decode.d8.loss_mask: 0.2697, decode.d8.loss_dice: 0.5905, loss: 9.6082
2023-09-28 19:01:37,874 - mmseg - INFO - Iter [13700/40000]	lr: 9.441e-07, eta: 19:34:38, time: 2.251, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0643, decode.loss_mask: 0.2972, decode.loss_dice: 0.5903, decode.d0.loss_cls: 0.2084, decode.d0.loss_mask: 0.2999, decode.d0.loss_dice: 0.5985, decode.d1.loss_cls: 0.1124, decode.d1.loss_mask: 0.2968, decode.d1.loss_dice: 0.6065, decode.d2.loss_cls: 0.0912, decode.d2.loss_mask: 0.2975, decode.d2.loss_dice: 0.6031, decode.d3.loss_cls: 0.0822, decode.d3.loss_mask: 0.2968, decode.d3.loss_dice: 0.5968, decode.d4.loss_cls: 0.0851, decode.d4.loss_mask: 0.2963, decode.d4.loss_dice: 0.6054, decode.d5.loss_cls: 0.0793, decode.d5.loss_mask: 0.2971, decode.d5.loss_dice: 0.6059, decode.d6.loss_cls: 0.0711, decode.d6.loss_mask: 0.2962, decode.d6.loss_dice: 0.5958, decode.d7.loss_cls: 0.0667, decode.d7.loss_mask: 0.2975, decode.d7.loss_dice: 0.5957, decode.d8.loss_cls: 0.0801, decode.d8.loss_mask: 0.2981, decode.d8.loss_dice: 0.6006, loss: 9.9127
2023-09-28 19:03:28,521 - mmseg - INFO - Iter [13750/40000]	lr: 9.423e-07, eta: 19:31:40, time: 2.213, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0735, decode.loss_mask: 0.2873, decode.loss_dice: 0.6271, decode.d0.loss_cls: 0.2248, decode.d0.loss_mask: 0.2906, decode.d0.loss_dice: 0.6413, decode.d1.loss_cls: 0.1099, decode.d1.loss_mask: 0.2888, decode.d1.loss_dice: 0.6281, decode.d2.loss_cls: 0.0889, decode.d2.loss_mask: 0.2889, decode.d2.loss_dice: 0.6348, decode.d3.loss_cls: 0.0991, decode.d3.loss_mask: 0.2886, decode.d3.loss_dice: 0.6298, decode.d4.loss_cls: 0.0829, decode.d4.loss_mask: 0.2892, decode.d4.loss_dice: 0.6356, decode.d5.loss_cls: 0.0999, decode.d5.loss_mask: 0.2879, decode.d5.loss_dice: 0.6253, decode.d6.loss_cls: 0.0775, decode.d6.loss_mask: 0.2899, decode.d6.loss_dice: 0.6222, decode.d7.loss_cls: 0.0836, decode.d7.loss_mask: 0.2887, decode.d7.loss_dice: 0.6314, decode.d8.loss_cls: 0.0823, decode.d8.loss_mask: 0.2883, decode.d8.loss_dice: 0.6426, loss: 10.2286
2023-09-28 19:05:20,208 - mmseg - INFO - Iter [13800/40000]	lr: 9.405e-07, eta: 19:28:44, time: 2.234, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0790, decode.loss_mask: 0.2619, decode.loss_dice: 0.5812, decode.d0.loss_cls: 0.2254, decode.d0.loss_mask: 0.2653, decode.d0.loss_dice: 0.5874, decode.d1.loss_cls: 0.0968, decode.d1.loss_mask: 0.2610, decode.d1.loss_dice: 0.5759, decode.d2.loss_cls: 0.0954, decode.d2.loss_mask: 0.2621, decode.d2.loss_dice: 0.5744, decode.d3.loss_cls: 0.0800, decode.d3.loss_mask: 0.2618, decode.d3.loss_dice: 0.5702, decode.d4.loss_cls: 0.0541, decode.d4.loss_mask: 0.2639, decode.d4.loss_dice: 0.5853, decode.d5.loss_cls: 0.0687, decode.d5.loss_mask: 0.2636, decode.d5.loss_dice: 0.5852, decode.d6.loss_cls: 0.0718, decode.d6.loss_mask: 0.2619, decode.d6.loss_dice: 0.5854, decode.d7.loss_cls: 0.1073, decode.d7.loss_mask: 0.2590, decode.d7.loss_dice: 0.5694, decode.d8.loss_cls: 0.0852, decode.d8.loss_mask: 0.2596, decode.d8.loss_dice: 0.5711, loss: 9.3692
2023-09-28 19:07:12,209 - mmseg - INFO - Iter [13850/40000]	lr: 9.387e-07, eta: 19:25:49, time: 2.240, data_time: 0.030, memory: 21542, decode.loss_cls: 0.1235, decode.loss_mask: 0.2907, decode.loss_dice: 0.6322, decode.d0.loss_cls: 0.2308, decode.d0.loss_mask: 0.2922, decode.d0.loss_dice: 0.6391, decode.d1.loss_cls: 0.1573, decode.d1.loss_mask: 0.2880, decode.d1.loss_dice: 0.6212, decode.d2.loss_cls: 0.1290, decode.d2.loss_mask: 0.2890, decode.d2.loss_dice: 0.6283, decode.d3.loss_cls: 0.1266, decode.d3.loss_mask: 0.2870, decode.d3.loss_dice: 0.6171, decode.d4.loss_cls: 0.1286, decode.d4.loss_mask: 0.2880, decode.d4.loss_dice: 0.6387, decode.d5.loss_cls: 0.1334, decode.d5.loss_mask: 0.2928, decode.d5.loss_dice: 0.6305, decode.d6.loss_cls: 0.1208, decode.d6.loss_mask: 0.2894, decode.d6.loss_dice: 0.6261, decode.d7.loss_cls: 0.1267, decode.d7.loss_mask: 0.2886, decode.d7.loss_dice: 0.6286, decode.d8.loss_cls: 0.1476, decode.d8.loss_mask: 0.2887, decode.d8.loss_dice: 0.6250, loss: 10.6051
2023-09-28 19:09:03,403 - mmseg - INFO - Iter [13900/40000]	lr: 9.369e-07, eta: 19:22:53, time: 2.224, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0881, decode.loss_mask: 0.2517, decode.loss_dice: 0.5582, decode.d0.loss_cls: 0.2134, decode.d0.loss_mask: 0.2583, decode.d0.loss_dice: 0.5723, decode.d1.loss_cls: 0.0932, decode.d1.loss_mask: 0.2524, decode.d1.loss_dice: 0.5618, decode.d2.loss_cls: 0.0762, decode.d2.loss_mask: 0.2537, decode.d2.loss_dice: 0.5495, decode.d3.loss_cls: 0.0764, decode.d3.loss_mask: 0.2555, decode.d3.loss_dice: 0.5526, decode.d4.loss_cls: 0.1059, decode.d4.loss_mask: 0.2537, decode.d4.loss_dice: 0.5637, decode.d5.loss_cls: 0.0785, decode.d5.loss_mask: 0.2526, decode.d5.loss_dice: 0.5511, decode.d6.loss_cls: 0.0832, decode.d6.loss_mask: 0.2502, decode.d6.loss_dice: 0.5582, decode.d7.loss_cls: 0.0833, decode.d7.loss_mask: 0.2531, decode.d7.loss_dice: 0.5514, decode.d8.loss_cls: 0.0808, decode.d8.loss_mask: 0.2524, decode.d8.loss_dice: 0.5581, loss: 9.0897
2023-09-28 19:10:53,768 - mmseg - INFO - Iter [13950/40000]	lr: 9.351e-07, eta: 19:19:55, time: 2.207, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0819, decode.loss_mask: 0.2942, decode.loss_dice: 0.5673, decode.d0.loss_cls: 0.2288, decode.d0.loss_mask: 0.3035, decode.d0.loss_dice: 0.5791, decode.d1.loss_cls: 0.0796, decode.d1.loss_mask: 0.2965, decode.d1.loss_dice: 0.5655, decode.d2.loss_cls: 0.0881, decode.d2.loss_mask: 0.2952, decode.d2.loss_dice: 0.5639, decode.d3.loss_cls: 0.0612, decode.d3.loss_mask: 0.2957, decode.d3.loss_dice: 0.5691, decode.d4.loss_cls: 0.0465, decode.d4.loss_mask: 0.2971, decode.d4.loss_dice: 0.5725, decode.d5.loss_cls: 0.0649, decode.d5.loss_mask: 0.2964, decode.d5.loss_dice: 0.5651, decode.d6.loss_cls: 0.0805, decode.d6.loss_mask: 0.2963, decode.d6.loss_dice: 0.5734, decode.d7.loss_cls: 0.0800, decode.d7.loss_mask: 0.2956, decode.d7.loss_dice: 0.5568, decode.d8.loss_cls: 0.0754, decode.d8.loss_mask: 0.2962, decode.d8.loss_dice: 0.5603, loss: 9.5266
2023-09-28 19:12:44,965 - mmseg - INFO - Saving checkpoint at 14000 iterations
2023-09-28 19:13:04,561 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 19:13:04,562 - mmseg - INFO - Iter [14000/40000]	lr: 9.333e-07, eta: 19:17:37, time: 2.616, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0509, decode.loss_mask: 0.2863, decode.loss_dice: 0.5591, decode.d0.loss_cls: 0.2230, decode.d0.loss_mask: 0.2919, decode.d0.loss_dice: 0.5663, decode.d1.loss_cls: 0.0696, decode.d1.loss_mask: 0.2885, decode.d1.loss_dice: 0.5598, decode.d2.loss_cls: 0.0751, decode.d2.loss_mask: 0.2902, decode.d2.loss_dice: 0.5740, decode.d3.loss_cls: 0.0543, decode.d3.loss_mask: 0.2865, decode.d3.loss_dice: 0.5714, decode.d4.loss_cls: 0.0539, decode.d4.loss_mask: 0.2903, decode.d4.loss_dice: 0.5779, decode.d5.loss_cls: 0.0522, decode.d5.loss_mask: 0.2897, decode.d5.loss_dice: 0.5702, decode.d6.loss_cls: 0.0603, decode.d6.loss_mask: 0.2868, decode.d6.loss_dice: 0.5686, decode.d7.loss_cls: 0.0611, decode.d7.loss_mask: 0.2856, decode.d7.loss_dice: 0.5698, decode.d8.loss_cls: 0.0552, decode.d8.loss_mask: 0.2872, decode.d8.loss_dice: 0.5608, loss: 9.3168
2023-09-28 19:30:05,006 - mmseg - INFO - per class results:
2023-09-28 19:30:05,008 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     |  92.8 | 96.86 |
|    Sidewalk   | 69.43 | 84.79 |
|  Construction | 82.04 | 94.07 |
|     Fence     | 33.25 | 37.13 |
|      Pole     | 55.99 | 71.89 |
| Traffic Light | 67.54 | 81.31 |
|  Traffic Sign | 72.09 | 82.49 |
|     Nature    | 88.54 | 93.39 |
|      Sky      | 96.61 | 97.99 |
|     Person    | 39.66 | 44.87 |
|     Rider     | 10.63 | 74.64 |
|      Car      | 91.77 |  95.7 |
|   background  | 96.08 | 97.51 |
+---------------+-------+-------+
2023-09-28 19:30:05,008 - mmseg - INFO - Summary:
2023-09-28 19:30:05,009 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.42 | 68.96 | 80.97 |
+-------+-------+-------+
2023-09-28 19:30:06,129 - mmseg - INFO - The previous best checkpoint /raid/hyundai/ViT-Adapter/segmentation/work_dirs/vit_13/best_mIoU_iter_10000.pth was removed
2023-09-28 19:30:25,603 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_14000.pth.
2023-09-28 19:30:25,604 - mmseg - INFO - Best mIoU is 0.6896 at 14000 iter.
2023-09-28 19:30:25,606 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 19:30:25,606 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9442, mIoU: 0.6896, mAcc: 0.8097, IoU.Road: 0.9280, IoU.Sidewalk: 0.6943, IoU.Construction: 0.8204, IoU.Fence: 0.3325, IoU.Pole: 0.5599, IoU.Traffic Light: 0.6754, IoU.Traffic Sign: 0.7209, IoU.Nature: 0.8854, IoU.Sky: 0.9661, IoU.Person: 0.3966, IoU.Rider: 0.1063, IoU.Car: 0.9177, IoU.background: 0.9608, Acc.Road: 0.9686, Acc.Sidewalk: 0.8479, Acc.Construction: 0.9407, Acc.Fence: 0.3713, Acc.Pole: 0.7189, Acc.Traffic Light: 0.8131, Acc.Traffic Sign: 0.8249, Acc.Nature: 0.9339, Acc.Sky: 0.9799, Acc.Person: 0.4487, Acc.Rider: 0.7464, Acc.Car: 0.9570, Acc.background: 0.9751
2023-09-28 19:32:24,117 - mmseg - INFO - Iter [14050/40000]	lr: 9.315e-07, eta: 19:46:58, time: 23.191, data_time: 20.852, memory: 21542, decode.loss_cls: 0.1034, decode.loss_mask: 0.2905, decode.loss_dice: 0.5758, decode.d0.loss_cls: 0.2423, decode.d0.loss_mask: 0.2929, decode.d0.loss_dice: 0.5897, decode.d1.loss_cls: 0.1309, decode.d1.loss_mask: 0.2904, decode.d1.loss_dice: 0.5867, decode.d2.loss_cls: 0.0871, decode.d2.loss_mask: 0.2889, decode.d2.loss_dice: 0.5918, decode.d3.loss_cls: 0.0906, decode.d3.loss_mask: 0.2878, decode.d3.loss_dice: 0.5810, decode.d4.loss_cls: 0.1024, decode.d4.loss_mask: 0.2896, decode.d4.loss_dice: 0.5836, decode.d5.loss_cls: 0.0769, decode.d5.loss_mask: 0.2895, decode.d5.loss_dice: 0.5801, decode.d6.loss_cls: 0.0953, decode.d6.loss_mask: 0.2900, decode.d6.loss_dice: 0.5805, decode.d7.loss_cls: 0.0919, decode.d7.loss_mask: 0.2900, decode.d7.loss_dice: 0.5831, decode.d8.loss_cls: 0.0885, decode.d8.loss_mask: 0.2889, decode.d8.loss_dice: 0.5852, loss: 9.8452
2023-09-28 19:34:15,136 - mmseg - INFO - Iter [14100/40000]	lr: 9.297e-07, eta: 19:43:53, time: 2.220, data_time: 0.035, memory: 21542, decode.loss_cls: 0.1042, decode.loss_mask: 0.3105, decode.loss_dice: 0.6082, decode.d0.loss_cls: 0.2567, decode.d0.loss_mask: 0.3160, decode.d0.loss_dice: 0.6110, decode.d1.loss_cls: 0.1267, decode.d1.loss_mask: 0.3139, decode.d1.loss_dice: 0.6036, decode.d2.loss_cls: 0.1223, decode.d2.loss_mask: 0.3101, decode.d2.loss_dice: 0.6054, decode.d3.loss_cls: 0.1130, decode.d3.loss_mask: 0.3105, decode.d3.loss_dice: 0.6026, decode.d4.loss_cls: 0.1212, decode.d4.loss_mask: 0.3024, decode.d4.loss_dice: 0.6105, decode.d5.loss_cls: 0.1323, decode.d5.loss_mask: 0.3085, decode.d5.loss_dice: 0.6065, decode.d6.loss_cls: 0.1081, decode.d6.loss_mask: 0.3100, decode.d6.loss_dice: 0.6018, decode.d7.loss_cls: 0.0977, decode.d7.loss_mask: 0.3096, decode.d7.loss_dice: 0.6016, decode.d8.loss_cls: 0.1158, decode.d8.loss_mask: 0.3093, decode.d8.loss_dice: 0.6065, loss: 10.4565
2023-09-28 19:36:11,496 - mmseg - INFO - Iter [14150/40000]	lr: 9.279e-07, eta: 19:40:57, time: 2.327, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0905, decode.loss_mask: 0.2927, decode.loss_dice: 0.6168, decode.d0.loss_cls: 0.2343, decode.d0.loss_mask: 0.2959, decode.d0.loss_dice: 0.6286, decode.d1.loss_cls: 0.0736, decode.d1.loss_mask: 0.2937, decode.d1.loss_dice: 0.6188, decode.d2.loss_cls: 0.0775, decode.d2.loss_mask: 0.2932, decode.d2.loss_dice: 0.6122, decode.d3.loss_cls: 0.0864, decode.d3.loss_mask: 0.2926, decode.d3.loss_dice: 0.6241, decode.d4.loss_cls: 0.0670, decode.d4.loss_mask: 0.2927, decode.d4.loss_dice: 0.6196, decode.d5.loss_cls: 0.0783, decode.d5.loss_mask: 0.2917, decode.d5.loss_dice: 0.6134, decode.d6.loss_cls: 0.0689, decode.d6.loss_mask: 0.2918, decode.d6.loss_dice: 0.6105, decode.d7.loss_cls: 0.0672, decode.d7.loss_mask: 0.2936, decode.d7.loss_dice: 0.6161, decode.d8.loss_cls: 0.0644, decode.d8.loss_mask: 0.2943, decode.d8.loss_dice: 0.6153, loss: 10.0158
2023-09-28 19:38:06,023 - mmseg - INFO - Iter [14200/40000]	lr: 9.261e-07, eta: 19:38:00, time: 2.291, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0862, decode.loss_mask: 0.3073, decode.loss_dice: 0.5949, decode.d0.loss_cls: 0.2544, decode.d0.loss_mask: 0.3128, decode.d0.loss_dice: 0.6089, decode.d1.loss_cls: 0.0808, decode.d1.loss_mask: 0.3104, decode.d1.loss_dice: 0.5911, decode.d2.loss_cls: 0.0893, decode.d2.loss_mask: 0.3108, decode.d2.loss_dice: 0.5919, decode.d3.loss_cls: 0.0708, decode.d3.loss_mask: 0.3061, decode.d3.loss_dice: 0.5893, decode.d4.loss_cls: 0.0705, decode.d4.loss_mask: 0.3110, decode.d4.loss_dice: 0.5987, decode.d5.loss_cls: 0.0831, decode.d5.loss_mask: 0.3065, decode.d5.loss_dice: 0.5962, decode.d6.loss_cls: 0.0696, decode.d6.loss_mask: 0.3038, decode.d6.loss_dice: 0.5918, decode.d7.loss_cls: 0.0722, decode.d7.loss_mask: 0.3019, decode.d7.loss_dice: 0.5977, decode.d8.loss_cls: 0.0833, decode.d8.loss_mask: 0.3009, decode.d8.loss_dice: 0.5956, loss: 9.9878
2023-09-28 19:39:58,070 - mmseg - INFO - Iter [14250/40000]	lr: 9.243e-07, eta: 19:34:57, time: 2.241, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0731, decode.loss_mask: 0.2663, decode.loss_dice: 0.5508, decode.d0.loss_cls: 0.2598, decode.d0.loss_mask: 0.2671, decode.d0.loss_dice: 0.5583, decode.d1.loss_cls: 0.0843, decode.d1.loss_mask: 0.2634, decode.d1.loss_dice: 0.5526, decode.d2.loss_cls: 0.0894, decode.d2.loss_mask: 0.2656, decode.d2.loss_dice: 0.5555, decode.d3.loss_cls: 0.0899, decode.d3.loss_mask: 0.2661, decode.d3.loss_dice: 0.5552, decode.d4.loss_cls: 0.0679, decode.d4.loss_mask: 0.2671, decode.d4.loss_dice: 0.5620, decode.d5.loss_cls: 0.0698, decode.d5.loss_mask: 0.2653, decode.d5.loss_dice: 0.5583, decode.d6.loss_cls: 0.0688, decode.d6.loss_mask: 0.2658, decode.d6.loss_dice: 0.5557, decode.d7.loss_cls: 0.0773, decode.d7.loss_mask: 0.2662, decode.d7.loss_dice: 0.5543, decode.d8.loss_cls: 0.0717, decode.d8.loss_mask: 0.2675, decode.d8.loss_dice: 0.5600, loss: 9.1754
2023-09-28 19:41:52,547 - mmseg - INFO - Iter [14300/40000]	lr: 9.225e-07, eta: 19:32:00, time: 2.290, data_time: 0.081, memory: 21542, decode.loss_cls: 0.0838, decode.loss_mask: 0.3078, decode.loss_dice: 0.5918, decode.d0.loss_cls: 0.2449, decode.d0.loss_mask: 0.3130, decode.d0.loss_dice: 0.5903, decode.d1.loss_cls: 0.1076, decode.d1.loss_mask: 0.3090, decode.d1.loss_dice: 0.5988, decode.d2.loss_cls: 0.0998, decode.d2.loss_mask: 0.3094, decode.d2.loss_dice: 0.5950, decode.d3.loss_cls: 0.0777, decode.d3.loss_mask: 0.3092, decode.d3.loss_dice: 0.5949, decode.d4.loss_cls: 0.0924, decode.d4.loss_mask: 0.3093, decode.d4.loss_dice: 0.6086, decode.d5.loss_cls: 0.0903, decode.d5.loss_mask: 0.3088, decode.d5.loss_dice: 0.5948, decode.d6.loss_cls: 0.0813, decode.d6.loss_mask: 0.3093, decode.d6.loss_dice: 0.5962, decode.d7.loss_cls: 0.0966, decode.d7.loss_mask: 0.3086, decode.d7.loss_dice: 0.5986, decode.d8.loss_cls: 0.0915, decode.d8.loss_mask: 0.3080, decode.d8.loss_dice: 0.5992, loss: 10.1267
2023-09-28 19:44:01,314 - mmseg - INFO - Iter [14350/40000]	lr: 9.207e-07, eta: 19:29:29, time: 2.575, data_time: 0.043, memory: 21542, decode.loss_cls: 0.0777, decode.loss_mask: 0.2709, decode.loss_dice: 0.5892, decode.d0.loss_cls: 0.2432, decode.d0.loss_mask: 0.2851, decode.d0.loss_dice: 0.6005, decode.d1.loss_cls: 0.0851, decode.d1.loss_mask: 0.2749, decode.d1.loss_dice: 0.5807, decode.d2.loss_cls: 0.0906, decode.d2.loss_mask: 0.2819, decode.d2.loss_dice: 0.5854, decode.d3.loss_cls: 0.0867, decode.d3.loss_mask: 0.2772, decode.d3.loss_dice: 0.5883, decode.d4.loss_cls: 0.1012, decode.d4.loss_mask: 0.2801, decode.d4.loss_dice: 0.5904, decode.d5.loss_cls: 0.1053, decode.d5.loss_mask: 0.2783, decode.d5.loss_dice: 0.5862, decode.d6.loss_cls: 0.1145, decode.d6.loss_mask: 0.2694, decode.d6.loss_dice: 0.5779, decode.d7.loss_cls: 0.1041, decode.d7.loss_mask: 0.2720, decode.d7.loss_dice: 0.5781, decode.d8.loss_cls: 0.1015, decode.d8.loss_mask: 0.2718, decode.d8.loss_dice: 0.5850, loss: 9.7333
2023-09-28 19:46:21,461 - mmseg - INFO - Iter [14400/40000]	lr: 9.189e-07, eta: 19:27:18, time: 2.803, data_time: 0.048, memory: 21542, decode.loss_cls: 0.0889, decode.loss_mask: 0.2775, decode.loss_dice: 0.6337, decode.d0.loss_cls: 0.2406, decode.d0.loss_mask: 0.2759, decode.d0.loss_dice: 0.6489, decode.d1.loss_cls: 0.1103, decode.d1.loss_mask: 0.2785, decode.d1.loss_dice: 0.6351, decode.d2.loss_cls: 0.1033, decode.d2.loss_mask: 0.2779, decode.d2.loss_dice: 0.6288, decode.d3.loss_cls: 0.1248, decode.d3.loss_mask: 0.2762, decode.d3.loss_dice: 0.6334, decode.d4.loss_cls: 0.1153, decode.d4.loss_mask: 0.2766, decode.d4.loss_dice: 0.6325, decode.d5.loss_cls: 0.0873, decode.d5.loss_mask: 0.2783, decode.d5.loss_dice: 0.6419, decode.d6.loss_cls: 0.0858, decode.d6.loss_mask: 0.2782, decode.d6.loss_dice: 0.6275, decode.d7.loss_cls: 0.0985, decode.d7.loss_mask: 0.2774, decode.d7.loss_dice: 0.6268, decode.d8.loss_cls: 0.1052, decode.d8.loss_mask: 0.2779, decode.d8.loss_dice: 0.6191, loss: 10.2622
2023-09-28 19:48:12,921 - mmseg - INFO - Iter [14450/40000]	lr: 9.172e-07, eta: 19:24:17, time: 2.229, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0669, decode.loss_mask: 0.2859, decode.loss_dice: 0.5842, decode.d0.loss_cls: 0.2225, decode.d0.loss_mask: 0.2877, decode.d0.loss_dice: 0.6012, decode.d1.loss_cls: 0.1039, decode.d1.loss_mask: 0.2869, decode.d1.loss_dice: 0.6043, decode.d2.loss_cls: 0.0824, decode.d2.loss_mask: 0.2855, decode.d2.loss_dice: 0.5894, decode.d3.loss_cls: 0.0806, decode.d3.loss_mask: 0.2875, decode.d3.loss_dice: 0.5869, decode.d4.loss_cls: 0.0848, decode.d4.loss_mask: 0.2846, decode.d4.loss_dice: 0.5923, decode.d5.loss_cls: 0.0690, decode.d5.loss_mask: 0.2857, decode.d5.loss_dice: 0.5993, decode.d6.loss_cls: 0.0674, decode.d6.loss_mask: 0.2864, decode.d6.loss_dice: 0.5941, decode.d7.loss_cls: 0.0659, decode.d7.loss_mask: 0.2858, decode.d7.loss_dice: 0.5950, decode.d8.loss_cls: 0.0824, decode.d8.loss_mask: 0.2875, decode.d8.loss_dice: 0.5944, loss: 9.7307
2023-09-28 19:50:17,393 - mmseg - INFO - Iter [14500/40000]	lr: 9.154e-07, eta: 19:21:39, time: 2.489, data_time: 0.038, memory: 21542, decode.loss_cls: 0.1226, decode.loss_mask: 0.2923, decode.loss_dice: 0.6281, decode.d0.loss_cls: 0.2292, decode.d0.loss_mask: 0.2950, decode.d0.loss_dice: 0.6552, decode.d1.loss_cls: 0.1173, decode.d1.loss_mask: 0.2931, decode.d1.loss_dice: 0.6357, decode.d2.loss_cls: 0.1276, decode.d2.loss_mask: 0.2948, decode.d2.loss_dice: 0.6202, decode.d3.loss_cls: 0.0962, decode.d3.loss_mask: 0.2943, decode.d3.loss_dice: 0.6232, decode.d4.loss_cls: 0.1089, decode.d4.loss_mask: 0.2933, decode.d4.loss_dice: 0.6429, decode.d5.loss_cls: 0.1030, decode.d5.loss_mask: 0.2943, decode.d5.loss_dice: 0.6294, decode.d6.loss_cls: 0.0920, decode.d6.loss_mask: 0.2947, decode.d6.loss_dice: 0.6306, decode.d7.loss_cls: 0.1010, decode.d7.loss_mask: 0.2950, decode.d7.loss_dice: 0.6439, decode.d8.loss_cls: 0.1108, decode.d8.loss_mask: 0.2955, decode.d8.loss_dice: 0.6363, loss: 10.4966
2023-09-28 19:53:17,943 - mmseg - INFO - Iter [14550/40000]	lr: 9.136e-07, eta: 19:20:38, time: 3.609, data_time: 0.067, memory: 21542, decode.loss_cls: 0.0777, decode.loss_mask: 0.2658, decode.loss_dice: 0.6077, decode.d0.loss_cls: 0.2423, decode.d0.loss_mask: 0.2664, decode.d0.loss_dice: 0.6006, decode.d1.loss_cls: 0.0954, decode.d1.loss_mask: 0.2673, decode.d1.loss_dice: 0.5987, decode.d2.loss_cls: 0.0622, decode.d2.loss_mask: 0.2674, decode.d2.loss_dice: 0.5874, decode.d3.loss_cls: 0.0593, decode.d3.loss_mask: 0.2674, decode.d3.loss_dice: 0.5937, decode.d4.loss_cls: 0.0663, decode.d4.loss_mask: 0.2662, decode.d4.loss_dice: 0.5881, decode.d5.loss_cls: 0.0726, decode.d5.loss_mask: 0.2670, decode.d5.loss_dice: 0.5983, decode.d6.loss_cls: 0.0503, decode.d6.loss_mask: 0.2680, decode.d6.loss_dice: 0.5910, decode.d7.loss_cls: 0.0538, decode.d7.loss_mask: 0.2671, decode.d7.loss_dice: 0.5906, decode.d8.loss_cls: 0.0665, decode.d8.loss_mask: 0.2671, decode.d8.loss_dice: 0.5850, loss: 9.4573
2023-09-28 19:56:11,919 - mmseg - INFO - Iter [14600/40000]	lr: 9.118e-07, eta: 19:19:26, time: 3.481, data_time: 0.075, memory: 21542, decode.loss_cls: 0.0617, decode.loss_mask: 0.2890, decode.loss_dice: 0.5637, decode.d0.loss_cls: 0.2044, decode.d0.loss_mask: 0.2930, decode.d0.loss_dice: 0.5823, decode.d1.loss_cls: 0.0769, decode.d1.loss_mask: 0.2902, decode.d1.loss_dice: 0.5660, decode.d2.loss_cls: 0.0834, decode.d2.loss_mask: 0.2898, decode.d2.loss_dice: 0.5617, decode.d3.loss_cls: 0.0764, decode.d3.loss_mask: 0.2887, decode.d3.loss_dice: 0.5668, decode.d4.loss_cls: 0.0825, decode.d4.loss_mask: 0.2901, decode.d4.loss_dice: 0.5645, decode.d5.loss_cls: 0.0794, decode.d5.loss_mask: 0.2885, decode.d5.loss_dice: 0.5638, decode.d6.loss_cls: 0.0681, decode.d6.loss_mask: 0.2866, decode.d6.loss_dice: 0.5554, decode.d7.loss_cls: 0.0777, decode.d7.loss_mask: 0.2875, decode.d7.loss_dice: 0.5617, decode.d8.loss_cls: 0.0704, decode.d8.loss_mask: 0.2886, decode.d8.loss_dice: 0.5618, loss: 9.4207
2023-09-28 19:59:14,998 - mmseg - INFO - Iter [14650/40000]	lr: 9.100e-07, eta: 19:18:29, time: 3.663, data_time: 0.076, memory: 21542, decode.loss_cls: 0.0770, decode.loss_mask: 0.3152, decode.loss_dice: 0.5979, decode.d0.loss_cls: 0.2278, decode.d0.loss_mask: 0.3213, decode.d0.loss_dice: 0.6184, decode.d1.loss_cls: 0.0930, decode.d1.loss_mask: 0.3157, decode.d1.loss_dice: 0.6112, decode.d2.loss_cls: 0.0879, decode.d2.loss_mask: 0.3172, decode.d2.loss_dice: 0.6124, decode.d3.loss_cls: 0.1274, decode.d3.loss_mask: 0.3167, decode.d3.loss_dice: 0.6064, decode.d4.loss_cls: 0.0833, decode.d4.loss_mask: 0.3168, decode.d4.loss_dice: 0.6102, decode.d5.loss_cls: 0.0753, decode.d5.loss_mask: 0.3155, decode.d5.loss_dice: 0.6154, decode.d6.loss_cls: 0.0761, decode.d6.loss_mask: 0.3148, decode.d6.loss_dice: 0.5931, decode.d7.loss_cls: 0.0956, decode.d7.loss_mask: 0.3177, decode.d7.loss_dice: 0.6118, decode.d8.loss_cls: 0.0941, decode.d8.loss_mask: 0.3156, decode.d8.loss_dice: 0.6092, loss: 10.2901
2023-09-28 20:02:27,451 - mmseg - INFO - Iter [14700/40000]	lr: 9.082e-07, eta: 19:17:47, time: 3.847, data_time: 0.077, memory: 21542, decode.loss_cls: 0.0565, decode.loss_mask: 0.2744, decode.loss_dice: 0.5283, decode.d0.loss_cls: 0.2310, decode.d0.loss_mask: 0.2786, decode.d0.loss_dice: 0.5342, decode.d1.loss_cls: 0.0575, decode.d1.loss_mask: 0.2758, decode.d1.loss_dice: 0.5306, decode.d2.loss_cls: 0.0772, decode.d2.loss_mask: 0.2744, decode.d2.loss_dice: 0.5312, decode.d3.loss_cls: 0.0598, decode.d3.loss_mask: 0.2745, decode.d3.loss_dice: 0.5269, decode.d4.loss_cls: 0.0645, decode.d4.loss_mask: 0.2734, decode.d4.loss_dice: 0.5352, decode.d5.loss_cls: 0.0666, decode.d5.loss_mask: 0.2720, decode.d5.loss_dice: 0.5352, decode.d6.loss_cls: 0.0609, decode.d6.loss_mask: 0.2730, decode.d6.loss_dice: 0.5401, decode.d7.loss_cls: 0.0453, decode.d7.loss_mask: 0.2736, decode.d7.loss_dice: 0.5345, decode.d8.loss_cls: 0.0501, decode.d8.loss_mask: 0.2749, decode.d8.loss_dice: 0.5246, loss: 8.8347
2023-09-28 20:05:26,496 - mmseg - INFO - Iter [14750/40000]	lr: 9.064e-07, eta: 19:16:42, time: 3.582, data_time: 0.072, memory: 21542, decode.loss_cls: 0.0928, decode.loss_mask: 0.3112, decode.loss_dice: 0.6055, decode.d0.loss_cls: 0.2768, decode.d0.loss_mask: 0.3217, decode.d0.loss_dice: 0.5982, decode.d1.loss_cls: 0.1454, decode.d1.loss_mask: 0.3130, decode.d1.loss_dice: 0.6115, decode.d2.loss_cls: 0.1280, decode.d2.loss_mask: 0.3101, decode.d2.loss_dice: 0.6058, decode.d3.loss_cls: 0.1172, decode.d3.loss_mask: 0.3123, decode.d3.loss_dice: 0.6083, decode.d4.loss_cls: 0.1112, decode.d4.loss_mask: 0.3118, decode.d4.loss_dice: 0.6034, decode.d5.loss_cls: 0.1272, decode.d5.loss_mask: 0.3103, decode.d5.loss_dice: 0.5957, decode.d6.loss_cls: 0.1127, decode.d6.loss_mask: 0.3083, decode.d6.loss_dice: 0.6011, decode.d7.loss_cls: 0.1200, decode.d7.loss_mask: 0.3130, decode.d7.loss_dice: 0.6141, decode.d8.loss_cls: 0.1167, decode.d8.loss_mask: 0.3100, decode.d8.loss_dice: 0.5994, loss: 10.5126
2023-09-28 20:08:24,842 - mmseg - INFO - Iter [14800/40000]	lr: 9.046e-07, eta: 19:15:34, time: 3.566, data_time: 0.076, memory: 21542, decode.loss_cls: 0.0581, decode.loss_mask: 0.2781, decode.loss_dice: 0.5937, decode.d0.loss_cls: 0.2245, decode.d0.loss_mask: 0.2843, decode.d0.loss_dice: 0.5940, decode.d1.loss_cls: 0.0649, decode.d1.loss_mask: 0.2786, decode.d1.loss_dice: 0.5833, decode.d2.loss_cls: 0.0491, decode.d2.loss_mask: 0.2781, decode.d2.loss_dice: 0.5924, decode.d3.loss_cls: 0.0685, decode.d3.loss_mask: 0.2791, decode.d3.loss_dice: 0.5910, decode.d4.loss_cls: 0.0620, decode.d4.loss_mask: 0.2778, decode.d4.loss_dice: 0.5850, decode.d5.loss_cls: 0.0479, decode.d5.loss_mask: 0.2788, decode.d5.loss_dice: 0.5913, decode.d6.loss_cls: 0.0727, decode.d6.loss_mask: 0.2796, decode.d6.loss_dice: 0.5912, decode.d7.loss_cls: 0.0449, decode.d7.loss_mask: 0.2791, decode.d7.loss_dice: 0.5843, decode.d8.loss_cls: 0.0528, decode.d8.loss_mask: 0.2782, decode.d8.loss_dice: 0.5861, loss: 9.4291
2023-09-28 20:11:36,162 - mmseg - INFO - Iter [14850/40000]	lr: 9.028e-07, eta: 19:14:47, time: 3.827, data_time: 0.079, memory: 21542, decode.loss_cls: 0.0618, decode.loss_mask: 0.2963, decode.loss_dice: 0.5731, decode.d0.loss_cls: 0.2178, decode.d0.loss_mask: 0.2988, decode.d0.loss_dice: 0.5857, decode.d1.loss_cls: 0.0811, decode.d1.loss_mask: 0.2946, decode.d1.loss_dice: 0.5855, decode.d2.loss_cls: 0.0980, decode.d2.loss_mask: 0.2924, decode.d2.loss_dice: 0.5785, decode.d3.loss_cls: 0.0872, decode.d3.loss_mask: 0.2958, decode.d3.loss_dice: 0.5776, decode.d4.loss_cls: 0.0808, decode.d4.loss_mask: 0.2943, decode.d4.loss_dice: 0.5862, decode.d5.loss_cls: 0.0543, decode.d5.loss_mask: 0.2957, decode.d5.loss_dice: 0.5810, decode.d6.loss_cls: 0.0584, decode.d6.loss_mask: 0.2956, decode.d6.loss_dice: 0.5797, decode.d7.loss_cls: 0.0469, decode.d7.loss_mask: 0.2957, decode.d7.loss_dice: 0.5806, decode.d8.loss_cls: 0.0695, decode.d8.loss_mask: 0.2938, decode.d8.loss_dice: 0.5768, loss: 9.6136
2023-09-28 20:14:42,911 - mmseg - INFO - Iter [14900/40000]	lr: 9.010e-07, eta: 19:13:52, time: 3.734, data_time: 0.080, memory: 21542, decode.loss_cls: 0.0909, decode.loss_mask: 0.2923, decode.loss_dice: 0.6141, decode.d0.loss_cls: 0.2346, decode.d0.loss_mask: 0.2925, decode.d0.loss_dice: 0.6254, decode.d1.loss_cls: 0.0970, decode.d1.loss_mask: 0.2909, decode.d1.loss_dice: 0.6134, decode.d2.loss_cls: 0.0827, decode.d2.loss_mask: 0.2921, decode.d2.loss_dice: 0.6204, decode.d3.loss_cls: 0.0671, decode.d3.loss_mask: 0.2933, decode.d3.loss_dice: 0.6244, decode.d4.loss_cls: 0.0792, decode.d4.loss_mask: 0.2940, decode.d4.loss_dice: 0.6297, decode.d5.loss_cls: 0.0809, decode.d5.loss_mask: 0.2895, decode.d5.loss_dice: 0.6259, decode.d6.loss_cls: 0.0763, decode.d6.loss_mask: 0.2921, decode.d6.loss_dice: 0.6153, decode.d7.loss_cls: 0.0841, decode.d7.loss_mask: 0.2897, decode.d7.loss_dice: 0.6090, decode.d8.loss_cls: 0.0675, decode.d8.loss_mask: 0.2940, decode.d8.loss_dice: 0.6135, loss: 10.0718
2023-09-28 20:17:42,717 - mmseg - INFO - Iter [14950/40000]	lr: 8.992e-07, eta: 19:12:44, time: 3.597, data_time: 0.077, memory: 21542, decode.loss_cls: 0.0649, decode.loss_mask: 0.2757, decode.loss_dice: 0.5775, decode.d0.loss_cls: 0.2174, decode.d0.loss_mask: 0.2778, decode.d0.loss_dice: 0.5834, decode.d1.loss_cls: 0.0972, decode.d1.loss_mask: 0.2766, decode.d1.loss_dice: 0.5935, decode.d2.loss_cls: 0.0782, decode.d2.loss_mask: 0.2754, decode.d2.loss_dice: 0.5847, decode.d3.loss_cls: 0.0626, decode.d3.loss_mask: 0.2752, decode.d3.loss_dice: 0.5814, decode.d4.loss_cls: 0.0698, decode.d4.loss_mask: 0.2759, decode.d4.loss_dice: 0.5759, decode.d5.loss_cls: 0.0838, decode.d5.loss_mask: 0.2758, decode.d5.loss_dice: 0.5857, decode.d6.loss_cls: 0.0677, decode.d6.loss_mask: 0.2752, decode.d6.loss_dice: 0.5814, decode.d7.loss_cls: 0.0580, decode.d7.loss_mask: 0.2751, decode.d7.loss_dice: 0.5785, decode.d8.loss_cls: 0.0736, decode.d8.loss_mask: 0.2767, decode.d8.loss_dice: 0.5793, loss: 9.4540
2023-09-28 20:20:44,411 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 20:20:44,415 - mmseg - INFO - Iter [15000/40000]	lr: 8.974e-07, eta: 19:11:39, time: 3.633, data_time: 0.074, memory: 21542, decode.loss_cls: 0.0932, decode.loss_mask: 0.2697, decode.loss_dice: 0.5673, decode.d0.loss_cls: 0.2407, decode.d0.loss_mask: 0.2786, decode.d0.loss_dice: 0.5791, decode.d1.loss_cls: 0.1136, decode.d1.loss_mask: 0.2695, decode.d1.loss_dice: 0.5555, decode.d2.loss_cls: 0.0966, decode.d2.loss_mask: 0.2690, decode.d2.loss_dice: 0.5688, decode.d3.loss_cls: 0.0869, decode.d3.loss_mask: 0.2755, decode.d3.loss_dice: 0.5843, decode.d4.loss_cls: 0.0941, decode.d4.loss_mask: 0.2755, decode.d4.loss_dice: 0.5667, decode.d5.loss_cls: 0.0978, decode.d5.loss_mask: 0.2716, decode.d5.loss_dice: 0.5834, decode.d6.loss_cls: 0.1041, decode.d6.loss_mask: 0.2721, decode.d6.loss_dice: 0.5886, decode.d7.loss_cls: 0.0954, decode.d7.loss_mask: 0.2778, decode.d7.loss_dice: 0.5752, decode.d8.loss_cls: 0.0859, decode.d8.loss_mask: 0.2784, decode.d8.loss_dice: 0.5723, loss: 9.5872
2023-09-28 20:24:00,786 - mmseg - INFO - Iter [15050/40000]	lr: 8.956e-07, eta: 19:10:57, time: 3.928, data_time: 0.082, memory: 21542, decode.loss_cls: 0.0695, decode.loss_mask: 0.3115, decode.loss_dice: 0.6238, decode.d0.loss_cls: 0.2547, decode.d0.loss_mask: 0.3183, decode.d0.loss_dice: 0.6466, decode.d1.loss_cls: 0.1144, decode.d1.loss_mask: 0.2988, decode.d1.loss_dice: 0.6139, decode.d2.loss_cls: 0.1271, decode.d2.loss_mask: 0.2945, decode.d2.loss_dice: 0.6282, decode.d3.loss_cls: 0.0785, decode.d3.loss_mask: 0.3087, decode.d3.loss_dice: 0.6180, decode.d4.loss_cls: 0.0860, decode.d4.loss_mask: 0.3103, decode.d4.loss_dice: 0.6283, decode.d5.loss_cls: 0.0823, decode.d5.loss_mask: 0.3113, decode.d5.loss_dice: 0.6217, decode.d6.loss_cls: 0.1023, decode.d6.loss_mask: 0.3131, decode.d6.loss_dice: 0.6199, decode.d7.loss_cls: 0.0713, decode.d7.loss_mask: 0.3109, decode.d7.loss_dice: 0.6220, decode.d8.loss_cls: 0.0753, decode.d8.loss_mask: 0.3102, decode.d8.loss_dice: 0.6250, loss: 10.3965
2023-09-28 20:27:01,603 - mmseg - INFO - Iter [15100/40000]	lr: 8.938e-07, eta: 19:09:49, time: 3.616, data_time: 0.072, memory: 21542, decode.loss_cls: 0.0828, decode.loss_mask: 0.2980, decode.loss_dice: 0.5468, decode.d0.loss_cls: 0.2360, decode.d0.loss_mask: 0.3012, decode.d0.loss_dice: 0.5594, decode.d1.loss_cls: 0.0868, decode.d1.loss_mask: 0.2987, decode.d1.loss_dice: 0.5515, decode.d2.loss_cls: 0.0891, decode.d2.loss_mask: 0.2964, decode.d2.loss_dice: 0.5433, decode.d3.loss_cls: 0.0918, decode.d3.loss_mask: 0.2963, decode.d3.loss_dice: 0.5597, decode.d4.loss_cls: 0.1097, decode.d4.loss_mask: 0.2950, decode.d4.loss_dice: 0.5527, decode.d5.loss_cls: 0.0705, decode.d5.loss_mask: 0.2962, decode.d5.loss_dice: 0.5591, decode.d6.loss_cls: 0.0849, decode.d6.loss_mask: 0.2998, decode.d6.loss_dice: 0.5481, decode.d7.loss_cls: 0.0859, decode.d7.loss_mask: 0.2981, decode.d7.loss_dice: 0.5473, decode.d8.loss_cls: 0.0804, decode.d8.loss_mask: 0.2980, decode.d8.loss_dice: 0.5523, loss: 9.5158
2023-09-28 20:30:03,475 - mmseg - INFO - Iter [15150/40000]	lr: 8.920e-07, eta: 19:08:41, time: 3.638, data_time: 0.076, memory: 21542, decode.loss_cls: 0.0529, decode.loss_mask: 0.2621, decode.loss_dice: 0.5775, decode.d0.loss_cls: 0.2146, decode.d0.loss_mask: 0.2663, decode.d0.loss_dice: 0.5871, decode.d1.loss_cls: 0.0716, decode.d1.loss_mask: 0.2607, decode.d1.loss_dice: 0.5741, decode.d2.loss_cls: 0.0630, decode.d2.loss_mask: 0.2619, decode.d2.loss_dice: 0.5709, decode.d3.loss_cls: 0.0743, decode.d3.loss_mask: 0.2617, decode.d3.loss_dice: 0.5736, decode.d4.loss_cls: 0.0719, decode.d4.loss_mask: 0.2623, decode.d4.loss_dice: 0.5690, decode.d5.loss_cls: 0.0774, decode.d5.loss_mask: 0.2621, decode.d5.loss_dice: 0.5727, decode.d6.loss_cls: 0.0724, decode.d6.loss_mask: 0.2620, decode.d6.loss_dice: 0.5703, decode.d7.loss_cls: 0.0564, decode.d7.loss_mask: 0.2615, decode.d7.loss_dice: 0.5732, decode.d8.loss_cls: 0.0664, decode.d8.loss_mask: 0.2620, decode.d8.loss_dice: 0.5794, loss: 9.1912
2023-09-28 20:33:09,643 - mmseg - INFO - Iter [15200/40000]	lr: 8.902e-07, eta: 19:07:40, time: 3.723, data_time: 0.079, memory: 21542, decode.loss_cls: 0.1041, decode.loss_mask: 0.2977, decode.loss_dice: 0.6248, decode.d0.loss_cls: 0.2100, decode.d0.loss_mask: 0.3072, decode.d0.loss_dice: 0.6306, decode.d1.loss_cls: 0.0956, decode.d1.loss_mask: 0.2974, decode.d1.loss_dice: 0.6174, decode.d2.loss_cls: 0.1037, decode.d2.loss_mask: 0.2978, decode.d2.loss_dice: 0.6169, decode.d3.loss_cls: 0.1163, decode.d3.loss_mask: 0.2965, decode.d3.loss_dice: 0.6195, decode.d4.loss_cls: 0.1062, decode.d4.loss_mask: 0.2996, decode.d4.loss_dice: 0.6146, decode.d5.loss_cls: 0.1103, decode.d5.loss_mask: 0.2994, decode.d5.loss_dice: 0.6159, decode.d6.loss_cls: 0.1208, decode.d6.loss_mask: 0.2992, decode.d6.loss_dice: 0.6178, decode.d7.loss_cls: 0.1161, decode.d7.loss_mask: 0.2982, decode.d7.loss_dice: 0.6200, decode.d8.loss_cls: 0.1112, decode.d8.loss_mask: 0.2989, decode.d8.loss_dice: 0.6190, loss: 10.3829
2023-09-28 20:36:19,615 - mmseg - INFO - Iter [15250/40000]	lr: 8.884e-07, eta: 19:06:44, time: 3.800, data_time: 0.072, memory: 21542, decode.loss_cls: 0.0852, decode.loss_mask: 0.3231, decode.loss_dice: 0.5888, decode.d0.loss_cls: 0.2453, decode.d0.loss_mask: 0.3348, decode.d0.loss_dice: 0.5989, decode.d1.loss_cls: 0.1137, decode.d1.loss_mask: 0.3237, decode.d1.loss_dice: 0.5973, decode.d2.loss_cls: 0.0955, decode.d2.loss_mask: 0.3253, decode.d2.loss_dice: 0.5985, decode.d3.loss_cls: 0.0869, decode.d3.loss_mask: 0.3226, decode.d3.loss_dice: 0.5867, decode.d4.loss_cls: 0.0841, decode.d4.loss_mask: 0.3234, decode.d4.loss_dice: 0.5999, decode.d5.loss_cls: 0.0997, decode.d5.loss_mask: 0.3230, decode.d5.loss_dice: 0.5993, decode.d6.loss_cls: 0.0838, decode.d6.loss_mask: 0.3237, decode.d6.loss_dice: 0.6063, decode.d7.loss_cls: 0.0772, decode.d7.loss_mask: 0.3239, decode.d7.loss_dice: 0.5985, decode.d8.loss_cls: 0.0838, decode.d8.loss_mask: 0.3218, decode.d8.loss_dice: 0.5905, loss: 10.2649
2023-09-28 20:39:15,419 - mmseg - INFO - Iter [15300/40000]	lr: 8.866e-07, eta: 19:05:25, time: 3.516, data_time: 0.070, memory: 21542, decode.loss_cls: 0.0888, decode.loss_mask: 0.3083, decode.loss_dice: 0.6207, decode.d0.loss_cls: 0.2369, decode.d0.loss_mask: 0.3200, decode.d0.loss_dice: 0.6470, decode.d1.loss_cls: 0.1106, decode.d1.loss_mask: 0.3109, decode.d1.loss_dice: 0.6335, decode.d2.loss_cls: 0.0891, decode.d2.loss_mask: 0.3115, decode.d2.loss_dice: 0.6202, decode.d3.loss_cls: 0.0967, decode.d3.loss_mask: 0.3113, decode.d3.loss_dice: 0.6261, decode.d4.loss_cls: 0.1018, decode.d4.loss_mask: 0.3099, decode.d4.loss_dice: 0.6324, decode.d5.loss_cls: 0.1036, decode.d5.loss_mask: 0.3089, decode.d5.loss_dice: 0.6233, decode.d6.loss_cls: 0.0818, decode.d6.loss_mask: 0.3074, decode.d6.loss_dice: 0.6232, decode.d7.loss_cls: 0.0780, decode.d7.loss_mask: 0.3066, decode.d7.loss_dice: 0.6240, decode.d8.loss_cls: 0.0818, decode.d8.loss_mask: 0.3104, decode.d8.loss_dice: 0.6270, loss: 10.4513
2023-09-28 20:42:16,437 - mmseg - INFO - Iter [15350/40000]	lr: 8.848e-07, eta: 19:04:13, time: 3.621, data_time: 0.064, memory: 21542, decode.loss_cls: 0.1239, decode.loss_mask: 0.3182, decode.loss_dice: 0.6414, decode.d0.loss_cls: 0.2639, decode.d0.loss_mask: 0.3233, decode.d0.loss_dice: 0.6591, decode.d1.loss_cls: 0.1192, decode.d1.loss_mask: 0.3220, decode.d1.loss_dice: 0.6455, decode.d2.loss_cls: 0.1087, decode.d2.loss_mask: 0.3199, decode.d2.loss_dice: 0.6507, decode.d3.loss_cls: 0.1178, decode.d3.loss_mask: 0.3170, decode.d3.loss_dice: 0.6546, decode.d4.loss_cls: 0.1300, decode.d4.loss_mask: 0.3197, decode.d4.loss_dice: 0.6539, decode.d5.loss_cls: 0.1373, decode.d5.loss_mask: 0.3194, decode.d5.loss_dice: 0.6435, decode.d6.loss_cls: 0.1408, decode.d6.loss_mask: 0.3200, decode.d6.loss_dice: 0.6471, decode.d7.loss_cls: 0.1314, decode.d7.loss_mask: 0.3184, decode.d7.loss_dice: 0.6633, decode.d8.loss_cls: 0.1200, decode.d8.loss_mask: 0.3196, decode.d8.loss_dice: 0.6504, loss: 11.1003
2023-09-28 20:45:23,897 - mmseg - INFO - Iter [15400/40000]	lr: 8.831e-07, eta: 19:03:11, time: 3.749, data_time: 0.135, memory: 21542, decode.loss_cls: 0.0667, decode.loss_mask: 0.2930, decode.loss_dice: 0.5579, decode.d0.loss_cls: 0.2541, decode.d0.loss_mask: 0.2979, decode.d0.loss_dice: 0.5672, decode.d1.loss_cls: 0.0846, decode.d1.loss_mask: 0.2938, decode.d1.loss_dice: 0.5650, decode.d2.loss_cls: 0.1005, decode.d2.loss_mask: 0.2932, decode.d2.loss_dice: 0.5643, decode.d3.loss_cls: 0.0741, decode.d3.loss_mask: 0.2925, decode.d3.loss_dice: 0.5641, decode.d4.loss_cls: 0.0732, decode.d4.loss_mask: 0.2954, decode.d4.loss_dice: 0.5678, decode.d5.loss_cls: 0.0837, decode.d5.loss_mask: 0.2939, decode.d5.loss_dice: 0.5580, decode.d6.loss_cls: 0.0664, decode.d6.loss_mask: 0.2937, decode.d6.loss_dice: 0.5558, decode.d7.loss_cls: 0.0673, decode.d7.loss_mask: 0.2929, decode.d7.loss_dice: 0.5613, decode.d8.loss_cls: 0.0658, decode.d8.loss_mask: 0.2939, decode.d8.loss_dice: 0.5594, loss: 9.4974
2023-09-28 20:48:29,172 - mmseg - INFO - Iter [15450/40000]	lr: 8.813e-07, eta: 19:02:04, time: 3.705, data_time: 0.072, memory: 21542, decode.loss_cls: 0.0693, decode.loss_mask: 0.2855, decode.loss_dice: 0.5194, decode.d0.loss_cls: 0.2322, decode.d0.loss_mask: 0.2981, decode.d0.loss_dice: 0.5483, decode.d1.loss_cls: 0.0798, decode.d1.loss_mask: 0.2859, decode.d1.loss_dice: 0.5308, decode.d2.loss_cls: 0.0673, decode.d2.loss_mask: 0.2860, decode.d2.loss_dice: 0.5333, decode.d3.loss_cls: 0.0594, decode.d3.loss_mask: 0.2875, decode.d3.loss_dice: 0.5348, decode.d4.loss_cls: 0.0749, decode.d4.loss_mask: 0.2863, decode.d4.loss_dice: 0.5330, decode.d5.loss_cls: 0.0682, decode.d5.loss_mask: 0.2850, decode.d5.loss_dice: 0.5327, decode.d6.loss_cls: 0.0647, decode.d6.loss_mask: 0.2850, decode.d6.loss_dice: 0.5334, decode.d7.loss_cls: 0.0625, decode.d7.loss_mask: 0.2863, decode.d7.loss_dice: 0.5309, decode.d8.loss_cls: 0.0728, decode.d8.loss_mask: 0.2844, decode.d8.loss_dice: 0.5264, loss: 9.0440
2023-09-28 20:51:29,187 - mmseg - INFO - Iter [15500/40000]	lr: 8.795e-07, eta: 19:00:49, time: 3.599, data_time: 0.079, memory: 21542, decode.loss_cls: 0.0722, decode.loss_mask: 0.2797, decode.loss_dice: 0.5646, decode.d0.loss_cls: 0.2407, decode.d0.loss_mask: 0.2859, decode.d0.loss_dice: 0.5693, decode.d1.loss_cls: 0.0750, decode.d1.loss_mask: 0.2821, decode.d1.loss_dice: 0.5670, decode.d2.loss_cls: 0.0763, decode.d2.loss_mask: 0.2819, decode.d2.loss_dice: 0.5649, decode.d3.loss_cls: 0.0743, decode.d3.loss_mask: 0.2808, decode.d3.loss_dice: 0.5570, decode.d4.loss_cls: 0.0788, decode.d4.loss_mask: 0.2812, decode.d4.loss_dice: 0.5647, decode.d5.loss_cls: 0.0660, decode.d5.loss_mask: 0.2799, decode.d5.loss_dice: 0.5531, decode.d6.loss_cls: 0.0632, decode.d6.loss_mask: 0.2804, decode.d6.loss_dice: 0.5615, decode.d7.loss_cls: 0.0642, decode.d7.loss_mask: 0.2818, decode.d7.loss_dice: 0.5603, decode.d8.loss_cls: 0.0708, decode.d8.loss_mask: 0.2830, decode.d8.loss_dice: 0.5647, loss: 9.3253
2023-09-28 20:54:28,639 - mmseg - INFO - Iter [15550/40000]	lr: 8.777e-07, eta: 18:59:31, time: 3.589, data_time: 0.077, memory: 21542, decode.loss_cls: 0.1097, decode.loss_mask: 0.2933, decode.loss_dice: 0.5986, decode.d0.loss_cls: 0.2407, decode.d0.loss_mask: 0.3011, decode.d0.loss_dice: 0.6217, decode.d1.loss_cls: 0.1338, decode.d1.loss_mask: 0.2934, decode.d1.loss_dice: 0.6102, decode.d2.loss_cls: 0.1329, decode.d2.loss_mask: 0.2928, decode.d2.loss_dice: 0.6000, decode.d3.loss_cls: 0.1173, decode.d3.loss_mask: 0.2917, decode.d3.loss_dice: 0.6016, decode.d4.loss_cls: 0.1080, decode.d4.loss_mask: 0.2953, decode.d4.loss_dice: 0.6191, decode.d5.loss_cls: 0.1190, decode.d5.loss_mask: 0.2945, decode.d5.loss_dice: 0.6087, decode.d6.loss_cls: 0.1074, decode.d6.loss_mask: 0.2932, decode.d6.loss_dice: 0.6150, decode.d7.loss_cls: 0.1118, decode.d7.loss_mask: 0.2923, decode.d7.loss_dice: 0.6026, decode.d8.loss_cls: 0.1138, decode.d8.loss_mask: 0.2948, decode.d8.loss_dice: 0.6078, loss: 10.3222
2023-09-28 20:57:36,832 - mmseg - INFO - Iter [15600/40000]	lr: 8.759e-07, eta: 18:58:27, time: 3.765, data_time: 0.079, memory: 21542, decode.loss_cls: 0.0713, decode.loss_mask: 0.2877, decode.loss_dice: 0.6133, decode.d0.loss_cls: 0.2311, decode.d0.loss_mask: 0.2924, decode.d0.loss_dice: 0.6245, decode.d1.loss_cls: 0.1154, decode.d1.loss_mask: 0.2866, decode.d1.loss_dice: 0.6050, decode.d2.loss_cls: 0.0825, decode.d2.loss_mask: 0.2883, decode.d2.loss_dice: 0.6239, decode.d3.loss_cls: 0.0902, decode.d3.loss_mask: 0.2883, decode.d3.loss_dice: 0.6160, decode.d4.loss_cls: 0.0821, decode.d4.loss_mask: 0.2878, decode.d4.loss_dice: 0.6272, decode.d5.loss_cls: 0.0987, decode.d5.loss_mask: 0.2865, decode.d5.loss_dice: 0.6185, decode.d6.loss_cls: 0.1010, decode.d6.loss_mask: 0.2862, decode.d6.loss_dice: 0.6168, decode.d7.loss_cls: 0.0795, decode.d7.loss_mask: 0.2887, decode.d7.loss_dice: 0.6032, decode.d8.loss_cls: 0.0891, decode.d8.loss_mask: 0.2889, decode.d8.loss_dice: 0.5995, loss: 10.0703
2023-09-28 21:00:42,108 - mmseg - INFO - Iter [15650/40000]	lr: 8.741e-07, eta: 18:57:18, time: 3.705, data_time: 0.074, memory: 21542, decode.loss_cls: 0.0989, decode.loss_mask: 0.2937, decode.loss_dice: 0.5844, decode.d0.loss_cls: 0.2428, decode.d0.loss_mask: 0.2996, decode.d0.loss_dice: 0.5903, decode.d1.loss_cls: 0.1157, decode.d1.loss_mask: 0.2967, decode.d1.loss_dice: 0.5828, decode.d2.loss_cls: 0.1342, decode.d2.loss_mask: 0.2950, decode.d2.loss_dice: 0.5861, decode.d3.loss_cls: 0.0999, decode.d3.loss_mask: 0.2951, decode.d3.loss_dice: 0.5871, decode.d4.loss_cls: 0.1093, decode.d4.loss_mask: 0.2955, decode.d4.loss_dice: 0.5868, decode.d5.loss_cls: 0.1053, decode.d5.loss_mask: 0.2947, decode.d5.loss_dice: 0.5884, decode.d6.loss_cls: 0.0923, decode.d6.loss_mask: 0.2946, decode.d6.loss_dice: 0.5775, decode.d7.loss_cls: 0.0985, decode.d7.loss_mask: 0.2941, decode.d7.loss_dice: 0.5849, decode.d8.loss_cls: 0.1136, decode.d8.loss_mask: 0.2937, decode.d8.loss_dice: 0.5776, loss: 10.0090
2023-09-28 21:03:38,893 - mmseg - INFO - Iter [15700/40000]	lr: 8.723e-07, eta: 18:55:54, time: 3.534, data_time: 0.066, memory: 21542, decode.loss_cls: 0.0614, decode.loss_mask: 0.3122, decode.loss_dice: 0.5501, decode.d0.loss_cls: 0.2160, decode.d0.loss_mask: 0.3180, decode.d0.loss_dice: 0.5727, decode.d1.loss_cls: 0.0634, decode.d1.loss_mask: 0.3149, decode.d1.loss_dice: 0.5483, decode.d2.loss_cls: 0.0623, decode.d2.loss_mask: 0.3134, decode.d2.loss_dice: 0.5513, decode.d3.loss_cls: 0.0931, decode.d3.loss_mask: 0.3132, decode.d3.loss_dice: 0.5478, decode.d4.loss_cls: 0.0708, decode.d4.loss_mask: 0.3137, decode.d4.loss_dice: 0.5482, decode.d5.loss_cls: 0.0599, decode.d5.loss_mask: 0.3130, decode.d5.loss_dice: 0.5458, decode.d6.loss_cls: 0.0694, decode.d6.loss_mask: 0.3123, decode.d6.loss_dice: 0.5482, decode.d7.loss_cls: 0.0617, decode.d7.loss_mask: 0.3132, decode.d7.loss_dice: 0.5633, decode.d8.loss_cls: 0.0601, decode.d8.loss_mask: 0.3108, decode.d8.loss_dice: 0.5566, loss: 9.4852
2023-09-28 21:06:40,465 - mmseg - INFO - Iter [15750/40000]	lr: 8.705e-07, eta: 18:54:38, time: 3.633, data_time: 0.073, memory: 21542, decode.loss_cls: 0.0626, decode.loss_mask: 0.2671, decode.loss_dice: 0.5584, decode.d0.loss_cls: 0.2172, decode.d0.loss_mask: 0.2675, decode.d0.loss_dice: 0.5526, decode.d1.loss_cls: 0.0585, decode.d1.loss_mask: 0.2683, decode.d1.loss_dice: 0.5535, decode.d2.loss_cls: 0.0474, decode.d2.loss_mask: 0.2671, decode.d2.loss_dice: 0.5589, decode.d3.loss_cls: 0.0728, decode.d3.loss_mask: 0.2673, decode.d3.loss_dice: 0.5475, decode.d4.loss_cls: 0.0655, decode.d4.loss_mask: 0.2664, decode.d4.loss_dice: 0.5557, decode.d5.loss_cls: 0.0677, decode.d5.loss_mask: 0.2669, decode.d5.loss_dice: 0.5582, decode.d6.loss_cls: 0.0675, decode.d6.loss_mask: 0.2678, decode.d6.loss_dice: 0.5456, decode.d7.loss_cls: 0.0826, decode.d7.loss_mask: 0.2679, decode.d7.loss_dice: 0.5671, decode.d8.loss_cls: 0.0714, decode.d8.loss_mask: 0.2676, decode.d8.loss_dice: 0.5585, loss: 9.0429
2023-09-28 21:09:50,345 - mmseg - INFO - Iter [15800/40000]	lr: 8.687e-07, eta: 18:53:33, time: 3.797, data_time: 0.078, memory: 21542, decode.loss_cls: 0.0597, decode.loss_mask: 0.2548, decode.loss_dice: 0.5491, decode.d0.loss_cls: 0.2042, decode.d0.loss_mask: 0.2560, decode.d0.loss_dice: 0.5525, decode.d1.loss_cls: 0.0989, decode.d1.loss_mask: 0.2534, decode.d1.loss_dice: 0.5440, decode.d2.loss_cls: 0.0747, decode.d2.loss_mask: 0.2555, decode.d2.loss_dice: 0.5449, decode.d3.loss_cls: 0.0774, decode.d3.loss_mask: 0.2549, decode.d3.loss_dice: 0.5540, decode.d4.loss_cls: 0.0657, decode.d4.loss_mask: 0.2547, decode.d4.loss_dice: 0.5422, decode.d5.loss_cls: 0.0661, decode.d5.loss_mask: 0.2544, decode.d5.loss_dice: 0.5455, decode.d6.loss_cls: 0.0668, decode.d6.loss_mask: 0.2545, decode.d6.loss_dice: 0.5491, decode.d7.loss_cls: 0.0558, decode.d7.loss_mask: 0.2555, decode.d7.loss_dice: 0.5522, decode.d8.loss_cls: 0.0639, decode.d8.loss_mask: 0.2554, decode.d8.loss_dice: 0.5469, loss: 8.8627
2023-09-28 21:12:51,473 - mmseg - INFO - Iter [15850/40000]	lr: 8.669e-07, eta: 18:52:14, time: 3.621, data_time: 0.075, memory: 21542, decode.loss_cls: 0.0447, decode.loss_mask: 0.2750, decode.loss_dice: 0.5128, decode.d0.loss_cls: 0.2449, decode.d0.loss_mask: 0.2794, decode.d0.loss_dice: 0.5181, decode.d1.loss_cls: 0.0681, decode.d1.loss_mask: 0.2763, decode.d1.loss_dice: 0.5087, decode.d2.loss_cls: 0.0637, decode.d2.loss_mask: 0.2755, decode.d2.loss_dice: 0.5178, decode.d3.loss_cls: 0.0493, decode.d3.loss_mask: 0.2739, decode.d3.loss_dice: 0.5039, decode.d4.loss_cls: 0.0653, decode.d4.loss_mask: 0.2758, decode.d4.loss_dice: 0.5238, decode.d5.loss_cls: 0.0527, decode.d5.loss_mask: 0.2738, decode.d5.loss_dice: 0.5111, decode.d6.loss_cls: 0.0589, decode.d6.loss_mask: 0.2741, decode.d6.loss_dice: 0.5184, decode.d7.loss_cls: 0.0661, decode.d7.loss_mask: 0.2752, decode.d7.loss_dice: 0.5138, decode.d8.loss_cls: 0.0709, decode.d8.loss_mask: 0.2744, decode.d8.loss_dice: 0.5128, loss: 8.6793
2023-09-28 21:15:32,243 - mmseg - INFO - Iter [15900/40000]	lr: 8.651e-07, eta: 18:50:24, time: 3.217, data_time: 0.063, memory: 21542, decode.loss_cls: 0.0805, decode.loss_mask: 0.2636, decode.loss_dice: 0.5692, decode.d0.loss_cls: 0.2380, decode.d0.loss_mask: 0.2684, decode.d0.loss_dice: 0.5813, decode.d1.loss_cls: 0.0800, decode.d1.loss_mask: 0.2634, decode.d1.loss_dice: 0.5702, decode.d2.loss_cls: 0.0864, decode.d2.loss_mask: 0.2655, decode.d2.loss_dice: 0.5692, decode.d3.loss_cls: 0.0682, decode.d3.loss_mask: 0.2622, decode.d3.loss_dice: 0.5634, decode.d4.loss_cls: 0.0670, decode.d4.loss_mask: 0.2650, decode.d4.loss_dice: 0.5636, decode.d5.loss_cls: 0.0866, decode.d5.loss_mask: 0.2632, decode.d5.loss_dice: 0.5581, decode.d6.loss_cls: 0.0672, decode.d6.loss_mask: 0.2629, decode.d6.loss_dice: 0.5679, decode.d7.loss_cls: 0.0689, decode.d7.loss_mask: 0.2665, decode.d7.loss_dice: 0.5669, decode.d8.loss_cls: 0.0653, decode.d8.loss_mask: 0.2649, decode.d8.loss_dice: 0.5640, loss: 9.2275
2023-09-28 21:17:23,390 - mmseg - INFO - Iter [15950/40000]	lr: 8.633e-07, eta: 18:47:19, time: 2.223, data_time: 0.032, memory: 21542, decode.loss_cls: 0.1006, decode.loss_mask: 0.2538, decode.loss_dice: 0.5669, decode.d0.loss_cls: 0.2329, decode.d0.loss_mask: 0.2594, decode.d0.loss_dice: 0.5727, decode.d1.loss_cls: 0.1295, decode.d1.loss_mask: 0.2550, decode.d1.loss_dice: 0.5778, decode.d2.loss_cls: 0.1261, decode.d2.loss_mask: 0.2539, decode.d2.loss_dice: 0.5849, decode.d3.loss_cls: 0.0992, decode.d3.loss_mask: 0.2519, decode.d3.loss_dice: 0.5847, decode.d4.loss_cls: 0.0985, decode.d4.loss_mask: 0.2561, decode.d4.loss_dice: 0.5778, decode.d5.loss_cls: 0.0975, decode.d5.loss_mask: 0.2545, decode.d5.loss_dice: 0.5706, decode.d6.loss_cls: 0.0956, decode.d6.loss_mask: 0.2546, decode.d6.loss_dice: 0.5694, decode.d7.loss_cls: 0.0960, decode.d7.loss_mask: 0.2540, decode.d7.loss_dice: 0.5791, decode.d8.loss_cls: 0.0929, decode.d8.loss_mask: 0.2545, decode.d8.loss_dice: 0.5810, loss: 9.4813
2023-09-28 21:19:13,919 - mmseg - INFO - Saving checkpoint at 16000 iterations
2023-09-28 21:19:33,981 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 21:19:33,982 - mmseg - INFO - Iter [16000/40000]	lr: 8.615e-07, eta: 18:44:43, time: 2.612, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0712, decode.loss_mask: 0.2593, decode.loss_dice: 0.5618, decode.d0.loss_cls: 0.2183, decode.d0.loss_mask: 0.2626, decode.d0.loss_dice: 0.5888, decode.d1.loss_cls: 0.0845, decode.d1.loss_mask: 0.2607, decode.d1.loss_dice: 0.5655, decode.d2.loss_cls: 0.0752, decode.d2.loss_mask: 0.2597, decode.d2.loss_dice: 0.5760, decode.d3.loss_cls: 0.0725, decode.d3.loss_mask: 0.2582, decode.d3.loss_dice: 0.5640, decode.d4.loss_cls: 0.0627, decode.d4.loss_mask: 0.2585, decode.d4.loss_dice: 0.5787, decode.d5.loss_cls: 0.0637, decode.d5.loss_mask: 0.2588, decode.d5.loss_dice: 0.5727, decode.d6.loss_cls: 0.0987, decode.d6.loss_mask: 0.2597, decode.d6.loss_dice: 0.5701, decode.d7.loss_cls: 0.0783, decode.d7.loss_mask: 0.2610, decode.d7.loss_dice: 0.5716, decode.d8.loss_cls: 0.0795, decode.d8.loss_mask: 0.2596, decode.d8.loss_dice: 0.5660, loss: 9.2181
2023-09-28 21:36:50,133 - mmseg - INFO - per class results:
2023-09-28 21:36:50,147 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 93.14 | 96.88 |
|    Sidewalk   | 69.74 | 81.58 |
|  Construction | 81.57 | 94.66 |
|     Fence     | 31.58 | 34.71 |
|      Pole     | 56.79 | 70.24 |
| Traffic Light |  67.1 | 80.02 |
|  Traffic Sign | 73.55 |  82.5 |
|     Nature    | 88.13 | 92.73 |
|      Sky      | 96.63 | 98.02 |
|     Person    | 33.32 | 35.74 |
|     Rider     |  9.93 | 73.29 |
|      Car      | 91.76 | 95.21 |
|   background  | 96.36 | 98.05 |
+---------------+-------+-------+
2023-09-28 21:36:50,147 - mmseg - INFO - Summary:
2023-09-28 21:36:50,147 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.39 | 68.43 | 79.51 |
+-------+-------+-------+
2023-09-28 21:36:50,150 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 21:36:50,150 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9439, mIoU: 0.6843, mAcc: 0.7951, IoU.Road: 0.9314, IoU.Sidewalk: 0.6974, IoU.Construction: 0.8157, IoU.Fence: 0.3158, IoU.Pole: 0.5679, IoU.Traffic Light: 0.6710, IoU.Traffic Sign: 0.7355, IoU.Nature: 0.8813, IoU.Sky: 0.9663, IoU.Person: 0.3332, IoU.Rider: 0.0993, IoU.Car: 0.9176, IoU.background: 0.9636, Acc.Road: 0.9688, Acc.Sidewalk: 0.8158, Acc.Construction: 0.9466, Acc.Fence: 0.3471, Acc.Pole: 0.7024, Acc.Traffic Light: 0.8002, Acc.Traffic Sign: 0.8250, Acc.Nature: 0.9273, Acc.Sky: 0.9802, Acc.Person: 0.3574, Acc.Rider: 0.7329, Acc.Car: 0.9521, Acc.background: 0.9805
2023-09-28 21:38:40,733 - mmseg - INFO - Iter [16050/40000]	lr: 8.597e-07, eta: 19:07:24, time: 22.935, data_time: 20.757, memory: 21542, decode.loss_cls: 0.0868, decode.loss_mask: 0.2937, decode.loss_dice: 0.6344, decode.d0.loss_cls: 0.2214, decode.d0.loss_mask: 0.3028, decode.d0.loss_dice: 0.6414, decode.d1.loss_cls: 0.0976, decode.d1.loss_mask: 0.2943, decode.d1.loss_dice: 0.6294, decode.d2.loss_cls: 0.1049, decode.d2.loss_mask: 0.2921, decode.d2.loss_dice: 0.6248, decode.d3.loss_cls: 0.0952, decode.d3.loss_mask: 0.2930, decode.d3.loss_dice: 0.6258, decode.d4.loss_cls: 0.0905, decode.d4.loss_mask: 0.2936, decode.d4.loss_dice: 0.6291, decode.d5.loss_cls: 0.0863, decode.d5.loss_mask: 0.2930, decode.d5.loss_dice: 0.6276, decode.d6.loss_cls: 0.0926, decode.d6.loss_mask: 0.2940, decode.d6.loss_dice: 0.6243, decode.d7.loss_cls: 0.1019, decode.d7.loss_mask: 0.2941, decode.d7.loss_dice: 0.6232, decode.d8.loss_cls: 0.0971, decode.d8.loss_mask: 0.2939, decode.d8.loss_dice: 0.6201, loss: 10.2989
2023-09-28 21:40:31,885 - mmseg - INFO - Iter [16100/40000]	lr: 8.579e-07, eta: 19:04:12, time: 2.223, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0722, decode.loss_mask: 0.3160, decode.loss_dice: 0.6001, decode.d0.loss_cls: 0.1947, decode.d0.loss_mask: 0.3174, decode.d0.loss_dice: 0.6090, decode.d1.loss_cls: 0.0996, decode.d1.loss_mask: 0.3162, decode.d1.loss_dice: 0.6118, decode.d2.loss_cls: 0.0721, decode.d2.loss_mask: 0.3157, decode.d2.loss_dice: 0.6087, decode.d3.loss_cls: 0.0647, decode.d3.loss_mask: 0.3189, decode.d3.loss_dice: 0.6047, decode.d4.loss_cls: 0.0638, decode.d4.loss_mask: 0.3198, decode.d4.loss_dice: 0.5993, decode.d5.loss_cls: 0.0587, decode.d5.loss_mask: 0.3176, decode.d5.loss_dice: 0.6020, decode.d6.loss_cls: 0.0477, decode.d6.loss_mask: 0.3203, decode.d6.loss_dice: 0.6060, decode.d7.loss_cls: 0.0632, decode.d7.loss_mask: 0.3187, decode.d7.loss_dice: 0.6003, decode.d8.loss_cls: 0.0696, decode.d8.loss_mask: 0.3183, decode.d8.loss_dice: 0.6067, loss: 10.0341
2023-09-28 21:42:22,555 - mmseg - INFO - Iter [16150/40000]	lr: 8.561e-07, eta: 19:01:00, time: 2.213, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0790, decode.loss_mask: 0.2673, decode.loss_dice: 0.6085, decode.d0.loss_cls: 0.2345, decode.d0.loss_mask: 0.2685, decode.d0.loss_dice: 0.5950, decode.d1.loss_cls: 0.0870, decode.d1.loss_mask: 0.2670, decode.d1.loss_dice: 0.5974, decode.d2.loss_cls: 0.0958, decode.d2.loss_mask: 0.2662, decode.d2.loss_dice: 0.5916, decode.d3.loss_cls: 0.1018, decode.d3.loss_mask: 0.2664, decode.d3.loss_dice: 0.5849, decode.d4.loss_cls: 0.0902, decode.d4.loss_mask: 0.2676, decode.d4.loss_dice: 0.6041, decode.d5.loss_cls: 0.0960, decode.d5.loss_mask: 0.2667, decode.d5.loss_dice: 0.5895, decode.d6.loss_cls: 0.0871, decode.d6.loss_mask: 0.2686, decode.d6.loss_dice: 0.5983, decode.d7.loss_cls: 0.0750, decode.d7.loss_mask: 0.2677, decode.d7.loss_dice: 0.6090, decode.d8.loss_cls: 0.0991, decode.d8.loss_mask: 0.2674, decode.d8.loss_dice: 0.5921, loss: 9.6892
2023-09-28 21:44:13,319 - mmseg - INFO - Iter [16200/40000]	lr: 8.543e-07, eta: 18:57:48, time: 2.216, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0957, decode.loss_mask: 0.3160, decode.loss_dice: 0.6077, decode.d0.loss_cls: 0.2511, decode.d0.loss_mask: 0.3212, decode.d0.loss_dice: 0.6177, decode.d1.loss_cls: 0.0978, decode.d1.loss_mask: 0.3159, decode.d1.loss_dice: 0.6157, decode.d2.loss_cls: 0.1067, decode.d2.loss_mask: 0.3148, decode.d2.loss_dice: 0.6047, decode.d3.loss_cls: 0.0945, decode.d3.loss_mask: 0.3241, decode.d3.loss_dice: 0.6071, decode.d4.loss_cls: 0.0831, decode.d4.loss_mask: 0.3274, decode.d4.loss_dice: 0.6222, decode.d5.loss_cls: 0.0928, decode.d5.loss_mask: 0.3237, decode.d5.loss_dice: 0.6088, decode.d6.loss_cls: 0.0956, decode.d6.loss_mask: 0.3142, decode.d6.loss_dice: 0.6003, decode.d7.loss_cls: 0.1006, decode.d7.loss_mask: 0.3155, decode.d7.loss_dice: 0.6084, decode.d8.loss_cls: 0.1090, decode.d8.loss_mask: 0.3149, decode.d8.loss_dice: 0.5970, loss: 10.4043
2023-09-28 21:46:04,642 - mmseg - INFO - Iter [16250/40000]	lr: 8.525e-07, eta: 18:54:38, time: 2.226, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0612, decode.loss_mask: 0.2970, decode.loss_dice: 0.5938, decode.d0.loss_cls: 0.2307, decode.d0.loss_mask: 0.3067, decode.d0.loss_dice: 0.5982, decode.d1.loss_cls: 0.1177, decode.d1.loss_mask: 0.2980, decode.d1.loss_dice: 0.5959, decode.d2.loss_cls: 0.0984, decode.d2.loss_mask: 0.2983, decode.d2.loss_dice: 0.6052, decode.d3.loss_cls: 0.0835, decode.d3.loss_mask: 0.2952, decode.d3.loss_dice: 0.5945, decode.d4.loss_cls: 0.0923, decode.d4.loss_mask: 0.2964, decode.d4.loss_dice: 0.5960, decode.d5.loss_cls: 0.0839, decode.d5.loss_mask: 0.2966, decode.d5.loss_dice: 0.5923, decode.d6.loss_cls: 0.0804, decode.d6.loss_mask: 0.2965, decode.d6.loss_dice: 0.5892, decode.d7.loss_cls: 0.0724, decode.d7.loss_mask: 0.2979, decode.d7.loss_dice: 0.6017, decode.d8.loss_cls: 0.0588, decode.d8.loss_mask: 0.2975, decode.d8.loss_dice: 0.5980, loss: 9.9241
2023-09-28 21:47:57,017 - mmseg - INFO - Iter [16300/40000]	lr: 8.507e-07, eta: 18:51:30, time: 2.248, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0639, decode.loss_mask: 0.2698, decode.loss_dice: 0.5427, decode.d0.loss_cls: 0.2141, decode.d0.loss_mask: 0.2773, decode.d0.loss_dice: 0.5467, decode.d1.loss_cls: 0.0854, decode.d1.loss_mask: 0.2721, decode.d1.loss_dice: 0.5366, decode.d2.loss_cls: 0.0745, decode.d2.loss_mask: 0.2725, decode.d2.loss_dice: 0.5416, decode.d3.loss_cls: 0.0708, decode.d3.loss_mask: 0.2701, decode.d3.loss_dice: 0.5403, decode.d4.loss_cls: 0.0709, decode.d4.loss_mask: 0.2713, decode.d4.loss_dice: 0.5424, decode.d5.loss_cls: 0.0804, decode.d5.loss_mask: 0.2722, decode.d5.loss_dice: 0.5374, decode.d6.loss_cls: 0.0572, decode.d6.loss_mask: 0.2715, decode.d6.loss_dice: 0.5391, decode.d7.loss_cls: 0.0726, decode.d7.loss_mask: 0.2700, decode.d7.loss_dice: 0.5405, decode.d8.loss_cls: 0.0786, decode.d8.loss_mask: 0.2709, decode.d8.loss_dice: 0.5427, loss: 8.9961
2023-09-28 21:49:48,173 - mmseg - INFO - Iter [16350/40000]	lr: 8.490e-07, eta: 18:48:20, time: 2.223, data_time: 0.026, memory: 21542, decode.loss_cls: 0.0830, decode.loss_mask: 0.2641, decode.loss_dice: 0.6006, decode.d0.loss_cls: 0.2252, decode.d0.loss_mask: 0.2712, decode.d0.loss_dice: 0.6071, decode.d1.loss_cls: 0.0927, decode.d1.loss_mask: 0.2650, decode.d1.loss_dice: 0.5931, decode.d2.loss_cls: 0.1049, decode.d2.loss_mask: 0.2641, decode.d2.loss_dice: 0.6016, decode.d3.loss_cls: 0.0824, decode.d3.loss_mask: 0.2649, decode.d3.loss_dice: 0.6098, decode.d4.loss_cls: 0.0869, decode.d4.loss_mask: 0.2639, decode.d4.loss_dice: 0.6073, decode.d5.loss_cls: 0.0832, decode.d5.loss_mask: 0.2647, decode.d5.loss_dice: 0.6139, decode.d6.loss_cls: 0.0778, decode.d6.loss_mask: 0.2661, decode.d6.loss_dice: 0.6123, decode.d7.loss_cls: 0.0781, decode.d7.loss_mask: 0.2649, decode.d7.loss_dice: 0.6079, decode.d8.loss_cls: 0.1080, decode.d8.loss_mask: 0.2642, decode.d8.loss_dice: 0.6034, loss: 9.7318
2023-09-28 21:51:40,239 - mmseg - INFO - Iter [16400/40000]	lr: 8.472e-07, eta: 18:45:12, time: 2.241, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0635, decode.loss_mask: 0.2758, decode.loss_dice: 0.5596, decode.d0.loss_cls: 0.2325, decode.d0.loss_mask: 0.2812, decode.d0.loss_dice: 0.5629, decode.d1.loss_cls: 0.0887, decode.d1.loss_mask: 0.2761, decode.d1.loss_dice: 0.5533, decode.d2.loss_cls: 0.0596, decode.d2.loss_mask: 0.2757, decode.d2.loss_dice: 0.5620, decode.d3.loss_cls: 0.0613, decode.d3.loss_mask: 0.2770, decode.d3.loss_dice: 0.5523, decode.d4.loss_cls: 0.0625, decode.d4.loss_mask: 0.2776, decode.d4.loss_dice: 0.5553, decode.d5.loss_cls: 0.0760, decode.d5.loss_mask: 0.2783, decode.d5.loss_dice: 0.5531, decode.d6.loss_cls: 0.0540, decode.d6.loss_mask: 0.2750, decode.d6.loss_dice: 0.5580, decode.d7.loss_cls: 0.0698, decode.d7.loss_mask: 0.2760, decode.d7.loss_dice: 0.5543, decode.d8.loss_cls: 0.0614, decode.d8.loss_mask: 0.2753, decode.d8.loss_dice: 0.5553, loss: 9.1635
2023-09-28 21:53:31,338 - mmseg - INFO - Iter [16450/40000]	lr: 8.454e-07, eta: 18:42:03, time: 2.222, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0794, decode.loss_mask: 0.2628, decode.loss_dice: 0.5977, decode.d0.loss_cls: 0.2230, decode.d0.loss_mask: 0.2700, decode.d0.loss_dice: 0.6067, decode.d1.loss_cls: 0.1120, decode.d1.loss_mask: 0.2655, decode.d1.loss_dice: 0.6097, decode.d2.loss_cls: 0.0981, decode.d2.loss_mask: 0.2643, decode.d2.loss_dice: 0.6153, decode.d3.loss_cls: 0.1112, decode.d3.loss_mask: 0.2645, decode.d3.loss_dice: 0.6005, decode.d4.loss_cls: 0.1010, decode.d4.loss_mask: 0.2699, decode.d4.loss_dice: 0.6096, decode.d5.loss_cls: 0.1048, decode.d5.loss_mask: 0.2679, decode.d5.loss_dice: 0.6102, decode.d6.loss_cls: 0.0898, decode.d6.loss_mask: 0.2637, decode.d6.loss_dice: 0.6034, decode.d7.loss_cls: 0.0973, decode.d7.loss_mask: 0.2663, decode.d7.loss_dice: 0.5965, decode.d8.loss_cls: 0.1093, decode.d8.loss_mask: 0.2649, decode.d8.loss_dice: 0.6026, loss: 9.8379
2023-09-28 21:55:25,126 - mmseg - INFO - Iter [16500/40000]	lr: 8.436e-07, eta: 18:38:59, time: 2.276, data_time: 0.080, memory: 21542, decode.loss_cls: 0.0516, decode.loss_mask: 0.2626, decode.loss_dice: 0.5689, decode.d0.loss_cls: 0.2276, decode.d0.loss_mask: 0.2622, decode.d0.loss_dice: 0.5621, decode.d1.loss_cls: 0.0810, decode.d1.loss_mask: 0.2611, decode.d1.loss_dice: 0.5661, decode.d2.loss_cls: 0.0882, decode.d2.loss_mask: 0.2599, decode.d2.loss_dice: 0.5578, decode.d3.loss_cls: 0.0687, decode.d3.loss_mask: 0.2607, decode.d3.loss_dice: 0.5488, decode.d4.loss_cls: 0.0461, decode.d4.loss_mask: 0.2610, decode.d4.loss_dice: 0.5659, decode.d5.loss_cls: 0.0543, decode.d5.loss_mask: 0.2601, decode.d5.loss_dice: 0.5615, decode.d6.loss_cls: 0.0446, decode.d6.loss_mask: 0.2596, decode.d6.loss_dice: 0.5671, decode.d7.loss_cls: 0.0616, decode.d7.loss_mask: 0.2605, decode.d7.loss_dice: 0.5653, decode.d8.loss_cls: 0.0566, decode.d8.loss_mask: 0.2615, decode.d8.loss_dice: 0.5607, loss: 9.0136
2023-09-28 21:57:15,097 - mmseg - INFO - Iter [16550/40000]	lr: 8.418e-07, eta: 18:35:49, time: 2.199, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0623, decode.loss_mask: 0.2831, decode.loss_dice: 0.5365, decode.d0.loss_cls: 0.2390, decode.d0.loss_mask: 0.2875, decode.d0.loss_dice: 0.5539, decode.d1.loss_cls: 0.0802, decode.d1.loss_mask: 0.2823, decode.d1.loss_dice: 0.5399, decode.d2.loss_cls: 0.0827, decode.d2.loss_mask: 0.2846, decode.d2.loss_dice: 0.5313, decode.d3.loss_cls: 0.0665, decode.d3.loss_mask: 0.2842, decode.d3.loss_dice: 0.5395, decode.d4.loss_cls: 0.0734, decode.d4.loss_mask: 0.2840, decode.d4.loss_dice: 0.5399, decode.d5.loss_cls: 0.0828, decode.d5.loss_mask: 0.2835, decode.d5.loss_dice: 0.5386, decode.d6.loss_cls: 0.0898, decode.d6.loss_mask: 0.2845, decode.d6.loss_dice: 0.5464, decode.d7.loss_cls: 0.0745, decode.d7.loss_mask: 0.2838, decode.d7.loss_dice: 0.5336, decode.d8.loss_cls: 0.0822, decode.d8.loss_mask: 0.2829, decode.d8.loss_dice: 0.5332, loss: 9.1666
2023-09-28 21:59:06,526 - mmseg - INFO - Iter [16600/40000]	lr: 8.400e-07, eta: 18:32:43, time: 2.229, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0632, decode.loss_mask: 0.2750, decode.loss_dice: 0.5932, decode.d0.loss_cls: 0.2188, decode.d0.loss_mask: 0.2807, decode.d0.loss_dice: 0.6062, decode.d1.loss_cls: 0.0918, decode.d1.loss_mask: 0.2781, decode.d1.loss_dice: 0.6002, decode.d2.loss_cls: 0.0909, decode.d2.loss_mask: 0.2763, decode.d2.loss_dice: 0.5999, decode.d3.loss_cls: 0.0829, decode.d3.loss_mask: 0.2752, decode.d3.loss_dice: 0.5892, decode.d4.loss_cls: 0.0938, decode.d4.loss_mask: 0.2763, decode.d4.loss_dice: 0.5902, decode.d5.loss_cls: 0.0860, decode.d5.loss_mask: 0.2766, decode.d5.loss_dice: 0.6034, decode.d6.loss_cls: 0.0730, decode.d6.loss_mask: 0.2760, decode.d6.loss_dice: 0.5922, decode.d7.loss_cls: 0.0595, decode.d7.loss_mask: 0.2747, decode.d7.loss_dice: 0.5897, decode.d8.loss_cls: 0.0530, decode.d8.loss_mask: 0.2744, decode.d8.loss_dice: 0.5986, loss: 9.6390
2023-09-28 22:00:57,513 - mmseg - INFO - Iter [16650/40000]	lr: 8.382e-07, eta: 18:29:35, time: 2.220, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0798, decode.loss_mask: 0.2606, decode.loss_dice: 0.5286, decode.d0.loss_cls: 0.2438, decode.d0.loss_mask: 0.2661, decode.d0.loss_dice: 0.5425, decode.d1.loss_cls: 0.0916, decode.d1.loss_mask: 0.2630, decode.d1.loss_dice: 0.5280, decode.d2.loss_cls: 0.0899, decode.d2.loss_mask: 0.2616, decode.d2.loss_dice: 0.5320, decode.d3.loss_cls: 0.0834, decode.d3.loss_mask: 0.2608, decode.d3.loss_dice: 0.5277, decode.d4.loss_cls: 0.0835, decode.d4.loss_mask: 0.2618, decode.d4.loss_dice: 0.5343, decode.d5.loss_cls: 0.0772, decode.d5.loss_mask: 0.2622, decode.d5.loss_dice: 0.5305, decode.d6.loss_cls: 0.0906, decode.d6.loss_mask: 0.2614, decode.d6.loss_dice: 0.5110, decode.d7.loss_cls: 0.0720, decode.d7.loss_mask: 0.2624, decode.d7.loss_dice: 0.5298, decode.d8.loss_cls: 0.0764, decode.d8.loss_mask: 0.2603, decode.d8.loss_dice: 0.5250, loss: 8.8978
2023-09-28 22:02:48,901 - mmseg - INFO - Iter [16700/40000]	lr: 8.364e-07, eta: 18:26:29, time: 2.228, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0682, decode.loss_mask: 0.2550, decode.loss_dice: 0.5501, decode.d0.loss_cls: 0.2315, decode.d0.loss_mask: 0.2630, decode.d0.loss_dice: 0.5682, decode.d1.loss_cls: 0.0872, decode.d1.loss_mask: 0.2572, decode.d1.loss_dice: 0.5535, decode.d2.loss_cls: 0.0787, decode.d2.loss_mask: 0.2570, decode.d2.loss_dice: 0.5338, decode.d3.loss_cls: 0.0801, decode.d3.loss_mask: 0.2546, decode.d3.loss_dice: 0.5416, decode.d4.loss_cls: 0.0811, decode.d4.loss_mask: 0.2556, decode.d4.loss_dice: 0.5424, decode.d5.loss_cls: 0.0904, decode.d5.loss_mask: 0.2559, decode.d5.loss_dice: 0.5407, decode.d6.loss_cls: 0.0845, decode.d6.loss_mask: 0.2572, decode.d6.loss_dice: 0.5437, decode.d7.loss_cls: 0.0688, decode.d7.loss_mask: 0.2571, decode.d7.loss_dice: 0.5436, decode.d8.loss_cls: 0.0714, decode.d8.loss_mask: 0.2555, decode.d8.loss_dice: 0.5411, loss: 8.9687
2023-09-28 22:04:40,136 - mmseg - INFO - Iter [16750/40000]	lr: 8.346e-07, eta: 18:23:24, time: 2.225, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0687, decode.loss_mask: 0.2692, decode.loss_dice: 0.5600, decode.d0.loss_cls: 0.2492, decode.d0.loss_mask: 0.2695, decode.d0.loss_dice: 0.5678, decode.d1.loss_cls: 0.0841, decode.d1.loss_mask: 0.2689, decode.d1.loss_dice: 0.5688, decode.d2.loss_cls: 0.0908, decode.d2.loss_mask: 0.2683, decode.d2.loss_dice: 0.5654, decode.d3.loss_cls: 0.0784, decode.d3.loss_mask: 0.2687, decode.d3.loss_dice: 0.5621, decode.d4.loss_cls: 0.0747, decode.d4.loss_mask: 0.2676, decode.d4.loss_dice: 0.5607, decode.d5.loss_cls: 0.0868, decode.d5.loss_mask: 0.2689, decode.d5.loss_dice: 0.5579, decode.d6.loss_cls: 0.0857, decode.d6.loss_mask: 0.2671, decode.d6.loss_dice: 0.5550, decode.d7.loss_cls: 0.0742, decode.d7.loss_mask: 0.2679, decode.d7.loss_dice: 0.5598, decode.d8.loss_cls: 0.0941, decode.d8.loss_mask: 0.2693, decode.d8.loss_dice: 0.5704, loss: 9.2997
2023-09-28 22:06:31,301 - mmseg - INFO - Iter [16800/40000]	lr: 8.328e-07, eta: 18:20:18, time: 2.223, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0558, decode.loss_mask: 0.2709, decode.loss_dice: 0.5847, decode.d0.loss_cls: 0.2275, decode.d0.loss_mask: 0.2736, decode.d0.loss_dice: 0.5908, decode.d1.loss_cls: 0.0933, decode.d1.loss_mask: 0.2690, decode.d1.loss_dice: 0.5677, decode.d2.loss_cls: 0.0639, decode.d2.loss_mask: 0.2692, decode.d2.loss_dice: 0.5611, decode.d3.loss_cls: 0.0754, decode.d3.loss_mask: 0.2697, decode.d3.loss_dice: 0.5697, decode.d4.loss_cls: 0.0775, decode.d4.loss_mask: 0.2708, decode.d4.loss_dice: 0.5649, decode.d5.loss_cls: 0.0839, decode.d5.loss_mask: 0.2701, decode.d5.loss_dice: 0.5625, decode.d6.loss_cls: 0.0660, decode.d6.loss_mask: 0.2693, decode.d6.loss_dice: 0.5653, decode.d7.loss_cls: 0.0711, decode.d7.loss_mask: 0.2695, decode.d7.loss_dice: 0.5662, decode.d8.loss_cls: 0.0678, decode.d8.loss_mask: 0.2675, decode.d8.loss_dice: 0.5730, loss: 9.2878
2023-09-28 22:08:22,292 - mmseg - INFO - Iter [16850/40000]	lr: 8.310e-07, eta: 18:17:13, time: 2.220, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0473, decode.loss_mask: 0.2737, decode.loss_dice: 0.5589, decode.d0.loss_cls: 0.2291, decode.d0.loss_mask: 0.2806, decode.d0.loss_dice: 0.5664, decode.d1.loss_cls: 0.0694, decode.d1.loss_mask: 0.2747, decode.d1.loss_dice: 0.5523, decode.d2.loss_cls: 0.0753, decode.d2.loss_mask: 0.2729, decode.d2.loss_dice: 0.5526, decode.d3.loss_cls: 0.0739, decode.d3.loss_mask: 0.2721, decode.d3.loss_dice: 0.5508, decode.d4.loss_cls: 0.0722, decode.d4.loss_mask: 0.2681, decode.d4.loss_dice: 0.5527, decode.d5.loss_cls: 0.0597, decode.d5.loss_mask: 0.2693, decode.d5.loss_dice: 0.5633, decode.d6.loss_cls: 0.0582, decode.d6.loss_mask: 0.2736, decode.d6.loss_dice: 0.5564, decode.d7.loss_cls: 0.0542, decode.d7.loss_mask: 0.2738, decode.d7.loss_dice: 0.5643, decode.d8.loss_cls: 0.0662, decode.d8.loss_mask: 0.2721, decode.d8.loss_dice: 0.5547, loss: 9.1089
2023-09-28 22:10:14,319 - mmseg - INFO - Iter [16900/40000]	lr: 8.292e-07, eta: 18:14:09, time: 2.240, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0724, decode.loss_mask: 0.2645, decode.loss_dice: 0.5685, decode.d0.loss_cls: 0.2375, decode.d0.loss_mask: 0.2671, decode.d0.loss_dice: 0.5738, decode.d1.loss_cls: 0.1180, decode.d1.loss_mask: 0.2641, decode.d1.loss_dice: 0.5593, decode.d2.loss_cls: 0.1058, decode.d2.loss_mask: 0.2636, decode.d2.loss_dice: 0.5720, decode.d3.loss_cls: 0.0918, decode.d3.loss_mask: 0.2615, decode.d3.loss_dice: 0.5658, decode.d4.loss_cls: 0.0762, decode.d4.loss_mask: 0.2636, decode.d4.loss_dice: 0.5748, decode.d5.loss_cls: 0.0911, decode.d5.loss_mask: 0.2639, decode.d5.loss_dice: 0.5691, decode.d6.loss_cls: 0.0802, decode.d6.loss_mask: 0.2637, decode.d6.loss_dice: 0.5614, decode.d7.loss_cls: 0.0936, decode.d7.loss_mask: 0.2617, decode.d7.loss_dice: 0.5763, decode.d8.loss_cls: 0.0727, decode.d8.loss_mask: 0.2635, decode.d8.loss_dice: 0.5690, loss: 9.3665
2023-09-28 22:12:06,489 - mmseg - INFO - Iter [16950/40000]	lr: 8.274e-07, eta: 18:11:07, time: 2.244, data_time: 0.031, memory: 21542, decode.loss_cls: 0.1133, decode.loss_mask: 0.2867, decode.loss_dice: 0.5834, decode.d0.loss_cls: 0.2421, decode.d0.loss_mask: 0.3063, decode.d0.loss_dice: 0.5965, decode.d1.loss_cls: 0.0794, decode.d1.loss_mask: 0.2907, decode.d1.loss_dice: 0.5859, decode.d2.loss_cls: 0.0809, decode.d2.loss_mask: 0.2922, decode.d2.loss_dice: 0.5779, decode.d3.loss_cls: 0.0831, decode.d3.loss_mask: 0.2922, decode.d3.loss_dice: 0.5871, decode.d4.loss_cls: 0.0781, decode.d4.loss_mask: 0.2993, decode.d4.loss_dice: 0.5849, decode.d5.loss_cls: 0.0993, decode.d5.loss_mask: 0.2902, decode.d5.loss_dice: 0.5835, decode.d6.loss_cls: 0.0991, decode.d6.loss_mask: 0.2880, decode.d6.loss_dice: 0.5656, decode.d7.loss_cls: 0.0923, decode.d7.loss_mask: 0.2915, decode.d7.loss_dice: 0.5936, decode.d8.loss_cls: 0.0763, decode.d8.loss_mask: 0.2957, decode.d8.loss_dice: 0.5804, loss: 9.8155
2023-09-28 22:13:58,191 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 22:13:58,191 - mmseg - INFO - Iter [17000/40000]	lr: 8.256e-07, eta: 18:08:04, time: 2.234, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0775, decode.loss_mask: 0.2529, decode.loss_dice: 0.5975, decode.d0.loss_cls: 0.1991, decode.d0.loss_mask: 0.2554, decode.d0.loss_dice: 0.5963, decode.d1.loss_cls: 0.0771, decode.d1.loss_mask: 0.2564, decode.d1.loss_dice: 0.5943, decode.d2.loss_cls: 0.0827, decode.d2.loss_mask: 0.2543, decode.d2.loss_dice: 0.5894, decode.d3.loss_cls: 0.0622, decode.d3.loss_mask: 0.2540, decode.d3.loss_dice: 0.5840, decode.d4.loss_cls: 0.0547, decode.d4.loss_mask: 0.2524, decode.d4.loss_dice: 0.5928, decode.d5.loss_cls: 0.0623, decode.d5.loss_mask: 0.2530, decode.d5.loss_dice: 0.5808, decode.d6.loss_cls: 0.0530, decode.d6.loss_mask: 0.2531, decode.d6.loss_dice: 0.5786, decode.d7.loss_cls: 0.0595, decode.d7.loss_mask: 0.2511, decode.d7.loss_dice: 0.5807, decode.d8.loss_cls: 0.0795, decode.d8.loss_mask: 0.2522, decode.d8.loss_dice: 0.5817, loss: 9.2187
2023-09-28 22:15:48,371 - mmseg - INFO - Iter [17050/40000]	lr: 8.238e-07, eta: 18:04:59, time: 2.204, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0797, decode.loss_mask: 0.3002, decode.loss_dice: 0.6025, decode.d0.loss_cls: 0.2169, decode.d0.loss_mask: 0.3042, decode.d0.loss_dice: 0.6215, decode.d1.loss_cls: 0.0970, decode.d1.loss_mask: 0.2962, decode.d1.loss_dice: 0.6071, decode.d2.loss_cls: 0.0922, decode.d2.loss_mask: 0.2965, decode.d2.loss_dice: 0.6033, decode.d3.loss_cls: 0.1042, decode.d3.loss_mask: 0.2966, decode.d3.loss_dice: 0.5975, decode.d4.loss_cls: 0.0909, decode.d4.loss_mask: 0.2958, decode.d4.loss_dice: 0.5995, decode.d5.loss_cls: 0.0911, decode.d5.loss_mask: 0.2967, decode.d5.loss_dice: 0.6056, decode.d6.loss_cls: 0.0778, decode.d6.loss_mask: 0.2959, decode.d6.loss_dice: 0.6012, decode.d7.loss_cls: 0.0741, decode.d7.loss_mask: 0.2987, decode.d7.loss_dice: 0.6112, decode.d8.loss_cls: 0.0707, decode.d8.loss_mask: 0.2983, decode.d8.loss_dice: 0.6112, loss: 10.0343
2023-09-28 22:17:39,515 - mmseg - INFO - Iter [17100/40000]	lr: 8.220e-07, eta: 18:01:56, time: 2.223, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0610, decode.loss_mask: 0.2860, decode.loss_dice: 0.5807, decode.d0.loss_cls: 0.2609, decode.d0.loss_mask: 0.2895, decode.d0.loss_dice: 0.5712, decode.d1.loss_cls: 0.0541, decode.d1.loss_mask: 0.2862, decode.d1.loss_dice: 0.5831, decode.d2.loss_cls: 0.0977, decode.d2.loss_mask: 0.2824, decode.d2.loss_dice: 0.5725, decode.d3.loss_cls: 0.0734, decode.d3.loss_mask: 0.2868, decode.d3.loss_dice: 0.5690, decode.d4.loss_cls: 0.1141, decode.d4.loss_mask: 0.2855, decode.d4.loss_dice: 0.5765, decode.d5.loss_cls: 0.0946, decode.d5.loss_mask: 0.2854, decode.d5.loss_dice: 0.5868, decode.d6.loss_cls: 0.0663, decode.d6.loss_mask: 0.2868, decode.d6.loss_dice: 0.5727, decode.d7.loss_cls: 0.0574, decode.d7.loss_mask: 0.2865, decode.d7.loss_dice: 0.5749, decode.d8.loss_cls: 0.0608, decode.d8.loss_mask: 0.2854, decode.d8.loss_dice: 0.5818, loss: 9.5701
2023-09-28 22:19:30,142 - mmseg - INFO - Iter [17150/40000]	lr: 8.202e-07, eta: 17:58:53, time: 2.212, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0778, decode.loss_mask: 0.2793, decode.loss_dice: 0.5850, decode.d0.loss_cls: 0.2218, decode.d0.loss_mask: 0.2841, decode.d0.loss_dice: 0.5918, decode.d1.loss_cls: 0.0919, decode.d1.loss_mask: 0.2809, decode.d1.loss_dice: 0.5882, decode.d2.loss_cls: 0.0746, decode.d2.loss_mask: 0.2812, decode.d2.loss_dice: 0.5990, decode.d3.loss_cls: 0.0807, decode.d3.loss_mask: 0.2791, decode.d3.loss_dice: 0.5736, decode.d4.loss_cls: 0.0811, decode.d4.loss_mask: 0.2800, decode.d4.loss_dice: 0.5871, decode.d5.loss_cls: 0.0769, decode.d5.loss_mask: 0.2783, decode.d5.loss_dice: 0.5948, decode.d6.loss_cls: 0.0712, decode.d6.loss_mask: 0.2811, decode.d6.loss_dice: 0.5890, decode.d7.loss_cls: 0.0839, decode.d7.loss_mask: 0.2797, decode.d7.loss_dice: 0.5772, decode.d8.loss_cls: 0.0522, decode.d8.loss_mask: 0.2792, decode.d8.loss_dice: 0.5844, loss: 9.5851
2023-09-28 22:21:21,225 - mmseg - INFO - Iter [17200/40000]	lr: 8.184e-07, eta: 17:55:51, time: 2.222, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0483, decode.loss_mask: 0.2871, decode.loss_dice: 0.5158, decode.d0.loss_cls: 0.2222, decode.d0.loss_mask: 0.2942, decode.d0.loss_dice: 0.5266, decode.d1.loss_cls: 0.0453, decode.d1.loss_mask: 0.2880, decode.d1.loss_dice: 0.5386, decode.d2.loss_cls: 0.0651, decode.d2.loss_mask: 0.2868, decode.d2.loss_dice: 0.5335, decode.d3.loss_cls: 0.0675, decode.d3.loss_mask: 0.2864, decode.d3.loss_dice: 0.5279, decode.d4.loss_cls: 0.0545, decode.d4.loss_mask: 0.2879, decode.d4.loss_dice: 0.5215, decode.d5.loss_cls: 0.0644, decode.d5.loss_mask: 0.2869, decode.d5.loss_dice: 0.5296, decode.d6.loss_cls: 0.0467, decode.d6.loss_mask: 0.2882, decode.d6.loss_dice: 0.5158, decode.d7.loss_cls: 0.0637, decode.d7.loss_mask: 0.2887, decode.d7.loss_dice: 0.5220, decode.d8.loss_cls: 0.0486, decode.d8.loss_mask: 0.2871, decode.d8.loss_dice: 0.5208, loss: 8.8595
2023-09-28 22:23:13,150 - mmseg - INFO - Iter [17250/40000]	lr: 8.166e-07, eta: 17:52:50, time: 2.239, data_time: 0.031, memory: 21542, decode.loss_cls: 0.1035, decode.loss_mask: 0.3118, decode.loss_dice: 0.6259, decode.d0.loss_cls: 0.2508, decode.d0.loss_mask: 0.3177, decode.d0.loss_dice: 0.6434, decode.d1.loss_cls: 0.1348, decode.d1.loss_mask: 0.3087, decode.d1.loss_dice: 0.6247, decode.d2.loss_cls: 0.1142, decode.d2.loss_mask: 0.3101, decode.d2.loss_dice: 0.6158, decode.d3.loss_cls: 0.0910, decode.d3.loss_mask: 0.3129, decode.d3.loss_dice: 0.6267, decode.d4.loss_cls: 0.1162, decode.d4.loss_mask: 0.3120, decode.d4.loss_dice: 0.6211, decode.d5.loss_cls: 0.0958, decode.d5.loss_mask: 0.3150, decode.d5.loss_dice: 0.6262, decode.d6.loss_cls: 0.0796, decode.d6.loss_mask: 0.3182, decode.d6.loss_dice: 0.6190, decode.d7.loss_cls: 0.0850, decode.d7.loss_mask: 0.3153, decode.d7.loss_dice: 0.6205, decode.d8.loss_cls: 0.0874, decode.d8.loss_mask: 0.3174, decode.d8.loss_dice: 0.6274, loss: 10.5482
2023-09-28 22:25:03,568 - mmseg - INFO - Iter [17300/40000]	lr: 8.149e-07, eta: 17:49:48, time: 2.208, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0645, decode.loss_mask: 0.2902, decode.loss_dice: 0.5482, decode.d0.loss_cls: 0.2237, decode.d0.loss_mask: 0.2967, decode.d0.loss_dice: 0.5710, decode.d1.loss_cls: 0.0982, decode.d1.loss_mask: 0.2826, decode.d1.loss_dice: 0.5598, decode.d2.loss_cls: 0.0711, decode.d2.loss_mask: 0.2894, decode.d2.loss_dice: 0.5663, decode.d3.loss_cls: 0.0673, decode.d3.loss_mask: 0.2911, decode.d3.loss_dice: 0.5676, decode.d4.loss_cls: 0.0674, decode.d4.loss_mask: 0.2904, decode.d4.loss_dice: 0.5701, decode.d5.loss_cls: 0.0625, decode.d5.loss_mask: 0.2808, decode.d5.loss_dice: 0.5544, decode.d6.loss_cls: 0.0640, decode.d6.loss_mask: 0.2900, decode.d6.loss_dice: 0.5603, decode.d7.loss_cls: 0.0697, decode.d7.loss_mask: 0.2896, decode.d7.loss_dice: 0.5584, decode.d8.loss_cls: 0.0742, decode.d8.loss_mask: 0.2889, decode.d8.loss_dice: 0.5548, loss: 9.3631
2023-09-28 22:26:55,543 - mmseg - INFO - Iter [17350/40000]	lr: 8.131e-07, eta: 17:46:48, time: 2.238, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0486, decode.loss_mask: 0.3036, decode.loss_dice: 0.5362, decode.d0.loss_cls: 0.2267, decode.d0.loss_mask: 0.3135, decode.d0.loss_dice: 0.5262, decode.d1.loss_cls: 0.0605, decode.d1.loss_mask: 0.3060, decode.d1.loss_dice: 0.5342, decode.d2.loss_cls: 0.0440, decode.d2.loss_mask: 0.3052, decode.d2.loss_dice: 0.5373, decode.d3.loss_cls: 0.0423, decode.d3.loss_mask: 0.3043, decode.d3.loss_dice: 0.5361, decode.d4.loss_cls: 0.0418, decode.d4.loss_mask: 0.3046, decode.d4.loss_dice: 0.5409, decode.d5.loss_cls: 0.0481, decode.d5.loss_mask: 0.3041, decode.d5.loss_dice: 0.5317, decode.d6.loss_cls: 0.0404, decode.d6.loss_mask: 0.3046, decode.d6.loss_dice: 0.5409, decode.d7.loss_cls: 0.0422, decode.d7.loss_mask: 0.3054, decode.d7.loss_dice: 0.5380, decode.d8.loss_cls: 0.0459, decode.d8.loss_mask: 0.3042, decode.d8.loss_dice: 0.5356, loss: 9.0532
2023-09-28 22:28:46,909 - mmseg - INFO - Iter [17400/40000]	lr: 8.113e-07, eta: 17:43:48, time: 2.229, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0846, decode.loss_mask: 0.2860, decode.loss_dice: 0.5861, decode.d0.loss_cls: 0.2345, decode.d0.loss_mask: 0.2861, decode.d0.loss_dice: 0.5986, decode.d1.loss_cls: 0.0903, decode.d1.loss_mask: 0.2908, decode.d1.loss_dice: 0.5836, decode.d2.loss_cls: 0.0896, decode.d2.loss_mask: 0.2886, decode.d2.loss_dice: 0.5850, decode.d3.loss_cls: 0.0882, decode.d3.loss_mask: 0.2883, decode.d3.loss_dice: 0.5907, decode.d4.loss_cls: 0.0870, decode.d4.loss_mask: 0.2895, decode.d4.loss_dice: 0.6056, decode.d5.loss_cls: 0.0829, decode.d5.loss_mask: 0.2874, decode.d5.loss_dice: 0.5972, decode.d6.loss_cls: 0.0799, decode.d6.loss_mask: 0.2874, decode.d6.loss_dice: 0.5928, decode.d7.loss_cls: 0.0681, decode.d7.loss_mask: 0.2879, decode.d7.loss_dice: 0.5801, decode.d8.loss_cls: 0.0725, decode.d8.loss_mask: 0.2876, decode.d8.loss_dice: 0.5845, loss: 9.7615
2023-09-28 22:30:38,160 - mmseg - INFO - Iter [17450/40000]	lr: 8.095e-07, eta: 17:40:48, time: 2.225, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0480, decode.loss_mask: 0.2749, decode.loss_dice: 0.5523, decode.d0.loss_cls: 0.2231, decode.d0.loss_mask: 0.2732, decode.d0.loss_dice: 0.5659, decode.d1.loss_cls: 0.0759, decode.d1.loss_mask: 0.2731, decode.d1.loss_dice: 0.5541, decode.d2.loss_cls: 0.0639, decode.d2.loss_mask: 0.2750, decode.d2.loss_dice: 0.5580, decode.d3.loss_cls: 0.0527, decode.d3.loss_mask: 0.2735, decode.d3.loss_dice: 0.5662, decode.d4.loss_cls: 0.0695, decode.d4.loss_mask: 0.2736, decode.d4.loss_dice: 0.5648, decode.d5.loss_cls: 0.0444, decode.d5.loss_mask: 0.2742, decode.d5.loss_dice: 0.5656, decode.d6.loss_cls: 0.0622, decode.d6.loss_mask: 0.2719, decode.d6.loss_dice: 0.5532, decode.d7.loss_cls: 0.0466, decode.d7.loss_mask: 0.2716, decode.d7.loss_dice: 0.5566, decode.d8.loss_cls: 0.0416, decode.d8.loss_mask: 0.2753, decode.d8.loss_dice: 0.5595, loss: 9.0606
2023-09-28 22:32:29,665 - mmseg - INFO - Iter [17500/40000]	lr: 8.077e-07, eta: 17:37:49, time: 2.230, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0802, decode.loss_mask: 0.2790, decode.loss_dice: 0.5909, decode.d0.loss_cls: 0.2340, decode.d0.loss_mask: 0.2805, decode.d0.loss_dice: 0.5954, decode.d1.loss_cls: 0.0731, decode.d1.loss_mask: 0.2789, decode.d1.loss_dice: 0.5870, decode.d2.loss_cls: 0.0787, decode.d2.loss_mask: 0.2795, decode.d2.loss_dice: 0.5803, decode.d3.loss_cls: 0.0905, decode.d3.loss_mask: 0.2790, decode.d3.loss_dice: 0.5859, decode.d4.loss_cls: 0.0871, decode.d4.loss_mask: 0.2788, decode.d4.loss_dice: 0.5919, decode.d5.loss_cls: 0.0864, decode.d5.loss_mask: 0.2788, decode.d5.loss_dice: 0.5876, decode.d6.loss_cls: 0.0760, decode.d6.loss_mask: 0.2801, decode.d6.loss_dice: 0.5903, decode.d7.loss_cls: 0.0766, decode.d7.loss_mask: 0.2805, decode.d7.loss_dice: 0.5944, decode.d8.loss_cls: 0.0842, decode.d8.loss_mask: 0.2778, decode.d8.loss_dice: 0.5795, loss: 9.6431
2023-09-28 22:34:21,256 - mmseg - INFO - Iter [17550/40000]	lr: 8.059e-07, eta: 17:34:50, time: 2.231, data_time: 0.034, memory: 21542, decode.loss_cls: 0.1039, decode.loss_mask: 0.2809, decode.loss_dice: 0.5915, decode.d0.loss_cls: 0.2205, decode.d0.loss_mask: 0.2953, decode.d0.loss_dice: 0.5958, decode.d1.loss_cls: 0.1190, decode.d1.loss_mask: 0.2804, decode.d1.loss_dice: 0.5897, decode.d2.loss_cls: 0.1106, decode.d2.loss_mask: 0.2799, decode.d2.loss_dice: 0.5869, decode.d3.loss_cls: 0.0936, decode.d3.loss_mask: 0.2784, decode.d3.loss_dice: 0.5785, decode.d4.loss_cls: 0.0894, decode.d4.loss_mask: 0.2806, decode.d4.loss_dice: 0.5863, decode.d5.loss_cls: 0.0980, decode.d5.loss_mask: 0.2824, decode.d5.loss_dice: 0.5782, decode.d6.loss_cls: 0.0896, decode.d6.loss_mask: 0.2809, decode.d6.loss_dice: 0.5833, decode.d7.loss_cls: 0.0849, decode.d7.loss_mask: 0.2808, decode.d7.loss_dice: 0.5886, decode.d8.loss_cls: 0.1020, decode.d8.loss_mask: 0.2827, decode.d8.loss_dice: 0.5849, loss: 9.7977
2023-09-28 22:36:14,435 - mmseg - INFO - Iter [17600/40000]	lr: 8.041e-07, eta: 17:31:54, time: 2.264, data_time: 0.081, memory: 21542, decode.loss_cls: 0.0769, decode.loss_mask: 0.2941, decode.loss_dice: 0.5920, decode.d0.loss_cls: 0.2289, decode.d0.loss_mask: 0.2985, decode.d0.loss_dice: 0.6069, decode.d1.loss_cls: 0.0809, decode.d1.loss_mask: 0.2959, decode.d1.loss_dice: 0.5870, decode.d2.loss_cls: 0.0920, decode.d2.loss_mask: 0.2955, decode.d2.loss_dice: 0.5764, decode.d3.loss_cls: 0.0839, decode.d3.loss_mask: 0.2956, decode.d3.loss_dice: 0.5899, decode.d4.loss_cls: 0.0699, decode.d4.loss_mask: 0.2945, decode.d4.loss_dice: 0.5842, decode.d5.loss_cls: 0.0844, decode.d5.loss_mask: 0.2956, decode.d5.loss_dice: 0.5918, decode.d6.loss_cls: 0.0845, decode.d6.loss_mask: 0.2924, decode.d6.loss_dice: 0.5833, decode.d7.loss_cls: 0.0794, decode.d7.loss_mask: 0.2948, decode.d7.loss_dice: 0.5787, decode.d8.loss_cls: 0.0644, decode.d8.loss_mask: 0.2943, decode.d8.loss_dice: 0.5807, loss: 9.7671
2023-09-28 22:38:05,751 - mmseg - INFO - Iter [17650/40000]	lr: 8.023e-07, eta: 17:28:55, time: 2.226, data_time: 0.035, memory: 21542, decode.loss_cls: 0.0746, decode.loss_mask: 0.2950, decode.loss_dice: 0.5502, decode.d0.loss_cls: 0.2363, decode.d0.loss_mask: 0.3047, decode.d0.loss_dice: 0.5603, decode.d1.loss_cls: 0.1024, decode.d1.loss_mask: 0.2932, decode.d1.loss_dice: 0.5514, decode.d2.loss_cls: 0.0885, decode.d2.loss_mask: 0.2972, decode.d2.loss_dice: 0.5495, decode.d3.loss_cls: 0.0842, decode.d3.loss_mask: 0.2967, decode.d3.loss_dice: 0.5535, decode.d4.loss_cls: 0.0761, decode.d4.loss_mask: 0.2959, decode.d4.loss_dice: 0.5595, decode.d5.loss_cls: 0.0704, decode.d5.loss_mask: 0.2944, decode.d5.loss_dice: 0.5532, decode.d6.loss_cls: 0.0826, decode.d6.loss_mask: 0.2935, decode.d6.loss_dice: 0.5557, decode.d7.loss_cls: 0.0864, decode.d7.loss_mask: 0.2951, decode.d7.loss_dice: 0.5413, decode.d8.loss_cls: 0.0768, decode.d8.loss_mask: 0.2942, decode.d8.loss_dice: 0.5389, loss: 9.4517
2023-09-28 22:39:57,279 - mmseg - INFO - Iter [17700/40000]	lr: 8.005e-07, eta: 17:25:58, time: 2.230, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0607, decode.loss_mask: 0.2509, decode.loss_dice: 0.5487, decode.d0.loss_cls: 0.2167, decode.d0.loss_mask: 0.2503, decode.d0.loss_dice: 0.5480, decode.d1.loss_cls: 0.0690, decode.d1.loss_mask: 0.2514, decode.d1.loss_dice: 0.5495, decode.d2.loss_cls: 0.0620, decode.d2.loss_mask: 0.2502, decode.d2.loss_dice: 0.5480, decode.d3.loss_cls: 0.0708, decode.d3.loss_mask: 0.2504, decode.d3.loss_dice: 0.5514, decode.d4.loss_cls: 0.0611, decode.d4.loss_mask: 0.2499, decode.d4.loss_dice: 0.5511, decode.d5.loss_cls: 0.0570, decode.d5.loss_mask: 0.2490, decode.d5.loss_dice: 0.5392, decode.d6.loss_cls: 0.0689, decode.d6.loss_mask: 0.2502, decode.d6.loss_dice: 0.5355, decode.d7.loss_cls: 0.0871, decode.d7.loss_mask: 0.2504, decode.d7.loss_dice: 0.5370, decode.d8.loss_cls: 0.0579, decode.d8.loss_mask: 0.2508, decode.d8.loss_dice: 0.5438, loss: 8.7670
2023-09-28 22:41:47,411 - mmseg - INFO - Iter [17750/40000]	lr: 7.987e-07, eta: 17:22:59, time: 2.203, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0690, decode.loss_mask: 0.2465, decode.loss_dice: 0.5421, decode.d0.loss_cls: 0.2243, decode.d0.loss_mask: 0.2481, decode.d0.loss_dice: 0.5519, decode.d1.loss_cls: 0.0921, decode.d1.loss_mask: 0.2476, decode.d1.loss_dice: 0.5337, decode.d2.loss_cls: 0.1058, decode.d2.loss_mask: 0.2471, decode.d2.loss_dice: 0.5422, decode.d3.loss_cls: 0.0930, decode.d3.loss_mask: 0.2473, decode.d3.loss_dice: 0.5322, decode.d4.loss_cls: 0.0734, decode.d4.loss_mask: 0.2473, decode.d4.loss_dice: 0.5354, decode.d5.loss_cls: 0.0756, decode.d5.loss_mask: 0.2474, decode.d5.loss_dice: 0.5372, decode.d6.loss_cls: 0.0688, decode.d6.loss_mask: 0.2480, decode.d6.loss_dice: 0.5383, decode.d7.loss_cls: 0.0745, decode.d7.loss_mask: 0.2476, decode.d7.loss_dice: 0.5324, decode.d8.loss_cls: 0.0796, decode.d8.loss_mask: 0.2478, decode.d8.loss_dice: 0.5331, loss: 8.8091
2023-09-28 22:43:38,823 - mmseg - INFO - Iter [17800/40000]	lr: 7.969e-07, eta: 17:20:02, time: 2.228, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0595, decode.loss_mask: 0.2715, decode.loss_dice: 0.5805, decode.d0.loss_cls: 0.2372, decode.d0.loss_mask: 0.2721, decode.d0.loss_dice: 0.5913, decode.d1.loss_cls: 0.0833, decode.d1.loss_mask: 0.2725, decode.d1.loss_dice: 0.5812, decode.d2.loss_cls: 0.0807, decode.d2.loss_mask: 0.2710, decode.d2.loss_dice: 0.5819, decode.d3.loss_cls: 0.0804, decode.d3.loss_mask: 0.2714, decode.d3.loss_dice: 0.5754, decode.d4.loss_cls: 0.0829, decode.d4.loss_mask: 0.2707, decode.d4.loss_dice: 0.5744, decode.d5.loss_cls: 0.0860, decode.d5.loss_mask: 0.2704, decode.d5.loss_dice: 0.5838, decode.d6.loss_cls: 0.0805, decode.d6.loss_mask: 0.2693, decode.d6.loss_dice: 0.5784, decode.d7.loss_cls: 0.0833, decode.d7.loss_mask: 0.2703, decode.d7.loss_dice: 0.5811, decode.d8.loss_cls: 0.0728, decode.d8.loss_mask: 0.2714, decode.d8.loss_dice: 0.5761, loss: 9.4611
2023-09-28 22:45:30,336 - mmseg - INFO - Iter [17850/40000]	lr: 7.951e-07, eta: 17:17:05, time: 2.230, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0681, decode.loss_mask: 0.2563, decode.loss_dice: 0.5507, decode.d0.loss_cls: 0.2149, decode.d0.loss_mask: 0.2637, decode.d0.loss_dice: 0.5464, decode.d1.loss_cls: 0.0652, decode.d1.loss_mask: 0.2649, decode.d1.loss_dice: 0.5498, decode.d2.loss_cls: 0.0698, decode.d2.loss_mask: 0.2570, decode.d2.loss_dice: 0.5464, decode.d3.loss_cls: 0.0753, decode.d3.loss_mask: 0.2616, decode.d3.loss_dice: 0.5497, decode.d4.loss_cls: 0.0722, decode.d4.loss_mask: 0.2624, decode.d4.loss_dice: 0.5521, decode.d5.loss_cls: 0.0735, decode.d5.loss_mask: 0.2627, decode.d5.loss_dice: 0.5529, decode.d6.loss_cls: 0.0675, decode.d6.loss_mask: 0.2635, decode.d6.loss_dice: 0.5536, decode.d7.loss_cls: 0.0690, decode.d7.loss_mask: 0.2624, decode.d7.loss_dice: 0.5529, decode.d8.loss_cls: 0.0725, decode.d8.loss_mask: 0.2641, decode.d8.loss_dice: 0.5555, loss: 8.9767
2023-09-28 22:47:21,374 - mmseg - INFO - Iter [17900/40000]	lr: 7.933e-07, eta: 17:14:08, time: 2.221, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0756, decode.loss_mask: 0.3013, decode.loss_dice: 0.6080, decode.d0.loss_cls: 0.2229, decode.d0.loss_mask: 0.3071, decode.d0.loss_dice: 0.6009, decode.d1.loss_cls: 0.0933, decode.d1.loss_mask: 0.3018, decode.d1.loss_dice: 0.6058, decode.d2.loss_cls: 0.0700, decode.d2.loss_mask: 0.3008, decode.d2.loss_dice: 0.6035, decode.d3.loss_cls: 0.0825, decode.d3.loss_mask: 0.2986, decode.d3.loss_dice: 0.6046, decode.d4.loss_cls: 0.0725, decode.d4.loss_mask: 0.3008, decode.d4.loss_dice: 0.6111, decode.d5.loss_cls: 0.0785, decode.d5.loss_mask: 0.3014, decode.d5.loss_dice: 0.6095, decode.d6.loss_cls: 0.1318, decode.d6.loss_mask: 0.2996, decode.d6.loss_dice: 0.5953, decode.d7.loss_cls: 0.0740, decode.d7.loss_mask: 0.2994, decode.d7.loss_dice: 0.5995, decode.d8.loss_cls: 0.0918, decode.d8.loss_mask: 0.3005, decode.d8.loss_dice: 0.6035, loss: 10.0459
2023-09-28 22:49:11,837 - mmseg - INFO - Iter [17950/40000]	lr: 7.915e-07, eta: 17:11:11, time: 2.209, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0742, decode.loss_mask: 0.2863, decode.loss_dice: 0.5747, decode.d0.loss_cls: 0.2376, decode.d0.loss_mask: 0.2865, decode.d0.loss_dice: 0.5634, decode.d1.loss_cls: 0.1273, decode.d1.loss_mask: 0.2837, decode.d1.loss_dice: 0.5588, decode.d2.loss_cls: 0.1319, decode.d2.loss_mask: 0.2842, decode.d2.loss_dice: 0.5636, decode.d3.loss_cls: 0.0905, decode.d3.loss_mask: 0.2861, decode.d3.loss_dice: 0.5695, decode.d4.loss_cls: 0.1195, decode.d4.loss_mask: 0.2848, decode.d4.loss_dice: 0.5684, decode.d5.loss_cls: 0.0962, decode.d5.loss_mask: 0.2866, decode.d5.loss_dice: 0.5652, decode.d6.loss_cls: 0.0796, decode.d6.loss_mask: 0.2858, decode.d6.loss_dice: 0.5696, decode.d7.loss_cls: 0.0951, decode.d7.loss_mask: 0.2837, decode.d7.loss_dice: 0.5607, decode.d8.loss_cls: 0.1199, decode.d8.loss_mask: 0.2862, decode.d8.loss_dice: 0.5715, loss: 9.6908
2023-09-28 22:51:02,794 - mmseg - INFO - Saving checkpoint at 18000 iterations
2023-09-28 22:51:22,812 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 22:51:22,813 - mmseg - INFO - Iter [18000/40000]	lr: 7.897e-07, eta: 17:08:39, time: 2.620, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0456, decode.loss_mask: 0.2904, decode.loss_dice: 0.5830, decode.d0.loss_cls: 0.2332, decode.d0.loss_mask: 0.2923, decode.d0.loss_dice: 0.5800, decode.d1.loss_cls: 0.0674, decode.d1.loss_mask: 0.2897, decode.d1.loss_dice: 0.5875, decode.d2.loss_cls: 0.0619, decode.d2.loss_mask: 0.2890, decode.d2.loss_dice: 0.5779, decode.d3.loss_cls: 0.0456, decode.d3.loss_mask: 0.2919, decode.d3.loss_dice: 0.5800, decode.d4.loss_cls: 0.0666, decode.d4.loss_mask: 0.2877, decode.d4.loss_dice: 0.5781, decode.d5.loss_cls: 0.0530, decode.d5.loss_mask: 0.2913, decode.d5.loss_dice: 0.5840, decode.d6.loss_cls: 0.0653, decode.d6.loss_mask: 0.2899, decode.d6.loss_dice: 0.5804, decode.d7.loss_cls: 0.0620, decode.d7.loss_mask: 0.2877, decode.d7.loss_dice: 0.5771, decode.d8.loss_cls: 0.0570, decode.d8.loss_mask: 0.2871, decode.d8.loss_dice: 0.5722, loss: 9.4548
2023-09-28 23:08:21,366 - mmseg - INFO - per class results:
2023-09-28 23:08:21,367 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 92.98 | 96.94 |
|    Sidewalk   | 69.96 | 80.61 |
|  Construction | 81.88 | 94.21 |
|     Fence     | 33.69 | 37.72 |
|      Pole     | 56.61 | 68.31 |
| Traffic Light |  66.5 | 80.64 |
|  Traffic Sign | 72.06 | 77.59 |
|     Nature    | 88.47 | 94.05 |
|      Sky      |  96.5 |  97.8 |
|     Person    | 39.59 | 43.88 |
|     Rider     | 10.18 | 68.73 |
|      Car      | 91.69 | 94.94 |
|   background  | 96.35 | 97.79 |
+---------------+-------+-------+
2023-09-28 23:08:21,367 - mmseg - INFO - Summary:
2023-09-28 23:08:21,367 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.44 | 68.96 | 79.48 |
+-------+-------+-------+
2023-09-28 23:08:21,369 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 23:08:21,369 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9444, mIoU: 0.6896, mAcc: 0.7948, IoU.Road: 0.9298, IoU.Sidewalk: 0.6996, IoU.Construction: 0.8188, IoU.Fence: 0.3369, IoU.Pole: 0.5661, IoU.Traffic Light: 0.6650, IoU.Traffic Sign: 0.7206, IoU.Nature: 0.8847, IoU.Sky: 0.9650, IoU.Person: 0.3959, IoU.Rider: 0.1018, IoU.Car: 0.9169, IoU.background: 0.9635, Acc.Road: 0.9694, Acc.Sidewalk: 0.8061, Acc.Construction: 0.9421, Acc.Fence: 0.3772, Acc.Pole: 0.6831, Acc.Traffic Light: 0.8064, Acc.Traffic Sign: 0.7759, Acc.Nature: 0.9405, Acc.Sky: 0.9780, Acc.Person: 0.4388, Acc.Rider: 0.6873, Acc.Car: 0.9494, Acc.background: 0.9779
2023-09-28 23:10:12,015 - mmseg - INFO - Iter [18050/40000]	lr: 7.879e-07, eta: 17:26:22, time: 22.584, data_time: 20.404, memory: 21542, decode.loss_cls: 0.0603, decode.loss_mask: 0.2717, decode.loss_dice: 0.5559, decode.d0.loss_cls: 0.2055, decode.d0.loss_mask: 0.2764, decode.d0.loss_dice: 0.5566, decode.d1.loss_cls: 0.0849, decode.d1.loss_mask: 0.2742, decode.d1.loss_dice: 0.5624, decode.d2.loss_cls: 0.0807, decode.d2.loss_mask: 0.2741, decode.d2.loss_dice: 0.5691, decode.d3.loss_cls: 0.0744, decode.d3.loss_mask: 0.2732, decode.d3.loss_dice: 0.5593, decode.d4.loss_cls: 0.0648, decode.d4.loss_mask: 0.2722, decode.d4.loss_dice: 0.5625, decode.d5.loss_cls: 0.0590, decode.d5.loss_mask: 0.2746, decode.d5.loss_dice: 0.5633, decode.d6.loss_cls: 0.0579, decode.d6.loss_mask: 0.2742, decode.d6.loss_dice: 0.5637, decode.d7.loss_cls: 0.0678, decode.d7.loss_mask: 0.2733, decode.d7.loss_dice: 0.5583, decode.d8.loss_cls: 0.0678, decode.d8.loss_mask: 0.2738, decode.d8.loss_dice: 0.5654, loss: 9.1774
2023-09-28 23:12:02,413 - mmseg - INFO - Iter [18100/40000]	lr: 7.861e-07, eta: 17:23:19, time: 2.208, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0806, decode.loss_mask: 0.2740, decode.loss_dice: 0.5307, decode.d0.loss_cls: 0.2335, decode.d0.loss_mask: 0.2809, decode.d0.loss_dice: 0.5405, decode.d1.loss_cls: 0.0793, decode.d1.loss_mask: 0.2732, decode.d1.loss_dice: 0.5408, decode.d2.loss_cls: 0.0797, decode.d2.loss_mask: 0.2758, decode.d2.loss_dice: 0.5354, decode.d3.loss_cls: 0.0661, decode.d3.loss_mask: 0.2738, decode.d3.loss_dice: 0.5325, decode.d4.loss_cls: 0.0740, decode.d4.loss_mask: 0.2732, decode.d4.loss_dice: 0.5351, decode.d5.loss_cls: 0.0779, decode.d5.loss_mask: 0.2755, decode.d5.loss_dice: 0.5396, decode.d6.loss_cls: 0.0991, decode.d6.loss_mask: 0.2718, decode.d6.loss_dice: 0.5425, decode.d7.loss_cls: 0.0793, decode.d7.loss_mask: 0.2731, decode.d7.loss_dice: 0.5349, decode.d8.loss_cls: 0.0791, decode.d8.loss_mask: 0.2743, decode.d8.loss_dice: 0.5343, loss: 9.0606
2023-09-28 23:13:53,773 - mmseg - INFO - Iter [18150/40000]	lr: 7.843e-07, eta: 17:20:18, time: 2.227, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0810, decode.loss_mask: 0.2907, decode.loss_dice: 0.5717, decode.d0.loss_cls: 0.2237, decode.d0.loss_mask: 0.2953, decode.d0.loss_dice: 0.5836, decode.d1.loss_cls: 0.1089, decode.d1.loss_mask: 0.2916, decode.d1.loss_dice: 0.5621, decode.d2.loss_cls: 0.0861, decode.d2.loss_mask: 0.2923, decode.d2.loss_dice: 0.5697, decode.d3.loss_cls: 0.0770, decode.d3.loss_mask: 0.2922, decode.d3.loss_dice: 0.5743, decode.d4.loss_cls: 0.0766, decode.d4.loss_mask: 0.2917, decode.d4.loss_dice: 0.5740, decode.d5.loss_cls: 0.0732, decode.d5.loss_mask: 0.2917, decode.d5.loss_dice: 0.5753, decode.d6.loss_cls: 0.0765, decode.d6.loss_mask: 0.2911, decode.d6.loss_dice: 0.5677, decode.d7.loss_cls: 0.0847, decode.d7.loss_mask: 0.2923, decode.d7.loss_dice: 0.5631, decode.d8.loss_cls: 0.0895, decode.d8.loss_mask: 0.2925, decode.d8.loss_dice: 0.5600, loss: 9.6002
2023-09-28 23:15:45,228 - mmseg - INFO - Iter [18200/40000]	lr: 7.825e-07, eta: 17:17:18, time: 2.229, data_time: 0.032, memory: 21542, decode.loss_cls: 0.1039, decode.loss_mask: 0.3078, decode.loss_dice: 0.6264, decode.d0.loss_cls: 0.2243, decode.d0.loss_mask: 0.3144, decode.d0.loss_dice: 0.6424, decode.d1.loss_cls: 0.0961, decode.d1.loss_mask: 0.3121, decode.d1.loss_dice: 0.6315, decode.d2.loss_cls: 0.1076, decode.d2.loss_mask: 0.3065, decode.d2.loss_dice: 0.6313, decode.d3.loss_cls: 0.1099, decode.d3.loss_mask: 0.3075, decode.d3.loss_dice: 0.6321, decode.d4.loss_cls: 0.1159, decode.d4.loss_mask: 0.3050, decode.d4.loss_dice: 0.6352, decode.d5.loss_cls: 0.1030, decode.d5.loss_mask: 0.3088, decode.d5.loss_dice: 0.6360, decode.d6.loss_cls: 0.1150, decode.d6.loss_mask: 0.3051, decode.d6.loss_dice: 0.6257, decode.d7.loss_cls: 0.1050, decode.d7.loss_mask: 0.3061, decode.d7.loss_dice: 0.6231, decode.d8.loss_cls: 0.1065, decode.d8.loss_mask: 0.3062, decode.d8.loss_dice: 0.6306, loss: 10.5811
2023-09-28 23:17:36,876 - mmseg - INFO - Iter [18250/40000]	lr: 7.807e-07, eta: 17:14:18, time: 2.233, data_time: 0.027, memory: 21542, decode.loss_cls: 0.1009, decode.loss_mask: 0.2664, decode.loss_dice: 0.5824, decode.d0.loss_cls: 0.2473, decode.d0.loss_mask: 0.2704, decode.d0.loss_dice: 0.5974, decode.d1.loss_cls: 0.1106, decode.d1.loss_mask: 0.2649, decode.d1.loss_dice: 0.6040, decode.d2.loss_cls: 0.1122, decode.d2.loss_mask: 0.2675, decode.d2.loss_dice: 0.5843, decode.d3.loss_cls: 0.0897, decode.d3.loss_mask: 0.2646, decode.d3.loss_dice: 0.5739, decode.d4.loss_cls: 0.1018, decode.d4.loss_mask: 0.2655, decode.d4.loss_dice: 0.5871, decode.d5.loss_cls: 0.1029, decode.d5.loss_mask: 0.2670, decode.d5.loss_dice: 0.5892, decode.d6.loss_cls: 0.0818, decode.d6.loss_mask: 0.2665, decode.d6.loss_dice: 0.5750, decode.d7.loss_cls: 0.0773, decode.d7.loss_mask: 0.2658, decode.d7.loss_dice: 0.5878, decode.d8.loss_cls: 0.0997, decode.d8.loss_mask: 0.2674, decode.d8.loss_dice: 0.5858, loss: 9.6571
2023-09-28 23:19:27,885 - mmseg - INFO - Iter [18300/40000]	lr: 7.790e-07, eta: 17:11:18, time: 2.220, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0856, decode.loss_mask: 0.2597, decode.loss_dice: 0.5469, decode.d0.loss_cls: 0.2327, decode.d0.loss_mask: 0.2631, decode.d0.loss_dice: 0.5667, decode.d1.loss_cls: 0.1045, decode.d1.loss_mask: 0.2586, decode.d1.loss_dice: 0.5720, decode.d2.loss_cls: 0.0832, decode.d2.loss_mask: 0.2593, decode.d2.loss_dice: 0.5613, decode.d3.loss_cls: 0.0927, decode.d3.loss_mask: 0.2592, decode.d3.loss_dice: 0.5510, decode.d4.loss_cls: 0.0750, decode.d4.loss_mask: 0.2672, decode.d4.loss_dice: 0.5562, decode.d5.loss_cls: 0.0992, decode.d5.loss_mask: 0.2594, decode.d5.loss_dice: 0.5564, decode.d6.loss_cls: 0.0754, decode.d6.loss_mask: 0.2578, decode.d6.loss_dice: 0.5503, decode.d7.loss_cls: 0.0839, decode.d7.loss_mask: 0.2570, decode.d7.loss_dice: 0.5587, decode.d8.loss_cls: 0.0735, decode.d8.loss_mask: 0.2572, decode.d8.loss_dice: 0.5595, loss: 9.1833
2023-09-28 23:21:18,483 - mmseg - INFO - Iter [18350/40000]	lr: 7.772e-07, eta: 17:08:18, time: 2.213, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0521, decode.loss_mask: 0.2535, decode.loss_dice: 0.5557, decode.d0.loss_cls: 0.1962, decode.d0.loss_mask: 0.2594, decode.d0.loss_dice: 0.5732, decode.d1.loss_cls: 0.0549, decode.d1.loss_mask: 0.2558, decode.d1.loss_dice: 0.5637, decode.d2.loss_cls: 0.0775, decode.d2.loss_mask: 0.2539, decode.d2.loss_dice: 0.5525, decode.d3.loss_cls: 0.0483, decode.d3.loss_mask: 0.2531, decode.d3.loss_dice: 0.5527, decode.d4.loss_cls: 0.0624, decode.d4.loss_mask: 0.2543, decode.d4.loss_dice: 0.5668, decode.d5.loss_cls: 0.0515, decode.d5.loss_mask: 0.2555, decode.d5.loss_dice: 0.5642, decode.d6.loss_cls: 0.0573, decode.d6.loss_mask: 0.2531, decode.d6.loss_dice: 0.5569, decode.d7.loss_cls: 0.0701, decode.d7.loss_mask: 0.2540, decode.d7.loss_dice: 0.5636, decode.d8.loss_cls: 0.0541, decode.d8.loss_mask: 0.2549, decode.d8.loss_dice: 0.5717, loss: 8.8930
2023-09-28 23:23:10,490 - mmseg - INFO - Iter [18400/40000]	lr: 7.754e-07, eta: 17:05:19, time: 2.240, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0781, decode.loss_mask: 0.2593, decode.loss_dice: 0.5669, decode.d0.loss_cls: 0.2142, decode.d0.loss_mask: 0.2599, decode.d0.loss_dice: 0.5739, decode.d1.loss_cls: 0.0804, decode.d1.loss_mask: 0.2554, decode.d1.loss_dice: 0.5745, decode.d2.loss_cls: 0.0935, decode.d2.loss_mask: 0.2570, decode.d2.loss_dice: 0.5657, decode.d3.loss_cls: 0.0681, decode.d3.loss_mask: 0.2587, decode.d3.loss_dice: 0.5727, decode.d4.loss_cls: 0.0805, decode.d4.loss_mask: 0.2594, decode.d4.loss_dice: 0.5772, decode.d5.loss_cls: 0.0702, decode.d5.loss_mask: 0.2586, decode.d5.loss_dice: 0.5752, decode.d6.loss_cls: 0.0790, decode.d6.loss_mask: 0.2580, decode.d6.loss_dice: 0.5700, decode.d7.loss_cls: 0.0646, decode.d7.loss_mask: 0.2582, decode.d7.loss_dice: 0.5778, decode.d8.loss_cls: 0.0742, decode.d8.loss_mask: 0.2583, decode.d8.loss_dice: 0.5739, loss: 9.2134
2023-09-28 23:25:00,968 - mmseg - INFO - Iter [18450/40000]	lr: 7.736e-07, eta: 17:02:20, time: 2.209, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0702, decode.loss_mask: 0.3109, decode.loss_dice: 0.5799, decode.d0.loss_cls: 0.2102, decode.d0.loss_mask: 0.3152, decode.d0.loss_dice: 0.5731, decode.d1.loss_cls: 0.0794, decode.d1.loss_mask: 0.3079, decode.d1.loss_dice: 0.5695, decode.d2.loss_cls: 0.0743, decode.d2.loss_mask: 0.3094, decode.d2.loss_dice: 0.5699, decode.d3.loss_cls: 0.0601, decode.d3.loss_mask: 0.3097, decode.d3.loss_dice: 0.5818, decode.d4.loss_cls: 0.0629, decode.d4.loss_mask: 0.3089, decode.d4.loss_dice: 0.5686, decode.d5.loss_cls: 0.0796, decode.d5.loss_mask: 0.3096, decode.d5.loss_dice: 0.5764, decode.d6.loss_cls: 0.0707, decode.d6.loss_mask: 0.3089, decode.d6.loss_dice: 0.5649, decode.d7.loss_cls: 0.0726, decode.d7.loss_mask: 0.3093, decode.d7.loss_dice: 0.5680, decode.d8.loss_cls: 0.0629, decode.d8.loss_mask: 0.3090, decode.d8.loss_dice: 0.5744, loss: 9.6683
2023-09-28 23:26:52,891 - mmseg - INFO - Iter [18500/40000]	lr: 7.718e-07, eta: 16:59:22, time: 2.238, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0670, decode.loss_mask: 0.2831, decode.loss_dice: 0.5441, decode.d0.loss_cls: 0.2084, decode.d0.loss_mask: 0.2881, decode.d0.loss_dice: 0.5541, decode.d1.loss_cls: 0.0794, decode.d1.loss_mask: 0.2824, decode.d1.loss_dice: 0.5469, decode.d2.loss_cls: 0.0798, decode.d2.loss_mask: 0.2837, decode.d2.loss_dice: 0.5372, decode.d3.loss_cls: 0.0731, decode.d3.loss_mask: 0.2831, decode.d3.loss_dice: 0.5429, decode.d4.loss_cls: 0.0734, decode.d4.loss_mask: 0.2822, decode.d4.loss_dice: 0.5411, decode.d5.loss_cls: 0.0802, decode.d5.loss_mask: 0.2832, decode.d5.loss_dice: 0.5422, decode.d6.loss_cls: 0.0729, decode.d6.loss_mask: 0.2844, decode.d6.loss_dice: 0.5452, decode.d7.loss_cls: 0.0616, decode.d7.loss_mask: 0.2839, decode.d7.loss_dice: 0.5466, decode.d8.loss_cls: 0.0822, decode.d8.loss_mask: 0.2841, decode.d8.loss_dice: 0.5474, loss: 9.1641
2023-09-28 23:28:44,729 - mmseg - INFO - Iter [18550/40000]	lr: 7.700e-07, eta: 16:56:25, time: 2.237, data_time: 0.026, memory: 21542, decode.loss_cls: 0.0797, decode.loss_mask: 0.2747, decode.loss_dice: 0.5911, decode.d0.loss_cls: 0.2153, decode.d0.loss_mask: 0.2803, decode.d0.loss_dice: 0.6029, decode.d1.loss_cls: 0.0867, decode.d1.loss_mask: 0.2758, decode.d1.loss_dice: 0.5974, decode.d2.loss_cls: 0.0801, decode.d2.loss_mask: 0.2750, decode.d2.loss_dice: 0.6013, decode.d3.loss_cls: 0.0802, decode.d3.loss_mask: 0.2746, decode.d3.loss_dice: 0.6096, decode.d4.loss_cls: 0.1110, decode.d4.loss_mask: 0.2755, decode.d4.loss_dice: 0.6036, decode.d5.loss_cls: 0.0753, decode.d5.loss_mask: 0.2743, decode.d5.loss_dice: 0.5934, decode.d6.loss_cls: 0.0893, decode.d6.loss_mask: 0.2764, decode.d6.loss_dice: 0.5818, decode.d7.loss_cls: 0.0725, decode.d7.loss_mask: 0.2761, decode.d7.loss_dice: 0.5925, decode.d8.loss_cls: 0.0785, decode.d8.loss_mask: 0.2754, decode.d8.loss_dice: 0.6015, loss: 9.7017
2023-09-28 23:30:35,271 - mmseg - INFO - Iter [18600/40000]	lr: 7.682e-07, eta: 16:53:26, time: 2.211, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0566, decode.loss_mask: 0.2881, decode.loss_dice: 0.6140, decode.d0.loss_cls: 0.2044, decode.d0.loss_mask: 0.2923, decode.d0.loss_dice: 0.6104, decode.d1.loss_cls: 0.0827, decode.d1.loss_mask: 0.2897, decode.d1.loss_dice: 0.6112, decode.d2.loss_cls: 0.0808, decode.d2.loss_mask: 0.2890, decode.d2.loss_dice: 0.5998, decode.d3.loss_cls: 0.0704, decode.d3.loss_mask: 0.2893, decode.d3.loss_dice: 0.6068, decode.d4.loss_cls: 0.0655, decode.d4.loss_mask: 0.2887, decode.d4.loss_dice: 0.5994, decode.d5.loss_cls: 0.0725, decode.d5.loss_mask: 0.2880, decode.d5.loss_dice: 0.6012, decode.d6.loss_cls: 0.0914, decode.d6.loss_mask: 0.2890, decode.d6.loss_dice: 0.6040, decode.d7.loss_cls: 0.0750, decode.d7.loss_mask: 0.2900, decode.d7.loss_dice: 0.5990, decode.d8.loss_cls: 0.0591, decode.d8.loss_mask: 0.2878, decode.d8.loss_dice: 0.6084, loss: 9.8046
2023-09-28 23:32:28,369 - mmseg - INFO - Iter [18650/40000]	lr: 7.664e-07, eta: 16:50:31, time: 2.262, data_time: 0.075, memory: 21542, decode.loss_cls: 0.0708, decode.loss_mask: 0.2945, decode.loss_dice: 0.5970, decode.d0.loss_cls: 0.2140, decode.d0.loss_mask: 0.3001, decode.d0.loss_dice: 0.6035, decode.d1.loss_cls: 0.0763, decode.d1.loss_mask: 0.2983, decode.d1.loss_dice: 0.6014, decode.d2.loss_cls: 0.0879, decode.d2.loss_mask: 0.2944, decode.d2.loss_dice: 0.5890, decode.d3.loss_cls: 0.0907, decode.d3.loss_mask: 0.2937, decode.d3.loss_dice: 0.5865, decode.d4.loss_cls: 0.0881, decode.d4.loss_mask: 0.2933, decode.d4.loss_dice: 0.5827, decode.d5.loss_cls: 0.0857, decode.d5.loss_mask: 0.2943, decode.d5.loss_dice: 0.5991, decode.d6.loss_cls: 0.0713, decode.d6.loss_mask: 0.2940, decode.d6.loss_dice: 0.5930, decode.d7.loss_cls: 0.0786, decode.d7.loss_mask: 0.2948, decode.d7.loss_dice: 0.5920, decode.d8.loss_cls: 0.0693, decode.d8.loss_mask: 0.2947, decode.d8.loss_dice: 0.5933, loss: 9.8224
2023-09-28 23:34:19,330 - mmseg - INFO - Iter [18700/40000]	lr: 7.646e-07, eta: 16:47:33, time: 2.219, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0697, decode.loss_mask: 0.2677, decode.loss_dice: 0.5462, decode.d0.loss_cls: 0.2117, decode.d0.loss_mask: 0.2696, decode.d0.loss_dice: 0.5458, decode.d1.loss_cls: 0.0634, decode.d1.loss_mask: 0.2690, decode.d1.loss_dice: 0.5550, decode.d2.loss_cls: 0.0716, decode.d2.loss_mask: 0.2695, decode.d2.loss_dice: 0.5439, decode.d3.loss_cls: 0.0655, decode.d3.loss_mask: 0.2669, decode.d3.loss_dice: 0.5465, decode.d4.loss_cls: 0.0727, decode.d4.loss_mask: 0.2671, decode.d4.loss_dice: 0.5564, decode.d5.loss_cls: 0.0699, decode.d5.loss_mask: 0.2691, decode.d5.loss_dice: 0.5496, decode.d6.loss_cls: 0.0690, decode.d6.loss_mask: 0.2678, decode.d6.loss_dice: 0.5526, decode.d7.loss_cls: 0.0635, decode.d7.loss_mask: 0.2678, decode.d7.loss_dice: 0.5495, decode.d8.loss_cls: 0.0645, decode.d8.loss_mask: 0.2683, decode.d8.loss_dice: 0.5536, loss: 9.0034
2023-09-28 23:36:10,253 - mmseg - INFO - Iter [18750/40000]	lr: 7.628e-07, eta: 16:44:36, time: 2.218, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0509, decode.loss_mask: 0.2568, decode.loss_dice: 0.5274, decode.d0.loss_cls: 0.2026, decode.d0.loss_mask: 0.2620, decode.d0.loss_dice: 0.5398, decode.d1.loss_cls: 0.0630, decode.d1.loss_mask: 0.2575, decode.d1.loss_dice: 0.5252, decode.d2.loss_cls: 0.0681, decode.d2.loss_mask: 0.2569, decode.d2.loss_dice: 0.5145, decode.d3.loss_cls: 0.0686, decode.d3.loss_mask: 0.2572, decode.d3.loss_dice: 0.5226, decode.d4.loss_cls: 0.0505, decode.d4.loss_mask: 0.2562, decode.d4.loss_dice: 0.5269, decode.d5.loss_cls: 0.0539, decode.d5.loss_mask: 0.2576, decode.d5.loss_dice: 0.5238, decode.d6.loss_cls: 0.0546, decode.d6.loss_mask: 0.2570, decode.d6.loss_dice: 0.5262, decode.d7.loss_cls: 0.0636, decode.d7.loss_mask: 0.2577, decode.d7.loss_dice: 0.5225, decode.d8.loss_cls: 0.0524, decode.d8.loss_mask: 0.2550, decode.d8.loss_dice: 0.5347, loss: 8.5658
2023-09-28 23:38:01,869 - mmseg - INFO - Iter [18800/40000]	lr: 7.610e-07, eta: 16:41:41, time: 2.232, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0853, decode.loss_mask: 0.2434, decode.loss_dice: 0.5447, decode.d0.loss_cls: 0.2263, decode.d0.loss_mask: 0.2445, decode.d0.loss_dice: 0.5517, decode.d1.loss_cls: 0.1177, decode.d1.loss_mask: 0.2445, decode.d1.loss_dice: 0.5429, decode.d2.loss_cls: 0.0995, decode.d2.loss_mask: 0.2442, decode.d2.loss_dice: 0.5570, decode.d3.loss_cls: 0.0901, decode.d3.loss_mask: 0.2434, decode.d3.loss_dice: 0.5533, decode.d4.loss_cls: 0.0742, decode.d4.loss_mask: 0.2430, decode.d4.loss_dice: 0.5434, decode.d5.loss_cls: 0.0901, decode.d5.loss_mask: 0.2418, decode.d5.loss_dice: 0.5557, decode.d6.loss_cls: 0.0869, decode.d6.loss_mask: 0.2423, decode.d6.loss_dice: 0.5427, decode.d7.loss_cls: 0.0899, decode.d7.loss_mask: 0.2418, decode.d7.loss_dice: 0.5369, decode.d8.loss_cls: 0.0944, decode.d8.loss_mask: 0.2426, decode.d8.loss_dice: 0.5461, loss: 8.9604
2023-09-28 23:39:53,338 - mmseg - INFO - Iter [18850/40000]	lr: 7.592e-07, eta: 16:38:45, time: 2.229, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0806, decode.loss_mask: 0.2852, decode.loss_dice: 0.5801, decode.d0.loss_cls: 0.2358, decode.d0.loss_mask: 0.2864, decode.d0.loss_dice: 0.5922, decode.d1.loss_cls: 0.0858, decode.d1.loss_mask: 0.2837, decode.d1.loss_dice: 0.5766, decode.d2.loss_cls: 0.0957, decode.d2.loss_mask: 0.2835, decode.d2.loss_dice: 0.5773, decode.d3.loss_cls: 0.0848, decode.d3.loss_mask: 0.2834, decode.d3.loss_dice: 0.5817, decode.d4.loss_cls: 0.0816, decode.d4.loss_mask: 0.2833, decode.d4.loss_dice: 0.5748, decode.d5.loss_cls: 0.0728, decode.d5.loss_mask: 0.2855, decode.d5.loss_dice: 0.5909, decode.d6.loss_cls: 0.0520, decode.d6.loss_mask: 0.2866, decode.d6.loss_dice: 0.5962, decode.d7.loss_cls: 0.0711, decode.d7.loss_mask: 0.2843, decode.d7.loss_dice: 0.5828, decode.d8.loss_cls: 0.0894, decode.d8.loss_mask: 0.2855, decode.d8.loss_dice: 0.5838, loss: 9.6331
2023-09-28 23:41:44,409 - mmseg - INFO - Iter [18900/40000]	lr: 7.574e-07, eta: 16:35:49, time: 2.221, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0659, decode.loss_mask: 0.2916, decode.loss_dice: 0.6005, decode.d0.loss_cls: 0.2304, decode.d0.loss_mask: 0.2974, decode.d0.loss_dice: 0.5940, decode.d1.loss_cls: 0.0659, decode.d1.loss_mask: 0.2935, decode.d1.loss_dice: 0.6003, decode.d2.loss_cls: 0.0610, decode.d2.loss_mask: 0.2924, decode.d2.loss_dice: 0.5956, decode.d3.loss_cls: 0.0609, decode.d3.loss_mask: 0.2914, decode.d3.loss_dice: 0.5922, decode.d4.loss_cls: 0.0655, decode.d4.loss_mask: 0.2905, decode.d4.loss_dice: 0.5990, decode.d5.loss_cls: 0.0582, decode.d5.loss_mask: 0.2888, decode.d5.loss_dice: 0.5953, decode.d6.loss_cls: 0.0624, decode.d6.loss_mask: 0.2905, decode.d6.loss_dice: 0.5948, decode.d7.loss_cls: 0.0546, decode.d7.loss_mask: 0.2910, decode.d7.loss_dice: 0.5988, decode.d8.loss_cls: 0.0526, decode.d8.loss_mask: 0.2905, decode.d8.loss_dice: 0.6052, loss: 9.6706
2023-09-28 23:43:36,324 - mmseg - INFO - Iter [18950/40000]	lr: 7.556e-07, eta: 16:32:54, time: 2.239, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0696, decode.loss_mask: 0.2762, decode.loss_dice: 0.6004, decode.d0.loss_cls: 0.2267, decode.d0.loss_mask: 0.2819, decode.d0.loss_dice: 0.5888, decode.d1.loss_cls: 0.0789, decode.d1.loss_mask: 0.2754, decode.d1.loss_dice: 0.5817, decode.d2.loss_cls: 0.0691, decode.d2.loss_mask: 0.2753, decode.d2.loss_dice: 0.5861, decode.d3.loss_cls: 0.0817, decode.d3.loss_mask: 0.2743, decode.d3.loss_dice: 0.5902, decode.d4.loss_cls: 0.0640, decode.d4.loss_mask: 0.2749, decode.d4.loss_dice: 0.5941, decode.d5.loss_cls: 0.0712, decode.d5.loss_mask: 0.2764, decode.d5.loss_dice: 0.5840, decode.d6.loss_cls: 0.0596, decode.d6.loss_mask: 0.2747, decode.d6.loss_dice: 0.5854, decode.d7.loss_cls: 0.0594, decode.d7.loss_mask: 0.2770, decode.d7.loss_dice: 0.5858, decode.d8.loss_cls: 0.0621, decode.d8.loss_mask: 0.2758, decode.d8.loss_dice: 0.5899, loss: 9.4906
2023-09-28 23:45:27,790 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-28 23:45:27,790 - mmseg - INFO - Iter [19000/40000]	lr: 7.538e-07, eta: 16:30:00, time: 2.229, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0964, decode.loss_mask: 0.2775, decode.loss_dice: 0.5838, decode.d0.loss_cls: 0.2202, decode.d0.loss_mask: 0.2787, decode.d0.loss_dice: 0.5936, decode.d1.loss_cls: 0.0808, decode.d1.loss_mask: 0.2774, decode.d1.loss_dice: 0.5984, decode.d2.loss_cls: 0.0845, decode.d2.loss_mask: 0.2761, decode.d2.loss_dice: 0.5875, decode.d3.loss_cls: 0.0665, decode.d3.loss_mask: 0.2785, decode.d3.loss_dice: 0.5936, decode.d4.loss_cls: 0.0625, decode.d4.loss_mask: 0.2797, decode.d4.loss_dice: 0.6102, decode.d5.loss_cls: 0.0779, decode.d5.loss_mask: 0.2788, decode.d5.loss_dice: 0.5994, decode.d6.loss_cls: 0.0910, decode.d6.loss_mask: 0.2773, decode.d6.loss_dice: 0.5989, decode.d7.loss_cls: 0.0853, decode.d7.loss_mask: 0.2781, decode.d7.loss_dice: 0.5909, decode.d8.loss_cls: 0.0797, decode.d8.loss_mask: 0.2775, decode.d8.loss_dice: 0.5991, loss: 9.6798
2023-09-28 23:47:18,921 - mmseg - INFO - Iter [19050/40000]	lr: 7.520e-07, eta: 16:27:05, time: 2.222, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0771, decode.loss_mask: 0.2699, decode.loss_dice: 0.5616, decode.d0.loss_cls: 0.2274, decode.d0.loss_mask: 0.2753, decode.d0.loss_dice: 0.5707, decode.d1.loss_cls: 0.0819, decode.d1.loss_mask: 0.2723, decode.d1.loss_dice: 0.5628, decode.d2.loss_cls: 0.0745, decode.d2.loss_mask: 0.2690, decode.d2.loss_dice: 0.5770, decode.d3.loss_cls: 0.0574, decode.d3.loss_mask: 0.2720, decode.d3.loss_dice: 0.5705, decode.d4.loss_cls: 0.0780, decode.d4.loss_mask: 0.2735, decode.d4.loss_dice: 0.5772, decode.d5.loss_cls: 0.0587, decode.d5.loss_mask: 0.2743, decode.d5.loss_dice: 0.5777, decode.d6.loss_cls: 0.0615, decode.d6.loss_mask: 0.2719, decode.d6.loss_dice: 0.5612, decode.d7.loss_cls: 0.0661, decode.d7.loss_mask: 0.2692, decode.d7.loss_dice: 0.5686, decode.d8.loss_cls: 0.0885, decode.d8.loss_mask: 0.2674, decode.d8.loss_dice: 0.5683, loss: 9.2817
2023-09-28 23:49:09,709 - mmseg - INFO - Iter [19100/40000]	lr: 7.502e-07, eta: 16:24:10, time: 2.216, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0593, decode.loss_mask: 0.3088, decode.loss_dice: 0.5782, decode.d0.loss_cls: 0.2135, decode.d0.loss_mask: 0.3199, decode.d0.loss_dice: 0.5719, decode.d1.loss_cls: 0.0482, decode.d1.loss_mask: 0.3100, decode.d1.loss_dice: 0.5724, decode.d2.loss_cls: 0.0622, decode.d2.loss_mask: 0.3106, decode.d2.loss_dice: 0.5768, decode.d3.loss_cls: 0.0787, decode.d3.loss_mask: 0.3066, decode.d3.loss_dice: 0.5625, decode.d4.loss_cls: 0.0760, decode.d4.loss_mask: 0.3094, decode.d4.loss_dice: 0.5710, decode.d5.loss_cls: 0.0729, decode.d5.loss_mask: 0.3066, decode.d5.loss_dice: 0.5662, decode.d6.loss_cls: 0.0627, decode.d6.loss_mask: 0.3059, decode.d6.loss_dice: 0.5717, decode.d7.loss_cls: 0.0481, decode.d7.loss_mask: 0.3092, decode.d7.loss_dice: 0.5780, decode.d8.loss_cls: 0.0700, decode.d8.loss_mask: 0.3075, decode.d8.loss_dice: 0.5665, loss: 9.6013
2023-09-28 23:51:00,813 - mmseg - INFO - Iter [19150/40000]	lr: 7.484e-07, eta: 16:21:16, time: 2.222, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0702, decode.loss_mask: 0.2875, decode.loss_dice: 0.5857, decode.d0.loss_cls: 0.2345, decode.d0.loss_mask: 0.2937, decode.d0.loss_dice: 0.5925, decode.d1.loss_cls: 0.1109, decode.d1.loss_mask: 0.2891, decode.d1.loss_dice: 0.5955, decode.d2.loss_cls: 0.0909, decode.d2.loss_mask: 0.2886, decode.d2.loss_dice: 0.5849, decode.d3.loss_cls: 0.1006, decode.d3.loss_mask: 0.2891, decode.d3.loss_dice: 0.6023, decode.d4.loss_cls: 0.1002, decode.d4.loss_mask: 0.2885, decode.d4.loss_dice: 0.5911, decode.d5.loss_cls: 0.0810, decode.d5.loss_mask: 0.2903, decode.d5.loss_dice: 0.5965, decode.d6.loss_cls: 0.0850, decode.d6.loss_mask: 0.2890, decode.d6.loss_dice: 0.5858, decode.d7.loss_cls: 0.0796, decode.d7.loss_mask: 0.2899, decode.d7.loss_dice: 0.5891, decode.d8.loss_cls: 0.0676, decode.d8.loss_mask: 0.2894, decode.d8.loss_dice: 0.5854, loss: 9.8243
2023-09-28 23:52:52,635 - mmseg - INFO - Iter [19200/40000]	lr: 7.466e-07, eta: 16:18:23, time: 2.237, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0645, decode.loss_mask: 0.2754, decode.loss_dice: 0.5688, decode.d0.loss_cls: 0.2358, decode.d0.loss_mask: 0.2796, decode.d0.loss_dice: 0.5769, decode.d1.loss_cls: 0.0976, decode.d1.loss_mask: 0.2755, decode.d1.loss_dice: 0.5580, decode.d2.loss_cls: 0.0730, decode.d2.loss_mask: 0.2776, decode.d2.loss_dice: 0.5600, decode.d3.loss_cls: 0.0818, decode.d3.loss_mask: 0.2762, decode.d3.loss_dice: 0.5611, decode.d4.loss_cls: 0.0782, decode.d4.loss_mask: 0.2760, decode.d4.loss_dice: 0.5588, decode.d5.loss_cls: 0.0846, decode.d5.loss_mask: 0.2767, decode.d5.loss_dice: 0.5712, decode.d6.loss_cls: 0.0684, decode.d6.loss_mask: 0.2754, decode.d6.loss_dice: 0.5756, decode.d7.loss_cls: 0.0584, decode.d7.loss_mask: 0.2772, decode.d7.loss_dice: 0.5662, decode.d8.loss_cls: 0.0722, decode.d8.loss_mask: 0.2769, decode.d8.loss_dice: 0.5683, loss: 9.3459
2023-09-28 23:54:44,030 - mmseg - INFO - Iter [19250/40000]	lr: 7.449e-07, eta: 16:15:30, time: 2.227, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0869, decode.loss_mask: 0.2899, decode.loss_dice: 0.6032, decode.d0.loss_cls: 0.2415, decode.d0.loss_mask: 0.2974, decode.d0.loss_dice: 0.6139, decode.d1.loss_cls: 0.0953, decode.d1.loss_mask: 0.2919, decode.d1.loss_dice: 0.5946, decode.d2.loss_cls: 0.1091, decode.d2.loss_mask: 0.2908, decode.d2.loss_dice: 0.5926, decode.d3.loss_cls: 0.0824, decode.d3.loss_mask: 0.2912, decode.d3.loss_dice: 0.6007, decode.d4.loss_cls: 0.0808, decode.d4.loss_mask: 0.2897, decode.d4.loss_dice: 0.5900, decode.d5.loss_cls: 0.0899, decode.d5.loss_mask: 0.2919, decode.d5.loss_dice: 0.5933, decode.d6.loss_cls: 0.0781, decode.d6.loss_mask: 0.2935, decode.d6.loss_dice: 0.5976, decode.d7.loss_cls: 0.0823, decode.d7.loss_mask: 0.2933, decode.d7.loss_dice: 0.6028, decode.d8.loss_cls: 0.0862, decode.d8.loss_mask: 0.2916, decode.d8.loss_dice: 0.5925, loss: 9.9349
2023-09-28 23:56:34,316 - mmseg - INFO - Iter [19300/40000]	lr: 7.431e-07, eta: 16:12:36, time: 2.206, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0779, decode.loss_mask: 0.2715, decode.loss_dice: 0.5248, decode.d0.loss_cls: 0.2437, decode.d0.loss_mask: 0.2750, decode.d0.loss_dice: 0.5357, decode.d1.loss_cls: 0.0820, decode.d1.loss_mask: 0.2725, decode.d1.loss_dice: 0.5307, decode.d2.loss_cls: 0.0822, decode.d2.loss_mask: 0.2711, decode.d2.loss_dice: 0.5296, decode.d3.loss_cls: 0.0655, decode.d3.loss_mask: 0.2719, decode.d3.loss_dice: 0.5248, decode.d4.loss_cls: 0.0676, decode.d4.loss_mask: 0.2734, decode.d4.loss_dice: 0.5299, decode.d5.loss_cls: 0.0729, decode.d5.loss_mask: 0.2739, decode.d5.loss_dice: 0.5309, decode.d6.loss_cls: 0.0717, decode.d6.loss_mask: 0.2741, decode.d6.loss_dice: 0.5209, decode.d7.loss_cls: 0.0772, decode.d7.loss_mask: 0.2723, decode.d7.loss_dice: 0.5344, decode.d8.loss_cls: 0.0658, decode.d8.loss_mask: 0.2723, decode.d8.loss_dice: 0.5278, loss: 8.9242
2023-09-28 23:58:25,694 - mmseg - INFO - Iter [19350/40000]	lr: 7.413e-07, eta: 16:09:43, time: 2.228, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0821, decode.loss_mask: 0.2790, decode.loss_dice: 0.5653, decode.d0.loss_cls: 0.2415, decode.d0.loss_mask: 0.2804, decode.d0.loss_dice: 0.5724, decode.d1.loss_cls: 0.1208, decode.d1.loss_mask: 0.2783, decode.d1.loss_dice: 0.5607, decode.d2.loss_cls: 0.0913, decode.d2.loss_mask: 0.2761, decode.d2.loss_dice: 0.5561, decode.d3.loss_cls: 0.0998, decode.d3.loss_mask: 0.2752, decode.d3.loss_dice: 0.5659, decode.d4.loss_cls: 0.0792, decode.d4.loss_mask: 0.2882, decode.d4.loss_dice: 0.5555, decode.d5.loss_cls: 0.0858, decode.d5.loss_mask: 0.2777, decode.d5.loss_dice: 0.5601, decode.d6.loss_cls: 0.0855, decode.d6.loss_mask: 0.2791, decode.d6.loss_dice: 0.5689, decode.d7.loss_cls: 0.0901, decode.d7.loss_mask: 0.2800, decode.d7.loss_dice: 0.5631, decode.d8.loss_cls: 0.0926, decode.d8.loss_mask: 0.2785, decode.d8.loss_dice: 0.5566, loss: 9.4855
2023-09-29 00:00:16,828 - mmseg - INFO - Iter [19400/40000]	lr: 7.395e-07, eta: 16:06:51, time: 2.223, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0711, decode.loss_mask: 0.2553, decode.loss_dice: 0.5708, decode.d0.loss_cls: 0.2214, decode.d0.loss_mask: 0.2569, decode.d0.loss_dice: 0.5817, decode.d1.loss_cls: 0.0946, decode.d1.loss_mask: 0.2580, decode.d1.loss_dice: 0.5694, decode.d2.loss_cls: 0.1020, decode.d2.loss_mask: 0.2571, decode.d2.loss_dice: 0.5760, decode.d3.loss_cls: 0.0772, decode.d3.loss_mask: 0.2545, decode.d3.loss_dice: 0.5706, decode.d4.loss_cls: 0.0772, decode.d4.loss_mask: 0.2544, decode.d4.loss_dice: 0.5640, decode.d5.loss_cls: 0.0725, decode.d5.loss_mask: 0.2548, decode.d5.loss_dice: 0.5798, decode.d6.loss_cls: 0.0754, decode.d6.loss_mask: 0.2561, decode.d6.loss_dice: 0.5723, decode.d7.loss_cls: 0.0893, decode.d7.loss_mask: 0.2566, decode.d7.loss_dice: 0.5651, decode.d8.loss_cls: 0.0881, decode.d8.loss_mask: 0.2550, decode.d8.loss_dice: 0.5711, loss: 9.2484
2023-09-29 00:02:07,866 - mmseg - INFO - Iter [19450/40000]	lr: 7.377e-07, eta: 16:03:59, time: 2.221, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0619, decode.loss_mask: 0.2953, decode.loss_dice: 0.5686, decode.d0.loss_cls: 0.2287, decode.d0.loss_mask: 0.2842, decode.d0.loss_dice: 0.5694, decode.d1.loss_cls: 0.0922, decode.d1.loss_mask: 0.3003, decode.d1.loss_dice: 0.5581, decode.d2.loss_cls: 0.0742, decode.d2.loss_mask: 0.2844, decode.d2.loss_dice: 0.5650, decode.d3.loss_cls: 0.0524, decode.d3.loss_mask: 0.2954, decode.d3.loss_dice: 0.5663, decode.d4.loss_cls: 0.0602, decode.d4.loss_mask: 0.2993, decode.d4.loss_dice: 0.5656, decode.d5.loss_cls: 0.0696, decode.d5.loss_mask: 0.2988, decode.d5.loss_dice: 0.5620, decode.d6.loss_cls: 0.0450, decode.d6.loss_mask: 0.2973, decode.d6.loss_dice: 0.5606, decode.d7.loss_cls: 0.0809, decode.d7.loss_mask: 0.2964, decode.d7.loss_dice: 0.5684, decode.d8.loss_cls: 0.0795, decode.d8.loss_mask: 0.2909, decode.d8.loss_dice: 0.5590, loss: 9.4299
2023-09-29 00:03:59,768 - mmseg - INFO - Iter [19500/40000]	lr: 7.359e-07, eta: 16:01:08, time: 2.238, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0755, decode.loss_mask: 0.3265, decode.loss_dice: 0.5700, decode.d0.loss_cls: 0.2716, decode.d0.loss_mask: 0.3316, decode.d0.loss_dice: 0.5731, decode.d1.loss_cls: 0.0953, decode.d1.loss_mask: 0.3237, decode.d1.loss_dice: 0.5843, decode.d2.loss_cls: 0.0814, decode.d2.loss_mask: 0.3289, decode.d2.loss_dice: 0.5897, decode.d3.loss_cls: 0.0902, decode.d3.loss_mask: 0.3257, decode.d3.loss_dice: 0.5807, decode.d4.loss_cls: 0.0950, decode.d4.loss_mask: 0.3252, decode.d4.loss_dice: 0.5829, decode.d5.loss_cls: 0.0912, decode.d5.loss_mask: 0.3250, decode.d5.loss_dice: 0.5815, decode.d6.loss_cls: 0.0923, decode.d6.loss_mask: 0.3168, decode.d6.loss_dice: 0.5763, decode.d7.loss_cls: 0.0898, decode.d7.loss_mask: 0.3262, decode.d7.loss_dice: 0.5761, decode.d8.loss_cls: 0.0828, decode.d8.loss_mask: 0.3197, decode.d8.loss_dice: 0.5828, loss: 10.1118
2023-09-29 00:05:51,142 - mmseg - INFO - Iter [19550/40000]	lr: 7.341e-07, eta: 15:58:16, time: 2.228, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0656, decode.loss_mask: 0.3017, decode.loss_dice: 0.5719, decode.d0.loss_cls: 0.2389, decode.d0.loss_mask: 0.3071, decode.d0.loss_dice: 0.5666, decode.d1.loss_cls: 0.0809, decode.d1.loss_mask: 0.3066, decode.d1.loss_dice: 0.5749, decode.d2.loss_cls: 0.0955, decode.d2.loss_mask: 0.3041, decode.d2.loss_dice: 0.5590, decode.d3.loss_cls: 0.0798, decode.d3.loss_mask: 0.3085, decode.d3.loss_dice: 0.5683, decode.d4.loss_cls: 0.0893, decode.d4.loss_mask: 0.3037, decode.d4.loss_dice: 0.5650, decode.d5.loss_cls: 0.0700, decode.d5.loss_mask: 0.3054, decode.d5.loss_dice: 0.5680, decode.d6.loss_cls: 0.0778, decode.d6.loss_mask: 0.3070, decode.d6.loss_dice: 0.5710, decode.d7.loss_cls: 0.0785, decode.d7.loss_mask: 0.3051, decode.d7.loss_dice: 0.5626, decode.d8.loss_cls: 0.0639, decode.d8.loss_mask: 0.3051, decode.d8.loss_dice: 0.5791, loss: 9.6812
2023-09-29 00:07:42,639 - mmseg - INFO - Iter [19600/40000]	lr: 7.323e-07, eta: 15:55:26, time: 2.230, data_time: 0.035, memory: 21542, decode.loss_cls: 0.0670, decode.loss_mask: 0.2550, decode.loss_dice: 0.5298, decode.d0.loss_cls: 0.2278, decode.d0.loss_mask: 0.2585, decode.d0.loss_dice: 0.5391, decode.d1.loss_cls: 0.0913, decode.d1.loss_mask: 0.2558, decode.d1.loss_dice: 0.5338, decode.d2.loss_cls: 0.0670, decode.d2.loss_mask: 0.2565, decode.d2.loss_dice: 0.5261, decode.d3.loss_cls: 0.0637, decode.d3.loss_mask: 0.2571, decode.d3.loss_dice: 0.5273, decode.d4.loss_cls: 0.0626, decode.d4.loss_mask: 0.2568, decode.d4.loss_dice: 0.5242, decode.d5.loss_cls: 0.0631, decode.d5.loss_mask: 0.2568, decode.d5.loss_dice: 0.5345, decode.d6.loss_cls: 0.0596, decode.d6.loss_mask: 0.2557, decode.d6.loss_dice: 0.5341, decode.d7.loss_cls: 0.0624, decode.d7.loss_mask: 0.2563, decode.d7.loss_dice: 0.5262, decode.d8.loss_cls: 0.0612, decode.d8.loss_mask: 0.2559, decode.d8.loss_dice: 0.5270, loss: 8.6920
2023-09-29 00:09:33,583 - mmseg - INFO - Iter [19650/40000]	lr: 7.305e-07, eta: 15:52:34, time: 2.219, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0885, decode.loss_mask: 0.2740, decode.loss_dice: 0.6020, decode.d0.loss_cls: 0.2318, decode.d0.loss_mask: 0.2771, decode.d0.loss_dice: 0.5995, decode.d1.loss_cls: 0.0609, decode.d1.loss_mask: 0.2739, decode.d1.loss_dice: 0.5976, decode.d2.loss_cls: 0.0793, decode.d2.loss_mask: 0.2735, decode.d2.loss_dice: 0.5920, decode.d3.loss_cls: 0.0928, decode.d3.loss_mask: 0.2698, decode.d3.loss_dice: 0.5857, decode.d4.loss_cls: 0.0899, decode.d4.loss_mask: 0.2714, decode.d4.loss_dice: 0.5995, decode.d5.loss_cls: 0.0733, decode.d5.loss_mask: 0.2700, decode.d5.loss_dice: 0.6001, decode.d6.loss_cls: 0.0796, decode.d6.loss_mask: 0.2712, decode.d6.loss_dice: 0.5925, decode.d7.loss_cls: 0.0784, decode.d7.loss_mask: 0.2718, decode.d7.loss_dice: 0.5932, decode.d8.loss_cls: 0.0965, decode.d8.loss_mask: 0.2718, decode.d8.loss_dice: 0.5944, loss: 9.6520
2023-09-29 00:11:24,728 - mmseg - INFO - Iter [19700/40000]	lr: 7.287e-07, eta: 15:49:44, time: 2.222, data_time: 0.036, memory: 21542, decode.loss_cls: 0.0861, decode.loss_mask: 0.2691, decode.loss_dice: 0.5693, decode.d0.loss_cls: 0.2504, decode.d0.loss_mask: 0.2687, decode.d0.loss_dice: 0.5734, decode.d1.loss_cls: 0.0768, decode.d1.loss_mask: 0.2704, decode.d1.loss_dice: 0.5751, decode.d2.loss_cls: 0.0834, decode.d2.loss_mask: 0.2688, decode.d2.loss_dice: 0.5708, decode.d3.loss_cls: 0.0792, decode.d3.loss_mask: 0.2688, decode.d3.loss_dice: 0.5602, decode.d4.loss_cls: 0.0839, decode.d4.loss_mask: 0.2739, decode.d4.loss_dice: 0.5744, decode.d5.loss_cls: 0.0790, decode.d5.loss_mask: 0.2730, decode.d5.loss_dice: 0.5624, decode.d6.loss_cls: 0.0812, decode.d6.loss_mask: 0.2654, decode.d6.loss_dice: 0.5726, decode.d7.loss_cls: 0.0770, decode.d7.loss_mask: 0.2677, decode.d7.loss_dice: 0.5695, decode.d8.loss_cls: 0.0817, decode.d8.loss_mask: 0.2706, decode.d8.loss_dice: 0.5723, loss: 9.3752
2023-09-29 00:13:18,646 - mmseg - INFO - Iter [19750/40000]	lr: 7.269e-07, eta: 15:46:56, time: 2.279, data_time: 0.074, memory: 21542, decode.loss_cls: 0.0610, decode.loss_mask: 0.2771, decode.loss_dice: 0.5653, decode.d0.loss_cls: 0.2046, decode.d0.loss_mask: 0.2846, decode.d0.loss_dice: 0.5685, decode.d1.loss_cls: 0.0711, decode.d1.loss_mask: 0.2743, decode.d1.loss_dice: 0.5716, decode.d2.loss_cls: 0.0584, decode.d2.loss_mask: 0.2756, decode.d2.loss_dice: 0.5696, decode.d3.loss_cls: 0.0800, decode.d3.loss_mask: 0.2744, decode.d3.loss_dice: 0.5813, decode.d4.loss_cls: 0.0637, decode.d4.loss_mask: 0.2742, decode.d4.loss_dice: 0.5767, decode.d5.loss_cls: 0.0556, decode.d5.loss_mask: 0.2757, decode.d5.loss_dice: 0.5796, decode.d6.loss_cls: 0.0652, decode.d6.loss_mask: 0.2741, decode.d6.loss_dice: 0.5718, decode.d7.loss_cls: 0.0711, decode.d7.loss_mask: 0.2778, decode.d7.loss_dice: 0.5723, decode.d8.loss_cls: 0.0712, decode.d8.loss_mask: 0.2741, decode.d8.loss_dice: 0.5581, loss: 9.2786
2023-09-29 00:15:10,344 - mmseg - INFO - Iter [19800/40000]	lr: 7.251e-07, eta: 15:44:07, time: 2.234, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0724, decode.loss_mask: 0.2936, decode.loss_dice: 0.5610, decode.d0.loss_cls: 0.2192, decode.d0.loss_mask: 0.2967, decode.d0.loss_dice: 0.5839, decode.d1.loss_cls: 0.0702, decode.d1.loss_mask: 0.2944, decode.d1.loss_dice: 0.5741, decode.d2.loss_cls: 0.0656, decode.d2.loss_mask: 0.2956, decode.d2.loss_dice: 0.5816, decode.d3.loss_cls: 0.0681, decode.d3.loss_mask: 0.2926, decode.d3.loss_dice: 0.5738, decode.d4.loss_cls: 0.0679, decode.d4.loss_mask: 0.2944, decode.d4.loss_dice: 0.5776, decode.d5.loss_cls: 0.0641, decode.d5.loss_mask: 0.2934, decode.d5.loss_dice: 0.5791, decode.d6.loss_cls: 0.0485, decode.d6.loss_mask: 0.2930, decode.d6.loss_dice: 0.5826, decode.d7.loss_cls: 0.0603, decode.d7.loss_mask: 0.2941, decode.d7.loss_dice: 0.5749, decode.d8.loss_cls: 0.0625, decode.d8.loss_mask: 0.2922, decode.d8.loss_dice: 0.5713, loss: 9.4985
2023-09-29 00:17:01,685 - mmseg - INFO - Iter [19850/40000]	lr: 7.233e-07, eta: 15:41:17, time: 2.227, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0872, decode.loss_mask: 0.2615, decode.loss_dice: 0.5481, decode.d0.loss_cls: 0.2106, decode.d0.loss_mask: 0.2655, decode.d0.loss_dice: 0.5760, decode.d1.loss_cls: 0.0835, decode.d1.loss_mask: 0.2639, decode.d1.loss_dice: 0.5526, decode.d2.loss_cls: 0.0901, decode.d2.loss_mask: 0.2631, decode.d2.loss_dice: 0.5454, decode.d3.loss_cls: 0.0663, decode.d3.loss_mask: 0.2628, decode.d3.loss_dice: 0.5498, decode.d4.loss_cls: 0.0852, decode.d4.loss_mask: 0.2618, decode.d4.loss_dice: 0.5485, decode.d5.loss_cls: 0.0858, decode.d5.loss_mask: 0.2620, decode.d5.loss_dice: 0.5477, decode.d6.loss_cls: 0.0755, decode.d6.loss_mask: 0.2619, decode.d6.loss_dice: 0.5543, decode.d7.loss_cls: 0.0839, decode.d7.loss_mask: 0.2626, decode.d7.loss_dice: 0.5584, decode.d8.loss_cls: 0.0839, decode.d8.loss_mask: 0.2608, decode.d8.loss_dice: 0.5461, loss: 9.1048
2023-09-29 00:18:51,867 - mmseg - INFO - Iter [19900/40000]	lr: 7.215e-07, eta: 15:38:27, time: 2.203, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0945, decode.loss_mask: 0.3209, decode.loss_dice: 0.6193, decode.d0.loss_cls: 0.2839, decode.d0.loss_mask: 0.3307, decode.d0.loss_dice: 0.6122, decode.d1.loss_cls: 0.1109, decode.d1.loss_mask: 0.3228, decode.d1.loss_dice: 0.6169, decode.d2.loss_cls: 0.1209, decode.d2.loss_mask: 0.3212, decode.d2.loss_dice: 0.6085, decode.d3.loss_cls: 0.1198, decode.d3.loss_mask: 0.3202, decode.d3.loss_dice: 0.6111, decode.d4.loss_cls: 0.1167, decode.d4.loss_mask: 0.3239, decode.d4.loss_dice: 0.6211, decode.d5.loss_cls: 0.1323, decode.d5.loss_mask: 0.3199, decode.d5.loss_dice: 0.6222, decode.d6.loss_cls: 0.1077, decode.d6.loss_mask: 0.3204, decode.d6.loss_dice: 0.6079, decode.d7.loss_cls: 0.1180, decode.d7.loss_mask: 0.3190, decode.d7.loss_dice: 0.6024, decode.d8.loss_cls: 0.1184, decode.d8.loss_mask: 0.3164, decode.d8.loss_dice: 0.6192, loss: 10.6794
2023-09-29 00:20:42,808 - mmseg - INFO - Iter [19950/40000]	lr: 7.197e-07, eta: 15:35:38, time: 2.219, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0692, decode.loss_mask: 0.2997, decode.loss_dice: 0.5815, decode.d0.loss_cls: 0.2248, decode.d0.loss_mask: 0.3075, decode.d0.loss_dice: 0.5839, decode.d1.loss_cls: 0.0738, decode.d1.loss_mask: 0.3029, decode.d1.loss_dice: 0.5860, decode.d2.loss_cls: 0.0716, decode.d2.loss_mask: 0.2954, decode.d2.loss_dice: 0.5828, decode.d3.loss_cls: 0.0629, decode.d3.loss_mask: 0.3007, decode.d3.loss_dice: 0.5839, decode.d4.loss_cls: 0.0684, decode.d4.loss_mask: 0.2961, decode.d4.loss_dice: 0.5894, decode.d5.loss_cls: 0.0641, decode.d5.loss_mask: 0.2990, decode.d5.loss_dice: 0.5797, decode.d6.loss_cls: 0.0617, decode.d6.loss_mask: 0.3004, decode.d6.loss_dice: 0.5902, decode.d7.loss_cls: 0.0806, decode.d7.loss_mask: 0.2994, decode.d7.loss_dice: 0.5896, decode.d8.loss_cls: 0.0649, decode.d8.loss_mask: 0.3026, decode.d8.loss_dice: 0.5792, loss: 9.6921
2023-09-29 00:22:33,830 - mmseg - INFO - Saving checkpoint at 20000 iterations
2023-09-29 00:22:53,787 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 00:22:53,788 - mmseg - INFO - Iter [20000/40000]	lr: 7.179e-07, eta: 15:33:09, time: 2.620, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0754, decode.loss_mask: 0.2865, decode.loss_dice: 0.6083, decode.d0.loss_cls: 0.2205, decode.d0.loss_mask: 0.2926, decode.d0.loss_dice: 0.6163, decode.d1.loss_cls: 0.0976, decode.d1.loss_mask: 0.2880, decode.d1.loss_dice: 0.5997, decode.d2.loss_cls: 0.0923, decode.d2.loss_mask: 0.2878, decode.d2.loss_dice: 0.6024, decode.d3.loss_cls: 0.0925, decode.d3.loss_mask: 0.2900, decode.d3.loss_dice: 0.5950, decode.d4.loss_cls: 0.0994, decode.d4.loss_mask: 0.2888, decode.d4.loss_dice: 0.6046, decode.d5.loss_cls: 0.0975, decode.d5.loss_mask: 0.2880, decode.d5.loss_dice: 0.6057, decode.d6.loss_cls: 0.0780, decode.d6.loss_mask: 0.2883, decode.d6.loss_dice: 0.6090, decode.d7.loss_cls: 0.0866, decode.d7.loss_mask: 0.2874, decode.d7.loss_dice: 0.5903, decode.d8.loss_cls: 0.0874, decode.d8.loss_mask: 0.2867, decode.d8.loss_dice: 0.5922, loss: 9.9349
2023-09-29 00:49:13,681 - mmseg - INFO - per class results:
2023-09-29 00:49:13,723 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 92.76 | 96.76 |
|    Sidewalk   | 66.44 | 82.68 |
|  Construction | 82.29 |  93.5 |
|     Fence     | 34.96 | 39.06 |
|      Pole     | 55.83 | 66.78 |
| Traffic Light | 65.38 | 79.87 |
|  Traffic Sign |  72.7 | 79.72 |
|     Nature    | 88.44 | 94.21 |
|      Sky      | 96.52 | 97.91 |
|     Person    | 40.09 | 43.54 |
|     Rider     |  8.75 | 56.89 |
|      Car      | 91.66 | 94.64 |
|   background  | 95.87 | 98.29 |
+---------------+-------+-------+
2023-09-29 00:49:13,744 - mmseg - INFO - Summary:
2023-09-29 00:49:13,745 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.43 | 68.59 | 78.76 |
+-------+-------+-------+
2023-09-29 00:49:13,774 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 00:49:13,774 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9443, mIoU: 0.6859, mAcc: 0.7876, IoU.Road: 0.9276, IoU.Sidewalk: 0.6644, IoU.Construction: 0.8229, IoU.Fence: 0.3496, IoU.Pole: 0.5583, IoU.Traffic Light: 0.6538, IoU.Traffic Sign: 0.7270, IoU.Nature: 0.8844, IoU.Sky: 0.9652, IoU.Person: 0.4009, IoU.Rider: 0.0875, IoU.Car: 0.9166, IoU.background: 0.9587, Acc.Road: 0.9676, Acc.Sidewalk: 0.8268, Acc.Construction: 0.9350, Acc.Fence: 0.3906, Acc.Pole: 0.6678, Acc.Traffic Light: 0.7987, Acc.Traffic Sign: 0.7972, Acc.Nature: 0.9421, Acc.Sky: 0.9791, Acc.Person: 0.4354, Acc.Rider: 0.5689, Acc.Car: 0.9464, Acc.background: 0.9829
2023-09-29 00:52:18,733 - mmseg - INFO - Iter [20050/40000]	lr: 7.161e-07, eta: 15:57:45, time: 35.299, data_time: 31.675, memory: 21542, decode.loss_cls: 0.0672, decode.loss_mask: 0.2652, decode.loss_dice: 0.5723, decode.d0.loss_cls: 0.2361, decode.d0.loss_mask: 0.2664, decode.d0.loss_dice: 0.5897, decode.d1.loss_cls: 0.0801, decode.d1.loss_mask: 0.2647, decode.d1.loss_dice: 0.5766, decode.d2.loss_cls: 0.0964, decode.d2.loss_mask: 0.2653, decode.d2.loss_dice: 0.5548, decode.d3.loss_cls: 0.0647, decode.d3.loss_mask: 0.2649, decode.d3.loss_dice: 0.5771, decode.d4.loss_cls: 0.0735, decode.d4.loss_mask: 0.2651, decode.d4.loss_dice: 0.5729, decode.d5.loss_cls: 0.0648, decode.d5.loss_mask: 0.2661, decode.d5.loss_dice: 0.5782, decode.d6.loss_cls: 0.0733, decode.d6.loss_mask: 0.2640, decode.d6.loss_dice: 0.5750, decode.d7.loss_cls: 0.0971, decode.d7.loss_mask: 0.2643, decode.d7.loss_dice: 0.5624, decode.d8.loss_cls: 0.0873, decode.d8.loss_mask: 0.2658, decode.d8.loss_dice: 0.5631, loss: 9.3144
2023-09-29 00:55:21,525 - mmseg - INFO - Iter [20100/40000]	lr: 7.143e-07, eta: 15:56:00, time: 3.656, data_time: 0.077, memory: 21542, decode.loss_cls: 0.0828, decode.loss_mask: 0.2908, decode.loss_dice: 0.5652, decode.d0.loss_cls: 0.2075, decode.d0.loss_mask: 0.2995, decode.d0.loss_dice: 0.5861, decode.d1.loss_cls: 0.0977, decode.d1.loss_mask: 0.2893, decode.d1.loss_dice: 0.5723, decode.d2.loss_cls: 0.0976, decode.d2.loss_mask: 0.2913, decode.d2.loss_dice: 0.5817, decode.d3.loss_cls: 0.0898, decode.d3.loss_mask: 0.2892, decode.d3.loss_dice: 0.5731, decode.d4.loss_cls: 0.0707, decode.d4.loss_mask: 0.2888, decode.d4.loss_dice: 0.5810, decode.d5.loss_cls: 0.0876, decode.d5.loss_mask: 0.2895, decode.d5.loss_dice: 0.5835, decode.d6.loss_cls: 0.0672, decode.d6.loss_mask: 0.2903, decode.d6.loss_dice: 0.5772, decode.d7.loss_cls: 0.0778, decode.d7.loss_mask: 0.2904, decode.d7.loss_dice: 0.5777, decode.d8.loss_cls: 0.0715, decode.d8.loss_mask: 0.2910, decode.d8.loss_dice: 0.5703, loss: 9.6286
2023-09-29 00:58:25,679 - mmseg - INFO - Iter [20150/40000]	lr: 7.125e-07, eta: 15:54:15, time: 3.682, data_time: 0.082, memory: 21542, decode.loss_cls: 0.0496, decode.loss_mask: 0.2906, decode.loss_dice: 0.5634, decode.d0.loss_cls: 0.2055, decode.d0.loss_mask: 0.2996, decode.d0.loss_dice: 0.5529, decode.d1.loss_cls: 0.0704, decode.d1.loss_mask: 0.2960, decode.d1.loss_dice: 0.5663, decode.d2.loss_cls: 0.0584, decode.d2.loss_mask: 0.2975, decode.d2.loss_dice: 0.5601, decode.d3.loss_cls: 0.0568, decode.d3.loss_mask: 0.2937, decode.d3.loss_dice: 0.5603, decode.d4.loss_cls: 0.0479, decode.d4.loss_mask: 0.2918, decode.d4.loss_dice: 0.5630, decode.d5.loss_cls: 0.0472, decode.d5.loss_mask: 0.2915, decode.d5.loss_dice: 0.5579, decode.d6.loss_cls: 0.0416, decode.d6.loss_mask: 0.2900, decode.d6.loss_dice: 0.5581, decode.d7.loss_cls: 0.0494, decode.d7.loss_mask: 0.2914, decode.d7.loss_dice: 0.5622, decode.d8.loss_cls: 0.0443, decode.d8.loss_mask: 0.2919, decode.d8.loss_dice: 0.5640, loss: 9.2133
2023-09-29 01:01:43,527 - mmseg - INFO - Iter [20200/40000]	lr: 7.108e-07, eta: 15:52:43, time: 3.957, data_time: 0.084, memory: 21542, decode.loss_cls: 0.0514, decode.loss_mask: 0.2771, decode.loss_dice: 0.5546, decode.d0.loss_cls: 0.2093, decode.d0.loss_mask: 0.2855, decode.d0.loss_dice: 0.5657, decode.d1.loss_cls: 0.0651, decode.d1.loss_mask: 0.2808, decode.d1.loss_dice: 0.5472, decode.d2.loss_cls: 0.0467, decode.d2.loss_mask: 0.2795, decode.d2.loss_dice: 0.5527, decode.d3.loss_cls: 0.0528, decode.d3.loss_mask: 0.2756, decode.d3.loss_dice: 0.5500, decode.d4.loss_cls: 0.0544, decode.d4.loss_mask: 0.2762, decode.d4.loss_dice: 0.5476, decode.d5.loss_cls: 0.0515, decode.d5.loss_mask: 0.2774, decode.d5.loss_dice: 0.5423, decode.d6.loss_cls: 0.0555, decode.d6.loss_mask: 0.2776, decode.d6.loss_dice: 0.5463, decode.d7.loss_cls: 0.0627, decode.d7.loss_mask: 0.2790, decode.d7.loss_dice: 0.5500, decode.d8.loss_cls: 0.0446, decode.d8.loss_mask: 0.2794, decode.d8.loss_dice: 0.5448, loss: 8.9832
2023-09-29 01:04:46,356 - mmseg - INFO - Iter [20250/40000]	lr: 7.090e-07, eta: 15:50:57, time: 3.657, data_time: 0.079, memory: 21542, decode.loss_cls: 0.0694, decode.loss_mask: 0.2870, decode.loss_dice: 0.5326, decode.d0.loss_cls: 0.2134, decode.d0.loss_mask: 0.2861, decode.d0.loss_dice: 0.5402, decode.d1.loss_cls: 0.0750, decode.d1.loss_mask: 0.2883, decode.d1.loss_dice: 0.5265, decode.d2.loss_cls: 0.0752, decode.d2.loss_mask: 0.2871, decode.d2.loss_dice: 0.5315, decode.d3.loss_cls: 0.0708, decode.d3.loss_mask: 0.2873, decode.d3.loss_dice: 0.5337, decode.d4.loss_cls: 0.0599, decode.d4.loss_mask: 0.2888, decode.d4.loss_dice: 0.5342, decode.d5.loss_cls: 0.0626, decode.d5.loss_mask: 0.2890, decode.d5.loss_dice: 0.5318, decode.d6.loss_cls: 0.0589, decode.d6.loss_mask: 0.2879, decode.d6.loss_dice: 0.5348, decode.d7.loss_cls: 0.0688, decode.d7.loss_mask: 0.2880, decode.d7.loss_dice: 0.5300, decode.d8.loss_cls: 0.0633, decode.d8.loss_mask: 0.2888, decode.d8.loss_dice: 0.5366, loss: 9.0274
2023-09-29 01:07:49,783 - mmseg - INFO - Iter [20300/40000]	lr: 7.072e-07, eta: 15:49:10, time: 3.669, data_time: 0.073, memory: 21542, decode.loss_cls: 0.0644, decode.loss_mask: 0.2427, decode.loss_dice: 0.5256, decode.d0.loss_cls: 0.2098, decode.d0.loss_mask: 0.2423, decode.d0.loss_dice: 0.5285, decode.d1.loss_cls: 0.0717, decode.d1.loss_mask: 0.2444, decode.d1.loss_dice: 0.5410, decode.d2.loss_cls: 0.0781, decode.d2.loss_mask: 0.2429, decode.d2.loss_dice: 0.5227, decode.d3.loss_cls: 0.0596, decode.d3.loss_mask: 0.2440, decode.d3.loss_dice: 0.5184, decode.d4.loss_cls: 0.0655, decode.d4.loss_mask: 0.2429, decode.d4.loss_dice: 0.5196, decode.d5.loss_cls: 0.0558, decode.d5.loss_mask: 0.2430, decode.d5.loss_dice: 0.5270, decode.d6.loss_cls: 0.0698, decode.d6.loss_mask: 0.2437, decode.d6.loss_dice: 0.5320, decode.d7.loss_cls: 0.0620, decode.d7.loss_mask: 0.2428, decode.d7.loss_dice: 0.5320, decode.d8.loss_cls: 0.0707, decode.d8.loss_mask: 0.2426, decode.d8.loss_dice: 0.5210, loss: 8.5063
2023-09-29 01:10:53,142 - mmseg - INFO - Iter [20350/40000]	lr: 7.054e-07, eta: 15:47:23, time: 3.667, data_time: 0.077, memory: 21542, decode.loss_cls: 0.0894, decode.loss_mask: 0.2741, decode.loss_dice: 0.5555, decode.d0.loss_cls: 0.2281, decode.d0.loss_mask: 0.2806, decode.d0.loss_dice: 0.5753, decode.d1.loss_cls: 0.0853, decode.d1.loss_mask: 0.2744, decode.d1.loss_dice: 0.5612, decode.d2.loss_cls: 0.0643, decode.d2.loss_mask: 0.2769, decode.d2.loss_dice: 0.5592, decode.d3.loss_cls: 0.0797, decode.d3.loss_mask: 0.2722, decode.d3.loss_dice: 0.5542, decode.d4.loss_cls: 0.0550, decode.d4.loss_mask: 0.2769, decode.d4.loss_dice: 0.5650, decode.d5.loss_cls: 0.0725, decode.d5.loss_mask: 0.2767, decode.d5.loss_dice: 0.5626, decode.d6.loss_cls: 0.0641, decode.d6.loss_mask: 0.2730, decode.d6.loss_dice: 0.5680, decode.d7.loss_cls: 0.0660, decode.d7.loss_mask: 0.2725, decode.d7.loss_dice: 0.5631, decode.d8.loss_cls: 0.0664, decode.d8.loss_mask: 0.2738, decode.d8.loss_dice: 0.5564, loss: 9.2424
2023-09-29 01:14:10,317 - mmseg - INFO - Iter [20400/40000]	lr: 7.036e-07, eta: 15:45:49, time: 3.943, data_time: 0.090, memory: 21542, decode.loss_cls: 0.0910, decode.loss_mask: 0.2794, decode.loss_dice: 0.5698, decode.d0.loss_cls: 0.2511, decode.d0.loss_mask: 0.2909, decode.d0.loss_dice: 0.5877, decode.d1.loss_cls: 0.1125, decode.d1.loss_mask: 0.2829, decode.d1.loss_dice: 0.5753, decode.d2.loss_cls: 0.1070, decode.d2.loss_mask: 0.2831, decode.d2.loss_dice: 0.5775, decode.d3.loss_cls: 0.0850, decode.d3.loss_mask: 0.2828, decode.d3.loss_dice: 0.5746, decode.d4.loss_cls: 0.0785, decode.d4.loss_mask: 0.2822, decode.d4.loss_dice: 0.5845, decode.d5.loss_cls: 0.0667, decode.d5.loss_mask: 0.2879, decode.d5.loss_dice: 0.5839, decode.d6.loss_cls: 0.0694, decode.d6.loss_mask: 0.2887, decode.d6.loss_dice: 0.5852, decode.d7.loss_cls: 0.0782, decode.d7.loss_mask: 0.2835, decode.d7.loss_dice: 0.5781, decode.d8.loss_cls: 0.0787, decode.d8.loss_mask: 0.2826, decode.d8.loss_dice: 0.5794, loss: 9.6582
2023-09-29 01:17:14,738 - mmseg - INFO - Iter [20450/40000]	lr: 7.018e-07, eta: 15:44:02, time: 3.688, data_time: 0.074, memory: 21542, decode.loss_cls: 0.0615, decode.loss_mask: 0.2574, decode.loss_dice: 0.5245, decode.d0.loss_cls: 0.2228, decode.d0.loss_mask: 0.2573, decode.d0.loss_dice: 0.5293, decode.d1.loss_cls: 0.0823, decode.d1.loss_mask: 0.2568, decode.d1.loss_dice: 0.5225, decode.d2.loss_cls: 0.0833, decode.d2.loss_mask: 0.2562, decode.d2.loss_dice: 0.5108, decode.d3.loss_cls: 0.0775, decode.d3.loss_mask: 0.2555, decode.d3.loss_dice: 0.5131, decode.d4.loss_cls: 0.0674, decode.d4.loss_mask: 0.2572, decode.d4.loss_dice: 0.5224, decode.d5.loss_cls: 0.0789, decode.d5.loss_mask: 0.2561, decode.d5.loss_dice: 0.5166, decode.d6.loss_cls: 0.0637, decode.d6.loss_mask: 0.2563, decode.d6.loss_dice: 0.5230, decode.d7.loss_cls: 0.0596, decode.d7.loss_mask: 0.2572, decode.d7.loss_dice: 0.5265, decode.d8.loss_cls: 0.0811, decode.d8.loss_mask: 0.2584, decode.d8.loss_dice: 0.5188, loss: 8.6541
2023-09-29 01:20:18,185 - mmseg - INFO - Iter [20500/40000]	lr: 7.000e-07, eta: 15:42:14, time: 3.669, data_time: 0.080, memory: 21542, decode.loss_cls: 0.0447, decode.loss_mask: 0.2813, decode.loss_dice: 0.5728, decode.d0.loss_cls: 0.2236, decode.d0.loss_mask: 0.2852, decode.d0.loss_dice: 0.5782, decode.d1.loss_cls: 0.0464, decode.d1.loss_mask: 0.2828, decode.d1.loss_dice: 0.5663, decode.d2.loss_cls: 0.0458, decode.d2.loss_mask: 0.2811, decode.d2.loss_dice: 0.5693, decode.d3.loss_cls: 0.0578, decode.d3.loss_mask: 0.2829, decode.d3.loss_dice: 0.5741, decode.d4.loss_cls: 0.0710, decode.d4.loss_mask: 0.2804, decode.d4.loss_dice: 0.5826, decode.d5.loss_cls: 0.0448, decode.d5.loss_mask: 0.2822, decode.d5.loss_dice: 0.5757, decode.d6.loss_cls: 0.0601, decode.d6.loss_mask: 0.2830, decode.d6.loss_dice: 0.5784, decode.d7.loss_cls: 0.0381, decode.d7.loss_mask: 0.2813, decode.d7.loss_dice: 0.5660, decode.d8.loss_cls: 0.0472, decode.d8.loss_mask: 0.2821, decode.d8.loss_dice: 0.5764, loss: 9.2416
2023-09-29 01:23:22,760 - mmseg - INFO - Iter [20550/40000]	lr: 6.982e-07, eta: 15:40:26, time: 3.691, data_time: 0.074, memory: 21542, decode.loss_cls: 0.0705, decode.loss_mask: 0.2587, decode.loss_dice: 0.5529, decode.d0.loss_cls: 0.2269, decode.d0.loss_mask: 0.2561, decode.d0.loss_dice: 0.5749, decode.d1.loss_cls: 0.0921, decode.d1.loss_mask: 0.2585, decode.d1.loss_dice: 0.5556, decode.d2.loss_cls: 0.0840, decode.d2.loss_mask: 0.2577, decode.d2.loss_dice: 0.5558, decode.d3.loss_cls: 0.0807, decode.d3.loss_mask: 0.2586, decode.d3.loss_dice: 0.5479, decode.d4.loss_cls: 0.0764, decode.d4.loss_mask: 0.2598, decode.d4.loss_dice: 0.5640, decode.d5.loss_cls: 0.0683, decode.d5.loss_mask: 0.2593, decode.d5.loss_dice: 0.5455, decode.d6.loss_cls: 0.0818, decode.d6.loss_mask: 0.2599, decode.d6.loss_dice: 0.5550, decode.d7.loss_cls: 0.0791, decode.d7.loss_mask: 0.2598, decode.d7.loss_dice: 0.5567, decode.d8.loss_cls: 0.0729, decode.d8.loss_mask: 0.2607, decode.d8.loss_dice: 0.5608, loss: 9.0910
2023-09-29 01:26:42,146 - mmseg - INFO - Iter [20600/40000]	lr: 6.964e-07, eta: 15:38:52, time: 3.987, data_time: 0.087, memory: 21542, decode.loss_cls: 0.0794, decode.loss_mask: 0.2923, decode.loss_dice: 0.5964, decode.d0.loss_cls: 0.2389, decode.d0.loss_mask: 0.2891, decode.d0.loss_dice: 0.6170, decode.d1.loss_cls: 0.0900, decode.d1.loss_mask: 0.2931, decode.d1.loss_dice: 0.5926, decode.d2.loss_cls: 0.0921, decode.d2.loss_mask: 0.2961, decode.d2.loss_dice: 0.6052, decode.d3.loss_cls: 0.0677, decode.d3.loss_mask: 0.2929, decode.d3.loss_dice: 0.5941, decode.d4.loss_cls: 0.0861, decode.d4.loss_mask: 0.2955, decode.d4.loss_dice: 0.6067, decode.d5.loss_cls: 0.0973, decode.d5.loss_mask: 0.2939, decode.d5.loss_dice: 0.6034, decode.d6.loss_cls: 0.0821, decode.d6.loss_mask: 0.2936, decode.d6.loss_dice: 0.6013, decode.d7.loss_cls: 0.0945, decode.d7.loss_mask: 0.2926, decode.d7.loss_dice: 0.5937, decode.d8.loss_cls: 0.0806, decode.d8.loss_mask: 0.2942, decode.d8.loss_dice: 0.6003, loss: 9.9528
2023-09-29 01:29:44,435 - mmseg - INFO - Iter [20650/40000]	lr: 6.946e-07, eta: 15:37:02, time: 3.643, data_time: 0.079, memory: 21542, decode.loss_cls: 0.0679, decode.loss_mask: 0.3026, decode.loss_dice: 0.5626, decode.d0.loss_cls: 0.2356, decode.d0.loss_mask: 0.3079, decode.d0.loss_dice: 0.5606, decode.d1.loss_cls: 0.0777, decode.d1.loss_mask: 0.3037, decode.d1.loss_dice: 0.5787, decode.d2.loss_cls: 0.0777, decode.d2.loss_mask: 0.3034, decode.d2.loss_dice: 0.5777, decode.d3.loss_cls: 0.0773, decode.d3.loss_mask: 0.3029, decode.d3.loss_dice: 0.5725, decode.d4.loss_cls: 0.0643, decode.d4.loss_mask: 0.3012, decode.d4.loss_dice: 0.5768, decode.d5.loss_cls: 0.0677, decode.d5.loss_mask: 0.3025, decode.d5.loss_dice: 0.5647, decode.d6.loss_cls: 0.0657, decode.d6.loss_mask: 0.3045, decode.d6.loss_dice: 0.5697, decode.d7.loss_cls: 0.0835, decode.d7.loss_mask: 0.3036, decode.d7.loss_dice: 0.5680, decode.d8.loss_cls: 0.0851, decode.d8.loss_mask: 0.3054, decode.d8.loss_dice: 0.5656, loss: 9.6371
2023-09-29 01:32:46,775 - mmseg - INFO - Iter [20700/40000]	lr: 6.928e-07, eta: 15:35:11, time: 3.650, data_time: 0.083, memory: 21542, decode.loss_cls: 0.0587, decode.loss_mask: 0.2798, decode.loss_dice: 0.5313, decode.d0.loss_cls: 0.2248, decode.d0.loss_mask: 0.2854, decode.d0.loss_dice: 0.5312, decode.d1.loss_cls: 0.0663, decode.d1.loss_mask: 0.2819, decode.d1.loss_dice: 0.5278, decode.d2.loss_cls: 0.0627, decode.d2.loss_mask: 0.2791, decode.d2.loss_dice: 0.5266, decode.d3.loss_cls: 0.0768, decode.d3.loss_mask: 0.2772, decode.d3.loss_dice: 0.5269, decode.d4.loss_cls: 0.0542, decode.d4.loss_mask: 0.2802, decode.d4.loss_dice: 0.5246, decode.d5.loss_cls: 0.0590, decode.d5.loss_mask: 0.2795, decode.d5.loss_dice: 0.5309, decode.d6.loss_cls: 0.0511, decode.d6.loss_mask: 0.2830, decode.d6.loss_dice: 0.5309, decode.d7.loss_cls: 0.0527, decode.d7.loss_mask: 0.2799, decode.d7.loss_dice: 0.5236, decode.d8.loss_cls: 0.0501, decode.d8.loss_mask: 0.2809, decode.d8.loss_dice: 0.5269, loss: 8.8438
2023-09-29 01:35:52,565 - mmseg - INFO - Iter [20750/40000]	lr: 6.910e-07, eta: 15:33:23, time: 3.716, data_time: 0.075, memory: 21542, decode.loss_cls: 0.0483, decode.loss_mask: 0.2684, decode.loss_dice: 0.5343, decode.d0.loss_cls: 0.2170, decode.d0.loss_mask: 0.2733, decode.d0.loss_dice: 0.5397, decode.d1.loss_cls: 0.0737, decode.d1.loss_mask: 0.2687, decode.d1.loss_dice: 0.5308, decode.d2.loss_cls: 0.0524, decode.d2.loss_mask: 0.2674, decode.d2.loss_dice: 0.5367, decode.d3.loss_cls: 0.0483, decode.d3.loss_mask: 0.2695, decode.d3.loss_dice: 0.5297, decode.d4.loss_cls: 0.0499, decode.d4.loss_mask: 0.2691, decode.d4.loss_dice: 0.5376, decode.d5.loss_cls: 0.0609, decode.d5.loss_mask: 0.2693, decode.d5.loss_dice: 0.5354, decode.d6.loss_cls: 0.0674, decode.d6.loss_mask: 0.2688, decode.d6.loss_dice: 0.5315, decode.d7.loss_cls: 0.0637, decode.d7.loss_mask: 0.2675, decode.d7.loss_dice: 0.5328, decode.d8.loss_cls: 0.0595, decode.d8.loss_mask: 0.2673, decode.d8.loss_dice: 0.5313, loss: 8.7700
2023-09-29 01:39:06,682 - mmseg - INFO - Iter [20800/40000]	lr: 6.892e-07, eta: 15:31:43, time: 3.879, data_time: 0.084, memory: 21542, decode.loss_cls: 0.0564, decode.loss_mask: 0.2679, decode.loss_dice: 0.5854, decode.d0.loss_cls: 0.2185, decode.d0.loss_mask: 0.2718, decode.d0.loss_dice: 0.5936, decode.d1.loss_cls: 0.0982, decode.d1.loss_mask: 0.2673, decode.d1.loss_dice: 0.5879, decode.d2.loss_cls: 0.0566, decode.d2.loss_mask: 0.2689, decode.d2.loss_dice: 0.5829, decode.d3.loss_cls: 0.0621, decode.d3.loss_mask: 0.2687, decode.d3.loss_dice: 0.5856, decode.d4.loss_cls: 0.0742, decode.d4.loss_mask: 0.2697, decode.d4.loss_dice: 0.5891, decode.d5.loss_cls: 0.0752, decode.d5.loss_mask: 0.2686, decode.d5.loss_dice: 0.5898, decode.d6.loss_cls: 0.0655, decode.d6.loss_mask: 0.2699, decode.d6.loss_dice: 0.5855, decode.d7.loss_cls: 0.1026, decode.d7.loss_mask: 0.2680, decode.d7.loss_dice: 0.5769, decode.d8.loss_cls: 0.0595, decode.d8.loss_mask: 0.2691, decode.d8.loss_dice: 0.5805, loss: 9.4158
2023-09-29 01:42:12,539 - mmseg - INFO - Iter [20850/40000]	lr: 6.874e-07, eta: 15:29:54, time: 3.719, data_time: 0.144, memory: 21542, decode.loss_cls: 0.0931, decode.loss_mask: 0.2704, decode.loss_dice: 0.5773, decode.d0.loss_cls: 0.2582, decode.d0.loss_mask: 0.2722, decode.d0.loss_dice: 0.5921, decode.d1.loss_cls: 0.0887, decode.d1.loss_mask: 0.2708, decode.d1.loss_dice: 0.5787, decode.d2.loss_cls: 0.0778, decode.d2.loss_mask: 0.2705, decode.d2.loss_dice: 0.5876, decode.d3.loss_cls: 0.0887, decode.d3.loss_mask: 0.2697, decode.d3.loss_dice: 0.5782, decode.d4.loss_cls: 0.0825, decode.d4.loss_mask: 0.2722, decode.d4.loss_dice: 0.5875, decode.d5.loss_cls: 0.0831, decode.d5.loss_mask: 0.2735, decode.d5.loss_dice: 0.5805, decode.d6.loss_cls: 0.1180, decode.d6.loss_mask: 0.2719, decode.d6.loss_dice: 0.5725, decode.d7.loss_cls: 0.1060, decode.d7.loss_mask: 0.2729, decode.d7.loss_dice: 0.5767, decode.d8.loss_cls: 0.1030, decode.d8.loss_mask: 0.2728, decode.d8.loss_dice: 0.5627, loss: 9.6098
2023-09-29 01:45:18,035 - mmseg - INFO - Iter [20900/40000]	lr: 6.856e-07, eta: 15:28:05, time: 3.709, data_time: 0.077, memory: 21542, decode.loss_cls: 0.0746, decode.loss_mask: 0.2908, decode.loss_dice: 0.5598, decode.d0.loss_cls: 0.2490, decode.d0.loss_mask: 0.2980, decode.d0.loss_dice: 0.5605, decode.d1.loss_cls: 0.0957, decode.d1.loss_mask: 0.2927, decode.d1.loss_dice: 0.5705, decode.d2.loss_cls: 0.0854, decode.d2.loss_mask: 0.2924, decode.d2.loss_dice: 0.5512, decode.d3.loss_cls: 0.0674, decode.d3.loss_mask: 0.2917, decode.d3.loss_dice: 0.5537, decode.d4.loss_cls: 0.0665, decode.d4.loss_mask: 0.2909, decode.d4.loss_dice: 0.5512, decode.d5.loss_cls: 0.0670, decode.d5.loss_mask: 0.2919, decode.d5.loss_dice: 0.5513, decode.d6.loss_cls: 0.0772, decode.d6.loss_mask: 0.2918, decode.d6.loss_dice: 0.5552, decode.d7.loss_cls: 0.0806, decode.d7.loss_mask: 0.2927, decode.d7.loss_dice: 0.5494, decode.d8.loss_cls: 0.0894, decode.d8.loss_mask: 0.2911, decode.d8.loss_dice: 0.5487, loss: 9.4286
2023-09-29 01:48:27,966 - mmseg - INFO - Iter [20950/40000]	lr: 6.838e-07, eta: 15:26:19, time: 3.798, data_time: 0.082, memory: 21542, decode.loss_cls: 0.0646, decode.loss_mask: 0.2546, decode.loss_dice: 0.5273, decode.d0.loss_cls: 0.2309, decode.d0.loss_mask: 0.2594, decode.d0.loss_dice: 0.5498, decode.d1.loss_cls: 0.1361, decode.d1.loss_mask: 0.2545, decode.d1.loss_dice: 0.5248, decode.d2.loss_cls: 0.0913, decode.d2.loss_mask: 0.2556, decode.d2.loss_dice: 0.5249, decode.d3.loss_cls: 0.0881, decode.d3.loss_mask: 0.2562, decode.d3.loss_dice: 0.5264, decode.d4.loss_cls: 0.0789, decode.d4.loss_mask: 0.2554, decode.d4.loss_dice: 0.5265, decode.d5.loss_cls: 0.0764, decode.d5.loss_mask: 0.2554, decode.d5.loss_dice: 0.5312, decode.d6.loss_cls: 0.0695, decode.d6.loss_mask: 0.2570, decode.d6.loss_dice: 0.5346, decode.d7.loss_cls: 0.0751, decode.d7.loss_mask: 0.2552, decode.d7.loss_dice: 0.5343, decode.d8.loss_cls: 0.0687, decode.d8.loss_mask: 0.2561, decode.d8.loss_dice: 0.5407, loss: 8.8594
2023-09-29 01:51:46,179 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 01:51:46,179 - mmseg - INFO - Iter [21000/40000]	lr: 6.820e-07, eta: 15:24:41, time: 3.965, data_time: 0.094, memory: 21542, decode.loss_cls: 0.0673, decode.loss_mask: 0.2600, decode.loss_dice: 0.5166, decode.d0.loss_cls: 0.2385, decode.d0.loss_mask: 0.2603, decode.d0.loss_dice: 0.5169, decode.d1.loss_cls: 0.0861, decode.d1.loss_mask: 0.2609, decode.d1.loss_dice: 0.5185, decode.d2.loss_cls: 0.0801, decode.d2.loss_mask: 0.2622, decode.d2.loss_dice: 0.5242, decode.d3.loss_cls: 0.0789, decode.d3.loss_mask: 0.2620, decode.d3.loss_dice: 0.5236, decode.d4.loss_cls: 0.0810, decode.d4.loss_mask: 0.2616, decode.d4.loss_dice: 0.5279, decode.d5.loss_cls: 0.0726, decode.d5.loss_mask: 0.2602, decode.d5.loss_dice: 0.5094, decode.d6.loss_cls: 0.0690, decode.d6.loss_mask: 0.2600, decode.d6.loss_dice: 0.5171, decode.d7.loss_cls: 0.0815, decode.d7.loss_mask: 0.2608, decode.d7.loss_dice: 0.5203, decode.d8.loss_cls: 0.0711, decode.d8.loss_mask: 0.2605, decode.d8.loss_dice: 0.5299, loss: 8.7389
2023-09-29 01:54:51,321 - mmseg - INFO - Iter [21050/40000]	lr: 6.802e-07, eta: 15:22:50, time: 3.703, data_time: 0.088, memory: 21542, decode.loss_cls: 0.0615, decode.loss_mask: 0.2517, decode.loss_dice: 0.5195, decode.d0.loss_cls: 0.1884, decode.d0.loss_mask: 0.2499, decode.d0.loss_dice: 0.5360, decode.d1.loss_cls: 0.0698, decode.d1.loss_mask: 0.2520, decode.d1.loss_dice: 0.5242, decode.d2.loss_cls: 0.0620, decode.d2.loss_mask: 0.2493, decode.d2.loss_dice: 0.5093, decode.d3.loss_cls: 0.0509, decode.d3.loss_mask: 0.2507, decode.d3.loss_dice: 0.5184, decode.d4.loss_cls: 0.0448, decode.d4.loss_mask: 0.2530, decode.d4.loss_dice: 0.5266, decode.d5.loss_cls: 0.0581, decode.d5.loss_mask: 0.2513, decode.d5.loss_dice: 0.5264, decode.d6.loss_cls: 0.0583, decode.d6.loss_mask: 0.2488, decode.d6.loss_dice: 0.5236, decode.d7.loss_cls: 0.0609, decode.d7.loss_mask: 0.2500, decode.d7.loss_dice: 0.5189, decode.d8.loss_cls: 0.0566, decode.d8.loss_mask: 0.2514, decode.d8.loss_dice: 0.5256, loss: 8.4481
2023-09-29 01:57:54,159 - mmseg - INFO - Iter [21100/40000]	lr: 6.784e-07, eta: 15:20:57, time: 3.657, data_time: 0.077, memory: 21542, decode.loss_cls: 0.0659, decode.loss_mask: 0.2345, decode.loss_dice: 0.5669, decode.d0.loss_cls: 0.2103, decode.d0.loss_mask: 0.2370, decode.d0.loss_dice: 0.5638, decode.d1.loss_cls: 0.0946, decode.d1.loss_mask: 0.2355, decode.d1.loss_dice: 0.5496, decode.d2.loss_cls: 0.0728, decode.d2.loss_mask: 0.2362, decode.d2.loss_dice: 0.5594, decode.d3.loss_cls: 0.0827, decode.d3.loss_mask: 0.2347, decode.d3.loss_dice: 0.5619, decode.d4.loss_cls: 0.0640, decode.d4.loss_mask: 0.2369, decode.d4.loss_dice: 0.5607, decode.d5.loss_cls: 0.0708, decode.d5.loss_mask: 0.2365, decode.d5.loss_dice: 0.5547, decode.d6.loss_cls: 0.0549, decode.d6.loss_mask: 0.2376, decode.d6.loss_dice: 0.5710, decode.d7.loss_cls: 0.0736, decode.d7.loss_mask: 0.2375, decode.d7.loss_dice: 0.5691, decode.d8.loss_cls: 0.0670, decode.d8.loss_mask: 0.2373, decode.d8.loss_dice: 0.5728, loss: 8.8505
2023-09-29 02:01:00,002 - mmseg - INFO - Iter [21150/40000]	lr: 6.767e-07, eta: 15:19:06, time: 3.718, data_time: 0.079, memory: 21542, decode.loss_cls: 0.0702, decode.loss_mask: 0.2988, decode.loss_dice: 0.5620, decode.d0.loss_cls: 0.2191, decode.d0.loss_mask: 0.3066, decode.d0.loss_dice: 0.5890, decode.d1.loss_cls: 0.0909, decode.d1.loss_mask: 0.3007, decode.d1.loss_dice: 0.5640, decode.d2.loss_cls: 0.0844, decode.d2.loss_mask: 0.3010, decode.d2.loss_dice: 0.5596, decode.d3.loss_cls: 0.0929, decode.d3.loss_mask: 0.3005, decode.d3.loss_dice: 0.5514, decode.d4.loss_cls: 0.0910, decode.d4.loss_mask: 0.3001, decode.d4.loss_dice: 0.5642, decode.d5.loss_cls: 0.0825, decode.d5.loss_mask: 0.3015, decode.d5.loss_dice: 0.5545, decode.d6.loss_cls: 0.0810, decode.d6.loss_mask: 0.3007, decode.d6.loss_dice: 0.5535, decode.d7.loss_cls: 0.0844, decode.d7.loss_mask: 0.3022, decode.d7.loss_dice: 0.5611, decode.d8.loss_cls: 0.0761, decode.d8.loss_mask: 0.3013, decode.d8.loss_dice: 0.5620, loss: 9.6069
2023-09-29 02:04:12,507 - mmseg - INFO - Iter [21200/40000]	lr: 6.749e-07, eta: 15:17:21, time: 3.850, data_time: 0.087, memory: 21542, decode.loss_cls: 0.0542, decode.loss_mask: 0.2726, decode.loss_dice: 0.5086, decode.d0.loss_cls: 0.2150, decode.d0.loss_mask: 0.2767, decode.d0.loss_dice: 0.5139, decode.d1.loss_cls: 0.0668, decode.d1.loss_mask: 0.2719, decode.d1.loss_dice: 0.5297, decode.d2.loss_cls: 0.0839, decode.d2.loss_mask: 0.2720, decode.d2.loss_dice: 0.5175, decode.d3.loss_cls: 0.0630, decode.d3.loss_mask: 0.2734, decode.d3.loss_dice: 0.5197, decode.d4.loss_cls: 0.0652, decode.d4.loss_mask: 0.2730, decode.d4.loss_dice: 0.5156, decode.d5.loss_cls: 0.0664, decode.d5.loss_mask: 0.2722, decode.d5.loss_dice: 0.5148, decode.d6.loss_cls: 0.0659, decode.d6.loss_mask: 0.2725, decode.d6.loss_dice: 0.5163, decode.d7.loss_cls: 0.0629, decode.d7.loss_mask: 0.2739, decode.d7.loss_dice: 0.5211, decode.d8.loss_cls: 0.0639, decode.d8.loss_mask: 0.2730, decode.d8.loss_dice: 0.5209, loss: 8.7165
2023-09-29 02:07:20,311 - mmseg - INFO - Iter [21250/40000]	lr: 6.731e-07, eta: 15:15:31, time: 3.754, data_time: 0.082, memory: 21542, decode.loss_cls: 0.1003, decode.loss_mask: 0.2661, decode.loss_dice: 0.5901, decode.d0.loss_cls: 0.2277, decode.d0.loss_mask: 0.2696, decode.d0.loss_dice: 0.5955, decode.d1.loss_cls: 0.1275, decode.d1.loss_mask: 0.2645, decode.d1.loss_dice: 0.5779, decode.d2.loss_cls: 0.1148, decode.d2.loss_mask: 0.2672, decode.d2.loss_dice: 0.5727, decode.d3.loss_cls: 0.0997, decode.d3.loss_mask: 0.2657, decode.d3.loss_dice: 0.5866, decode.d4.loss_cls: 0.1122, decode.d4.loss_mask: 0.2657, decode.d4.loss_dice: 0.5722, decode.d5.loss_cls: 0.0987, decode.d5.loss_mask: 0.2676, decode.d5.loss_dice: 0.5828, decode.d6.loss_cls: 0.1088, decode.d6.loss_mask: 0.2641, decode.d6.loss_dice: 0.5707, decode.d7.loss_cls: 0.1029, decode.d7.loss_mask: 0.2649, decode.d7.loss_dice: 0.5870, decode.d8.loss_cls: 0.1280, decode.d8.loss_mask: 0.2649, decode.d8.loss_dice: 0.5811, loss: 9.6975
2023-09-29 02:10:24,939 - mmseg - INFO - Iter [21300/40000]	lr: 6.713e-07, eta: 15:13:38, time: 3.694, data_time: 0.080, memory: 21542, decode.loss_cls: 0.0784, decode.loss_mask: 0.2552, decode.loss_dice: 0.5599, decode.d0.loss_cls: 0.2247, decode.d0.loss_mask: 0.2598, decode.d0.loss_dice: 0.5687, decode.d1.loss_cls: 0.0998, decode.d1.loss_mask: 0.2565, decode.d1.loss_dice: 0.5631, decode.d2.loss_cls: 0.1006, decode.d2.loss_mask: 0.2577, decode.d2.loss_dice: 0.5539, decode.d3.loss_cls: 0.0807, decode.d3.loss_mask: 0.2572, decode.d3.loss_dice: 0.5572, decode.d4.loss_cls: 0.0719, decode.d4.loss_mask: 0.2574, decode.d4.loss_dice: 0.5522, decode.d5.loss_cls: 0.0629, decode.d5.loss_mask: 0.2561, decode.d5.loss_dice: 0.5559, decode.d6.loss_cls: 0.0834, decode.d6.loss_mask: 0.2567, decode.d6.loss_dice: 0.5544, decode.d7.loss_cls: 0.0811, decode.d7.loss_mask: 0.2559, decode.d7.loss_dice: 0.5592, decode.d8.loss_cls: 0.0700, decode.d8.loss_mask: 0.2564, decode.d8.loss_dice: 0.5599, loss: 9.1068
2023-09-29 02:13:32,867 - mmseg - INFO - Iter [21350/40000]	lr: 6.695e-07, eta: 15:11:47, time: 3.758, data_time: 0.079, memory: 21542, decode.loss_cls: 0.0660, decode.loss_mask: 0.2914, decode.loss_dice: 0.5707, decode.d0.loss_cls: 0.2175, decode.d0.loss_mask: 0.3037, decode.d0.loss_dice: 0.5767, decode.d1.loss_cls: 0.0907, decode.d1.loss_mask: 0.2946, decode.d1.loss_dice: 0.5737, decode.d2.loss_cls: 0.0771, decode.d2.loss_mask: 0.2941, decode.d2.loss_dice: 0.5668, decode.d3.loss_cls: 0.0766, decode.d3.loss_mask: 0.2926, decode.d3.loss_dice: 0.5736, decode.d4.loss_cls: 0.0659, decode.d4.loss_mask: 0.2941, decode.d4.loss_dice: 0.5773, decode.d5.loss_cls: 0.0726, decode.d5.loss_mask: 0.2922, decode.d5.loss_dice: 0.5737, decode.d6.loss_cls: 0.0630, decode.d6.loss_mask: 0.2939, decode.d6.loss_dice: 0.5706, decode.d7.loss_cls: 0.0474, decode.d7.loss_mask: 0.2934, decode.d7.loss_dice: 0.5718, decode.d8.loss_cls: 0.0488, decode.d8.loss_mask: 0.2934, decode.d8.loss_dice: 0.5753, loss: 9.4990
2023-09-29 02:16:45,422 - mmseg - INFO - Iter [21400/40000]	lr: 6.677e-07, eta: 15:10:01, time: 3.852, data_time: 0.090, memory: 21542, decode.loss_cls: 0.0553, decode.loss_mask: 0.2924, decode.loss_dice: 0.5480, decode.d0.loss_cls: 0.2256, decode.d0.loss_mask: 0.2955, decode.d0.loss_dice: 0.5419, decode.d1.loss_cls: 0.0663, decode.d1.loss_mask: 0.2906, decode.d1.loss_dice: 0.5505, decode.d2.loss_cls: 0.0531, decode.d2.loss_mask: 0.2900, decode.d2.loss_dice: 0.5491, decode.d3.loss_cls: 0.0517, decode.d3.loss_mask: 0.2911, decode.d3.loss_dice: 0.5519, decode.d4.loss_cls: 0.0422, decode.d4.loss_mask: 0.2918, decode.d4.loss_dice: 0.5452, decode.d5.loss_cls: 0.0517, decode.d5.loss_mask: 0.2909, decode.d5.loss_dice: 0.5494, decode.d6.loss_cls: 0.0438, decode.d6.loss_mask: 0.2919, decode.d6.loss_dice: 0.5554, decode.d7.loss_cls: 0.0456, decode.d7.loss_mask: 0.2918, decode.d7.loss_dice: 0.5542, decode.d8.loss_cls: 0.0683, decode.d8.loss_mask: 0.2904, decode.d8.loss_dice: 0.5518, loss: 9.1174
2023-09-29 02:19:49,183 - mmseg - INFO - Iter [21450/40000]	lr: 6.659e-07, eta: 15:08:06, time: 3.674, data_time: 0.077, memory: 21542, decode.loss_cls: 0.0501, decode.loss_mask: 0.2504, decode.loss_dice: 0.5681, decode.d0.loss_cls: 0.2186, decode.d0.loss_mask: 0.2531, decode.d0.loss_dice: 0.5833, decode.d1.loss_cls: 0.0715, decode.d1.loss_mask: 0.2512, decode.d1.loss_dice: 0.5859, decode.d2.loss_cls: 0.0712, decode.d2.loss_mask: 0.2493, decode.d2.loss_dice: 0.5823, decode.d3.loss_cls: 0.0612, decode.d3.loss_mask: 0.2490, decode.d3.loss_dice: 0.5804, decode.d4.loss_cls: 0.0613, decode.d4.loss_mask: 0.2481, decode.d4.loss_dice: 0.5836, decode.d5.loss_cls: 0.0585, decode.d5.loss_mask: 0.2505, decode.d5.loss_dice: 0.5816, decode.d6.loss_cls: 0.0632, decode.d6.loss_mask: 0.2505, decode.d6.loss_dice: 0.5813, decode.d7.loss_cls: 0.0544, decode.d7.loss_mask: 0.2497, decode.d7.loss_dice: 0.5866, decode.d8.loss_cls: 0.0563, decode.d8.loss_mask: 0.2501, decode.d8.loss_dice: 0.5758, loss: 9.0774
2023-09-29 02:22:56,283 - mmseg - INFO - Iter [21500/40000]	lr: 6.641e-07, eta: 15:06:13, time: 3.740, data_time: 0.084, memory: 21542, decode.loss_cls: 0.0959, decode.loss_mask: 0.2735, decode.loss_dice: 0.5619, decode.d0.loss_cls: 0.2413, decode.d0.loss_mask: 0.2811, decode.d0.loss_dice: 0.5703, decode.d1.loss_cls: 0.0834, decode.d1.loss_mask: 0.2741, decode.d1.loss_dice: 0.5705, decode.d2.loss_cls: 0.1071, decode.d2.loss_mask: 0.2728, decode.d2.loss_dice: 0.5705, decode.d3.loss_cls: 0.0898, decode.d3.loss_mask: 0.2751, decode.d3.loss_dice: 0.5599, decode.d4.loss_cls: 0.0714, decode.d4.loss_mask: 0.2781, decode.d4.loss_dice: 0.5646, decode.d5.loss_cls: 0.0932, decode.d5.loss_mask: 0.2726, decode.d5.loss_dice: 0.5647, decode.d6.loss_cls: 0.0975, decode.d6.loss_mask: 0.2776, decode.d6.loss_dice: 0.5751, decode.d7.loss_cls: 0.1072, decode.d7.loss_mask: 0.2746, decode.d7.loss_dice: 0.5625, decode.d8.loss_cls: 0.0846, decode.d8.loss_mask: 0.2737, decode.d8.loss_dice: 0.5596, loss: 9.4845
2023-09-29 02:26:04,822 - mmseg - INFO - Iter [21550/40000]	lr: 6.623e-07, eta: 15:04:22, time: 3.773, data_time: 0.085, memory: 21542, decode.loss_cls: 0.0824, decode.loss_mask: 0.2935, decode.loss_dice: 0.5543, decode.d0.loss_cls: 0.2422, decode.d0.loss_mask: 0.2964, decode.d0.loss_dice: 0.5578, decode.d1.loss_cls: 0.0932, decode.d1.loss_mask: 0.2969, decode.d1.loss_dice: 0.5618, decode.d2.loss_cls: 0.0917, decode.d2.loss_mask: 0.2963, decode.d2.loss_dice: 0.5560, decode.d3.loss_cls: 0.0882, decode.d3.loss_mask: 0.2960, decode.d3.loss_dice: 0.5593, decode.d4.loss_cls: 0.0796, decode.d4.loss_mask: 0.3019, decode.d4.loss_dice: 0.5660, decode.d5.loss_cls: 0.0836, decode.d5.loss_mask: 0.2947, decode.d5.loss_dice: 0.5593, decode.d6.loss_cls: 0.0780, decode.d6.loss_mask: 0.2964, decode.d6.loss_dice: 0.5523, decode.d7.loss_cls: 0.0834, decode.d7.loss_mask: 0.2957, decode.d7.loss_dice: 0.5618, decode.d8.loss_cls: 0.0930, decode.d8.loss_mask: 0.2960, decode.d8.loss_dice: 0.5593, loss: 9.5665
2023-09-29 02:29:16,780 - mmseg - INFO - Iter [21600/40000]	lr: 6.605e-07, eta: 15:02:33, time: 3.838, data_time: 0.094, memory: 21542, decode.loss_cls: 0.0724, decode.loss_mask: 0.2777, decode.loss_dice: 0.5114, decode.d0.loss_cls: 0.2406, decode.d0.loss_mask: 0.2846, decode.d0.loss_dice: 0.5339, decode.d1.loss_cls: 0.0818, decode.d1.loss_mask: 0.2780, decode.d1.loss_dice: 0.5210, decode.d2.loss_cls: 0.0752, decode.d2.loss_mask: 0.2748, decode.d2.loss_dice: 0.5176, decode.d3.loss_cls: 0.0790, decode.d3.loss_mask: 0.2773, decode.d3.loss_dice: 0.5176, decode.d4.loss_cls: 0.0630, decode.d4.loss_mask: 0.2775, decode.d4.loss_dice: 0.5244, decode.d5.loss_cls: 0.0750, decode.d5.loss_mask: 0.2771, decode.d5.loss_dice: 0.5155, decode.d6.loss_cls: 0.0648, decode.d6.loss_mask: 0.2793, decode.d6.loss_dice: 0.5261, decode.d7.loss_cls: 0.0945, decode.d7.loss_mask: 0.2789, decode.d7.loss_dice: 0.5279, decode.d8.loss_cls: 0.0762, decode.d8.loss_mask: 0.2782, decode.d8.loss_dice: 0.5233, loss: 8.9247
2023-09-29 02:32:18,770 - mmseg - INFO - Iter [21650/40000]	lr: 6.587e-07, eta: 15:00:36, time: 3.642, data_time: 0.080, memory: 21542, decode.loss_cls: 0.0805, decode.loss_mask: 0.2540, decode.loss_dice: 0.5165, decode.d0.loss_cls: 0.2162, decode.d0.loss_mask: 0.2559, decode.d0.loss_dice: 0.5232, decode.d1.loss_cls: 0.1052, decode.d1.loss_mask: 0.2538, decode.d1.loss_dice: 0.5161, decode.d2.loss_cls: 0.0931, decode.d2.loss_mask: 0.2529, decode.d2.loss_dice: 0.5175, decode.d3.loss_cls: 0.0839, decode.d3.loss_mask: 0.2523, decode.d3.loss_dice: 0.5084, decode.d4.loss_cls: 0.0778, decode.d4.loss_mask: 0.2524, decode.d4.loss_dice: 0.5165, decode.d5.loss_cls: 0.0786, decode.d5.loss_mask: 0.2535, decode.d5.loss_dice: 0.5184, decode.d6.loss_cls: 0.0870, decode.d6.loss_mask: 0.2522, decode.d6.loss_dice: 0.5180, decode.d7.loss_cls: 0.0862, decode.d7.loss_mask: 0.2532, decode.d7.loss_dice: 0.5147, decode.d8.loss_cls: 0.0719, decode.d8.loss_mask: 0.2530, decode.d8.loss_dice: 0.5160, loss: 8.6787
2023-09-29 02:35:26,643 - mmseg - INFO - Iter [21700/40000]	lr: 6.569e-07, eta: 14:58:43, time: 3.755, data_time: 0.087, memory: 21542, decode.loss_cls: 0.0606, decode.loss_mask: 0.2971, decode.loss_dice: 0.5792, decode.d0.loss_cls: 0.2144, decode.d0.loss_mask: 0.3008, decode.d0.loss_dice: 0.5970, decode.d1.loss_cls: 0.0612, decode.d1.loss_mask: 0.2955, decode.d1.loss_dice: 0.5950, decode.d2.loss_cls: 0.0660, decode.d2.loss_mask: 0.2952, decode.d2.loss_dice: 0.5897, decode.d3.loss_cls: 0.0715, decode.d3.loss_mask: 0.2937, decode.d3.loss_dice: 0.5910, decode.d4.loss_cls: 0.0731, decode.d4.loss_mask: 0.2942, decode.d4.loss_dice: 0.5917, decode.d5.loss_cls: 0.0599, decode.d5.loss_mask: 0.2951, decode.d5.loss_dice: 0.5888, decode.d6.loss_cls: 0.0697, decode.d6.loss_mask: 0.2951, decode.d6.loss_dice: 0.5772, decode.d7.loss_cls: 0.0652, decode.d7.loss_mask: 0.2972, decode.d7.loss_dice: 0.5925, decode.d8.loss_cls: 0.0689, decode.d8.loss_mask: 0.2956, decode.d8.loss_dice: 0.5892, loss: 9.6617
2023-09-29 02:38:38,135 - mmseg - INFO - Iter [21750/40000]	lr: 6.551e-07, eta: 14:56:53, time: 3.831, data_time: 0.093, memory: 21542, decode.loss_cls: 0.0754, decode.loss_mask: 0.2759, decode.loss_dice: 0.5769, decode.d0.loss_cls: 0.2019, decode.d0.loss_mask: 0.2811, decode.d0.loss_dice: 0.6022, decode.d1.loss_cls: 0.0856, decode.d1.loss_mask: 0.2743, decode.d1.loss_dice: 0.5783, decode.d2.loss_cls: 0.1146, decode.d2.loss_mask: 0.2749, decode.d2.loss_dice: 0.5749, decode.d3.loss_cls: 0.0895, decode.d3.loss_mask: 0.2737, decode.d3.loss_dice: 0.5763, decode.d4.loss_cls: 0.0707, decode.d4.loss_mask: 0.2760, decode.d4.loss_dice: 0.5775, decode.d5.loss_cls: 0.0933, decode.d5.loss_mask: 0.2722, decode.d5.loss_dice: 0.5774, decode.d6.loss_cls: 0.0845, decode.d6.loss_mask: 0.2746, decode.d6.loss_dice: 0.5750, decode.d7.loss_cls: 0.0914, decode.d7.loss_mask: 0.2749, decode.d7.loss_dice: 0.5834, decode.d8.loss_cls: 0.0820, decode.d8.loss_mask: 0.2743, decode.d8.loss_dice: 0.5799, loss: 9.5429
2023-09-29 02:41:51,841 - mmseg - INFO - Iter [21800/40000]	lr: 6.533e-07, eta: 14:55:04, time: 3.874, data_time: 0.084, memory: 21542, decode.loss_cls: 0.0878, decode.loss_mask: 0.2936, decode.loss_dice: 0.5790, decode.d0.loss_cls: 0.2259, decode.d0.loss_mask: 0.3068, decode.d0.loss_dice: 0.5937, decode.d1.loss_cls: 0.0873, decode.d1.loss_mask: 0.2950, decode.d1.loss_dice: 0.5780, decode.d2.loss_cls: 0.0833, decode.d2.loss_mask: 0.2960, decode.d2.loss_dice: 0.5944, decode.d3.loss_cls: 0.0872, decode.d3.loss_mask: 0.2950, decode.d3.loss_dice: 0.5880, decode.d4.loss_cls: 0.0860, decode.d4.loss_mask: 0.2936, decode.d4.loss_dice: 0.5829, decode.d5.loss_cls: 0.0812, decode.d5.loss_mask: 0.2947, decode.d5.loss_dice: 0.5762, decode.d6.loss_cls: 0.0787, decode.d6.loss_mask: 0.2956, decode.d6.loss_dice: 0.5895, decode.d7.loss_cls: 0.0711, decode.d7.loss_mask: 0.2936, decode.d7.loss_dice: 0.5837, decode.d8.loss_cls: 0.0905, decode.d8.loss_mask: 0.2929, decode.d8.loss_dice: 0.5876, loss: 9.7887
2023-09-29 02:44:56,848 - mmseg - INFO - Iter [21850/40000]	lr: 6.515e-07, eta: 14:53:07, time: 3.697, data_time: 0.088, memory: 21542, decode.loss_cls: 0.0865, decode.loss_mask: 0.2473, decode.loss_dice: 0.5442, decode.d0.loss_cls: 0.2161, decode.d0.loss_mask: 0.2542, decode.d0.loss_dice: 0.5484, decode.d1.loss_cls: 0.0922, decode.d1.loss_mask: 0.2474, decode.d1.loss_dice: 0.5498, decode.d2.loss_cls: 0.0914, decode.d2.loss_mask: 0.2481, decode.d2.loss_dice: 0.5380, decode.d3.loss_cls: 0.0680, decode.d3.loss_mask: 0.2487, decode.d3.loss_dice: 0.5441, decode.d4.loss_cls: 0.0630, decode.d4.loss_mask: 0.2471, decode.d4.loss_dice: 0.5413, decode.d5.loss_cls: 0.0795, decode.d5.loss_mask: 0.2474, decode.d5.loss_dice: 0.5453, decode.d6.loss_cls: 0.0639, decode.d6.loss_mask: 0.2480, decode.d6.loss_dice: 0.5426, decode.d7.loss_cls: 0.0637, decode.d7.loss_mask: 0.2453, decode.d7.loss_dice: 0.5408, decode.d8.loss_cls: 0.0772, decode.d8.loss_mask: 0.2468, decode.d8.loss_dice: 0.5377, loss: 8.8141
2023-09-29 02:48:03,398 - mmseg - INFO - Iter [21900/40000]	lr: 6.497e-07, eta: 14:51:12, time: 3.733, data_time: 0.084, memory: 21542, decode.loss_cls: 0.0939, decode.loss_mask: 0.2728, decode.loss_dice: 0.5522, decode.d0.loss_cls: 0.2185, decode.d0.loss_mask: 0.2800, decode.d0.loss_dice: 0.5508, decode.d1.loss_cls: 0.0931, decode.d1.loss_mask: 0.2734, decode.d1.loss_dice: 0.5565, decode.d2.loss_cls: 0.0736, decode.d2.loss_mask: 0.2738, decode.d2.loss_dice: 0.5494, decode.d3.loss_cls: 0.0838, decode.d3.loss_mask: 0.2704, decode.d3.loss_dice: 0.5616, decode.d4.loss_cls: 0.0994, decode.d4.loss_mask: 0.2732, decode.d4.loss_dice: 0.5519, decode.d5.loss_cls: 0.0612, decode.d5.loss_mask: 0.2774, decode.d5.loss_dice: 0.5577, decode.d6.loss_cls: 0.0903, decode.d6.loss_mask: 0.2741, decode.d6.loss_dice: 0.5573, decode.d7.loss_cls: 0.0912, decode.d7.loss_mask: 0.2720, decode.d7.loss_dice: 0.5627, decode.d8.loss_cls: 0.0766, decode.d8.loss_mask: 0.2725, decode.d8.loss_dice: 0.5493, loss: 9.2705
2023-09-29 02:51:16,843 - mmseg - INFO - Iter [21950/40000]	lr: 6.479e-07, eta: 14:49:22, time: 3.868, data_time: 0.148, memory: 21542, decode.loss_cls: 0.0929, decode.loss_mask: 0.2791, decode.loss_dice: 0.5451, decode.d0.loss_cls: 0.2502, decode.d0.loss_mask: 0.2801, decode.d0.loss_dice: 0.5492, decode.d1.loss_cls: 0.1044, decode.d1.loss_mask: 0.2788, decode.d1.loss_dice: 0.5500, decode.d2.loss_cls: 0.0993, decode.d2.loss_mask: 0.2784, decode.d2.loss_dice: 0.5745, decode.d3.loss_cls: 0.0864, decode.d3.loss_mask: 0.2786, decode.d3.loss_dice: 0.5578, decode.d4.loss_cls: 0.0948, decode.d4.loss_mask: 0.2781, decode.d4.loss_dice: 0.5502, decode.d5.loss_cls: 0.0916, decode.d5.loss_mask: 0.2784, decode.d5.loss_dice: 0.5457, decode.d6.loss_cls: 0.0839, decode.d6.loss_mask: 0.2784, decode.d6.loss_dice: 0.5442, decode.d7.loss_cls: 0.0698, decode.d7.loss_mask: 0.2792, decode.d7.loss_dice: 0.5471, decode.d8.loss_cls: 0.0721, decode.d8.loss_mask: 0.2787, decode.d8.loss_dice: 0.5395, loss: 9.3363
2023-09-29 02:54:32,269 - mmseg - INFO - Saving checkpoint at 22000 iterations
2023-09-29 02:55:44,424 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 02:55:44,443 - mmseg - INFO - Iter [22000/40000]	lr: 6.461e-07, eta: 14:48:32, time: 5.352, data_time: 0.087, memory: 21542, decode.loss_cls: 0.0608, decode.loss_mask: 0.2674, decode.loss_dice: 0.5688, decode.d0.loss_cls: 0.1951, decode.d0.loss_mask: 0.2713, decode.d0.loss_dice: 0.5705, decode.d1.loss_cls: 0.0904, decode.d1.loss_mask: 0.2671, decode.d1.loss_dice: 0.5668, decode.d2.loss_cls: 0.0869, decode.d2.loss_mask: 0.2671, decode.d2.loss_dice: 0.5727, decode.d3.loss_cls: 0.0854, decode.d3.loss_mask: 0.2669, decode.d3.loss_dice: 0.5774, decode.d4.loss_cls: 0.0666, decode.d4.loss_mask: 0.2691, decode.d4.loss_dice: 0.5654, decode.d5.loss_cls: 0.0716, decode.d5.loss_mask: 0.2662, decode.d5.loss_dice: 0.5730, decode.d6.loss_cls: 0.0874, decode.d6.loss_mask: 0.2665, decode.d6.loss_dice: 0.5655, decode.d7.loss_cls: 0.0657, decode.d7.loss_mask: 0.2660, decode.d7.loss_dice: 0.5702, decode.d8.loss_cls: 0.0669, decode.d8.loss_mask: 0.2659, decode.d8.loss_dice: 0.5706, loss: 9.2510
2023-09-29 03:25:03,346 - mmseg - INFO - per class results:
2023-09-29 03:25:03,348 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 92.64 | 97.45 |
|    Sidewalk   | 69.01 |  80.5 |
|  Construction | 82.21 | 93.87 |
|     Fence     |  33.3 | 36.94 |
|      Pole     | 57.15 | 71.74 |
| Traffic Light | 66.65 | 80.19 |
|  Traffic Sign | 70.88 | 81.58 |
|     Nature    | 88.73 | 94.25 |
|      Sky      |  96.6 | 97.93 |
|     Person    | 33.27 | 35.58 |
|     Rider     |  8.47 |  68.2 |
|      Car      |  91.6 | 94.98 |
|   background  | 95.99 | 97.01 |
+---------------+-------+-------+
2023-09-29 03:25:03,348 - mmseg - INFO - Summary:
2023-09-29 03:25:03,348 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.43 | 68.19 | 79.25 |
+-------+-------+-------+
2023-09-29 03:25:03,350 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 03:25:03,351 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9443, mIoU: 0.6819, mAcc: 0.7925, IoU.Road: 0.9264, IoU.Sidewalk: 0.6901, IoU.Construction: 0.8221, IoU.Fence: 0.3330, IoU.Pole: 0.5715, IoU.Traffic Light: 0.6665, IoU.Traffic Sign: 0.7088, IoU.Nature: 0.8873, IoU.Sky: 0.9660, IoU.Person: 0.3327, IoU.Rider: 0.0847, IoU.Car: 0.9160, IoU.background: 0.9599, Acc.Road: 0.9745, Acc.Sidewalk: 0.8050, Acc.Construction: 0.9387, Acc.Fence: 0.3694, Acc.Pole: 0.7174, Acc.Traffic Light: 0.8019, Acc.Traffic Sign: 0.8158, Acc.Nature: 0.9425, Acc.Sky: 0.9793, Acc.Person: 0.3558, Acc.Rider: 0.6820, Acc.Car: 0.9498, Acc.background: 0.9701
2023-09-29 03:28:08,299 - mmseg - INFO - Iter [22050/40000]	lr: 6.443e-07, eta: 15:10:26, time: 38.878, data_time: 35.262, memory: 21542, decode.loss_cls: 0.0498, decode.loss_mask: 0.2639, decode.loss_dice: 0.5394, decode.d0.loss_cls: 0.2125, decode.d0.loss_mask: 0.2687, decode.d0.loss_dice: 0.5441, decode.d1.loss_cls: 0.0844, decode.d1.loss_mask: 0.2658, decode.d1.loss_dice: 0.5438, decode.d2.loss_cls: 0.0657, decode.d2.loss_mask: 0.2642, decode.d2.loss_dice: 0.5466, decode.d3.loss_cls: 0.0660, decode.d3.loss_mask: 0.2635, decode.d3.loss_dice: 0.5336, decode.d4.loss_cls: 0.0483, decode.d4.loss_mask: 0.2640, decode.d4.loss_dice: 0.5370, decode.d5.loss_cls: 0.0617, decode.d5.loss_mask: 0.2647, decode.d5.loss_dice: 0.5424, decode.d6.loss_cls: 0.0530, decode.d6.loss_mask: 0.2640, decode.d6.loss_dice: 0.5414, decode.d7.loss_cls: 0.0550, decode.d7.loss_mask: 0.2626, decode.d7.loss_dice: 0.5358, decode.d8.loss_cls: 0.0613, decode.d8.loss_mask: 0.2629, decode.d8.loss_dice: 0.5454, loss: 8.8112
2023-09-29 03:31:13,651 - mmseg - INFO - Iter [22100/40000]	lr: 6.426e-07, eta: 15:08:20, time: 3.706, data_time: 0.076, memory: 21542, decode.loss_cls: 0.0760, decode.loss_mask: 0.2693, decode.loss_dice: 0.5566, decode.d0.loss_cls: 0.2103, decode.d0.loss_mask: 0.2740, decode.d0.loss_dice: 0.5714, decode.d1.loss_cls: 0.0892, decode.d1.loss_mask: 0.2710, decode.d1.loss_dice: 0.5662, decode.d2.loss_cls: 0.0898, decode.d2.loss_mask: 0.2714, decode.d2.loss_dice: 0.5664, decode.d3.loss_cls: 0.0771, decode.d3.loss_mask: 0.2705, decode.d3.loss_dice: 0.5525, decode.d4.loss_cls: 0.0626, decode.d4.loss_mask: 0.2715, decode.d4.loss_dice: 0.5570, decode.d5.loss_cls: 0.0712, decode.d5.loss_mask: 0.2698, decode.d5.loss_dice: 0.5616, decode.d6.loss_cls: 0.0823, decode.d6.loss_mask: 0.2677, decode.d6.loss_dice: 0.5629, decode.d7.loss_cls: 0.0837, decode.d7.loss_mask: 0.2687, decode.d7.loss_dice: 0.5566, decode.d8.loss_cls: 0.0712, decode.d8.loss_mask: 0.2672, decode.d8.loss_dice: 0.5585, loss: 9.2243
2023-09-29 03:34:32,880 - mmseg - INFO - Iter [22150/40000]	lr: 6.408e-07, eta: 15:06:26, time: 3.985, data_time: 0.091, memory: 21542, decode.loss_cls: 0.0747, decode.loss_mask: 0.2871, decode.loss_dice: 0.5714, decode.d0.loss_cls: 0.2080, decode.d0.loss_mask: 0.2935, decode.d0.loss_dice: 0.5833, decode.d1.loss_cls: 0.1053, decode.d1.loss_mask: 0.2861, decode.d1.loss_dice: 0.5672, decode.d2.loss_cls: 0.0804, decode.d2.loss_mask: 0.2866, decode.d2.loss_dice: 0.5699, decode.d3.loss_cls: 0.0677, decode.d3.loss_mask: 0.2874, decode.d3.loss_dice: 0.5638, decode.d4.loss_cls: 0.0805, decode.d4.loss_mask: 0.2873, decode.d4.loss_dice: 0.5643, decode.d5.loss_cls: 0.0823, decode.d5.loss_mask: 0.2862, decode.d5.loss_dice: 0.5722, decode.d6.loss_cls: 0.0713, decode.d6.loss_mask: 0.2878, decode.d6.loss_dice: 0.5655, decode.d7.loss_cls: 0.0790, decode.d7.loss_mask: 0.2862, decode.d7.loss_dice: 0.5653, decode.d8.loss_cls: 0.0715, decode.d8.loss_mask: 0.2844, decode.d8.loss_dice: 0.5656, loss: 9.4818
2023-09-29 03:37:37,972 - mmseg - INFO - Iter [22200/40000]	lr: 6.390e-07, eta: 15:04:20, time: 3.699, data_time: 0.079, memory: 21542, decode.loss_cls: 0.0500, decode.loss_mask: 0.2491, decode.loss_dice: 0.5365, decode.d0.loss_cls: 0.2033, decode.d0.loss_mask: 0.2502, decode.d0.loss_dice: 0.5396, decode.d1.loss_cls: 0.0615, decode.d1.loss_mask: 0.2474, decode.d1.loss_dice: 0.5425, decode.d2.loss_cls: 0.0679, decode.d2.loss_mask: 0.2467, decode.d2.loss_dice: 0.5409, decode.d3.loss_cls: 0.0680, decode.d3.loss_mask: 0.2452, decode.d3.loss_dice: 0.5356, decode.d4.loss_cls: 0.0617, decode.d4.loss_mask: 0.2475, decode.d4.loss_dice: 0.5473, decode.d5.loss_cls: 0.0520, decode.d5.loss_mask: 0.2486, decode.d5.loss_dice: 0.5346, decode.d6.loss_cls: 0.0545, decode.d6.loss_mask: 0.2473, decode.d6.loss_dice: 0.5296, decode.d7.loss_cls: 0.0580, decode.d7.loss_mask: 0.2467, decode.d7.loss_dice: 0.5420, decode.d8.loss_cls: 0.0642, decode.d8.loss_mask: 0.2477, decode.d8.loss_dice: 0.5293, loss: 8.5957
2023-09-29 03:40:36,517 - mmseg - INFO - Iter [22250/40000]	lr: 6.372e-07, eta: 15:02:08, time: 3.573, data_time: 0.074, memory: 21542, decode.loss_cls: 0.0553, decode.loss_mask: 0.2678, decode.loss_dice: 0.5581, decode.d0.loss_cls: 0.2187, decode.d0.loss_mask: 0.2719, decode.d0.loss_dice: 0.5708, decode.d1.loss_cls: 0.0809, decode.d1.loss_mask: 0.2648, decode.d1.loss_dice: 0.5599, decode.d2.loss_cls: 0.1004, decode.d2.loss_mask: 0.2654, decode.d2.loss_dice: 0.5703, decode.d3.loss_cls: 0.0825, decode.d3.loss_mask: 0.2650, decode.d3.loss_dice: 0.5608, decode.d4.loss_cls: 0.0884, decode.d4.loss_mask: 0.2677, decode.d4.loss_dice: 0.5692, decode.d5.loss_cls: 0.0863, decode.d5.loss_mask: 0.2676, decode.d5.loss_dice: 0.5671, decode.d6.loss_cls: 0.0618, decode.d6.loss_mask: 0.2669, decode.d6.loss_dice: 0.5723, decode.d7.loss_cls: 0.0818, decode.d7.loss_mask: 0.2665, decode.d7.loss_dice: 0.5614, decode.d8.loss_cls: 0.0931, decode.d8.loss_mask: 0.2662, decode.d8.loss_dice: 0.5602, loss: 9.2691
2023-09-29 03:43:43,199 - mmseg - INFO - Iter [22300/40000]	lr: 6.354e-07, eta: 15:00:03, time: 3.731, data_time: 0.072, memory: 21542, decode.loss_cls: 0.0675, decode.loss_mask: 0.2742, decode.loss_dice: 0.5719, decode.d0.loss_cls: 0.2509, decode.d0.loss_mask: 0.2756, decode.d0.loss_dice: 0.5722, decode.d1.loss_cls: 0.1021, decode.d1.loss_mask: 0.2746, decode.d1.loss_dice: 0.5666, decode.d2.loss_cls: 0.0779, decode.d2.loss_mask: 0.2750, decode.d2.loss_dice: 0.5627, decode.d3.loss_cls: 0.0767, decode.d3.loss_mask: 0.2735, decode.d3.loss_dice: 0.5611, decode.d4.loss_cls: 0.0786, decode.d4.loss_mask: 0.2746, decode.d4.loss_dice: 0.5578, decode.d5.loss_cls: 0.0693, decode.d5.loss_mask: 0.2757, decode.d5.loss_dice: 0.5709, decode.d6.loss_cls: 0.0764, decode.d6.loss_mask: 0.2739, decode.d6.loss_dice: 0.5633, decode.d7.loss_cls: 0.0651, decode.d7.loss_mask: 0.2752, decode.d7.loss_dice: 0.5544, decode.d8.loss_cls: 0.0636, decode.d8.loss_mask: 0.2738, decode.d8.loss_dice: 0.5695, loss: 9.3243
2023-09-29 03:47:00,285 - mmseg - INFO - Iter [22350/40000]	lr: 6.336e-07, eta: 14:58:06, time: 3.944, data_time: 0.079, memory: 21542, decode.loss_cls: 0.0574, decode.loss_mask: 0.2702, decode.loss_dice: 0.5454, decode.d0.loss_cls: 0.2201, decode.d0.loss_mask: 0.2737, decode.d0.loss_dice: 0.5653, decode.d1.loss_cls: 0.0806, decode.d1.loss_mask: 0.2699, decode.d1.loss_dice: 0.5480, decode.d2.loss_cls: 0.0621, decode.d2.loss_mask: 0.2703, decode.d2.loss_dice: 0.5431, decode.d3.loss_cls: 0.0578, decode.d3.loss_mask: 0.2684, decode.d3.loss_dice: 0.5430, decode.d4.loss_cls: 0.0732, decode.d4.loss_mask: 0.2696, decode.d4.loss_dice: 0.5398, decode.d5.loss_cls: 0.0614, decode.d5.loss_mask: 0.2691, decode.d5.loss_dice: 0.5511, decode.d6.loss_cls: 0.0479, decode.d6.loss_mask: 0.2697, decode.d6.loss_dice: 0.5400, decode.d7.loss_cls: 0.0504, decode.d7.loss_mask: 0.2698, decode.d7.loss_dice: 0.5394, decode.d8.loss_cls: 0.0407, decode.d8.loss_mask: 0.2692, decode.d8.loss_dice: 0.5439, loss: 8.9105
2023-09-29 03:50:05,168 - mmseg - INFO - Iter [22400/40000]	lr: 6.318e-07, eta: 14:55:58, time: 3.697, data_time: 0.076, memory: 21542, decode.loss_cls: 0.0745, decode.loss_mask: 0.2602, decode.loss_dice: 0.5557, decode.d0.loss_cls: 0.2053, decode.d0.loss_mask: 0.2691, decode.d0.loss_dice: 0.5882, decode.d1.loss_cls: 0.1011, decode.d1.loss_mask: 0.2610, decode.d1.loss_dice: 0.5700, decode.d2.loss_cls: 0.0673, decode.d2.loss_mask: 0.2599, decode.d2.loss_dice: 0.5609, decode.d3.loss_cls: 0.0565, decode.d3.loss_mask: 0.2661, decode.d3.loss_dice: 0.5773, decode.d4.loss_cls: 0.0586, decode.d4.loss_mask: 0.2694, decode.d4.loss_dice: 0.5750, decode.d5.loss_cls: 0.0617, decode.d5.loss_mask: 0.2682, decode.d5.loss_dice: 0.5698, decode.d6.loss_cls: 0.0849, decode.d6.loss_mask: 0.2598, decode.d6.loss_dice: 0.5580, decode.d7.loss_cls: 0.0993, decode.d7.loss_mask: 0.2601, decode.d7.loss_dice: 0.5622, decode.d8.loss_cls: 0.0765, decode.d8.loss_mask: 0.2591, decode.d8.loss_dice: 0.5672, loss: 9.2030
2023-09-29 03:53:11,236 - mmseg - INFO - Iter [22450/40000]	lr: 6.300e-07, eta: 14:53:52, time: 3.722, data_time: 0.084, memory: 21542, decode.loss_cls: 0.0773, decode.loss_mask: 0.2486, decode.loss_dice: 0.5132, decode.d0.loss_cls: 0.2152, decode.d0.loss_mask: 0.2538, decode.d0.loss_dice: 0.5257, decode.d1.loss_cls: 0.0804, decode.d1.loss_mask: 0.2478, decode.d1.loss_dice: 0.5162, decode.d2.loss_cls: 0.0670, decode.d2.loss_mask: 0.2504, decode.d2.loss_dice: 0.5208, decode.d3.loss_cls: 0.0768, decode.d3.loss_mask: 0.2498, decode.d3.loss_dice: 0.5146, decode.d4.loss_cls: 0.0745, decode.d4.loss_mask: 0.2482, decode.d4.loss_dice: 0.5114, decode.d5.loss_cls: 0.0752, decode.d5.loss_mask: 0.2478, decode.d5.loss_dice: 0.5175, decode.d6.loss_cls: 0.0702, decode.d6.loss_mask: 0.2503, decode.d6.loss_dice: 0.5214, decode.d7.loss_cls: 0.0829, decode.d7.loss_mask: 0.2501, decode.d7.loss_dice: 0.5237, decode.d8.loss_cls: 0.0861, decode.d8.loss_mask: 0.2506, decode.d8.loss_dice: 0.5180, loss: 8.5854
2023-09-29 03:56:22,024 - mmseg - INFO - Iter [22500/40000]	lr: 6.282e-07, eta: 14:51:48, time: 3.815, data_time: 0.082, memory: 21542, decode.loss_cls: 0.0607, decode.loss_mask: 0.2548, decode.loss_dice: 0.5265, decode.d0.loss_cls: 0.2008, decode.d0.loss_mask: 0.2589, decode.d0.loss_dice: 0.5329, decode.d1.loss_cls: 0.0385, decode.d1.loss_mask: 0.2571, decode.d1.loss_dice: 0.5155, decode.d2.loss_cls: 0.0417, decode.d2.loss_mask: 0.2565, decode.d2.loss_dice: 0.5220, decode.d3.loss_cls: 0.0334, decode.d3.loss_mask: 0.2573, decode.d3.loss_dice: 0.5287, decode.d4.loss_cls: 0.0392, decode.d4.loss_mask: 0.2561, decode.d4.loss_dice: 0.5226, decode.d5.loss_cls: 0.0422, decode.d5.loss_mask: 0.2550, decode.d5.loss_dice: 0.5272, decode.d6.loss_cls: 0.0458, decode.d6.loss_mask: 0.2567, decode.d6.loss_dice: 0.5226, decode.d7.loss_cls: 0.0624, decode.d7.loss_mask: 0.2566, decode.d7.loss_dice: 0.5239, decode.d8.loss_cls: 0.0448, decode.d8.loss_mask: 0.2568, decode.d8.loss_dice: 0.5309, loss: 8.4281
2023-09-29 03:59:40,508 - mmseg - INFO - Iter [22550/40000]	lr: 6.264e-07, eta: 14:49:51, time: 3.969, data_time: 0.088, memory: 21542, decode.loss_cls: 0.0843, decode.loss_mask: 0.2980, decode.loss_dice: 0.5618, decode.d0.loss_cls: 0.2599, decode.d0.loss_mask: 0.3099, decode.d0.loss_dice: 0.5744, decode.d1.loss_cls: 0.1271, decode.d1.loss_mask: 0.3019, decode.d1.loss_dice: 0.5694, decode.d2.loss_cls: 0.1135, decode.d2.loss_mask: 0.2994, decode.d2.loss_dice: 0.5718, decode.d3.loss_cls: 0.1054, decode.d3.loss_mask: 0.3006, decode.d3.loss_dice: 0.5654, decode.d4.loss_cls: 0.0966, decode.d4.loss_mask: 0.2981, decode.d4.loss_dice: 0.5612, decode.d5.loss_cls: 0.1185, decode.d5.loss_mask: 0.2985, decode.d5.loss_dice: 0.5611, decode.d6.loss_cls: 0.0857, decode.d6.loss_mask: 0.2992, decode.d6.loss_dice: 0.5615, decode.d7.loss_cls: 0.0813, decode.d7.loss_mask: 0.2989, decode.d7.loss_dice: 0.5679, decode.d8.loss_cls: 0.0949, decode.d8.loss_mask: 0.2992, decode.d8.loss_dice: 0.5673, loss: 9.8325
2023-09-29 04:02:48,004 - mmseg - INFO - Iter [22600/40000]	lr: 6.246e-07, eta: 14:47:44, time: 3.751, data_time: 0.084, memory: 21542, decode.loss_cls: 0.1116, decode.loss_mask: 0.2453, decode.loss_dice: 0.5737, decode.d0.loss_cls: 0.2274, decode.d0.loss_mask: 0.2489, decode.d0.loss_dice: 0.5593, decode.d1.loss_cls: 0.1240, decode.d1.loss_mask: 0.2440, decode.d1.loss_dice: 0.5727, decode.d2.loss_cls: 0.1179, decode.d2.loss_mask: 0.2428, decode.d2.loss_dice: 0.5746, decode.d3.loss_cls: 0.1062, decode.d3.loss_mask: 0.2432, decode.d3.loss_dice: 0.5727, decode.d4.loss_cls: 0.1093, decode.d4.loss_mask: 0.2447, decode.d4.loss_dice: 0.5669, decode.d5.loss_cls: 0.1083, decode.d5.loss_mask: 0.2453, decode.d5.loss_dice: 0.5633, decode.d6.loss_cls: 0.1030, decode.d6.loss_mask: 0.2443, decode.d6.loss_dice: 0.5747, decode.d7.loss_cls: 0.1065, decode.d7.loss_mask: 0.2456, decode.d7.loss_dice: 0.5766, decode.d8.loss_cls: 0.0973, decode.d8.loss_mask: 0.2443, decode.d8.loss_dice: 0.5657, loss: 9.3601
2023-09-29 04:05:57,757 - mmseg - INFO - Iter [22650/40000]	lr: 6.228e-07, eta: 14:45:39, time: 3.794, data_time: 0.092, memory: 21542, decode.loss_cls: 0.0696, decode.loss_mask: 0.2902, decode.loss_dice: 0.5679, decode.d0.loss_cls: 0.2165, decode.d0.loss_mask: 0.2959, decode.d0.loss_dice: 0.5816, decode.d1.loss_cls: 0.0842, decode.d1.loss_mask: 0.2869, decode.d1.loss_dice: 0.5896, decode.d2.loss_cls: 0.0786, decode.d2.loss_mask: 0.2882, decode.d2.loss_dice: 0.5786, decode.d3.loss_cls: 0.0592, decode.d3.loss_mask: 0.2893, decode.d3.loss_dice: 0.5871, decode.d4.loss_cls: 0.0932, decode.d4.loss_mask: 0.2884, decode.d4.loss_dice: 0.5821, decode.d5.loss_cls: 0.0834, decode.d5.loss_mask: 0.2896, decode.d5.loss_dice: 0.5709, decode.d6.loss_cls: 0.0853, decode.d6.loss_mask: 0.2896, decode.d6.loss_dice: 0.5902, decode.d7.loss_cls: 0.0808, decode.d7.loss_mask: 0.2889, decode.d7.loss_dice: 0.5911, decode.d8.loss_cls: 0.0687, decode.d8.loss_mask: 0.2897, decode.d8.loss_dice: 0.5845, loss: 9.6400
2023-09-29 04:09:05,671 - mmseg - INFO - Iter [22700/40000]	lr: 6.210e-07, eta: 14:43:33, time: 3.759, data_time: 0.084, memory: 21542, decode.loss_cls: 0.0499, decode.loss_mask: 0.2769, decode.loss_dice: 0.5609, decode.d0.loss_cls: 0.2188, decode.d0.loss_mask: 0.2810, decode.d0.loss_dice: 0.5538, decode.d1.loss_cls: 0.0491, decode.d1.loss_mask: 0.2773, decode.d1.loss_dice: 0.5560, decode.d2.loss_cls: 0.0581, decode.d2.loss_mask: 0.2779, decode.d2.loss_dice: 0.5472, decode.d3.loss_cls: 0.0513, decode.d3.loss_mask: 0.2769, decode.d3.loss_dice: 0.5510, decode.d4.loss_cls: 0.0506, decode.d4.loss_mask: 0.2779, decode.d4.loss_dice: 0.5479, decode.d5.loss_cls: 0.0585, decode.d5.loss_mask: 0.2760, decode.d5.loss_dice: 0.5523, decode.d6.loss_cls: 0.0545, decode.d6.loss_mask: 0.2770, decode.d6.loss_dice: 0.5504, decode.d7.loss_cls: 0.0522, decode.d7.loss_mask: 0.2765, decode.d7.loss_dice: 0.5563, decode.d8.loss_cls: 0.0506, decode.d8.loss_mask: 0.2774, decode.d8.loss_dice: 0.5459, loss: 8.9899
2023-09-29 04:12:28,155 - mmseg - INFO - Iter [22750/40000]	lr: 6.192e-07, eta: 14:41:37, time: 4.048, data_time: 0.089, memory: 21542, decode.loss_cls: 0.0532, decode.loss_mask: 0.2650, decode.loss_dice: 0.5516, decode.d0.loss_cls: 0.2302, decode.d0.loss_mask: 0.2667, decode.d0.loss_dice: 0.5400, decode.d1.loss_cls: 0.0540, decode.d1.loss_mask: 0.2661, decode.d1.loss_dice: 0.5297, decode.d2.loss_cls: 0.0456, decode.d2.loss_mask: 0.2664, decode.d2.loss_dice: 0.5480, decode.d3.loss_cls: 0.0610, decode.d3.loss_mask: 0.2656, decode.d3.loss_dice: 0.5401, decode.d4.loss_cls: 0.0652, decode.d4.loss_mask: 0.2657, decode.d4.loss_dice: 0.5453, decode.d5.loss_cls: 0.0604, decode.d5.loss_mask: 0.2651, decode.d5.loss_dice: 0.5456, decode.d6.loss_cls: 0.0515, decode.d6.loss_mask: 0.2637, decode.d6.loss_dice: 0.5419, decode.d7.loss_cls: 0.0524, decode.d7.loss_mask: 0.2649, decode.d7.loss_dice: 0.5392, decode.d8.loss_cls: 0.0661, decode.d8.loss_mask: 0.2642, decode.d8.loss_dice: 0.5455, loss: 8.8197
2023-09-29 04:15:35,418 - mmseg - INFO - Iter [22800/40000]	lr: 6.174e-07, eta: 14:39:29, time: 3.747, data_time: 0.081, memory: 21542, decode.loss_cls: 0.0760, decode.loss_mask: 0.2842, decode.loss_dice: 0.5492, decode.d0.loss_cls: 0.2053, decode.d0.loss_mask: 0.3007, decode.d0.loss_dice: 0.5761, decode.d1.loss_cls: 0.0933, decode.d1.loss_mask: 0.2893, decode.d1.loss_dice: 0.5673, decode.d2.loss_cls: 0.0778, decode.d2.loss_mask: 0.2862, decode.d2.loss_dice: 0.5622, decode.d3.loss_cls: 0.0742, decode.d3.loss_mask: 0.2835, decode.d3.loss_dice: 0.5631, decode.d4.loss_cls: 0.0638, decode.d4.loss_mask: 0.2911, decode.d4.loss_dice: 0.5750, decode.d5.loss_cls: 0.0590, decode.d5.loss_mask: 0.2857, decode.d5.loss_dice: 0.5628, decode.d6.loss_cls: 0.0686, decode.d6.loss_mask: 0.2857, decode.d6.loss_dice: 0.5711, decode.d7.loss_cls: 0.0758, decode.d7.loss_mask: 0.2862, decode.d7.loss_dice: 0.5719, decode.d8.loss_cls: 0.0552, decode.d8.loss_mask: 0.2870, decode.d8.loss_dice: 0.5578, loss: 9.3850
2023-09-29 04:18:42,296 - mmseg - INFO - Iter [22850/40000]	lr: 6.156e-07, eta: 14:37:21, time: 3.737, data_time: 0.086, memory: 21542, decode.loss_cls: 0.0497, decode.loss_mask: 0.2581, decode.loss_dice: 0.5576, decode.d0.loss_cls: 0.2110, decode.d0.loss_mask: 0.2605, decode.d0.loss_dice: 0.5605, decode.d1.loss_cls: 0.0635, decode.d1.loss_mask: 0.2587, decode.d1.loss_dice: 0.5490, decode.d2.loss_cls: 0.0735, decode.d2.loss_mask: 0.2592, decode.d2.loss_dice: 0.5517, decode.d3.loss_cls: 0.0575, decode.d3.loss_mask: 0.2589, decode.d3.loss_dice: 0.5661, decode.d4.loss_cls: 0.0579, decode.d4.loss_mask: 0.2582, decode.d4.loss_dice: 0.5672, decode.d5.loss_cls: 0.0704, decode.d5.loss_mask: 0.2584, decode.d5.loss_dice: 0.5556, decode.d6.loss_cls: 0.0578, decode.d6.loss_mask: 0.2592, decode.d6.loss_dice: 0.5592, decode.d7.loss_cls: 0.0634, decode.d7.loss_mask: 0.2575, decode.d7.loss_dice: 0.5503, decode.d8.loss_cls: 0.0497, decode.d8.loss_mask: 0.2578, decode.d8.loss_dice: 0.5531, loss: 8.9111
2023-09-29 04:21:48,507 - mmseg - INFO - Iter [22900/40000]	lr: 6.138e-07, eta: 14:35:12, time: 3.723, data_time: 0.076, memory: 21542, decode.loss_cls: 0.0740, decode.loss_mask: 0.2782, decode.loss_dice: 0.5412, decode.d0.loss_cls: 0.2343, decode.d0.loss_mask: 0.2831, decode.d0.loss_dice: 0.5533, decode.d1.loss_cls: 0.1217, decode.d1.loss_mask: 0.2783, decode.d1.loss_dice: 0.5444, decode.d2.loss_cls: 0.0682, decode.d2.loss_mask: 0.2778, decode.d2.loss_dice: 0.5379, decode.d3.loss_cls: 0.1035, decode.d3.loss_mask: 0.2784, decode.d3.loss_dice: 0.5410, decode.d4.loss_cls: 0.0787, decode.d4.loss_mask: 0.2775, decode.d4.loss_dice: 0.5521, decode.d5.loss_cls: 0.0861, decode.d5.loss_mask: 0.2795, decode.d5.loss_dice: 0.5509, decode.d6.loss_cls: 0.0756, decode.d6.loss_mask: 0.2791, decode.d6.loss_dice: 0.5438, decode.d7.loss_cls: 0.0778, decode.d7.loss_mask: 0.2787, decode.d7.loss_dice: 0.5428, decode.d8.loss_cls: 0.0805, decode.d8.loss_mask: 0.2780, decode.d8.loss_dice: 0.5471, loss: 9.2437
2023-09-29 04:25:07,249 - mmseg - INFO - Iter [22950/40000]	lr: 6.120e-07, eta: 14:33:12, time: 3.977, data_time: 0.086, memory: 21542, decode.loss_cls: 0.0481, decode.loss_mask: 0.2416, decode.loss_dice: 0.5427, decode.d0.loss_cls: 0.2329, decode.d0.loss_mask: 0.2428, decode.d0.loss_dice: 0.5484, decode.d1.loss_cls: 0.0968, decode.d1.loss_mask: 0.2418, decode.d1.loss_dice: 0.5398, decode.d2.loss_cls: 0.0618, decode.d2.loss_mask: 0.2434, decode.d2.loss_dice: 0.5401, decode.d3.loss_cls: 0.0481, decode.d3.loss_mask: 0.2434, decode.d3.loss_dice: 0.5418, decode.d4.loss_cls: 0.0612, decode.d4.loss_mask: 0.2414, decode.d4.loss_dice: 0.5347, decode.d5.loss_cls: 0.0686, decode.d5.loss_mask: 0.2434, decode.d5.loss_dice: 0.5506, decode.d6.loss_cls: 0.0465, decode.d6.loss_mask: 0.2419, decode.d6.loss_dice: 0.5413, decode.d7.loss_cls: 0.0534, decode.d7.loss_mask: 0.2423, decode.d7.loss_dice: 0.5419, decode.d8.loss_cls: 0.0467, decode.d8.loss_mask: 0.2423, decode.d8.loss_dice: 0.5385, loss: 8.6085
2023-09-29 04:28:16,866 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 04:28:16,866 - mmseg - INFO - Iter [23000/40000]	lr: 6.102e-07, eta: 14:31:05, time: 3.792, data_time: 0.074, memory: 21542, decode.loss_cls: 0.1047, decode.loss_mask: 0.2796, decode.loss_dice: 0.5250, decode.d0.loss_cls: 0.2442, decode.d0.loss_mask: 0.2856, decode.d0.loss_dice: 0.5501, decode.d1.loss_cls: 0.1149, decode.d1.loss_mask: 0.2820, decode.d1.loss_dice: 0.5283, decode.d2.loss_cls: 0.1081, decode.d2.loss_mask: 0.2793, decode.d2.loss_dice: 0.5352, decode.d3.loss_cls: 0.0917, decode.d3.loss_mask: 0.2776, decode.d3.loss_dice: 0.5333, decode.d4.loss_cls: 0.1111, decode.d4.loss_mask: 0.2791, decode.d4.loss_dice: 0.5465, decode.d5.loss_cls: 0.0858, decode.d5.loss_mask: 0.2801, decode.d5.loss_dice: 0.5425, decode.d6.loss_cls: 0.0810, decode.d6.loss_mask: 0.2808, decode.d6.loss_dice: 0.5315, decode.d7.loss_cls: 0.0784, decode.d7.loss_mask: 0.2807, decode.d7.loss_dice: 0.5408, decode.d8.loss_cls: 0.1098, decode.d8.loss_mask: 0.2794, decode.d8.loss_dice: 0.5409, loss: 9.3077
2023-09-29 04:31:24,847 - mmseg - INFO - Iter [23050/40000]	lr: 6.085e-07, eta: 14:28:56, time: 3.759, data_time: 0.135, memory: 21542, decode.loss_cls: 0.0891, decode.loss_mask: 0.2987, decode.loss_dice: 0.5770, decode.d0.loss_cls: 0.2206, decode.d0.loss_mask: 0.3031, decode.d0.loss_dice: 0.5777, decode.d1.loss_cls: 0.0905, decode.d1.loss_mask: 0.2985, decode.d1.loss_dice: 0.5826, decode.d2.loss_cls: 0.0977, decode.d2.loss_mask: 0.2954, decode.d2.loss_dice: 0.5984, decode.d3.loss_cls: 0.0910, decode.d3.loss_mask: 0.2965, decode.d3.loss_dice: 0.5847, decode.d4.loss_cls: 0.0979, decode.d4.loss_mask: 0.2961, decode.d4.loss_dice: 0.5978, decode.d5.loss_cls: 0.1115, decode.d5.loss_mask: 0.2976, decode.d5.loss_dice: 0.5857, decode.d6.loss_cls: 0.0842, decode.d6.loss_mask: 0.2975, decode.d6.loss_dice: 0.5913, decode.d7.loss_cls: 0.0845, decode.d7.loss_mask: 0.2972, decode.d7.loss_dice: 0.5877, decode.d8.loss_cls: 0.0789, decode.d8.loss_mask: 0.2971, decode.d8.loss_dice: 0.5824, loss: 9.8887
2023-09-29 04:34:36,629 - mmseg - INFO - Iter [23100/40000]	lr: 6.067e-07, eta: 14:26:50, time: 3.836, data_time: 0.086, memory: 21542, decode.loss_cls: 0.0606, decode.loss_mask: 0.2785, decode.loss_dice: 0.5901, decode.d0.loss_cls: 0.1791, decode.d0.loss_mask: 0.2871, decode.d0.loss_dice: 0.6065, decode.d1.loss_cls: 0.0748, decode.d1.loss_mask: 0.2796, decode.d1.loss_dice: 0.5906, decode.d2.loss_cls: 0.0837, decode.d2.loss_mask: 0.2771, decode.d2.loss_dice: 0.5830, decode.d3.loss_cls: 0.0693, decode.d3.loss_mask: 0.2803, decode.d3.loss_dice: 0.5950, decode.d4.loss_cls: 0.0533, decode.d4.loss_mask: 0.2788, decode.d4.loss_dice: 0.5867, decode.d5.loss_cls: 0.0658, decode.d5.loss_mask: 0.2798, decode.d5.loss_dice: 0.5941, decode.d6.loss_cls: 0.0515, decode.d6.loss_mask: 0.2781, decode.d6.loss_dice: 0.5955, decode.d7.loss_cls: 0.0597, decode.d7.loss_mask: 0.2787, decode.d7.loss_dice: 0.5854, decode.d8.loss_cls: 0.0533, decode.d8.loss_mask: 0.2798, decode.d8.loss_dice: 0.5992, loss: 9.4749
2023-09-29 04:37:53,779 - mmseg - INFO - Iter [23150/40000]	lr: 6.049e-07, eta: 14:24:48, time: 3.942, data_time: 0.088, memory: 21542, decode.loss_cls: 0.0422, decode.loss_mask: 0.2544, decode.loss_dice: 0.4874, decode.d0.loss_cls: 0.2137, decode.d0.loss_mask: 0.2579, decode.d0.loss_dice: 0.5035, decode.d1.loss_cls: 0.0415, decode.d1.loss_mask: 0.2550, decode.d1.loss_dice: 0.4973, decode.d2.loss_cls: 0.0506, decode.d2.loss_mask: 0.2549, decode.d2.loss_dice: 0.4959, decode.d3.loss_cls: 0.0419, decode.d3.loss_mask: 0.2546, decode.d3.loss_dice: 0.4978, decode.d4.loss_cls: 0.0407, decode.d4.loss_mask: 0.2541, decode.d4.loss_dice: 0.4942, decode.d5.loss_cls: 0.0439, decode.d5.loss_mask: 0.2548, decode.d5.loss_dice: 0.4926, decode.d6.loss_cls: 0.0537, decode.d6.loss_mask: 0.2552, decode.d6.loss_dice: 0.4946, decode.d7.loss_cls: 0.0439, decode.d7.loss_mask: 0.2546, decode.d7.loss_dice: 0.4953, decode.d8.loss_cls: 0.0385, decode.d8.loss_mask: 0.2542, decode.d8.loss_dice: 0.4927, loss: 8.1119
2023-09-29 04:40:59,679 - mmseg - INFO - Iter [23200/40000]	lr: 6.031e-07, eta: 14:22:37, time: 3.718, data_time: 0.082, memory: 21542, decode.loss_cls: 0.0624, decode.loss_mask: 0.2543, decode.loss_dice: 0.5132, decode.d0.loss_cls: 0.2344, decode.d0.loss_mask: 0.2545, decode.d0.loss_dice: 0.5287, decode.d1.loss_cls: 0.0871, decode.d1.loss_mask: 0.2533, decode.d1.loss_dice: 0.5242, decode.d2.loss_cls: 0.0533, decode.d2.loss_mask: 0.2570, decode.d2.loss_dice: 0.5342, decode.d3.loss_cls: 0.0678, decode.d3.loss_mask: 0.2525, decode.d3.loss_dice: 0.5218, decode.d4.loss_cls: 0.0560, decode.d4.loss_mask: 0.2531, decode.d4.loss_dice: 0.5225, decode.d5.loss_cls: 0.0634, decode.d5.loss_mask: 0.2540, decode.d5.loss_dice: 0.5137, decode.d6.loss_cls: 0.0793, decode.d6.loss_mask: 0.2540, decode.d6.loss_dice: 0.5242, decode.d7.loss_cls: 0.0589, decode.d7.loss_mask: 0.2538, decode.d7.loss_dice: 0.5294, decode.d8.loss_cls: 0.0701, decode.d8.loss_mask: 0.2530, decode.d8.loss_dice: 0.5193, loss: 8.6032
2023-09-29 04:44:09,700 - mmseg - INFO - Iter [23250/40000]	lr: 6.013e-07, eta: 14:20:29, time: 3.800, data_time: 0.083, memory: 21542, decode.loss_cls: 0.0684, decode.loss_mask: 0.2685, decode.loss_dice: 0.5541, decode.d0.loss_cls: 0.2148, decode.d0.loss_mask: 0.2716, decode.d0.loss_dice: 0.5648, decode.d1.loss_cls: 0.0642, decode.d1.loss_mask: 0.2690, decode.d1.loss_dice: 0.5613, decode.d2.loss_cls: 0.0772, decode.d2.loss_mask: 0.2680, decode.d2.loss_dice: 0.5588, decode.d3.loss_cls: 0.0616, decode.d3.loss_mask: 0.2694, decode.d3.loss_dice: 0.5551, decode.d4.loss_cls: 0.0578, decode.d4.loss_mask: 0.2682, decode.d4.loss_dice: 0.5553, decode.d5.loss_cls: 0.0648, decode.d5.loss_mask: 0.2692, decode.d5.loss_dice: 0.5586, decode.d6.loss_cls: 0.0661, decode.d6.loss_mask: 0.2692, decode.d6.loss_dice: 0.5555, decode.d7.loss_cls: 0.0703, decode.d7.loss_mask: 0.2693, decode.d7.loss_dice: 0.5670, decode.d8.loss_cls: 0.0715, decode.d8.loss_mask: 0.2694, decode.d8.loss_dice: 0.5549, loss: 9.0940
2023-09-29 04:47:23,931 - mmseg - INFO - Iter [23300/40000]	lr: 5.995e-07, eta: 14:18:24, time: 3.885, data_time: 0.084, memory: 21542, decode.loss_cls: 0.0597, decode.loss_mask: 0.2892, decode.loss_dice: 0.5586, decode.d0.loss_cls: 0.2561, decode.d0.loss_mask: 0.2918, decode.d0.loss_dice: 0.5509, decode.d1.loss_cls: 0.1020, decode.d1.loss_mask: 0.2907, decode.d1.loss_dice: 0.5541, decode.d2.loss_cls: 0.0698, decode.d2.loss_mask: 0.2904, decode.d2.loss_dice: 0.5572, decode.d3.loss_cls: 0.0815, decode.d3.loss_mask: 0.2879, decode.d3.loss_dice: 0.5551, decode.d4.loss_cls: 0.0803, decode.d4.loss_mask: 0.2884, decode.d4.loss_dice: 0.5573, decode.d5.loss_cls: 0.0715, decode.d5.loss_mask: 0.2897, decode.d5.loss_dice: 0.5662, decode.d6.loss_cls: 0.0789, decode.d6.loss_mask: 0.2872, decode.d6.loss_dice: 0.5547, decode.d7.loss_cls: 0.0835, decode.d7.loss_mask: 0.2912, decode.d7.loss_dice: 0.5567, decode.d8.loss_cls: 0.0820, decode.d8.loss_mask: 0.2844, decode.d8.loss_dice: 0.5603, loss: 9.4271
2023-09-29 04:50:41,642 - mmseg - INFO - Iter [23350/40000]	lr: 5.977e-07, eta: 14:16:20, time: 3.956, data_time: 0.091, memory: 21542, decode.loss_cls: 0.0764, decode.loss_mask: 0.2721, decode.loss_dice: 0.5130, decode.d0.loss_cls: 0.2282, decode.d0.loss_mask: 0.2737, decode.d0.loss_dice: 0.5216, decode.d1.loss_cls: 0.0778, decode.d1.loss_mask: 0.2717, decode.d1.loss_dice: 0.5097, decode.d2.loss_cls: 0.0763, decode.d2.loss_mask: 0.2697, decode.d2.loss_dice: 0.5209, decode.d3.loss_cls: 0.0854, decode.d3.loss_mask: 0.2712, decode.d3.loss_dice: 0.5066, decode.d4.loss_cls: 0.0740, decode.d4.loss_mask: 0.2708, decode.d4.loss_dice: 0.5162, decode.d5.loss_cls: 0.0733, decode.d5.loss_mask: 0.2714, decode.d5.loss_dice: 0.5139, decode.d6.loss_cls: 0.0714, decode.d6.loss_mask: 0.2717, decode.d6.loss_dice: 0.5187, decode.d7.loss_cls: 0.0798, decode.d7.loss_mask: 0.2739, decode.d7.loss_dice: 0.5141, decode.d8.loss_cls: 0.0681, decode.d8.loss_mask: 0.2710, decode.d8.loss_dice: 0.5200, loss: 8.7826
2023-09-29 04:53:50,780 - mmseg - INFO - Iter [23400/40000]	lr: 5.959e-07, eta: 14:14:11, time: 3.782, data_time: 0.084, memory: 21542, decode.loss_cls: 0.0661, decode.loss_mask: 0.2472, decode.loss_dice: 0.5505, decode.d0.loss_cls: 0.2229, decode.d0.loss_mask: 0.2490, decode.d0.loss_dice: 0.5495, decode.d1.loss_cls: 0.1049, decode.d1.loss_mask: 0.2507, decode.d1.loss_dice: 0.5497, decode.d2.loss_cls: 0.0848, decode.d2.loss_mask: 0.2491, decode.d2.loss_dice: 0.5441, decode.d3.loss_cls: 0.1057, decode.d3.loss_mask: 0.2491, decode.d3.loss_dice: 0.5407, decode.d4.loss_cls: 0.1051, decode.d4.loss_mask: 0.2484, decode.d4.loss_dice: 0.5368, decode.d5.loss_cls: 0.0908, decode.d5.loss_mask: 0.2473, decode.d5.loss_dice: 0.5369, decode.d6.loss_cls: 0.0826, decode.d6.loss_mask: 0.2491, decode.d6.loss_dice: 0.5436, decode.d7.loss_cls: 0.0735, decode.d7.loss_mask: 0.2487, decode.d7.loss_dice: 0.5406, decode.d8.loss_cls: 0.1000, decode.d8.loss_mask: 0.2478, decode.d8.loss_dice: 0.5527, loss: 8.9680
2023-09-29 04:56:57,386 - mmseg - INFO - Iter [23450/40000]	lr: 5.941e-07, eta: 14:11:59, time: 3.732, data_time: 0.081, memory: 21542, decode.loss_cls: 0.0621, decode.loss_mask: 0.2956, decode.loss_dice: 0.5715, decode.d0.loss_cls: 0.2369, decode.d0.loss_mask: 0.2973, decode.d0.loss_dice: 0.5728, decode.d1.loss_cls: 0.0704, decode.d1.loss_mask: 0.2952, decode.d1.loss_dice: 0.5755, decode.d2.loss_cls: 0.0780, decode.d2.loss_mask: 0.2968, decode.d2.loss_dice: 0.5785, decode.d3.loss_cls: 0.0765, decode.d3.loss_mask: 0.2981, decode.d3.loss_dice: 0.5709, decode.d4.loss_cls: 0.0692, decode.d4.loss_mask: 0.2978, decode.d4.loss_dice: 0.5756, decode.d5.loss_cls: 0.0675, decode.d5.loss_mask: 0.2966, decode.d5.loss_dice: 0.5746, decode.d6.loss_cls: 0.0607, decode.d6.loss_mask: 0.2973, decode.d6.loss_dice: 0.5706, decode.d7.loss_cls: 0.0632, decode.d7.loss_mask: 0.2977, decode.d7.loss_dice: 0.5723, decode.d8.loss_cls: 0.0758, decode.d8.loss_mask: 0.2971, decode.d8.loss_dice: 0.5745, loss: 9.5668
2023-09-29 05:00:14,981 - mmseg - INFO - Iter [23500/40000]	lr: 5.923e-07, eta: 14:09:55, time: 3.952, data_time: 0.084, memory: 21542, decode.loss_cls: 0.0520, decode.loss_mask: 0.2955, decode.loss_dice: 0.5381, decode.d0.loss_cls: 0.2497, decode.d0.loss_mask: 0.3022, decode.d0.loss_dice: 0.5425, decode.d1.loss_cls: 0.0665, decode.d1.loss_mask: 0.2992, decode.d1.loss_dice: 0.5471, decode.d2.loss_cls: 0.0604, decode.d2.loss_mask: 0.2993, decode.d2.loss_dice: 0.5368, decode.d3.loss_cls: 0.0683, decode.d3.loss_mask: 0.2979, decode.d3.loss_dice: 0.5415, decode.d4.loss_cls: 0.0727, decode.d4.loss_mask: 0.2942, decode.d4.loss_dice: 0.5356, decode.d5.loss_cls: 0.0735, decode.d5.loss_mask: 0.2947, decode.d5.loss_dice: 0.5397, decode.d6.loss_cls: 0.0609, decode.d6.loss_mask: 0.2977, decode.d6.loss_dice: 0.5474, decode.d7.loss_cls: 0.0752, decode.d7.loss_mask: 0.2961, decode.d7.loss_dice: 0.5429, decode.d8.loss_cls: 0.0641, decode.d8.loss_mask: 0.2962, decode.d8.loss_dice: 0.5355, loss: 9.2235
2023-09-29 05:03:33,373 - mmseg - INFO - Iter [23550/40000]	lr: 5.905e-07, eta: 14:07:51, time: 3.967, data_time: 0.089, memory: 21542, decode.loss_cls: 0.0592, decode.loss_mask: 0.2608, decode.loss_dice: 0.5538, decode.d0.loss_cls: 0.1995, decode.d0.loss_mask: 0.2632, decode.d0.loss_dice: 0.5590, decode.d1.loss_cls: 0.0584, decode.d1.loss_mask: 0.2608, decode.d1.loss_dice: 0.5567, decode.d2.loss_cls: 0.0690, decode.d2.loss_mask: 0.2597, decode.d2.loss_dice: 0.5562, decode.d3.loss_cls: 0.0791, decode.d3.loss_mask: 0.2598, decode.d3.loss_dice: 0.5581, decode.d4.loss_cls: 0.0680, decode.d4.loss_mask: 0.2625, decode.d4.loss_dice: 0.5667, decode.d5.loss_cls: 0.0559, decode.d5.loss_mask: 0.2599, decode.d5.loss_dice: 0.5601, decode.d6.loss_cls: 0.0624, decode.d6.loss_mask: 0.2613, decode.d6.loss_dice: 0.5560, decode.d7.loss_cls: 0.0594, decode.d7.loss_mask: 0.2593, decode.d7.loss_dice: 0.5541, decode.d8.loss_cls: 0.0647, decode.d8.loss_mask: 0.2599, decode.d8.loss_dice: 0.5531, loss: 8.9566
2023-09-29 05:06:40,579 - mmseg - INFO - Iter [23600/40000]	lr: 5.887e-07, eta: 14:05:39, time: 3.744, data_time: 0.076, memory: 21542, decode.loss_cls: 0.0905, decode.loss_mask: 0.2677, decode.loss_dice: 0.5307, decode.d0.loss_cls: 0.2269, decode.d0.loss_mask: 0.2688, decode.d0.loss_dice: 0.5483, decode.d1.loss_cls: 0.0722, decode.d1.loss_mask: 0.2665, decode.d1.loss_dice: 0.5447, decode.d2.loss_cls: 0.0739, decode.d2.loss_mask: 0.2673, decode.d2.loss_dice: 0.5284, decode.d3.loss_cls: 0.0787, decode.d3.loss_mask: 0.2673, decode.d3.loss_dice: 0.5522, decode.d4.loss_cls: 0.0595, decode.d4.loss_mask: 0.2660, decode.d4.loss_dice: 0.5283, decode.d5.loss_cls: 0.0631, decode.d5.loss_mask: 0.2675, decode.d5.loss_dice: 0.5478, decode.d6.loss_cls: 0.0699, decode.d6.loss_mask: 0.2679, decode.d6.loss_dice: 0.5336, decode.d7.loss_cls: 0.0710, decode.d7.loss_mask: 0.2667, decode.d7.loss_dice: 0.5380, decode.d8.loss_cls: 0.0616, decode.d8.loss_mask: 0.2652, decode.d8.loss_dice: 0.5408, loss: 8.9308
2023-09-29 05:09:48,443 - mmseg - INFO - Iter [23650/40000]	lr: 5.869e-07, eta: 14:03:27, time: 3.757, data_time: 0.068, memory: 21542, decode.loss_cls: 0.0499, decode.loss_mask: 0.2815, decode.loss_dice: 0.5421, decode.d0.loss_cls: 0.2157, decode.d0.loss_mask: 0.2790, decode.d0.loss_dice: 0.5552, decode.d1.loss_cls: 0.0713, decode.d1.loss_mask: 0.2777, decode.d1.loss_dice: 0.5495, decode.d2.loss_cls: 0.0707, decode.d2.loss_mask: 0.2815, decode.d2.loss_dice: 0.5479, decode.d3.loss_cls: 0.0564, decode.d3.loss_mask: 0.2812, decode.d3.loss_dice: 0.5423, decode.d4.loss_cls: 0.0660, decode.d4.loss_mask: 0.2813, decode.d4.loss_dice: 0.5442, decode.d5.loss_cls: 0.0670, decode.d5.loss_mask: 0.2830, decode.d5.loss_dice: 0.5453, decode.d6.loss_cls: 0.0643, decode.d6.loss_mask: 0.2836, decode.d6.loss_dice: 0.5505, decode.d7.loss_cls: 0.0706, decode.d7.loss_mask: 0.2828, decode.d7.loss_dice: 0.5402, decode.d8.loss_cls: 0.0652, decode.d8.loss_mask: 0.2820, decode.d8.loss_dice: 0.5471, loss: 9.0750
2023-09-29 05:13:06,005 - mmseg - INFO - Iter [23700/40000]	lr: 5.851e-07, eta: 14:01:22, time: 3.953, data_time: 0.077, memory: 21542, decode.loss_cls: 0.0529, decode.loss_mask: 0.2534, decode.loss_dice: 0.5161, decode.d0.loss_cls: 0.2079, decode.d0.loss_mask: 0.2558, decode.d0.loss_dice: 0.5278, decode.d1.loss_cls: 0.0572, decode.d1.loss_mask: 0.2504, decode.d1.loss_dice: 0.5121, decode.d2.loss_cls: 0.0430, decode.d2.loss_mask: 0.2542, decode.d2.loss_dice: 0.5237, decode.d3.loss_cls: 0.0473, decode.d3.loss_mask: 0.2535, decode.d3.loss_dice: 0.5202, decode.d4.loss_cls: 0.0422, decode.d4.loss_mask: 0.2534, decode.d4.loss_dice: 0.5195, decode.d5.loss_cls: 0.0519, decode.d5.loss_mask: 0.2536, decode.d5.loss_dice: 0.5205, decode.d6.loss_cls: 0.0416, decode.d6.loss_mask: 0.2538, decode.d6.loss_dice: 0.5212, decode.d7.loss_cls: 0.0397, decode.d7.loss_mask: 0.2543, decode.d7.loss_dice: 0.5158, decode.d8.loss_cls: 0.0549, decode.d8.loss_mask: 0.2503, decode.d8.loss_dice: 0.5182, loss: 8.3665
2023-09-29 05:16:23,431 - mmseg - INFO - Iter [23750/40000]	lr: 5.833e-07, eta: 13:59:16, time: 3.948, data_time: 0.080, memory: 21542, decode.loss_cls: 0.0698, decode.loss_mask: 0.2414, decode.loss_dice: 0.5175, decode.d0.loss_cls: 0.2154, decode.d0.loss_mask: 0.2406, decode.d0.loss_dice: 0.5313, decode.d1.loss_cls: 0.0640, decode.d1.loss_mask: 0.2425, decode.d1.loss_dice: 0.5124, decode.d2.loss_cls: 0.0590, decode.d2.loss_mask: 0.2429, decode.d2.loss_dice: 0.5176, decode.d3.loss_cls: 0.0659, decode.d3.loss_mask: 0.2417, decode.d3.loss_dice: 0.5172, decode.d4.loss_cls: 0.0724, decode.d4.loss_mask: 0.2424, decode.d4.loss_dice: 0.5120, decode.d5.loss_cls: 0.0633, decode.d5.loss_mask: 0.2423, decode.d5.loss_dice: 0.5119, decode.d6.loss_cls: 0.0586, decode.d6.loss_mask: 0.2435, decode.d6.loss_dice: 0.5121, decode.d7.loss_cls: 0.0702, decode.d7.loss_mask: 0.2431, decode.d7.loss_dice: 0.5118, decode.d8.loss_cls: 0.0658, decode.d8.loss_mask: 0.2418, decode.d8.loss_dice: 0.5179, loss: 8.3883
2023-09-29 05:19:32,213 - mmseg - INFO - Iter [23800/40000]	lr: 5.815e-07, eta: 13:57:04, time: 3.776, data_time: 0.079, memory: 21542, decode.loss_cls: 0.0573, decode.loss_mask: 0.2642, decode.loss_dice: 0.5270, decode.d0.loss_cls: 0.2026, decode.d0.loss_mask: 0.2673, decode.d0.loss_dice: 0.5438, decode.d1.loss_cls: 0.0907, decode.d1.loss_mask: 0.2636, decode.d1.loss_dice: 0.5234, decode.d2.loss_cls: 0.1008, decode.d2.loss_mask: 0.2631, decode.d2.loss_dice: 0.5169, decode.d3.loss_cls: 0.0659, decode.d3.loss_mask: 0.2622, decode.d3.loss_dice: 0.5161, decode.d4.loss_cls: 0.0671, decode.d4.loss_mask: 0.2627, decode.d4.loss_dice: 0.5141, decode.d5.loss_cls: 0.0641, decode.d5.loss_mask: 0.2631, decode.d5.loss_dice: 0.5240, decode.d6.loss_cls: 0.0624, decode.d6.loss_mask: 0.2630, decode.d6.loss_dice: 0.5138, decode.d7.loss_cls: 0.0744, decode.d7.loss_mask: 0.2629, decode.d7.loss_dice: 0.5238, decode.d8.loss_cls: 0.0706, decode.d8.loss_mask: 0.2630, decode.d8.loss_dice: 0.5182, loss: 8.7121
2023-09-29 05:22:44,391 - mmseg - INFO - Iter [23850/40000]	lr: 5.797e-07, eta: 13:54:55, time: 3.842, data_time: 0.085, memory: 21542, decode.loss_cls: 0.0866, decode.loss_mask: 0.2550, decode.loss_dice: 0.5632, decode.d0.loss_cls: 0.2392, decode.d0.loss_mask: 0.2580, decode.d0.loss_dice: 0.5722, decode.d1.loss_cls: 0.0891, decode.d1.loss_mask: 0.2551, decode.d1.loss_dice: 0.5732, decode.d2.loss_cls: 0.1059, decode.d2.loss_mask: 0.2567, decode.d2.loss_dice: 0.5593, decode.d3.loss_cls: 0.0869, decode.d3.loss_mask: 0.2550, decode.d3.loss_dice: 0.5522, decode.d4.loss_cls: 0.0935, decode.d4.loss_mask: 0.2563, decode.d4.loss_dice: 0.5471, decode.d5.loss_cls: 0.0981, decode.d5.loss_mask: 0.2563, decode.d5.loss_dice: 0.5551, decode.d6.loss_cls: 0.0907, decode.d6.loss_mask: 0.2555, decode.d6.loss_dice: 0.5561, decode.d7.loss_cls: 0.0771, decode.d7.loss_mask: 0.2550, decode.d7.loss_dice: 0.5577, decode.d8.loss_cls: 0.0697, decode.d8.loss_mask: 0.2553, decode.d8.loss_dice: 0.5696, loss: 9.2006
2023-09-29 05:26:03,658 - mmseg - INFO - Iter [23900/40000]	lr: 5.779e-07, eta: 13:52:49, time: 3.987, data_time: 0.085, memory: 21542, decode.loss_cls: 0.0568, decode.loss_mask: 0.2481, decode.loss_dice: 0.5461, decode.d0.loss_cls: 0.2069, decode.d0.loss_mask: 0.2488, decode.d0.loss_dice: 0.5582, decode.d1.loss_cls: 0.0814, decode.d1.loss_mask: 0.2493, decode.d1.loss_dice: 0.5454, decode.d2.loss_cls: 0.0693, decode.d2.loss_mask: 0.2491, decode.d2.loss_dice: 0.5528, decode.d3.loss_cls: 0.0625, decode.d3.loss_mask: 0.2479, decode.d3.loss_dice: 0.5425, decode.d4.loss_cls: 0.0695, decode.d4.loss_mask: 0.2476, decode.d4.loss_dice: 0.5360, decode.d5.loss_cls: 0.0586, decode.d5.loss_mask: 0.2477, decode.d5.loss_dice: 0.5439, decode.d6.loss_cls: 0.0566, decode.d6.loss_mask: 0.2500, decode.d6.loss_dice: 0.5491, decode.d7.loss_cls: 0.0594, decode.d7.loss_mask: 0.2491, decode.d7.loss_dice: 0.5480, decode.d8.loss_cls: 0.0688, decode.d8.loss_mask: 0.2484, decode.d8.loss_dice: 0.5469, loss: 8.7445
2023-09-29 05:29:23,517 - mmseg - INFO - Iter [23950/40000]	lr: 5.761e-07, eta: 13:50:44, time: 3.996, data_time: 0.093, memory: 21542, decode.loss_cls: 0.0628, decode.loss_mask: 0.2612, decode.loss_dice: 0.5407, decode.d0.loss_cls: 0.1938, decode.d0.loss_mask: 0.2653, decode.d0.loss_dice: 0.5605, decode.d1.loss_cls: 0.0664, decode.d1.loss_mask: 0.2609, decode.d1.loss_dice: 0.5582, decode.d2.loss_cls: 0.1024, decode.d2.loss_mask: 0.2606, decode.d2.loss_dice: 0.5356, decode.d3.loss_cls: 0.0744, decode.d3.loss_mask: 0.2619, decode.d3.loss_dice: 0.5419, decode.d4.loss_cls: 0.0854, decode.d4.loss_mask: 0.2625, decode.d4.loss_dice: 0.5444, decode.d5.loss_cls: 0.0638, decode.d5.loss_mask: 0.2601, decode.d5.loss_dice: 0.5433, decode.d6.loss_cls: 0.0572, decode.d6.loss_mask: 0.2612, decode.d6.loss_dice: 0.5522, decode.d7.loss_cls: 0.0710, decode.d7.loss_mask: 0.2606, decode.d7.loss_dice: 0.5414, decode.d8.loss_cls: 0.0505, decode.d8.loss_mask: 0.2591, decode.d8.loss_dice: 0.5502, loss: 8.9097
2023-09-29 05:32:33,140 - mmseg - INFO - Saving checkpoint at 24000 iterations
2023-09-29 05:34:00,171 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 05:34:00,172 - mmseg - INFO - Iter [24000/40000]	lr: 5.744e-07, eta: 13:49:30, time: 5.534, data_time: 0.080, memory: 21542, decode.loss_cls: 0.0680, decode.loss_mask: 0.2521, decode.loss_dice: 0.5240, decode.d0.loss_cls: 0.2233, decode.d0.loss_mask: 0.2549, decode.d0.loss_dice: 0.5363, decode.d1.loss_cls: 0.0845, decode.d1.loss_mask: 0.2518, decode.d1.loss_dice: 0.5276, decode.d2.loss_cls: 0.0831, decode.d2.loss_mask: 0.2517, decode.d2.loss_dice: 0.5286, decode.d3.loss_cls: 0.0627, decode.d3.loss_mask: 0.2515, decode.d3.loss_dice: 0.5322, decode.d4.loss_cls: 0.0547, decode.d4.loss_mask: 0.2528, decode.d4.loss_dice: 0.5308, decode.d5.loss_cls: 0.0626, decode.d5.loss_mask: 0.2530, decode.d5.loss_dice: 0.5428, decode.d6.loss_cls: 0.0611, decode.d6.loss_mask: 0.2520, decode.d6.loss_dice: 0.5341, decode.d7.loss_cls: 0.0568, decode.d7.loss_mask: 0.2519, decode.d7.loss_dice: 0.5366, decode.d8.loss_cls: 0.0507, decode.d8.loss_mask: 0.2518, decode.d8.loss_dice: 0.5263, loss: 8.6502
2023-09-29 06:03:57,903 - mmseg - INFO - per class results:
2023-09-29 06:03:57,905 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 93.09 | 96.54 |
|    Sidewalk   | 69.29 | 82.14 |
|  Construction | 82.22 | 94.56 |
|     Fence     | 32.44 | 35.85 |
|      Pole     | 58.87 | 69.61 |
| Traffic Light | 66.88 | 79.43 |
|  Traffic Sign | 72.96 | 82.43 |
|     Nature    |  88.5 | 93.62 |
|      Sky      | 96.61 | 97.94 |
|     Person    | 33.33 | 35.94 |
|     Rider     |  8.9  | 64.65 |
|      Car      | 91.62 | 95.06 |
|   background  | 96.27 |  98.4 |
+---------------+-------+-------+
2023-09-29 06:03:57,905 - mmseg - INFO - Summary:
2023-09-29 06:03:57,905 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.49 | 68.54 | 78.94 |
+-------+-------+-------+
2023-09-29 06:03:57,909 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 06:03:57,909 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9449, mIoU: 0.6854, mAcc: 0.7894, IoU.Road: 0.9309, IoU.Sidewalk: 0.6929, IoU.Construction: 0.8222, IoU.Fence: 0.3244, IoU.Pole: 0.5887, IoU.Traffic Light: 0.6688, IoU.Traffic Sign: 0.7296, IoU.Nature: 0.8850, IoU.Sky: 0.9661, IoU.Person: 0.3333, IoU.Rider: 0.0890, IoU.Car: 0.9162, IoU.background: 0.9627, Acc.Road: 0.9654, Acc.Sidewalk: 0.8214, Acc.Construction: 0.9456, Acc.Fence: 0.3585, Acc.Pole: 0.6961, Acc.Traffic Light: 0.7943, Acc.Traffic Sign: 0.8243, Acc.Nature: 0.9362, Acc.Sky: 0.9794, Acc.Person: 0.3594, Acc.Rider: 0.6465, Acc.Car: 0.9506, Acc.background: 0.9840
2023-09-29 06:07:13,655 - mmseg - INFO - Iter [24050/40000]	lr: 5.726e-07, eta: 14:07:13, time: 39.870, data_time: 36.045, memory: 21542, decode.loss_cls: 0.0752, decode.loss_mask: 0.2546, decode.loss_dice: 0.5243, decode.d0.loss_cls: 0.2552, decode.d0.loss_mask: 0.2597, decode.d0.loss_dice: 0.5315, decode.d1.loss_cls: 0.0876, decode.d1.loss_mask: 0.2534, decode.d1.loss_dice: 0.5125, decode.d2.loss_cls: 0.0993, decode.d2.loss_mask: 0.2522, decode.d2.loss_dice: 0.5154, decode.d3.loss_cls: 0.0852, decode.d3.loss_mask: 0.2539, decode.d3.loss_dice: 0.5118, decode.d4.loss_cls: 0.0946, decode.d4.loss_mask: 0.2534, decode.d4.loss_dice: 0.5302, decode.d5.loss_cls: 0.0774, decode.d5.loss_mask: 0.2544, decode.d5.loss_dice: 0.5153, decode.d6.loss_cls: 0.0838, decode.d6.loss_mask: 0.2541, decode.d6.loss_dice: 0.5122, decode.d7.loss_cls: 0.0912, decode.d7.loss_mask: 0.2544, decode.d7.loss_dice: 0.5214, decode.d8.loss_cls: 0.0977, decode.d8.loss_mask: 0.2533, decode.d8.loss_dice: 0.5062, loss: 8.7713
2023-09-29 06:10:39,203 - mmseg - INFO - Iter [24100/40000]	lr: 5.708e-07, eta: 14:05:04, time: 4.110, data_time: 0.093, memory: 21542, decode.loss_cls: 0.0534, decode.loss_mask: 0.2428, decode.loss_dice: 0.5302, decode.d0.loss_cls: 0.2428, decode.d0.loss_mask: 0.2448, decode.d0.loss_dice: 0.5479, decode.d1.loss_cls: 0.0748, decode.d1.loss_mask: 0.2416, decode.d1.loss_dice: 0.5258, decode.d2.loss_cls: 0.0671, decode.d2.loss_mask: 0.2418, decode.d2.loss_dice: 0.5277, decode.d3.loss_cls: 0.0507, decode.d3.loss_mask: 0.2421, decode.d3.loss_dice: 0.5308, decode.d4.loss_cls: 0.0682, decode.d4.loss_mask: 0.2418, decode.d4.loss_dice: 0.5281, decode.d5.loss_cls: 0.0696, decode.d5.loss_mask: 0.2423, decode.d5.loss_dice: 0.5275, decode.d6.loss_cls: 0.0693, decode.d6.loss_mask: 0.2415, decode.d6.loss_dice: 0.5363, decode.d7.loss_cls: 0.0708, decode.d7.loss_mask: 0.2404, decode.d7.loss_dice: 0.5237, decode.d8.loss_cls: 0.0578, decode.d8.loss_mask: 0.2407, decode.d8.loss_dice: 0.5327, loss: 8.5550
2023-09-29 06:13:54,940 - mmseg - INFO - Iter [24150/40000]	lr: 5.690e-07, eta: 14:02:49, time: 3.914, data_time: 0.142, memory: 21542, decode.loss_cls: 0.0638, decode.loss_mask: 0.2733, decode.loss_dice: 0.5653, decode.d0.loss_cls: 0.2210, decode.d0.loss_mask: 0.2785, decode.d0.loss_dice: 0.5831, decode.d1.loss_cls: 0.0717, decode.d1.loss_mask: 0.2750, decode.d1.loss_dice: 0.5685, decode.d2.loss_cls: 0.0447, decode.d2.loss_mask: 0.2730, decode.d2.loss_dice: 0.5677, decode.d3.loss_cls: 0.0488, decode.d3.loss_mask: 0.2739, decode.d3.loss_dice: 0.5674, decode.d4.loss_cls: 0.0645, decode.d4.loss_mask: 0.2747, decode.d4.loss_dice: 0.5692, decode.d5.loss_cls: 0.0653, decode.d5.loss_mask: 0.2756, decode.d5.loss_dice: 0.5662, decode.d6.loss_cls: 0.0579, decode.d6.loss_mask: 0.2745, decode.d6.loss_dice: 0.5774, decode.d7.loss_cls: 0.0595, decode.d7.loss_mask: 0.2757, decode.d7.loss_dice: 0.5727, decode.d8.loss_cls: 0.0542, decode.d8.loss_mask: 0.2734, decode.d8.loss_dice: 0.5798, loss: 9.2163
2023-09-29 06:17:04,363 - mmseg - INFO - Iter [24200/40000]	lr: 5.672e-07, eta: 14:00:28, time: 3.787, data_time: 0.088, memory: 21542, decode.loss_cls: 0.0542, decode.loss_mask: 0.2978, decode.loss_dice: 0.5302, decode.d0.loss_cls: 0.2276, decode.d0.loss_mask: 0.3090, decode.d0.loss_dice: 0.5396, decode.d1.loss_cls: 0.0670, decode.d1.loss_mask: 0.3022, decode.d1.loss_dice: 0.5410, decode.d2.loss_cls: 0.0623, decode.d2.loss_mask: 0.2983, decode.d2.loss_dice: 0.5207, decode.d3.loss_cls: 0.0571, decode.d3.loss_mask: 0.2985, decode.d3.loss_dice: 0.5287, decode.d4.loss_cls: 0.0502, decode.d4.loss_mask: 0.3000, decode.d4.loss_dice: 0.5375, decode.d5.loss_cls: 0.0593, decode.d5.loss_mask: 0.2999, decode.d5.loss_dice: 0.5380, decode.d6.loss_cls: 0.0591, decode.d6.loss_mask: 0.2996, decode.d6.loss_dice: 0.5268, decode.d7.loss_cls: 0.0517, decode.d7.loss_mask: 0.2982, decode.d7.loss_dice: 0.5268, decode.d8.loss_cls: 0.0401, decode.d8.loss_mask: 0.3001, decode.d8.loss_dice: 0.5311, loss: 9.0528
2023-09-29 06:20:15,967 - mmseg - INFO - Iter [24250/40000]	lr: 5.654e-07, eta: 13:58:10, time: 3.834, data_time: 0.079, memory: 21542, decode.loss_cls: 0.0419, decode.loss_mask: 0.2600, decode.loss_dice: 0.5368, decode.d0.loss_cls: 0.2383, decode.d0.loss_mask: 0.2704, decode.d0.loss_dice: 0.5442, decode.d1.loss_cls: 0.0549, decode.d1.loss_mask: 0.2640, decode.d1.loss_dice: 0.5317, decode.d2.loss_cls: 0.0568, decode.d2.loss_mask: 0.2619, decode.d2.loss_dice: 0.5326, decode.d3.loss_cls: 0.0684, decode.d3.loss_mask: 0.2599, decode.d3.loss_dice: 0.5271, decode.d4.loss_cls: 0.0599, decode.d4.loss_mask: 0.2621, decode.d4.loss_dice: 0.5452, decode.d5.loss_cls: 0.0621, decode.d5.loss_mask: 0.2629, decode.d5.loss_dice: 0.5382, decode.d6.loss_cls: 0.0607, decode.d6.loss_mask: 0.2629, decode.d6.loss_dice: 0.5421, decode.d7.loss_cls: 0.0583, decode.d7.loss_mask: 0.2605, decode.d7.loss_dice: 0.5314, decode.d8.loss_cls: 0.0551, decode.d8.loss_mask: 0.2601, decode.d8.loss_dice: 0.5410, loss: 8.7514
2023-09-29 06:23:40,568 - mmseg - INFO - Iter [24300/40000]	lr: 5.636e-07, eta: 13:55:59, time: 4.092, data_time: 0.091, memory: 21542, decode.loss_cls: 0.0574, decode.loss_mask: 0.2610, decode.loss_dice: 0.5298, decode.d0.loss_cls: 0.2086, decode.d0.loss_mask: 0.2665, decode.d0.loss_dice: 0.5401, decode.d1.loss_cls: 0.0580, decode.d1.loss_mask: 0.2649, decode.d1.loss_dice: 0.5275, decode.d2.loss_cls: 0.0497, decode.d2.loss_mask: 0.2626, decode.d2.loss_dice: 0.5271, decode.d3.loss_cls: 0.0555, decode.d3.loss_mask: 0.2638, decode.d3.loss_dice: 0.5344, decode.d4.loss_cls: 0.0561, decode.d4.loss_mask: 0.2635, decode.d4.loss_dice: 0.5231, decode.d5.loss_cls: 0.0595, decode.d5.loss_mask: 0.2651, decode.d5.loss_dice: 0.5237, decode.d6.loss_cls: 0.0635, decode.d6.loss_mask: 0.2624, decode.d6.loss_dice: 0.5374, decode.d7.loss_cls: 0.0541, decode.d7.loss_mask: 0.2630, decode.d7.loss_dice: 0.5277, decode.d8.loss_cls: 0.0585, decode.d8.loss_mask: 0.2614, decode.d8.loss_dice: 0.5279, loss: 8.6537
2023-09-29 06:26:51,773 - mmseg - INFO - Iter [24350/40000]	lr: 5.618e-07, eta: 13:53:40, time: 3.824, data_time: 0.086, memory: 21542, decode.loss_cls: 0.0772, decode.loss_mask: 0.2756, decode.loss_dice: 0.5519, decode.d0.loss_cls: 0.2178, decode.d0.loss_mask: 0.2786, decode.d0.loss_dice: 0.5693, decode.d1.loss_cls: 0.0785, decode.d1.loss_mask: 0.2741, decode.d1.loss_dice: 0.5629, decode.d2.loss_cls: 0.0847, decode.d2.loss_mask: 0.2771, decode.d2.loss_dice: 0.5490, decode.d3.loss_cls: 0.0799, decode.d3.loss_mask: 0.2750, decode.d3.loss_dice: 0.5407, decode.d4.loss_cls: 0.0842, decode.d4.loss_mask: 0.2761, decode.d4.loss_dice: 0.5492, decode.d5.loss_cls: 0.0793, decode.d5.loss_mask: 0.2741, decode.d5.loss_dice: 0.5430, decode.d6.loss_cls: 0.0810, decode.d6.loss_mask: 0.2773, decode.d6.loss_dice: 0.5517, decode.d7.loss_cls: 0.0727, decode.d7.loss_mask: 0.2750, decode.d7.loss_dice: 0.5496, decode.d8.loss_cls: 0.0801, decode.d8.loss_mask: 0.2748, decode.d8.loss_dice: 0.5512, loss: 9.2118
2023-09-29 06:30:03,323 - mmseg - INFO - Iter [24400/40000]	lr: 5.600e-07, eta: 13:51:20, time: 3.832, data_time: 0.089, memory: 21542, decode.loss_cls: 0.0586, decode.loss_mask: 0.2617, decode.loss_dice: 0.5249, decode.d0.loss_cls: 0.2265, decode.d0.loss_mask: 0.2571, decode.d0.loss_dice: 0.5411, decode.d1.loss_cls: 0.0589, decode.d1.loss_mask: 0.2631, decode.d1.loss_dice: 0.5451, decode.d2.loss_cls: 0.0560, decode.d2.loss_mask: 0.2627, decode.d2.loss_dice: 0.5436, decode.d3.loss_cls: 0.0497, decode.d3.loss_mask: 0.2631, decode.d3.loss_dice: 0.5271, decode.d4.loss_cls: 0.0401, decode.d4.loss_mask: 0.2639, decode.d4.loss_dice: 0.5283, decode.d5.loss_cls: 0.0529, decode.d5.loss_mask: 0.2621, decode.d5.loss_dice: 0.5265, decode.d6.loss_cls: 0.0558, decode.d6.loss_mask: 0.2612, decode.d6.loss_dice: 0.5365, decode.d7.loss_cls: 0.0615, decode.d7.loss_mask: 0.2632, decode.d7.loss_dice: 0.5347, decode.d8.loss_cls: 0.0495, decode.d8.loss_mask: 0.2625, decode.d8.loss_dice: 0.5381, loss: 8.6758
2023-09-29 06:33:18,679 - mmseg - INFO - Iter [24450/40000]	lr: 5.582e-07, eta: 13:49:03, time: 3.906, data_time: 0.082, memory: 21542, decode.loss_cls: 0.0726, decode.loss_mask: 0.2418, decode.loss_dice: 0.5190, decode.d0.loss_cls: 0.2166, decode.d0.loss_mask: 0.2424, decode.d0.loss_dice: 0.5476, decode.d1.loss_cls: 0.0811, decode.d1.loss_mask: 0.2420, decode.d1.loss_dice: 0.5263, decode.d2.loss_cls: 0.0618, decode.d2.loss_mask: 0.2430, decode.d2.loss_dice: 0.5245, decode.d3.loss_cls: 0.0575, decode.d3.loss_mask: 0.2439, decode.d3.loss_dice: 0.5248, decode.d4.loss_cls: 0.0505, decode.d4.loss_mask: 0.2433, decode.d4.loss_dice: 0.5252, decode.d5.loss_cls: 0.0597, decode.d5.loss_mask: 0.2427, decode.d5.loss_dice: 0.5310, decode.d6.loss_cls: 0.0741, decode.d6.loss_mask: 0.2424, decode.d6.loss_dice: 0.5216, decode.d7.loss_cls: 0.0747, decode.d7.loss_mask: 0.2441, decode.d7.loss_dice: 0.5253, decode.d8.loss_cls: 0.0572, decode.d8.loss_mask: 0.2430, decode.d8.loss_dice: 0.5235, loss: 8.5032
2023-09-29 06:36:46,961 - mmseg - INFO - Iter [24500/40000]	lr: 5.564e-07, eta: 13:46:53, time: 4.167, data_time: 0.090, memory: 21542, decode.loss_cls: 0.0594, decode.loss_mask: 0.2571, decode.loss_dice: 0.5304, decode.d0.loss_cls: 0.2169, decode.d0.loss_mask: 0.2621, decode.d0.loss_dice: 0.5371, decode.d1.loss_cls: 0.0839, decode.d1.loss_mask: 0.2573, decode.d1.loss_dice: 0.5320, decode.d2.loss_cls: 0.0919, decode.d2.loss_mask: 0.2566, decode.d2.loss_dice: 0.5318, decode.d3.loss_cls: 0.0679, decode.d3.loss_mask: 0.2569, decode.d3.loss_dice: 0.5297, decode.d4.loss_cls: 0.0546, decode.d4.loss_mask: 0.2579, decode.d4.loss_dice: 0.5269, decode.d5.loss_cls: 0.0627, decode.d5.loss_mask: 0.2590, decode.d5.loss_dice: 0.5322, decode.d6.loss_cls: 0.0680, decode.d6.loss_mask: 0.2585, decode.d6.loss_dice: 0.5318, decode.d7.loss_cls: 0.0620, decode.d7.loss_mask: 0.2595, decode.d7.loss_dice: 0.5322, decode.d8.loss_cls: 0.0508, decode.d8.loss_mask: 0.2569, decode.d8.loss_dice: 0.5278, loss: 8.7117
2023-09-29 06:40:01,904 - mmseg - INFO - Iter [24550/40000]	lr: 5.546e-07, eta: 13:44:35, time: 3.899, data_time: 0.091, memory: 21542, decode.loss_cls: 0.0673, decode.loss_mask: 0.2478, decode.loss_dice: 0.5364, decode.d0.loss_cls: 0.2272, decode.d0.loss_mask: 0.2490, decode.d0.loss_dice: 0.5355, decode.d1.loss_cls: 0.0870, decode.d1.loss_mask: 0.2482, decode.d1.loss_dice: 0.5322, decode.d2.loss_cls: 0.0789, decode.d2.loss_mask: 0.2485, decode.d2.loss_dice: 0.5330, decode.d3.loss_cls: 0.0611, decode.d3.loss_mask: 0.2485, decode.d3.loss_dice: 0.5259, decode.d4.loss_cls: 0.0696, decode.d4.loss_mask: 0.2494, decode.d4.loss_dice: 0.5402, decode.d5.loss_cls: 0.0711, decode.d5.loss_mask: 0.2498, decode.d5.loss_dice: 0.5361, decode.d6.loss_cls: 0.0631, decode.d6.loss_mask: 0.2479, decode.d6.loss_dice: 0.5263, decode.d7.loss_cls: 0.0560, decode.d7.loss_mask: 0.2496, decode.d7.loss_dice: 0.5350, decode.d8.loss_cls: 0.0755, decode.d8.loss_mask: 0.2474, decode.d8.loss_dice: 0.5301, loss: 8.6738
2023-09-29 06:43:17,131 - mmseg - INFO - Iter [24600/40000]	lr: 5.528e-07, eta: 13:42:17, time: 3.902, data_time: 0.084, memory: 21542, decode.loss_cls: 0.0686, decode.loss_mask: 0.2652, decode.loss_dice: 0.5802, decode.d0.loss_cls: 0.2428, decode.d0.loss_mask: 0.2689, decode.d0.loss_dice: 0.5740, decode.d1.loss_cls: 0.0837, decode.d1.loss_mask: 0.2650, decode.d1.loss_dice: 0.5686, decode.d2.loss_cls: 0.0774, decode.d2.loss_mask: 0.2643, decode.d2.loss_dice: 0.5787, decode.d3.loss_cls: 0.0663, decode.d3.loss_mask: 0.2637, decode.d3.loss_dice: 0.5733, decode.d4.loss_cls: 0.0620, decode.d4.loss_mask: 0.2647, decode.d4.loss_dice: 0.5703, decode.d5.loss_cls: 0.0651, decode.d5.loss_mask: 0.2649, decode.d5.loss_dice: 0.5616, decode.d6.loss_cls: 0.0888, decode.d6.loss_mask: 0.2651, decode.d6.loss_dice: 0.5624, decode.d7.loss_cls: 0.0510, decode.d7.loss_mask: 0.2662, decode.d7.loss_dice: 0.5702, decode.d8.loss_cls: 0.0645, decode.d8.loss_mask: 0.2650, decode.d8.loss_dice: 0.5610, loss: 9.2234
2023-09-29 06:46:29,356 - mmseg - INFO - Iter [24650/40000]	lr: 5.510e-07, eta: 13:39:57, time: 3.845, data_time: 0.081, memory: 21542, decode.loss_cls: 0.0612, decode.loss_mask: 0.2875, decode.loss_dice: 0.5368, decode.d0.loss_cls: 0.2049, decode.d0.loss_mask: 0.2988, decode.d0.loss_dice: 0.5539, decode.d1.loss_cls: 0.0750, decode.d1.loss_mask: 0.2917, decode.d1.loss_dice: 0.5463, decode.d2.loss_cls: 0.0682, decode.d2.loss_mask: 0.2886, decode.d2.loss_dice: 0.5420, decode.d3.loss_cls: 0.0808, decode.d3.loss_mask: 0.2862, decode.d3.loss_dice: 0.5465, decode.d4.loss_cls: 0.0708, decode.d4.loss_mask: 0.2903, decode.d4.loss_dice: 0.5342, decode.d5.loss_cls: 0.0737, decode.d5.loss_mask: 0.2890, decode.d5.loss_dice: 0.5392, decode.d6.loss_cls: 0.0577, decode.d6.loss_mask: 0.2909, decode.d6.loss_dice: 0.5451, decode.d7.loss_cls: 0.0533, decode.d7.loss_mask: 0.2915, decode.d7.loss_dice: 0.5373, decode.d8.loss_cls: 0.0502, decode.d8.loss_mask: 0.2901, decode.d8.loss_dice: 0.5447, loss: 9.1264
2023-09-29 06:49:55,012 - mmseg - INFO - Iter [24700/40000]	lr: 5.492e-07, eta: 13:37:45, time: 4.114, data_time: 0.098, memory: 21542, decode.loss_cls: 0.0980, decode.loss_mask: 0.2796, decode.loss_dice: 0.5673, decode.d0.loss_cls: 0.2430, decode.d0.loss_mask: 0.2919, decode.d0.loss_dice: 0.6009, decode.d1.loss_cls: 0.1234, decode.d1.loss_mask: 0.2871, decode.d1.loss_dice: 0.5768, decode.d2.loss_cls: 0.1095, decode.d2.loss_mask: 0.2870, decode.d2.loss_dice: 0.5867, decode.d3.loss_cls: 0.0996, decode.d3.loss_mask: 0.2861, decode.d3.loss_dice: 0.5712, decode.d4.loss_cls: 0.1193, decode.d4.loss_mask: 0.2823, decode.d4.loss_dice: 0.5814, decode.d5.loss_cls: 0.1011, decode.d5.loss_mask: 0.2865, decode.d5.loss_dice: 0.5673, decode.d6.loss_cls: 0.0932, decode.d6.loss_mask: 0.2808, decode.d6.loss_dice: 0.5800, decode.d7.loss_cls: 0.0838, decode.d7.loss_mask: 0.2875, decode.d7.loss_dice: 0.5712, decode.d8.loss_cls: 0.0893, decode.d8.loss_mask: 0.2874, decode.d8.loss_dice: 0.5841, loss: 9.8031
2023-09-29 06:53:05,367 - mmseg - INFO - Iter [24750/40000]	lr: 5.474e-07, eta: 13:35:23, time: 3.807, data_time: 0.083, memory: 21542, decode.loss_cls: 0.0601, decode.loss_mask: 0.2981, decode.loss_dice: 0.6118, decode.d0.loss_cls: 0.2000, decode.d0.loss_mask: 0.3056, decode.d0.loss_dice: 0.6212, decode.d1.loss_cls: 0.0932, decode.d1.loss_mask: 0.2978, decode.d1.loss_dice: 0.6081, decode.d2.loss_cls: 0.0887, decode.d2.loss_mask: 0.2990, decode.d2.loss_dice: 0.6100, decode.d3.loss_cls: 0.0797, decode.d3.loss_mask: 0.2992, decode.d3.loss_dice: 0.6058, decode.d4.loss_cls: 0.0759, decode.d4.loss_mask: 0.2998, decode.d4.loss_dice: 0.6082, decode.d5.loss_cls: 0.0865, decode.d5.loss_mask: 0.2995, decode.d5.loss_dice: 0.6066, decode.d6.loss_cls: 0.0559, decode.d6.loss_mask: 0.2995, decode.d6.loss_dice: 0.6167, decode.d7.loss_cls: 0.0594, decode.d7.loss_mask: 0.2970, decode.d7.loss_dice: 0.6178, decode.d8.loss_cls: 0.0706, decode.d8.loss_mask: 0.2995, decode.d8.loss_dice: 0.6231, loss: 9.9942
2023-09-29 06:56:18,715 - mmseg - INFO - Iter [24800/40000]	lr: 5.456e-07, eta: 13:33:03, time: 3.867, data_time: 0.084, memory: 21542, decode.loss_cls: 0.0700, decode.loss_mask: 0.2620, decode.loss_dice: 0.5638, decode.d0.loss_cls: 0.2212, decode.d0.loss_mask: 0.2702, decode.d0.loss_dice: 0.5839, decode.d1.loss_cls: 0.1023, decode.d1.loss_mask: 0.2640, decode.d1.loss_dice: 0.5590, decode.d2.loss_cls: 0.0777, decode.d2.loss_mask: 0.2632, decode.d2.loss_dice: 0.5576, decode.d3.loss_cls: 0.0673, decode.d3.loss_mask: 0.2646, decode.d3.loss_dice: 0.5562, decode.d4.loss_cls: 0.0693, decode.d4.loss_mask: 0.2631, decode.d4.loss_dice: 0.5615, decode.d5.loss_cls: 0.0731, decode.d5.loss_mask: 0.2628, decode.d5.loss_dice: 0.5602, decode.d6.loss_cls: 0.0712, decode.d6.loss_mask: 0.2649, decode.d6.loss_dice: 0.5496, decode.d7.loss_cls: 0.0686, decode.d7.loss_mask: 0.2621, decode.d7.loss_dice: 0.5579, decode.d8.loss_cls: 0.0537, decode.d8.loss_mask: 0.2627, decode.d8.loss_dice: 0.5561, loss: 9.1199
2023-09-29 06:59:30,871 - mmseg - INFO - Iter [24850/40000]	lr: 5.438e-07, eta: 13:30:42, time: 3.842, data_time: 0.076, memory: 21542, decode.loss_cls: 0.0675, decode.loss_mask: 0.2461, decode.loss_dice: 0.5482, decode.d0.loss_cls: 0.2272, decode.d0.loss_mask: 0.2487, decode.d0.loss_dice: 0.5472, decode.d1.loss_cls: 0.0848, decode.d1.loss_mask: 0.2472, decode.d1.loss_dice: 0.5504, decode.d2.loss_cls: 0.0833, decode.d2.loss_mask: 0.2474, decode.d2.loss_dice: 0.5456, decode.d3.loss_cls: 0.0609, decode.d3.loss_mask: 0.2464, decode.d3.loss_dice: 0.5378, decode.d4.loss_cls: 0.0629, decode.d4.loss_mask: 0.2476, decode.d4.loss_dice: 0.5530, decode.d5.loss_cls: 0.0677, decode.d5.loss_mask: 0.2466, decode.d5.loss_dice: 0.5411, decode.d6.loss_cls: 0.0485, decode.d6.loss_mask: 0.2471, decode.d6.loss_dice: 0.5483, decode.d7.loss_cls: 0.0604, decode.d7.loss_mask: 0.2470, decode.d7.loss_dice: 0.5526, decode.d8.loss_cls: 0.0596, decode.d8.loss_mask: 0.2467, decode.d8.loss_dice: 0.5450, loss: 8.7628
2023-09-29 07:02:49,476 - mmseg - INFO - Iter [24900/40000]	lr: 5.420e-07, eta: 13:28:24, time: 3.971, data_time: 0.084, memory: 21542, decode.loss_cls: 0.0449, decode.loss_mask: 0.2642, decode.loss_dice: 0.5474, decode.d0.loss_cls: 0.2122, decode.d0.loss_mask: 0.2691, decode.d0.loss_dice: 0.5474, decode.d1.loss_cls: 0.0550, decode.d1.loss_mask: 0.2669, decode.d1.loss_dice: 0.5429, decode.d2.loss_cls: 0.0592, decode.d2.loss_mask: 0.2649, decode.d2.loss_dice: 0.5461, decode.d3.loss_cls: 0.0546, decode.d3.loss_mask: 0.2673, decode.d3.loss_dice: 0.5379, decode.d4.loss_cls: 0.0417, decode.d4.loss_mask: 0.2674, decode.d4.loss_dice: 0.5523, decode.d5.loss_cls: 0.0487, decode.d5.loss_mask: 0.2639, decode.d5.loss_dice: 0.5406, decode.d6.loss_cls: 0.0449, decode.d6.loss_mask: 0.2664, decode.d6.loss_dice: 0.5412, decode.d7.loss_cls: 0.0541, decode.d7.loss_mask: 0.2670, decode.d7.loss_dice: 0.5427, decode.d8.loss_cls: 0.0397, decode.d8.loss_mask: 0.2643, decode.d8.loss_dice: 0.5409, loss: 8.7558
2023-09-29 07:05:53,475 - mmseg - INFO - Iter [24950/40000]	lr: 5.403e-07, eta: 13:25:58, time: 3.682, data_time: 0.079, memory: 21542, decode.loss_cls: 0.0919, decode.loss_mask: 0.2670, decode.loss_dice: 0.5760, decode.d0.loss_cls: 0.2361, decode.d0.loss_mask: 0.2650, decode.d0.loss_dice: 0.5984, decode.d1.loss_cls: 0.1299, decode.d1.loss_mask: 0.2673, decode.d1.loss_dice: 0.5806, decode.d2.loss_cls: 0.0913, decode.d2.loss_mask: 0.2671, decode.d2.loss_dice: 0.5668, decode.d3.loss_cls: 0.0770, decode.d3.loss_mask: 0.2674, decode.d3.loss_dice: 0.5706, decode.d4.loss_cls: 0.0947, decode.d4.loss_mask: 0.2672, decode.d4.loss_dice: 0.5676, decode.d5.loss_cls: 0.1132, decode.d5.loss_mask: 0.2646, decode.d5.loss_dice: 0.5640, decode.d6.loss_cls: 0.1072, decode.d6.loss_mask: 0.2664, decode.d6.loss_dice: 0.5638, decode.d7.loss_cls: 0.0972, decode.d7.loss_mask: 0.2675, decode.d7.loss_dice: 0.5651, decode.d8.loss_cls: 0.1076, decode.d8.loss_mask: 0.2666, decode.d8.loss_dice: 0.5703, loss: 9.5356
2023-09-29 07:09:04,497 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 07:09:04,498 - mmseg - INFO - Iter [25000/40000]	lr: 5.385e-07, eta: 13:23:35, time: 3.821, data_time: 0.079, memory: 21542, decode.loss_cls: 0.0583, decode.loss_mask: 0.2753, decode.loss_dice: 0.5466, decode.d0.loss_cls: 0.2091, decode.d0.loss_mask: 0.2661, decode.d0.loss_dice: 0.5526, decode.d1.loss_cls: 0.0686, decode.d1.loss_mask: 0.2756, decode.d1.loss_dice: 0.5555, decode.d2.loss_cls: 0.0667, decode.d2.loss_mask: 0.2747, decode.d2.loss_dice: 0.5461, decode.d3.loss_cls: 0.0739, decode.d3.loss_mask: 0.2644, decode.d3.loss_dice: 0.5348, decode.d4.loss_cls: 0.0597, decode.d4.loss_mask: 0.2733, decode.d4.loss_dice: 0.5556, decode.d5.loss_cls: 0.0677, decode.d5.loss_mask: 0.2737, decode.d5.loss_dice: 0.5573, decode.d6.loss_cls: 0.0605, decode.d6.loss_mask: 0.2752, decode.d6.loss_dice: 0.5436, decode.d7.loss_cls: 0.0768, decode.d7.loss_mask: 0.2746, decode.d7.loss_dice: 0.5541, decode.d8.loss_cls: 0.0669, decode.d8.loss_mask: 0.2762, decode.d8.loss_dice: 0.5514, loss: 9.0349
2023-09-29 07:12:19,597 - mmseg - INFO - Iter [25050/40000]	lr: 5.367e-07, eta: 13:21:15, time: 3.903, data_time: 0.091, memory: 21542, decode.loss_cls: 0.0676, decode.loss_mask: 0.2431, decode.loss_dice: 0.5109, decode.d0.loss_cls: 0.2143, decode.d0.loss_mask: 0.2451, decode.d0.loss_dice: 0.5347, decode.d1.loss_cls: 0.0879, decode.d1.loss_mask: 0.2434, decode.d1.loss_dice: 0.5209, decode.d2.loss_cls: 0.0960, decode.d2.loss_mask: 0.2431, decode.d2.loss_dice: 0.5230, decode.d3.loss_cls: 0.0820, decode.d3.loss_mask: 0.2436, decode.d3.loss_dice: 0.5252, decode.d4.loss_cls: 0.0781, decode.d4.loss_mask: 0.2435, decode.d4.loss_dice: 0.5189, decode.d5.loss_cls: 0.0717, decode.d5.loss_mask: 0.2446, decode.d5.loss_dice: 0.5159, decode.d6.loss_cls: 0.0773, decode.d6.loss_mask: 0.2432, decode.d6.loss_dice: 0.5234, decode.d7.loss_cls: 0.0638, decode.d7.loss_mask: 0.2421, decode.d7.loss_dice: 0.5188, decode.d8.loss_cls: 0.0775, decode.d8.loss_mask: 0.2434, decode.d8.loss_dice: 0.5196, loss: 8.5627
2023-09-29 07:15:40,999 - mmseg - INFO - Iter [25100/40000]	lr: 5.349e-07, eta: 13:18:58, time: 4.027, data_time: 0.088, memory: 21542, decode.loss_cls: 0.0626, decode.loss_mask: 0.2839, decode.loss_dice: 0.5273, decode.d0.loss_cls: 0.2443, decode.d0.loss_mask: 0.2907, decode.d0.loss_dice: 0.5385, decode.d1.loss_cls: 0.0651, decode.d1.loss_mask: 0.2851, decode.d1.loss_dice: 0.5349, decode.d2.loss_cls: 0.0558, decode.d2.loss_mask: 0.2831, decode.d2.loss_dice: 0.5399, decode.d3.loss_cls: 0.0485, decode.d3.loss_mask: 0.2845, decode.d3.loss_dice: 0.5389, decode.d4.loss_cls: 0.0623, decode.d4.loss_mask: 0.2846, decode.d4.loss_dice: 0.5381, decode.d5.loss_cls: 0.0583, decode.d5.loss_mask: 0.2851, decode.d5.loss_dice: 0.5353, decode.d6.loss_cls: 0.0513, decode.d6.loss_mask: 0.2833, decode.d6.loss_dice: 0.5356, decode.d7.loss_cls: 0.0788, decode.d7.loss_mask: 0.2841, decode.d7.loss_dice: 0.5312, decode.d8.loss_cls: 0.0595, decode.d8.loss_mask: 0.2853, decode.d8.loss_dice: 0.5371, loss: 8.9932
2023-09-29 07:18:50,510 - mmseg - INFO - Iter [25150/40000]	lr: 5.331e-07, eta: 13:16:34, time: 3.792, data_time: 0.083, memory: 21542, decode.loss_cls: 0.1161, decode.loss_mask: 0.2999, decode.loss_dice: 0.5602, decode.d0.loss_cls: 0.2434, decode.d0.loss_mask: 0.3082, decode.d0.loss_dice: 0.5944, decode.d1.loss_cls: 0.1025, decode.d1.loss_mask: 0.3027, decode.d1.loss_dice: 0.5885, decode.d2.loss_cls: 0.1075, decode.d2.loss_mask: 0.3003, decode.d2.loss_dice: 0.5717, decode.d3.loss_cls: 0.1017, decode.d3.loss_mask: 0.2996, decode.d3.loss_dice: 0.5715, decode.d4.loss_cls: 0.1147, decode.d4.loss_mask: 0.3028, decode.d4.loss_dice: 0.5742, decode.d5.loss_cls: 0.1137, decode.d5.loss_mask: 0.3005, decode.d5.loss_dice: 0.5732, decode.d6.loss_cls: 0.1058, decode.d6.loss_mask: 0.2972, decode.d6.loss_dice: 0.5724, decode.d7.loss_cls: 0.0905, decode.d7.loss_mask: 0.3013, decode.d7.loss_dice: 0.5755, decode.d8.loss_cls: 0.1018, decode.d8.loss_mask: 0.2978, decode.d8.loss_dice: 0.5737, loss: 9.9631
2023-09-29 07:22:01,625 - mmseg - INFO - Iter [25200/40000]	lr: 5.313e-07, eta: 13:14:11, time: 3.821, data_time: 0.079, memory: 21542, decode.loss_cls: 0.0621, decode.loss_mask: 0.2679, decode.loss_dice: 0.5312, decode.d0.loss_cls: 0.2171, decode.d0.loss_mask: 0.2732, decode.d0.loss_dice: 0.5442, decode.d1.loss_cls: 0.0850, decode.d1.loss_mask: 0.2682, decode.d1.loss_dice: 0.5420, decode.d2.loss_cls: 0.0696, decode.d2.loss_mask: 0.2671, decode.d2.loss_dice: 0.5271, decode.d3.loss_cls: 0.0716, decode.d3.loss_mask: 0.2679, decode.d3.loss_dice: 0.5325, decode.d4.loss_cls: 0.0638, decode.d4.loss_mask: 0.2702, decode.d4.loss_dice: 0.5365, decode.d5.loss_cls: 0.0703, decode.d5.loss_mask: 0.2674, decode.d5.loss_dice: 0.5250, decode.d6.loss_cls: 0.0575, decode.d6.loss_mask: 0.2658, decode.d6.loss_dice: 0.5330, decode.d7.loss_cls: 0.0604, decode.d7.loss_mask: 0.2678, decode.d7.loss_dice: 0.5322, decode.d8.loss_cls: 0.0627, decode.d8.loss_mask: 0.2683, decode.d8.loss_dice: 0.5336, loss: 8.8414
2023-09-29 07:25:18,173 - mmseg - INFO - Iter [25250/40000]	lr: 5.295e-07, eta: 13:11:51, time: 3.931, data_time: 0.151, memory: 21542, decode.loss_cls: 0.0713, decode.loss_mask: 0.2518, decode.loss_dice: 0.5063, decode.d0.loss_cls: 0.2215, decode.d0.loss_mask: 0.2569, decode.d0.loss_dice: 0.5150, decode.d1.loss_cls: 0.0858, decode.d1.loss_mask: 0.2550, decode.d1.loss_dice: 0.5062, decode.d2.loss_cls: 0.0827, decode.d2.loss_mask: 0.2546, decode.d2.loss_dice: 0.5109, decode.d3.loss_cls: 0.0707, decode.d3.loss_mask: 0.2542, decode.d3.loss_dice: 0.5128, decode.d4.loss_cls: 0.0719, decode.d4.loss_mask: 0.2542, decode.d4.loss_dice: 0.5203, decode.d5.loss_cls: 0.0626, decode.d5.loss_mask: 0.2525, decode.d5.loss_dice: 0.5166, decode.d6.loss_cls: 0.0672, decode.d6.loss_mask: 0.2531, decode.d6.loss_dice: 0.5013, decode.d7.loss_cls: 0.0633, decode.d7.loss_mask: 0.2527, decode.d7.loss_dice: 0.5118, decode.d8.loss_cls: 0.0697, decode.d8.loss_mask: 0.2527, decode.d8.loss_dice: 0.5039, loss: 8.5094
2023-09-29 07:28:42,531 - mmseg - INFO - Iter [25300/40000]	lr: 5.277e-07, eta: 13:09:35, time: 4.087, data_time: 0.088, memory: 21542, decode.loss_cls: 0.0796, decode.loss_mask: 0.2980, decode.loss_dice: 0.5740, decode.d0.loss_cls: 0.2227, decode.d0.loss_mask: 0.2972, decode.d0.loss_dice: 0.5899, decode.d1.loss_cls: 0.1199, decode.d1.loss_mask: 0.2924, decode.d1.loss_dice: 0.5644, decode.d2.loss_cls: 0.0972, decode.d2.loss_mask: 0.2909, decode.d2.loss_dice: 0.5812, decode.d3.loss_cls: 0.1036, decode.d3.loss_mask: 0.2968, decode.d3.loss_dice: 0.5633, decode.d4.loss_cls: 0.0766, decode.d4.loss_mask: 0.2965, decode.d4.loss_dice: 0.5718, decode.d5.loss_cls: 0.0789, decode.d5.loss_mask: 0.2951, decode.d5.loss_dice: 0.5678, decode.d6.loss_cls: 0.0864, decode.d6.loss_mask: 0.2958, decode.d6.loss_dice: 0.5710, decode.d7.loss_cls: 0.0879, decode.d7.loss_mask: 0.2951, decode.d7.loss_dice: 0.5787, decode.d8.loss_cls: 0.0849, decode.d8.loss_mask: 0.2961, decode.d8.loss_dice: 0.5729, loss: 9.7265
2023-09-29 07:31:48,955 - mmseg - INFO - Iter [25350/40000]	lr: 5.259e-07, eta: 13:07:09, time: 3.730, data_time: 0.089, memory: 21542, decode.loss_cls: 0.0582, decode.loss_mask: 0.2671, decode.loss_dice: 0.5342, decode.d0.loss_cls: 0.2133, decode.d0.loss_mask: 0.2688, decode.d0.loss_dice: 0.5598, decode.d1.loss_cls: 0.0803, decode.d1.loss_mask: 0.2663, decode.d1.loss_dice: 0.5447, decode.d2.loss_cls: 0.0639, decode.d2.loss_mask: 0.2672, decode.d2.loss_dice: 0.5492, decode.d3.loss_cls: 0.0497, decode.d3.loss_mask: 0.2665, decode.d3.loss_dice: 0.5338, decode.d4.loss_cls: 0.0664, decode.d4.loss_mask: 0.2679, decode.d4.loss_dice: 0.5275, decode.d5.loss_cls: 0.0716, decode.d5.loss_mask: 0.2641, decode.d5.loss_dice: 0.5323, decode.d6.loss_cls: 0.0641, decode.d6.loss_mask: 0.2653, decode.d6.loss_dice: 0.5242, decode.d7.loss_cls: 0.0637, decode.d7.loss_mask: 0.2656, decode.d7.loss_dice: 0.5355, decode.d8.loss_cls: 0.0552, decode.d8.loss_mask: 0.2671, decode.d8.loss_dice: 0.5295, loss: 8.8233
2023-09-29 07:35:02,295 - mmseg - INFO - Iter [25400/40000]	lr: 5.241e-07, eta: 13:04:46, time: 3.866, data_time: 0.078, memory: 21542, decode.loss_cls: 0.1135, decode.loss_mask: 0.2765, decode.loss_dice: 0.5992, decode.d0.loss_cls: 0.2411, decode.d0.loss_mask: 0.2860, decode.d0.loss_dice: 0.6305, decode.d1.loss_cls: 0.1355, decode.d1.loss_mask: 0.2775, decode.d1.loss_dice: 0.6041, decode.d2.loss_cls: 0.1228, decode.d2.loss_mask: 0.2760, decode.d2.loss_dice: 0.5984, decode.d3.loss_cls: 0.1087, decode.d3.loss_mask: 0.2773, decode.d3.loss_dice: 0.6018, decode.d4.loss_cls: 0.1095, decode.d4.loss_mask: 0.2767, decode.d4.loss_dice: 0.5999, decode.d5.loss_cls: 0.1115, decode.d5.loss_mask: 0.2779, decode.d5.loss_dice: 0.5988, decode.d6.loss_cls: 0.1149, decode.d6.loss_mask: 0.2771, decode.d6.loss_dice: 0.6098, decode.d7.loss_cls: 0.1173, decode.d7.loss_mask: 0.2774, decode.d7.loss_dice: 0.6146, decode.d8.loss_cls: 0.1319, decode.d8.loss_mask: 0.2754, decode.d8.loss_dice: 0.6011, loss: 10.1426
2023-09-29 07:38:09,511 - mmseg - INFO - Iter [25450/40000]	lr: 5.223e-07, eta: 13:02:19, time: 3.744, data_time: 0.078, memory: 21542, decode.loss_cls: 0.0635, decode.loss_mask: 0.2598, decode.loss_dice: 0.5222, decode.d0.loss_cls: 0.2191, decode.d0.loss_mask: 0.2657, decode.d0.loss_dice: 0.5380, decode.d1.loss_cls: 0.0849, decode.d1.loss_mask: 0.2602, decode.d1.loss_dice: 0.5325, decode.d2.loss_cls: 0.0643, decode.d2.loss_mask: 0.2590, decode.d2.loss_dice: 0.5365, decode.d3.loss_cls: 0.0589, decode.d3.loss_mask: 0.2585, decode.d3.loss_dice: 0.5285, decode.d4.loss_cls: 0.0555, decode.d4.loss_mask: 0.2597, decode.d4.loss_dice: 0.5261, decode.d5.loss_cls: 0.0781, decode.d5.loss_mask: 0.2578, decode.d5.loss_dice: 0.5200, decode.d6.loss_cls: 0.0709, decode.d6.loss_mask: 0.2589, decode.d6.loss_dice: 0.5258, decode.d7.loss_cls: 0.0727, decode.d7.loss_mask: 0.2581, decode.d7.loss_dice: 0.5221, decode.d8.loss_cls: 0.0712, decode.d8.loss_mask: 0.2579, decode.d8.loss_dice: 0.5230, loss: 8.7092
2023-09-29 07:40:17,521 - mmseg - INFO - Iter [25500/40000]	lr: 5.205e-07, eta: 12:59:19, time: 2.561, data_time: 0.040, memory: 21542, decode.loss_cls: 0.0888, decode.loss_mask: 0.2560, decode.loss_dice: 0.5021, decode.d0.loss_cls: 0.2313, decode.d0.loss_mask: 0.2624, decode.d0.loss_dice: 0.5240, decode.d1.loss_cls: 0.0902, decode.d1.loss_mask: 0.2562, decode.d1.loss_dice: 0.5041, decode.d2.loss_cls: 0.0776, decode.d2.loss_mask: 0.2581, decode.d2.loss_dice: 0.5075, decode.d3.loss_cls: 0.0758, decode.d3.loss_mask: 0.2567, decode.d3.loss_dice: 0.4955, decode.d4.loss_cls: 0.0883, decode.d4.loss_mask: 0.2561, decode.d4.loss_dice: 0.4931, decode.d5.loss_cls: 0.0673, decode.d5.loss_mask: 0.2559, decode.d5.loss_dice: 0.5012, decode.d6.loss_cls: 0.0690, decode.d6.loss_mask: 0.2563, decode.d6.loss_dice: 0.4934, decode.d7.loss_cls: 0.0822, decode.d7.loss_mask: 0.2558, decode.d7.loss_dice: 0.4935, decode.d8.loss_cls: 0.0726, decode.d8.loss_mask: 0.2563, decode.d8.loss_dice: 0.4973, loss: 8.5247
2023-09-29 07:42:10,563 - mmseg - INFO - Iter [25550/40000]	lr: 5.187e-07, eta: 12:56:11, time: 2.260, data_time: 0.027, memory: 21542, decode.loss_cls: 0.1061, decode.loss_mask: 0.2819, decode.loss_dice: 0.5884, decode.d0.loss_cls: 0.2476, decode.d0.loss_mask: 0.2857, decode.d0.loss_dice: 0.5844, decode.d1.loss_cls: 0.1033, decode.d1.loss_mask: 0.2814, decode.d1.loss_dice: 0.5789, decode.d2.loss_cls: 0.0972, decode.d2.loss_mask: 0.2814, decode.d2.loss_dice: 0.5776, decode.d3.loss_cls: 0.0922, decode.d3.loss_mask: 0.2780, decode.d3.loss_dice: 0.5676, decode.d4.loss_cls: 0.0982, decode.d4.loss_mask: 0.2806, decode.d4.loss_dice: 0.5758, decode.d5.loss_cls: 0.0860, decode.d5.loss_mask: 0.2814, decode.d5.loss_dice: 0.5757, decode.d6.loss_cls: 0.1003, decode.d6.loss_mask: 0.2811, decode.d6.loss_dice: 0.5824, decode.d7.loss_cls: 0.0943, decode.d7.loss_mask: 0.2825, decode.d7.loss_dice: 0.5857, decode.d8.loss_cls: 0.0971, decode.d8.loss_mask: 0.2820, decode.d8.loss_dice: 0.5696, loss: 9.7246
2023-09-29 07:44:03,460 - mmseg - INFO - Iter [25600/40000]	lr: 5.169e-07, eta: 12:53:02, time: 2.258, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0426, decode.loss_mask: 0.2630, decode.loss_dice: 0.5284, decode.d0.loss_cls: 0.1975, decode.d0.loss_mask: 0.2675, decode.d0.loss_dice: 0.5390, decode.d1.loss_cls: 0.0706, decode.d1.loss_mask: 0.2646, decode.d1.loss_dice: 0.5360, decode.d2.loss_cls: 0.0742, decode.d2.loss_mask: 0.2652, decode.d2.loss_dice: 0.5307, decode.d3.loss_cls: 0.0528, decode.d3.loss_mask: 0.2644, decode.d3.loss_dice: 0.5260, decode.d4.loss_cls: 0.0574, decode.d4.loss_mask: 0.2660, decode.d4.loss_dice: 0.5336, decode.d5.loss_cls: 0.0665, decode.d5.loss_mask: 0.2646, decode.d5.loss_dice: 0.5311, decode.d6.loss_cls: 0.0611, decode.d6.loss_mask: 0.2652, decode.d6.loss_dice: 0.5309, decode.d7.loss_cls: 0.0726, decode.d7.loss_mask: 0.2645, decode.d7.loss_dice: 0.5299, decode.d8.loss_cls: 0.0466, decode.d8.loss_mask: 0.2635, decode.d8.loss_dice: 0.5375, loss: 8.7134
2023-09-29 07:45:56,398 - mmseg - INFO - Iter [25650/40000]	lr: 5.151e-07, eta: 12:49:54, time: 2.259, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0835, decode.loss_mask: 0.2601, decode.loss_dice: 0.5729, decode.d0.loss_cls: 0.2063, decode.d0.loss_mask: 0.2644, decode.d0.loss_dice: 0.5842, decode.d1.loss_cls: 0.1298, decode.d1.loss_mask: 0.2602, decode.d1.loss_dice: 0.5757, decode.d2.loss_cls: 0.0849, decode.d2.loss_mask: 0.2601, decode.d2.loss_dice: 0.5817, decode.d3.loss_cls: 0.0846, decode.d3.loss_mask: 0.2610, decode.d3.loss_dice: 0.5705, decode.d4.loss_cls: 0.0892, decode.d4.loss_mask: 0.2601, decode.d4.loss_dice: 0.5680, decode.d5.loss_cls: 0.0833, decode.d5.loss_mask: 0.2600, decode.d5.loss_dice: 0.5782, decode.d6.loss_cls: 0.1043, decode.d6.loss_mask: 0.2597, decode.d6.loss_dice: 0.5738, decode.d7.loss_cls: 0.0864, decode.d7.loss_mask: 0.2606, decode.d7.loss_dice: 0.5717, decode.d8.loss_cls: 0.0747, decode.d8.loss_mask: 0.2605, decode.d8.loss_dice: 0.5721, loss: 9.3826
2023-09-29 07:47:48,618 - mmseg - INFO - Iter [25700/40000]	lr: 5.133e-07, eta: 12:46:46, time: 2.245, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0351, decode.loss_mask: 0.2583, decode.loss_dice: 0.5196, decode.d0.loss_cls: 0.2065, decode.d0.loss_mask: 0.2614, decode.d0.loss_dice: 0.5285, decode.d1.loss_cls: 0.0388, decode.d1.loss_mask: 0.2608, decode.d1.loss_dice: 0.5294, decode.d2.loss_cls: 0.0433, decode.d2.loss_mask: 0.2602, decode.d2.loss_dice: 0.5177, decode.d3.loss_cls: 0.0454, decode.d3.loss_mask: 0.2596, decode.d3.loss_dice: 0.5172, decode.d4.loss_cls: 0.0510, decode.d4.loss_mask: 0.2579, decode.d4.loss_dice: 0.5167, decode.d5.loss_cls: 0.0416, decode.d5.loss_mask: 0.2598, decode.d5.loss_dice: 0.5274, decode.d6.loss_cls: 0.0304, decode.d6.loss_mask: 0.2587, decode.d6.loss_dice: 0.5152, decode.d7.loss_cls: 0.0460, decode.d7.loss_mask: 0.2596, decode.d7.loss_dice: 0.5214, decode.d8.loss_cls: 0.0287, decode.d8.loss_mask: 0.2590, decode.d8.loss_dice: 0.5229, loss: 8.3780
2023-09-29 07:49:41,486 - mmseg - INFO - Iter [25750/40000]	lr: 5.115e-07, eta: 12:43:39, time: 2.257, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0550, decode.loss_mask: 0.2741, decode.loss_dice: 0.5642, decode.d0.loss_cls: 0.2272, decode.d0.loss_mask: 0.2809, decode.d0.loss_dice: 0.5881, decode.d1.loss_cls: 0.0770, decode.d1.loss_mask: 0.2776, decode.d1.loss_dice: 0.5708, decode.d2.loss_cls: 0.0815, decode.d2.loss_mask: 0.2756, decode.d2.loss_dice: 0.5615, decode.d3.loss_cls: 0.0613, decode.d3.loss_mask: 0.2766, decode.d3.loss_dice: 0.5694, decode.d4.loss_cls: 0.0618, decode.d4.loss_mask: 0.2760, decode.d4.loss_dice: 0.5663, decode.d5.loss_cls: 0.0637, decode.d5.loss_mask: 0.2759, decode.d5.loss_dice: 0.5591, decode.d6.loss_cls: 0.0493, decode.d6.loss_mask: 0.2767, decode.d6.loss_dice: 0.5647, decode.d7.loss_cls: 0.0502, decode.d7.loss_mask: 0.2757, decode.d7.loss_dice: 0.5617, decode.d8.loss_cls: 0.0551, decode.d8.loss_mask: 0.2752, decode.d8.loss_dice: 0.5629, loss: 9.2151
2023-09-29 07:51:34,073 - mmseg - INFO - Iter [25800/40000]	lr: 5.097e-07, eta: 12:40:32, time: 2.252, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0927, decode.loss_mask: 0.2390, decode.loss_dice: 0.5203, decode.d0.loss_cls: 0.2194, decode.d0.loss_mask: 0.2436, decode.d0.loss_dice: 0.5427, decode.d1.loss_cls: 0.0651, decode.d1.loss_mask: 0.2423, decode.d1.loss_dice: 0.5312, decode.d2.loss_cls: 0.0820, decode.d2.loss_mask: 0.2396, decode.d2.loss_dice: 0.5264, decode.d3.loss_cls: 0.0657, decode.d3.loss_mask: 0.2402, decode.d3.loss_dice: 0.5339, decode.d4.loss_cls: 0.0622, decode.d4.loss_mask: 0.2409, decode.d4.loss_dice: 0.5280, decode.d5.loss_cls: 0.0979, decode.d5.loss_mask: 0.2397, decode.d5.loss_dice: 0.5336, decode.d6.loss_cls: 0.0816, decode.d6.loss_mask: 0.2410, decode.d6.loss_dice: 0.5269, decode.d7.loss_cls: 0.0843, decode.d7.loss_mask: 0.2394, decode.d7.loss_dice: 0.5390, decode.d8.loss_cls: 0.0670, decode.d8.loss_mask: 0.2392, decode.d8.loss_dice: 0.5285, loss: 8.6335
2023-09-29 07:53:26,681 - mmseg - INFO - Iter [25850/40000]	lr: 5.079e-07, eta: 12:37:25, time: 2.252, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0603, decode.loss_mask: 0.2347, decode.loss_dice: 0.5350, decode.d0.loss_cls: 0.2118, decode.d0.loss_mask: 0.2371, decode.d0.loss_dice: 0.5329, decode.d1.loss_cls: 0.0748, decode.d1.loss_mask: 0.2349, decode.d1.loss_dice: 0.5329, decode.d2.loss_cls: 0.0549, decode.d2.loss_mask: 0.2354, decode.d2.loss_dice: 0.5168, decode.d3.loss_cls: 0.0565, decode.d3.loss_mask: 0.2344, decode.d3.loss_dice: 0.5160, decode.d4.loss_cls: 0.0608, decode.d4.loss_mask: 0.2353, decode.d4.loss_dice: 0.5292, decode.d5.loss_cls: 0.0672, decode.d5.loss_mask: 0.2349, decode.d5.loss_dice: 0.5263, decode.d6.loss_cls: 0.0494, decode.d6.loss_mask: 0.2348, decode.d6.loss_dice: 0.5255, decode.d7.loss_cls: 0.0506, decode.d7.loss_mask: 0.2342, decode.d7.loss_dice: 0.5267, decode.d8.loss_cls: 0.0480, decode.d8.loss_mask: 0.2347, decode.d8.loss_dice: 0.5253, loss: 8.3512
2023-09-29 07:55:19,081 - mmseg - INFO - Iter [25900/40000]	lr: 5.062e-07, eta: 12:34:18, time: 2.248, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0584, decode.loss_mask: 0.2661, decode.loss_dice: 0.5128, decode.d0.loss_cls: 0.2388, decode.d0.loss_mask: 0.2734, decode.d0.loss_dice: 0.5423, decode.d1.loss_cls: 0.0521, decode.d1.loss_mask: 0.2691, decode.d1.loss_dice: 0.5280, decode.d2.loss_cls: 0.0562, decode.d2.loss_mask: 0.2683, decode.d2.loss_dice: 0.5218, decode.d3.loss_cls: 0.0685, decode.d3.loss_mask: 0.2667, decode.d3.loss_dice: 0.5168, decode.d4.loss_cls: 0.0582, decode.d4.loss_mask: 0.2659, decode.d4.loss_dice: 0.5227, decode.d5.loss_cls: 0.0636, decode.d5.loss_mask: 0.2671, decode.d5.loss_dice: 0.5250, decode.d6.loss_cls: 0.0580, decode.d6.loss_mask: 0.2674, decode.d6.loss_dice: 0.5238, decode.d7.loss_cls: 0.0646, decode.d7.loss_mask: 0.2665, decode.d7.loss_dice: 0.5174, decode.d8.loss_cls: 0.0508, decode.d8.loss_mask: 0.2685, decode.d8.loss_dice: 0.5237, loss: 8.6826
2023-09-29 07:57:12,244 - mmseg - INFO - Iter [25950/40000]	lr: 5.044e-07, eta: 12:31:12, time: 2.263, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0665, decode.loss_mask: 0.2687, decode.loss_dice: 0.5483, decode.d0.loss_cls: 0.2357, decode.d0.loss_mask: 0.2746, decode.d0.loss_dice: 0.5711, decode.d1.loss_cls: 0.1018, decode.d1.loss_mask: 0.2700, decode.d1.loss_dice: 0.5490, decode.d2.loss_cls: 0.0963, decode.d2.loss_mask: 0.2701, decode.d2.loss_dice: 0.5591, decode.d3.loss_cls: 0.0863, decode.d3.loss_mask: 0.2706, decode.d3.loss_dice: 0.5495, decode.d4.loss_cls: 0.0804, decode.d4.loss_mask: 0.2733, decode.d4.loss_dice: 0.5490, decode.d5.loss_cls: 0.0635, decode.d5.loss_mask: 0.2708, decode.d5.loss_dice: 0.5524, decode.d6.loss_cls: 0.0777, decode.d6.loss_mask: 0.2699, decode.d6.loss_dice: 0.5454, decode.d7.loss_cls: 0.0741, decode.d7.loss_mask: 0.2697, decode.d7.loss_dice: 0.5598, decode.d8.loss_cls: 0.0580, decode.d8.loss_mask: 0.2681, decode.d8.loss_dice: 0.5538, loss: 9.1838
2023-09-29 07:59:05,474 - mmseg - INFO - Saving checkpoint at 26000 iterations
2023-09-29 07:59:26,116 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 07:59:26,116 - mmseg - INFO - Iter [26000/40000]	lr: 5.026e-07, eta: 12:28:17, time: 2.678, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0675, decode.loss_mask: 0.2756, decode.loss_dice: 0.5598, decode.d0.loss_cls: 0.2060, decode.d0.loss_mask: 0.2878, decode.d0.loss_dice: 0.5850, decode.d1.loss_cls: 0.0866, decode.d1.loss_mask: 0.2790, decode.d1.loss_dice: 0.5497, decode.d2.loss_cls: 0.0704, decode.d2.loss_mask: 0.2772, decode.d2.loss_dice: 0.5552, decode.d3.loss_cls: 0.0653, decode.d3.loss_mask: 0.2775, decode.d3.loss_dice: 0.5749, decode.d4.loss_cls: 0.0730, decode.d4.loss_mask: 0.2769, decode.d4.loss_dice: 0.5722, decode.d5.loss_cls: 0.0491, decode.d5.loss_mask: 0.2769, decode.d5.loss_dice: 0.5719, decode.d6.loss_cls: 0.0613, decode.d6.loss_mask: 0.2744, decode.d6.loss_dice: 0.5520, decode.d7.loss_cls: 0.0618, decode.d7.loss_mask: 0.2774, decode.d7.loss_dice: 0.5730, decode.d8.loss_cls: 0.0536, decode.d8.loss_mask: 0.2768, decode.d8.loss_dice: 0.5595, loss: 9.2273
2023-09-29 08:16:41,797 - mmseg - INFO - per class results:
2023-09-29 08:16:41,798 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 92.84 | 97.13 |
|    Sidewalk   |  69.0 | 82.06 |
|  Construction | 82.28 | 94.19 |
|     Fence     | 32.34 | 35.87 |
|      Pole     | 58.79 | 72.27 |
| Traffic Light |  66.4 | 79.23 |
|  Traffic Sign | 72.51 | 80.19 |
|     Nature    | 88.69 | 93.95 |
|      Sky      | 96.54 | 97.98 |
|     Person    | 36.81 | 40.72 |
|     Rider     |  9.46 | 71.05 |
|      Car      | 91.61 | 94.97 |
|   background  | 96.21 | 97.57 |
+---------------+-------+-------+
2023-09-29 08:16:41,799 - mmseg - INFO - Summary:
2023-09-29 08:16:41,799 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.46 | 68.73 | 79.78 |
+-------+-------+-------+
2023-09-29 08:16:41,801 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 08:16:41,815 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9446, mIoU: 0.6873, mAcc: 0.7978, IoU.Road: 0.9284, IoU.Sidewalk: 0.6900, IoU.Construction: 0.8228, IoU.Fence: 0.3234, IoU.Pole: 0.5879, IoU.Traffic Light: 0.6640, IoU.Traffic Sign: 0.7251, IoU.Nature: 0.8869, IoU.Sky: 0.9654, IoU.Person: 0.3681, IoU.Rider: 0.0946, IoU.Car: 0.9161, IoU.background: 0.9621, Acc.Road: 0.9713, Acc.Sidewalk: 0.8206, Acc.Construction: 0.9419, Acc.Fence: 0.3587, Acc.Pole: 0.7227, Acc.Traffic Light: 0.7923, Acc.Traffic Sign: 0.8019, Acc.Nature: 0.9395, Acc.Sky: 0.9798, Acc.Person: 0.4072, Acc.Rider: 0.7105, Acc.Car: 0.9497, Acc.background: 0.9757
2023-09-29 08:18:34,010 - mmseg - INFO - Iter [26050/40000]	lr: 5.008e-07, eta: 12:34:25, time: 22.958, data_time: 20.744, memory: 21542, decode.loss_cls: 0.0567, decode.loss_mask: 0.2737, decode.loss_dice: 0.5548, decode.d0.loss_cls: 0.2190, decode.d0.loss_mask: 0.2768, decode.d0.loss_dice: 0.5602, decode.d1.loss_cls: 0.1088, decode.d1.loss_mask: 0.2724, decode.d1.loss_dice: 0.5612, decode.d2.loss_cls: 0.0737, decode.d2.loss_mask: 0.2725, decode.d2.loss_dice: 0.5565, decode.d3.loss_cls: 0.0584, decode.d3.loss_mask: 0.2761, decode.d3.loss_dice: 0.5467, decode.d4.loss_cls: 0.0552, decode.d4.loss_mask: 0.2747, decode.d4.loss_dice: 0.5568, decode.d5.loss_cls: 0.0538, decode.d5.loss_mask: 0.2738, decode.d5.loss_dice: 0.5607, decode.d6.loss_cls: 0.0518, decode.d6.loss_mask: 0.2752, decode.d6.loss_dice: 0.5595, decode.d7.loss_cls: 0.0594, decode.d7.loss_mask: 0.2730, decode.d7.loss_dice: 0.5531, decode.d8.loss_cls: 0.0480, decode.d8.loss_mask: 0.2738, decode.d8.loss_dice: 0.5425, loss: 9.0788
2023-09-29 08:20:27,294 - mmseg - INFO - Iter [26100/40000]	lr: 4.990e-07, eta: 12:31:17, time: 2.266, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0803, decode.loss_mask: 0.2669, decode.loss_dice: 0.5142, decode.d0.loss_cls: 0.2394, decode.d0.loss_mask: 0.2667, decode.d0.loss_dice: 0.5350, decode.d1.loss_cls: 0.1004, decode.d1.loss_mask: 0.2658, decode.d1.loss_dice: 0.5243, decode.d2.loss_cls: 0.0861, decode.d2.loss_mask: 0.2659, decode.d2.loss_dice: 0.5165, decode.d3.loss_cls: 0.0722, decode.d3.loss_mask: 0.2678, decode.d3.loss_dice: 0.5095, decode.d4.loss_cls: 0.0765, decode.d4.loss_mask: 0.2684, decode.d4.loss_dice: 0.5263, decode.d5.loss_cls: 0.0801, decode.d5.loss_mask: 0.2693, decode.d5.loss_dice: 0.5170, decode.d6.loss_cls: 0.0810, decode.d6.loss_mask: 0.2663, decode.d6.loss_dice: 0.5187, decode.d7.loss_cls: 0.0721, decode.d7.loss_mask: 0.2665, decode.d7.loss_dice: 0.5168, decode.d8.loss_cls: 0.0836, decode.d8.loss_mask: 0.2703, decode.d8.loss_dice: 0.5109, loss: 8.8348
2023-09-29 08:22:19,514 - mmseg - INFO - Iter [26150/40000]	lr: 4.972e-07, eta: 12:28:09, time: 2.244, data_time: 0.037, memory: 21542, decode.loss_cls: 0.0645, decode.loss_mask: 0.2632, decode.loss_dice: 0.5184, decode.d0.loss_cls: 0.2056, decode.d0.loss_mask: 0.2657, decode.d0.loss_dice: 0.5328, decode.d1.loss_cls: 0.0850, decode.d1.loss_mask: 0.2642, decode.d1.loss_dice: 0.5195, decode.d2.loss_cls: 0.0665, decode.d2.loss_mask: 0.2632, decode.d2.loss_dice: 0.5170, decode.d3.loss_cls: 0.0605, decode.d3.loss_mask: 0.2638, decode.d3.loss_dice: 0.5205, decode.d4.loss_cls: 0.0619, decode.d4.loss_mask: 0.2632, decode.d4.loss_dice: 0.5230, decode.d5.loss_cls: 0.0586, decode.d5.loss_mask: 0.2624, decode.d5.loss_dice: 0.5164, decode.d6.loss_cls: 0.0580, decode.d6.loss_mask: 0.2624, decode.d6.loss_dice: 0.5199, decode.d7.loss_cls: 0.0546, decode.d7.loss_mask: 0.2621, decode.d7.loss_dice: 0.5199, decode.d8.loss_cls: 0.0564, decode.d8.loss_mask: 0.2632, decode.d8.loss_dice: 0.5160, loss: 8.6084
2023-09-29 08:24:12,464 - mmseg - INFO - Iter [26200/40000]	lr: 4.954e-07, eta: 12:25:01, time: 2.259, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0818, decode.loss_mask: 0.2627, decode.loss_dice: 0.5816, decode.d0.loss_cls: 0.2159, decode.d0.loss_mask: 0.2695, decode.d0.loss_dice: 0.6042, decode.d1.loss_cls: 0.0916, decode.d1.loss_mask: 0.2664, decode.d1.loss_dice: 0.5810, decode.d2.loss_cls: 0.0815, decode.d2.loss_mask: 0.2644, decode.d2.loss_dice: 0.5692, decode.d3.loss_cls: 0.0711, decode.d3.loss_mask: 0.2661, decode.d3.loss_dice: 0.5871, decode.d4.loss_cls: 0.0716, decode.d4.loss_mask: 0.2636, decode.d4.loss_dice: 0.5824, decode.d5.loss_cls: 0.0719, decode.d5.loss_mask: 0.2647, decode.d5.loss_dice: 0.5864, decode.d6.loss_cls: 0.0697, decode.d6.loss_mask: 0.2644, decode.d6.loss_dice: 0.5833, decode.d7.loss_cls: 0.0903, decode.d7.loss_mask: 0.2613, decode.d7.loss_dice: 0.5753, decode.d8.loss_cls: 0.0819, decode.d8.loss_mask: 0.2643, decode.d8.loss_dice: 0.5849, loss: 9.4100
2023-09-29 08:26:05,310 - mmseg - INFO - Iter [26250/40000]	lr: 4.936e-07, eta: 12:21:53, time: 2.257, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0536, decode.loss_mask: 0.2534, decode.loss_dice: 0.5788, decode.d0.loss_cls: 0.2007, decode.d0.loss_mask: 0.2547, decode.d0.loss_dice: 0.6007, decode.d1.loss_cls: 0.0791, decode.d1.loss_mask: 0.2530, decode.d1.loss_dice: 0.5730, decode.d2.loss_cls: 0.0481, decode.d2.loss_mask: 0.2532, decode.d2.loss_dice: 0.5721, decode.d3.loss_cls: 0.0377, decode.d3.loss_mask: 0.2534, decode.d3.loss_dice: 0.5736, decode.d4.loss_cls: 0.0585, decode.d4.loss_mask: 0.2526, decode.d4.loss_dice: 0.5779, decode.d5.loss_cls: 0.0464, decode.d5.loss_mask: 0.2519, decode.d5.loss_dice: 0.5713, decode.d6.loss_cls: 0.0381, decode.d6.loss_mask: 0.2519, decode.d6.loss_dice: 0.5654, decode.d7.loss_cls: 0.0353, decode.d7.loss_mask: 0.2517, decode.d7.loss_dice: 0.5738, decode.d8.loss_cls: 0.0429, decode.d8.loss_mask: 0.2524, decode.d8.loss_dice: 0.5671, loss: 8.9222
2023-09-29 08:27:58,286 - mmseg - INFO - Iter [26300/40000]	lr: 4.918e-07, eta: 12:18:46, time: 2.259, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0558, decode.loss_mask: 0.2431, decode.loss_dice: 0.5214, decode.d0.loss_cls: 0.2266, decode.d0.loss_mask: 0.2459, decode.d0.loss_dice: 0.5377, decode.d1.loss_cls: 0.0601, decode.d1.loss_mask: 0.2446, decode.d1.loss_dice: 0.5298, decode.d2.loss_cls: 0.0615, decode.d2.loss_mask: 0.2441, decode.d2.loss_dice: 0.5164, decode.d3.loss_cls: 0.0536, decode.d3.loss_mask: 0.2438, decode.d3.loss_dice: 0.5131, decode.d4.loss_cls: 0.0656, decode.d4.loss_mask: 0.2451, decode.d4.loss_dice: 0.5224, decode.d5.loss_cls: 0.0552, decode.d5.loss_mask: 0.2449, decode.d5.loss_dice: 0.5232, decode.d6.loss_cls: 0.0591, decode.d6.loss_mask: 0.2436, decode.d6.loss_dice: 0.5132, decode.d7.loss_cls: 0.0489, decode.d7.loss_mask: 0.2438, decode.d7.loss_dice: 0.5155, decode.d8.loss_cls: 0.0481, decode.d8.loss_mask: 0.2450, decode.d8.loss_dice: 0.5146, loss: 8.3858
2023-09-29 08:29:53,177 - mmseg - INFO - Iter [26350/40000]	lr: 4.900e-07, eta: 12:15:40, time: 2.298, data_time: 0.077, memory: 21542, decode.loss_cls: 0.0355, decode.loss_mask: 0.2402, decode.loss_dice: 0.4950, decode.d0.loss_cls: 0.2051, decode.d0.loss_mask: 0.2416, decode.d0.loss_dice: 0.5088, decode.d1.loss_cls: 0.0529, decode.d1.loss_mask: 0.2420, decode.d1.loss_dice: 0.4983, decode.d2.loss_cls: 0.0534, decode.d2.loss_mask: 0.2404, decode.d2.loss_dice: 0.4978, decode.d3.loss_cls: 0.0651, decode.d3.loss_mask: 0.2396, decode.d3.loss_dice: 0.4954, decode.d4.loss_cls: 0.0580, decode.d4.loss_mask: 0.2409, decode.d4.loss_dice: 0.5017, decode.d5.loss_cls: 0.0443, decode.d5.loss_mask: 0.2401, decode.d5.loss_dice: 0.5035, decode.d6.loss_cls: 0.0502, decode.d6.loss_mask: 0.2419, decode.d6.loss_dice: 0.5030, decode.d7.loss_cls: 0.0381, decode.d7.loss_mask: 0.2411, decode.d7.loss_dice: 0.4938, decode.d8.loss_cls: 0.0476, decode.d8.loss_mask: 0.2393, decode.d8.loss_dice: 0.4955, loss: 8.0500
2023-09-29 08:31:45,684 - mmseg - INFO - Iter [26400/40000]	lr: 4.882e-07, eta: 12:12:33, time: 2.250, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0597, decode.loss_mask: 0.2782, decode.loss_dice: 0.5945, decode.d0.loss_cls: 0.2209, decode.d0.loss_mask: 0.2794, decode.d0.loss_dice: 0.6099, decode.d1.loss_cls: 0.0796, decode.d1.loss_mask: 0.2830, decode.d1.loss_dice: 0.5925, decode.d2.loss_cls: 0.0766, decode.d2.loss_mask: 0.2812, decode.d2.loss_dice: 0.5920, decode.d3.loss_cls: 0.0682, decode.d3.loss_mask: 0.2791, decode.d3.loss_dice: 0.5838, decode.d4.loss_cls: 0.0639, decode.d4.loss_mask: 0.2816, decode.d4.loss_dice: 0.5998, decode.d5.loss_cls: 0.0591, decode.d5.loss_mask: 0.2790, decode.d5.loss_dice: 0.5971, decode.d6.loss_cls: 0.0743, decode.d6.loss_mask: 0.2792, decode.d6.loss_dice: 0.5865, decode.d7.loss_cls: 0.0663, decode.d7.loss_mask: 0.2805, decode.d7.loss_dice: 0.5839, decode.d8.loss_cls: 0.0687, decode.d8.loss_mask: 0.2803, decode.d8.loss_dice: 0.6009, loss: 9.5795
2023-09-29 08:33:39,245 - mmseg - INFO - Iter [26450/40000]	lr: 4.864e-07, eta: 12:09:26, time: 2.271, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0637, decode.loss_mask: 0.2844, decode.loss_dice: 0.5818, decode.d0.loss_cls: 0.2214, decode.d0.loss_mask: 0.2927, decode.d0.loss_dice: 0.5938, decode.d1.loss_cls: 0.0648, decode.d1.loss_mask: 0.2940, decode.d1.loss_dice: 0.5913, decode.d2.loss_cls: 0.0538, decode.d2.loss_mask: 0.2895, decode.d2.loss_dice: 0.5881, decode.d3.loss_cls: 0.0741, decode.d3.loss_mask: 0.2916, decode.d3.loss_dice: 0.5878, decode.d4.loss_cls: 0.0618, decode.d4.loss_mask: 0.2916, decode.d4.loss_dice: 0.5991, decode.d5.loss_cls: 0.0646, decode.d5.loss_mask: 0.2831, decode.d5.loss_dice: 0.5869, decode.d6.loss_cls: 0.0618, decode.d6.loss_mask: 0.2830, decode.d6.loss_dice: 0.5782, decode.d7.loss_cls: 0.0776, decode.d7.loss_mask: 0.2855, decode.d7.loss_dice: 0.5826, decode.d8.loss_cls: 0.0565, decode.d8.loss_mask: 0.2924, decode.d8.loss_dice: 0.5862, loss: 9.5635
2023-09-29 08:35:31,531 - mmseg - INFO - Iter [26500/40000]	lr: 4.846e-07, eta: 12:06:20, time: 2.246, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0603, decode.loss_mask: 0.2491, decode.loss_dice: 0.5405, decode.d0.loss_cls: 0.1856, decode.d0.loss_mask: 0.2510, decode.d0.loss_dice: 0.5589, decode.d1.loss_cls: 0.1175, decode.d1.loss_mask: 0.2473, decode.d1.loss_dice: 0.5410, decode.d2.loss_cls: 0.0767, decode.d2.loss_mask: 0.2462, decode.d2.loss_dice: 0.5370, decode.d3.loss_cls: 0.0637, decode.d3.loss_mask: 0.2482, decode.d3.loss_dice: 0.5473, decode.d4.loss_cls: 0.0827, decode.d4.loss_mask: 0.2488, decode.d4.loss_dice: 0.5459, decode.d5.loss_cls: 0.0805, decode.d5.loss_mask: 0.2497, decode.d5.loss_dice: 0.5417, decode.d6.loss_cls: 0.0580, decode.d6.loss_mask: 0.2491, decode.d6.loss_dice: 0.5482, decode.d7.loss_cls: 0.0779, decode.d7.loss_mask: 0.2494, decode.d7.loss_dice: 0.5457, decode.d8.loss_cls: 0.0580, decode.d8.loss_mask: 0.2486, decode.d8.loss_dice: 0.5315, loss: 8.7860
2023-09-29 08:37:24,823 - mmseg - INFO - Iter [26550/40000]	lr: 4.828e-07, eta: 12:03:14, time: 2.266, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0552, decode.loss_mask: 0.2789, decode.loss_dice: 0.5369, decode.d0.loss_cls: 0.2112, decode.d0.loss_mask: 0.2863, decode.d0.loss_dice: 0.5549, decode.d1.loss_cls: 0.0650, decode.d1.loss_mask: 0.2792, decode.d1.loss_dice: 0.5407, decode.d2.loss_cls: 0.0664, decode.d2.loss_mask: 0.2783, decode.d2.loss_dice: 0.5539, decode.d3.loss_cls: 0.0764, decode.d3.loss_mask: 0.2786, decode.d3.loss_dice: 0.5488, decode.d4.loss_cls: 0.0538, decode.d4.loss_mask: 0.2793, decode.d4.loss_dice: 0.5621, decode.d5.loss_cls: 0.0602, decode.d5.loss_mask: 0.2777, decode.d5.loss_dice: 0.5355, decode.d6.loss_cls: 0.0699, decode.d6.loss_mask: 0.2793, decode.d6.loss_dice: 0.5443, decode.d7.loss_cls: 0.0600, decode.d7.loss_mask: 0.2806, decode.d7.loss_dice: 0.5469, decode.d8.loss_cls: 0.0662, decode.d8.loss_mask: 0.2785, decode.d8.loss_dice: 0.5508, loss: 9.0557
2023-09-29 08:39:16,962 - mmseg - INFO - Iter [26600/40000]	lr: 4.810e-07, eta: 12:00:08, time: 2.243, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0763, decode.loss_mask: 0.2886, decode.loss_dice: 0.5842, decode.d0.loss_cls: 0.2534, decode.d0.loss_mask: 0.2942, decode.d0.loss_dice: 0.6086, decode.d1.loss_cls: 0.0847, decode.d1.loss_mask: 0.2896, decode.d1.loss_dice: 0.6007, decode.d2.loss_cls: 0.0677, decode.d2.loss_mask: 0.2889, decode.d2.loss_dice: 0.6050, decode.d3.loss_cls: 0.0910, decode.d3.loss_mask: 0.2887, decode.d3.loss_dice: 0.5938, decode.d4.loss_cls: 0.0748, decode.d4.loss_mask: 0.2889, decode.d4.loss_dice: 0.6021, decode.d5.loss_cls: 0.0728, decode.d5.loss_mask: 0.2887, decode.d5.loss_dice: 0.5983, decode.d6.loss_cls: 0.0729, decode.d6.loss_mask: 0.2889, decode.d6.loss_dice: 0.6003, decode.d7.loss_cls: 0.0830, decode.d7.loss_mask: 0.2884, decode.d7.loss_dice: 0.5943, decode.d8.loss_cls: 0.0635, decode.d8.loss_mask: 0.2892, decode.d8.loss_dice: 0.5978, loss: 9.8196
2023-09-29 08:41:09,907 - mmseg - INFO - Iter [26650/40000]	lr: 4.792e-07, eta: 11:57:02, time: 2.259, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0542, decode.loss_mask: 0.2278, decode.loss_dice: 0.5060, decode.d0.loss_cls: 0.2175, decode.d0.loss_mask: 0.2292, decode.d0.loss_dice: 0.5203, decode.d1.loss_cls: 0.0831, decode.d1.loss_mask: 0.2286, decode.d1.loss_dice: 0.5146, decode.d2.loss_cls: 0.0596, decode.d2.loss_mask: 0.2289, decode.d2.loss_dice: 0.5154, decode.d3.loss_cls: 0.0737, decode.d3.loss_mask: 0.2286, decode.d3.loss_dice: 0.5054, decode.d4.loss_cls: 0.0742, decode.d4.loss_mask: 0.2274, decode.d4.loss_dice: 0.5067, decode.d5.loss_cls: 0.0703, decode.d5.loss_mask: 0.2272, decode.d5.loss_dice: 0.5097, decode.d6.loss_cls: 0.0568, decode.d6.loss_mask: 0.2282, decode.d6.loss_dice: 0.5061, decode.d7.loss_cls: 0.0599, decode.d7.loss_mask: 0.2285, decode.d7.loss_dice: 0.5164, decode.d8.loss_cls: 0.0518, decode.d8.loss_mask: 0.2294, decode.d8.loss_dice: 0.5150, loss: 8.2005
2023-09-29 08:43:02,806 - mmseg - INFO - Iter [26700/40000]	lr: 4.774e-07, eta: 11:53:57, time: 2.258, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0738, decode.loss_mask: 0.2639, decode.loss_dice: 0.5290, decode.d0.loss_cls: 0.2155, decode.d0.loss_mask: 0.2691, decode.d0.loss_dice: 0.5527, decode.d1.loss_cls: 0.0759, decode.d1.loss_mask: 0.2638, decode.d1.loss_dice: 0.5278, decode.d2.loss_cls: 0.0884, decode.d2.loss_mask: 0.2632, decode.d2.loss_dice: 0.5265, decode.d3.loss_cls: 0.0833, decode.d3.loss_mask: 0.2641, decode.d3.loss_dice: 0.5312, decode.d4.loss_cls: 0.0941, decode.d4.loss_mask: 0.2643, decode.d4.loss_dice: 0.5302, decode.d5.loss_cls: 0.0603, decode.d5.loss_mask: 0.2646, decode.d5.loss_dice: 0.5247, decode.d6.loss_cls: 0.0640, decode.d6.loss_mask: 0.2653, decode.d6.loss_dice: 0.5278, decode.d7.loss_cls: 0.0650, decode.d7.loss_mask: 0.2652, decode.d7.loss_dice: 0.5241, decode.d8.loss_cls: 0.0623, decode.d8.loss_mask: 0.2644, decode.d8.loss_dice: 0.5195, loss: 8.8239
2023-09-29 08:44:55,663 - mmseg - INFO - Iter [26750/40000]	lr: 4.756e-07, eta: 11:50:52, time: 2.257, data_time: 0.026, memory: 21542, decode.loss_cls: 0.0728, decode.loss_mask: 0.2773, decode.loss_dice: 0.5756, decode.d0.loss_cls: 0.2389, decode.d0.loss_mask: 0.2810, decode.d0.loss_dice: 0.5757, decode.d1.loss_cls: 0.0874, decode.d1.loss_mask: 0.2762, decode.d1.loss_dice: 0.5722, decode.d2.loss_cls: 0.0767, decode.d2.loss_mask: 0.2755, decode.d2.loss_dice: 0.5748, decode.d3.loss_cls: 0.0692, decode.d3.loss_mask: 0.2761, decode.d3.loss_dice: 0.5699, decode.d4.loss_cls: 0.0926, decode.d4.loss_mask: 0.2745, decode.d4.loss_dice: 0.5672, decode.d5.loss_cls: 0.0660, decode.d5.loss_mask: 0.2762, decode.d5.loss_dice: 0.5667, decode.d6.loss_cls: 0.0802, decode.d6.loss_mask: 0.2768, decode.d6.loss_dice: 0.5700, decode.d7.loss_cls: 0.0647, decode.d7.loss_mask: 0.2754, decode.d7.loss_dice: 0.5702, decode.d8.loss_cls: 0.0708, decode.d8.loss_mask: 0.2782, decode.d8.loss_dice: 0.5769, loss: 9.4057
2023-09-29 08:46:47,946 - mmseg - INFO - Iter [26800/40000]	lr: 4.738e-07, eta: 11:47:47, time: 2.246, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0647, decode.loss_mask: 0.2388, decode.loss_dice: 0.5206, decode.d0.loss_cls: 0.2320, decode.d0.loss_mask: 0.2390, decode.d0.loss_dice: 0.5311, decode.d1.loss_cls: 0.0729, decode.d1.loss_mask: 0.2405, decode.d1.loss_dice: 0.5251, decode.d2.loss_cls: 0.0959, decode.d2.loss_mask: 0.2397, decode.d2.loss_dice: 0.5165, decode.d3.loss_cls: 0.0760, decode.d3.loss_mask: 0.2394, decode.d3.loss_dice: 0.5228, decode.d4.loss_cls: 0.0757, decode.d4.loss_mask: 0.2397, decode.d4.loss_dice: 0.5329, decode.d5.loss_cls: 0.0752, decode.d5.loss_mask: 0.2394, decode.d5.loss_dice: 0.5332, decode.d6.loss_cls: 0.0483, decode.d6.loss_mask: 0.2406, decode.d6.loss_dice: 0.5349, decode.d7.loss_cls: 0.0698, decode.d7.loss_mask: 0.2403, decode.d7.loss_dice: 0.5229, decode.d8.loss_cls: 0.0536, decode.d8.loss_mask: 0.2401, decode.d8.loss_dice: 0.5305, loss: 8.5320
2023-09-29 08:48:41,212 - mmseg - INFO - Iter [26850/40000]	lr: 4.721e-07, eta: 11:44:43, time: 2.265, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0707, decode.loss_mask: 0.2707, decode.loss_dice: 0.5408, decode.d0.loss_cls: 0.2402, decode.d0.loss_mask: 0.2740, decode.d0.loss_dice: 0.5624, decode.d1.loss_cls: 0.0991, decode.d1.loss_mask: 0.2708, decode.d1.loss_dice: 0.5470, decode.d2.loss_cls: 0.0992, decode.d2.loss_mask: 0.2709, decode.d2.loss_dice: 0.5522, decode.d3.loss_cls: 0.0776, decode.d3.loss_mask: 0.2710, decode.d3.loss_dice: 0.5514, decode.d4.loss_cls: 0.0637, decode.d4.loss_mask: 0.2699, decode.d4.loss_dice: 0.5506, decode.d5.loss_cls: 0.0661, decode.d5.loss_mask: 0.2725, decode.d5.loss_dice: 0.5489, decode.d6.loss_cls: 0.0717, decode.d6.loss_mask: 0.2714, decode.d6.loss_dice: 0.5450, decode.d7.loss_cls: 0.0745, decode.d7.loss_mask: 0.2697, decode.d7.loss_dice: 0.5428, decode.d8.loss_cls: 0.0831, decode.d8.loss_mask: 0.2715, decode.d8.loss_dice: 0.5481, loss: 9.1471
2023-09-29 08:50:34,167 - mmseg - INFO - Iter [26900/40000]	lr: 4.703e-07, eta: 11:41:39, time: 2.259, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0906, decode.loss_mask: 0.2896, decode.loss_dice: 0.5597, decode.d0.loss_cls: 0.2490, decode.d0.loss_mask: 0.2967, decode.d0.loss_dice: 0.5703, decode.d1.loss_cls: 0.0934, decode.d1.loss_mask: 0.2917, decode.d1.loss_dice: 0.5515, decode.d2.loss_cls: 0.0874, decode.d2.loss_mask: 0.2891, decode.d2.loss_dice: 0.5526, decode.d3.loss_cls: 0.0784, decode.d3.loss_mask: 0.2875, decode.d3.loss_dice: 0.5615, decode.d4.loss_cls: 0.0982, decode.d4.loss_mask: 0.2845, decode.d4.loss_dice: 0.5524, decode.d5.loss_cls: 0.0769, decode.d5.loss_mask: 0.2865, decode.d5.loss_dice: 0.5477, decode.d6.loss_cls: 0.0916, decode.d6.loss_mask: 0.2884, decode.d6.loss_dice: 0.5571, decode.d7.loss_cls: 0.0983, decode.d7.loss_mask: 0.2863, decode.d7.loss_dice: 0.5529, decode.d8.loss_cls: 0.0845, decode.d8.loss_mask: 0.2878, decode.d8.loss_dice: 0.5512, loss: 9.4931
2023-09-29 08:52:27,099 - mmseg - INFO - Iter [26950/40000]	lr: 4.685e-07, eta: 11:38:35, time: 2.258, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0623, decode.loss_mask: 0.2695, decode.loss_dice: 0.5374, decode.d0.loss_cls: 0.2076, decode.d0.loss_mask: 0.2743, decode.d0.loss_dice: 0.5416, decode.d1.loss_cls: 0.0755, decode.d1.loss_mask: 0.2699, decode.d1.loss_dice: 0.5307, decode.d2.loss_cls: 0.0690, decode.d2.loss_mask: 0.2696, decode.d2.loss_dice: 0.5342, decode.d3.loss_cls: 0.0515, decode.d3.loss_mask: 0.2680, decode.d3.loss_dice: 0.5316, decode.d4.loss_cls: 0.0594, decode.d4.loss_mask: 0.2671, decode.d4.loss_dice: 0.5352, decode.d5.loss_cls: 0.0632, decode.d5.loss_mask: 0.2686, decode.d5.loss_dice: 0.5340, decode.d6.loss_cls: 0.0554, decode.d6.loss_mask: 0.2684, decode.d6.loss_dice: 0.5295, decode.d7.loss_cls: 0.0599, decode.d7.loss_mask: 0.2700, decode.d7.loss_dice: 0.5358, decode.d8.loss_cls: 0.0575, decode.d8.loss_mask: 0.2693, decode.d8.loss_dice: 0.5351, loss: 8.8011
2023-09-29 08:54:20,276 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 08:54:20,276 - mmseg - INFO - Iter [27000/40000]	lr: 4.667e-07, eta: 11:35:32, time: 2.264, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0579, decode.loss_mask: 0.2572, decode.loss_dice: 0.5616, decode.d0.loss_cls: 0.2143, decode.d0.loss_mask: 0.2592, decode.d0.loss_dice: 0.5684, decode.d1.loss_cls: 0.0770, decode.d1.loss_mask: 0.2560, decode.d1.loss_dice: 0.5486, decode.d2.loss_cls: 0.0764, decode.d2.loss_mask: 0.2554, decode.d2.loss_dice: 0.5398, decode.d3.loss_cls: 0.0771, decode.d3.loss_mask: 0.2574, decode.d3.loss_dice: 0.5450, decode.d4.loss_cls: 0.0804, decode.d4.loss_mask: 0.2554, decode.d4.loss_dice: 0.5516, decode.d5.loss_cls: 0.0722, decode.d5.loss_mask: 0.2552, decode.d5.loss_dice: 0.5328, decode.d6.loss_cls: 0.0718, decode.d6.loss_mask: 0.2566, decode.d6.loss_dice: 0.5374, decode.d7.loss_cls: 0.0683, decode.d7.loss_mask: 0.2567, decode.d7.loss_dice: 0.5525, decode.d8.loss_cls: 0.0685, decode.d8.loss_mask: 0.2578, decode.d8.loss_dice: 0.5551, loss: 8.9237
2023-09-29 08:56:12,612 - mmseg - INFO - Iter [27050/40000]	lr: 4.649e-07, eta: 11:32:28, time: 2.247, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0630, decode.loss_mask: 0.2479, decode.loss_dice: 0.5111, decode.d0.loss_cls: 0.1981, decode.d0.loss_mask: 0.2555, decode.d0.loss_dice: 0.5277, decode.d1.loss_cls: 0.0815, decode.d1.loss_mask: 0.2483, decode.d1.loss_dice: 0.5129, decode.d2.loss_cls: 0.0735, decode.d2.loss_mask: 0.2486, decode.d2.loss_dice: 0.5270, decode.d3.loss_cls: 0.0525, decode.d3.loss_mask: 0.2488, decode.d3.loss_dice: 0.5137, decode.d4.loss_cls: 0.0625, decode.d4.loss_mask: 0.2487, decode.d4.loss_dice: 0.5219, decode.d5.loss_cls: 0.0610, decode.d5.loss_mask: 0.2495, decode.d5.loss_dice: 0.5168, decode.d6.loss_cls: 0.0505, decode.d6.loss_mask: 0.2482, decode.d6.loss_dice: 0.5060, decode.d7.loss_cls: 0.0510, decode.d7.loss_mask: 0.2491, decode.d7.loss_dice: 0.5177, decode.d8.loss_cls: 0.0616, decode.d8.loss_mask: 0.2506, decode.d8.loss_dice: 0.5135, loss: 8.4187
2023-09-29 08:58:04,905 - mmseg - INFO - Iter [27100/40000]	lr: 4.631e-07, eta: 11:29:25, time: 2.246, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0669, decode.loss_mask: 0.2937, decode.loss_dice: 0.5123, decode.d0.loss_cls: 0.2585, decode.d0.loss_mask: 0.2968, decode.d0.loss_dice: 0.5270, decode.d1.loss_cls: 0.0747, decode.d1.loss_mask: 0.2967, decode.d1.loss_dice: 0.5268, decode.d2.loss_cls: 0.0654, decode.d2.loss_mask: 0.2999, decode.d2.loss_dice: 0.5233, decode.d3.loss_cls: 0.0672, decode.d3.loss_mask: 0.2988, decode.d3.loss_dice: 0.5180, decode.d4.loss_cls: 0.0649, decode.d4.loss_mask: 0.3000, decode.d4.loss_dice: 0.5155, decode.d5.loss_cls: 0.0736, decode.d5.loss_mask: 0.2997, decode.d5.loss_dice: 0.5212, decode.d6.loss_cls: 0.0622, decode.d6.loss_mask: 0.2988, decode.d6.loss_dice: 0.5206, decode.d7.loss_cls: 0.0657, decode.d7.loss_mask: 0.3001, decode.d7.loss_dice: 0.5172, decode.d8.loss_cls: 0.0664, decode.d8.loss_mask: 0.2952, decode.d8.loss_dice: 0.5156, loss: 9.0426
2023-09-29 08:59:57,000 - mmseg - INFO - Iter [27150/40000]	lr: 4.613e-07, eta: 11:26:22, time: 2.242, data_time: 0.028, memory: 21542, decode.loss_cls: 0.1085, decode.loss_mask: 0.2856, decode.loss_dice: 0.6041, decode.d0.loss_cls: 0.2360, decode.d0.loss_mask: 0.2932, decode.d0.loss_dice: 0.6170, decode.d1.loss_cls: 0.1224, decode.d1.loss_mask: 0.2876, decode.d1.loss_dice: 0.5968, decode.d2.loss_cls: 0.1059, decode.d2.loss_mask: 0.2874, decode.d2.loss_dice: 0.6075, decode.d3.loss_cls: 0.0990, decode.d3.loss_mask: 0.2852, decode.d3.loss_dice: 0.6001, decode.d4.loss_cls: 0.0990, decode.d4.loss_mask: 0.2866, decode.d4.loss_dice: 0.6140, decode.d5.loss_cls: 0.1077, decode.d5.loss_mask: 0.2852, decode.d5.loss_dice: 0.6071, decode.d6.loss_cls: 0.1103, decode.d6.loss_mask: 0.2878, decode.d6.loss_dice: 0.6081, decode.d7.loss_cls: 0.1123, decode.d7.loss_mask: 0.2861, decode.d7.loss_dice: 0.6002, decode.d8.loss_cls: 0.1045, decode.d8.loss_mask: 0.2893, decode.d8.loss_dice: 0.6055, loss: 10.1400
2023-09-29 09:01:49,828 - mmseg - INFO - Iter [27200/40000]	lr: 4.595e-07, eta: 11:23:19, time: 2.257, data_time: 0.026, memory: 21542, decode.loss_cls: 0.0665, decode.loss_mask: 0.2271, decode.loss_dice: 0.4998, decode.d0.loss_cls: 0.2682, decode.d0.loss_mask: 0.2298, decode.d0.loss_dice: 0.5103, decode.d1.loss_cls: 0.0918, decode.d1.loss_mask: 0.2282, decode.d1.loss_dice: 0.5086, decode.d2.loss_cls: 0.0865, decode.d2.loss_mask: 0.2269, decode.d2.loss_dice: 0.5101, decode.d3.loss_cls: 0.0648, decode.d3.loss_mask: 0.2275, decode.d3.loss_dice: 0.4995, decode.d4.loss_cls: 0.0654, decode.d4.loss_mask: 0.2267, decode.d4.loss_dice: 0.5091, decode.d5.loss_cls: 0.0679, decode.d5.loss_mask: 0.2269, decode.d5.loss_dice: 0.5046, decode.d6.loss_cls: 0.0652, decode.d6.loss_mask: 0.2266, decode.d6.loss_dice: 0.5067, decode.d7.loss_cls: 0.0638, decode.d7.loss_mask: 0.2283, decode.d7.loss_dice: 0.5037, decode.d8.loss_cls: 0.0737, decode.d8.loss_mask: 0.2268, decode.d8.loss_dice: 0.5058, loss: 8.2468
2023-09-29 09:03:42,324 - mmseg - INFO - Iter [27250/40000]	lr: 4.577e-07, eta: 11:20:17, time: 2.250, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0790, decode.loss_mask: 0.2762, decode.loss_dice: 0.5620, decode.d0.loss_cls: 0.2126, decode.d0.loss_mask: 0.2845, decode.d0.loss_dice: 0.5857, decode.d1.loss_cls: 0.0991, decode.d1.loss_mask: 0.2767, decode.d1.loss_dice: 0.5629, decode.d2.loss_cls: 0.0894, decode.d2.loss_mask: 0.2771, decode.d2.loss_dice: 0.5689, decode.d3.loss_cls: 0.0752, decode.d3.loss_mask: 0.2763, decode.d3.loss_dice: 0.5626, decode.d4.loss_cls: 0.0965, decode.d4.loss_mask: 0.2762, decode.d4.loss_dice: 0.5618, decode.d5.loss_cls: 0.0774, decode.d5.loss_mask: 0.2760, decode.d5.loss_dice: 0.5690, decode.d6.loss_cls: 0.0739, decode.d6.loss_mask: 0.2764, decode.d6.loss_dice: 0.5673, decode.d7.loss_cls: 0.0664, decode.d7.loss_mask: 0.2748, decode.d7.loss_dice: 0.5645, decode.d8.loss_cls: 0.0765, decode.d8.loss_mask: 0.2750, decode.d8.loss_dice: 0.5660, loss: 9.3862
2023-09-29 09:05:35,666 - mmseg - INFO - Iter [27300/40000]	lr: 4.559e-07, eta: 11:17:15, time: 2.267, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0896, decode.loss_mask: 0.2871, decode.loss_dice: 0.5788, decode.d0.loss_cls: 0.2240, decode.d0.loss_mask: 0.2976, decode.d0.loss_dice: 0.5953, decode.d1.loss_cls: 0.0983, decode.d1.loss_mask: 0.2865, decode.d1.loss_dice: 0.5746, decode.d2.loss_cls: 0.0812, decode.d2.loss_mask: 0.2865, decode.d2.loss_dice: 0.5755, decode.d3.loss_cls: 0.0923, decode.d3.loss_mask: 0.2875, decode.d3.loss_dice: 0.5839, decode.d4.loss_cls: 0.0831, decode.d4.loss_mask: 0.2870, decode.d4.loss_dice: 0.5821, decode.d5.loss_cls: 0.0829, decode.d5.loss_mask: 0.2872, decode.d5.loss_dice: 0.5886, decode.d6.loss_cls: 0.0714, decode.d6.loss_mask: 0.2888, decode.d6.loss_dice: 0.5738, decode.d7.loss_cls: 0.0878, decode.d7.loss_mask: 0.2873, decode.d7.loss_dice: 0.5684, decode.d8.loss_cls: 0.0802, decode.d8.loss_mask: 0.2889, decode.d8.loss_dice: 0.5784, loss: 9.6747
2023-09-29 09:07:28,689 - mmseg - INFO - Iter [27350/40000]	lr: 4.541e-07, eta: 11:14:13, time: 2.260, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0609, decode.loss_mask: 0.2517, decode.loss_dice: 0.5329, decode.d0.loss_cls: 0.2016, decode.d0.loss_mask: 0.2568, decode.d0.loss_dice: 0.5401, decode.d1.loss_cls: 0.0615, decode.d1.loss_mask: 0.2540, decode.d1.loss_dice: 0.5240, decode.d2.loss_cls: 0.0862, decode.d2.loss_mask: 0.2537, decode.d2.loss_dice: 0.5301, decode.d3.loss_cls: 0.0514, decode.d3.loss_mask: 0.2528, decode.d3.loss_dice: 0.5387, decode.d4.loss_cls: 0.0672, decode.d4.loss_mask: 0.2537, decode.d4.loss_dice: 0.5390, decode.d5.loss_cls: 0.0651, decode.d5.loss_mask: 0.2538, decode.d5.loss_dice: 0.5311, decode.d6.loss_cls: 0.0797, decode.d6.loss_mask: 0.2549, decode.d6.loss_dice: 0.5402, decode.d7.loss_cls: 0.0573, decode.d7.loss_mask: 0.2534, decode.d7.loss_dice: 0.5292, decode.d8.loss_cls: 0.0708, decode.d8.loss_mask: 0.2546, decode.d8.loss_dice: 0.5318, loss: 8.6783
2023-09-29 09:09:20,960 - mmseg - INFO - Iter [27400/40000]	lr: 4.523e-07, eta: 11:11:12, time: 2.246, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0552, decode.loss_mask: 0.2426, decode.loss_dice: 0.5293, decode.d0.loss_cls: 0.2224, decode.d0.loss_mask: 0.2447, decode.d0.loss_dice: 0.5399, decode.d1.loss_cls: 0.0922, decode.d1.loss_mask: 0.2446, decode.d1.loss_dice: 0.5250, decode.d2.loss_cls: 0.0588, decode.d2.loss_mask: 0.2448, decode.d2.loss_dice: 0.5387, decode.d3.loss_cls: 0.0439, decode.d3.loss_mask: 0.2429, decode.d3.loss_dice: 0.5297, decode.d4.loss_cls: 0.0475, decode.d4.loss_mask: 0.2431, decode.d4.loss_dice: 0.5270, decode.d5.loss_cls: 0.0679, decode.d5.loss_mask: 0.2437, decode.d5.loss_dice: 0.5193, decode.d6.loss_cls: 0.0614, decode.d6.loss_mask: 0.2439, decode.d6.loss_dice: 0.5202, decode.d7.loss_cls: 0.0493, decode.d7.loss_mask: 0.2439, decode.d7.loss_dice: 0.5267, decode.d8.loss_cls: 0.0531, decode.d8.loss_mask: 0.2426, decode.d8.loss_dice: 0.5285, loss: 8.4731
2023-09-29 09:11:16,224 - mmseg - INFO - Iter [27450/40000]	lr: 4.505e-07, eta: 11:08:11, time: 2.305, data_time: 0.073, memory: 21542, decode.loss_cls: 0.0637, decode.loss_mask: 0.2635, decode.loss_dice: 0.5318, decode.d0.loss_cls: 0.2487, decode.d0.loss_mask: 0.2748, decode.d0.loss_dice: 0.5407, decode.d1.loss_cls: 0.1012, decode.d1.loss_mask: 0.2643, decode.d1.loss_dice: 0.5192, decode.d2.loss_cls: 0.1009, decode.d2.loss_mask: 0.2666, decode.d2.loss_dice: 0.5271, decode.d3.loss_cls: 0.0858, decode.d3.loss_mask: 0.2662, decode.d3.loss_dice: 0.5321, decode.d4.loss_cls: 0.0714, decode.d4.loss_mask: 0.2679, decode.d4.loss_dice: 0.5389, decode.d5.loss_cls: 0.0889, decode.d5.loss_mask: 0.2678, decode.d5.loss_dice: 0.5253, decode.d6.loss_cls: 0.0652, decode.d6.loss_mask: 0.2669, decode.d6.loss_dice: 0.5190, decode.d7.loss_cls: 0.0795, decode.d7.loss_mask: 0.2652, decode.d7.loss_dice: 0.5337, decode.d8.loss_cls: 0.0562, decode.d8.loss_mask: 0.2631, decode.d8.loss_dice: 0.5355, loss: 8.9313
2023-09-29 09:13:08,661 - mmseg - INFO - Iter [27500/40000]	lr: 4.487e-07, eta: 11:05:10, time: 2.249, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0490, decode.loss_mask: 0.2690, decode.loss_dice: 0.5347, decode.d0.loss_cls: 0.2396, decode.d0.loss_mask: 0.2726, decode.d0.loss_dice: 0.5342, decode.d1.loss_cls: 0.0607, decode.d1.loss_mask: 0.2668, decode.d1.loss_dice: 0.5340, decode.d2.loss_cls: 0.0608, decode.d2.loss_mask: 0.2674, decode.d2.loss_dice: 0.5321, decode.d3.loss_cls: 0.0586, decode.d3.loss_mask: 0.2680, decode.d3.loss_dice: 0.5303, decode.d4.loss_cls: 0.0483, decode.d4.loss_mask: 0.2693, decode.d4.loss_dice: 0.5373, decode.d5.loss_cls: 0.0548, decode.d5.loss_mask: 0.2704, decode.d5.loss_dice: 0.5350, decode.d6.loss_cls: 0.0497, decode.d6.loss_mask: 0.2686, decode.d6.loss_dice: 0.5294, decode.d7.loss_cls: 0.0597, decode.d7.loss_mask: 0.2696, decode.d7.loss_dice: 0.5335, decode.d8.loss_cls: 0.0548, decode.d8.loss_mask: 0.2678, decode.d8.loss_dice: 0.5316, loss: 8.7575
2023-09-29 09:15:01,700 - mmseg - INFO - Iter [27550/40000]	lr: 4.469e-07, eta: 11:02:10, time: 2.261, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0666, decode.loss_mask: 0.2604, decode.loss_dice: 0.5261, decode.d0.loss_cls: 0.2312, decode.d0.loss_mask: 0.2640, decode.d0.loss_dice: 0.5380, decode.d1.loss_cls: 0.0884, decode.d1.loss_mask: 0.2605, decode.d1.loss_dice: 0.5256, decode.d2.loss_cls: 0.0655, decode.d2.loss_mask: 0.2595, decode.d2.loss_dice: 0.5266, decode.d3.loss_cls: 0.0530, decode.d3.loss_mask: 0.2606, decode.d3.loss_dice: 0.5183, decode.d4.loss_cls: 0.0756, decode.d4.loss_mask: 0.2595, decode.d4.loss_dice: 0.5281, decode.d5.loss_cls: 0.0652, decode.d5.loss_mask: 0.2614, decode.d5.loss_dice: 0.5320, decode.d6.loss_cls: 0.0864, decode.d6.loss_mask: 0.2599, decode.d6.loss_dice: 0.5230, decode.d7.loss_cls: 0.0772, decode.d7.loss_mask: 0.2604, decode.d7.loss_dice: 0.5246, decode.d8.loss_cls: 0.0564, decode.d8.loss_mask: 0.2596, decode.d8.loss_dice: 0.5246, loss: 8.7380
2023-09-29 09:16:53,889 - mmseg - INFO - Iter [27600/40000]	lr: 4.451e-07, eta: 10:59:09, time: 2.244, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0497, decode.loss_mask: 0.2654, decode.loss_dice: 0.5261, decode.d0.loss_cls: 0.2281, decode.d0.loss_mask: 0.2669, decode.d0.loss_dice: 0.5374, decode.d1.loss_cls: 0.0737, decode.d1.loss_mask: 0.2678, decode.d1.loss_dice: 0.5302, decode.d2.loss_cls: 0.0577, decode.d2.loss_mask: 0.2656, decode.d2.loss_dice: 0.5247, decode.d3.loss_cls: 0.0579, decode.d3.loss_mask: 0.2655, decode.d3.loss_dice: 0.5290, decode.d4.loss_cls: 0.0616, decode.d4.loss_mask: 0.2659, decode.d4.loss_dice: 0.5281, decode.d5.loss_cls: 0.0527, decode.d5.loss_mask: 0.2655, decode.d5.loss_dice: 0.5277, decode.d6.loss_cls: 0.0445, decode.d6.loss_mask: 0.2650, decode.d6.loss_dice: 0.5217, decode.d7.loss_cls: 0.0512, decode.d7.loss_mask: 0.2670, decode.d7.loss_dice: 0.5250, decode.d8.loss_cls: 0.0584, decode.d8.loss_mask: 0.2658, decode.d8.loss_dice: 0.5181, loss: 8.6639
2023-09-29 09:18:46,097 - mmseg - INFO - Iter [27650/40000]	lr: 4.433e-07, eta: 10:56:08, time: 2.244, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0611, decode.loss_mask: 0.2681, decode.loss_dice: 0.5208, decode.d0.loss_cls: 0.2663, decode.d0.loss_mask: 0.2746, decode.d0.loss_dice: 0.5305, decode.d1.loss_cls: 0.0889, decode.d1.loss_mask: 0.2698, decode.d1.loss_dice: 0.5136, decode.d2.loss_cls: 0.0573, decode.d2.loss_mask: 0.2692, decode.d2.loss_dice: 0.5341, decode.d3.loss_cls: 0.0585, decode.d3.loss_mask: 0.2667, decode.d3.loss_dice: 0.5199, decode.d4.loss_cls: 0.0701, decode.d4.loss_mask: 0.2663, decode.d4.loss_dice: 0.5228, decode.d5.loss_cls: 0.0661, decode.d5.loss_mask: 0.2683, decode.d5.loss_dice: 0.5160, decode.d6.loss_cls: 0.0711, decode.d6.loss_mask: 0.2685, decode.d6.loss_dice: 0.5138, decode.d7.loss_cls: 0.0655, decode.d7.loss_mask: 0.2686, decode.d7.loss_dice: 0.5182, decode.d8.loss_cls: 0.0608, decode.d8.loss_mask: 0.2679, decode.d8.loss_dice: 0.5178, loss: 8.7614
2023-09-29 09:20:38,357 - mmseg - INFO - Iter [27700/40000]	lr: 4.415e-07, eta: 10:53:08, time: 2.245, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0519, decode.loss_mask: 0.2551, decode.loss_dice: 0.4741, decode.d0.loss_cls: 0.2218, decode.d0.loss_mask: 0.2544, decode.d0.loss_dice: 0.4862, decode.d1.loss_cls: 0.0463, decode.d1.loss_mask: 0.2541, decode.d1.loss_dice: 0.4707, decode.d2.loss_cls: 0.0492, decode.d2.loss_mask: 0.2564, decode.d2.loss_dice: 0.4738, decode.d3.loss_cls: 0.0521, decode.d3.loss_mask: 0.2544, decode.d3.loss_dice: 0.4784, decode.d4.loss_cls: 0.0460, decode.d4.loss_mask: 0.2561, decode.d4.loss_dice: 0.4841, decode.d5.loss_cls: 0.0507, decode.d5.loss_mask: 0.2555, decode.d5.loss_dice: 0.4817, decode.d6.loss_cls: 0.0515, decode.d6.loss_mask: 0.2540, decode.d6.loss_dice: 0.4793, decode.d7.loss_cls: 0.0436, decode.d7.loss_mask: 0.2546, decode.d7.loss_dice: 0.4748, decode.d8.loss_cls: 0.0459, decode.d8.loss_mask: 0.2550, decode.d8.loss_dice: 0.4791, loss: 7.9905
2023-09-29 09:22:31,158 - mmseg - INFO - Iter [27750/40000]	lr: 4.397e-07, eta: 10:50:08, time: 2.256, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0808, decode.loss_mask: 0.2600, decode.loss_dice: 0.5370, decode.d0.loss_cls: 0.2169, decode.d0.loss_mask: 0.2623, decode.d0.loss_dice: 0.5423, decode.d1.loss_cls: 0.0836, decode.d1.loss_mask: 0.2620, decode.d1.loss_dice: 0.5364, decode.d2.loss_cls: 0.0726, decode.d2.loss_mask: 0.2606, decode.d2.loss_dice: 0.5358, decode.d3.loss_cls: 0.0823, decode.d3.loss_mask: 0.2605, decode.d3.loss_dice: 0.5387, decode.d4.loss_cls: 0.0818, decode.d4.loss_mask: 0.2606, decode.d4.loss_dice: 0.5452, decode.d5.loss_cls: 0.0619, decode.d5.loss_mask: 0.2606, decode.d5.loss_dice: 0.5409, decode.d6.loss_cls: 0.0585, decode.d6.loss_mask: 0.2611, decode.d6.loss_dice: 0.5346, decode.d7.loss_cls: 0.0697, decode.d7.loss_mask: 0.2610, decode.d7.loss_dice: 0.5379, decode.d8.loss_cls: 0.0773, decode.d8.loss_mask: 0.2596, decode.d8.loss_dice: 0.5290, loss: 8.8718
2023-09-29 09:24:23,997 - mmseg - INFO - Iter [27800/40000]	lr: 4.380e-07, eta: 10:47:08, time: 2.257, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0479, decode.loss_mask: 0.2506, decode.loss_dice: 0.5065, decode.d0.loss_cls: 0.2240, decode.d0.loss_mask: 0.2530, decode.d0.loss_dice: 0.5117, decode.d1.loss_cls: 0.0616, decode.d1.loss_mask: 0.2518, decode.d1.loss_dice: 0.5088, decode.d2.loss_cls: 0.0581, decode.d2.loss_mask: 0.2508, decode.d2.loss_dice: 0.4950, decode.d3.loss_cls: 0.0414, decode.d3.loss_mask: 0.2483, decode.d3.loss_dice: 0.4970, decode.d4.loss_cls: 0.0355, decode.d4.loss_mask: 0.2506, decode.d4.loss_dice: 0.5018, decode.d5.loss_cls: 0.0472, decode.d5.loss_mask: 0.2497, decode.d5.loss_dice: 0.5091, decode.d6.loss_cls: 0.0510, decode.d6.loss_mask: 0.2499, decode.d6.loss_dice: 0.5100, decode.d7.loss_cls: 0.0358, decode.d7.loss_mask: 0.2498, decode.d7.loss_dice: 0.5084, decode.d8.loss_cls: 0.0422, decode.d8.loss_mask: 0.2507, decode.d8.loss_dice: 0.5093, loss: 8.2072
2023-09-29 09:26:16,782 - mmseg - INFO - Iter [27850/40000]	lr: 4.362e-07, eta: 10:44:09, time: 2.256, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0761, decode.loss_mask: 0.2530, decode.loss_dice: 0.5185, decode.d0.loss_cls: 0.1800, decode.d0.loss_mask: 0.2517, decode.d0.loss_dice: 0.5164, decode.d1.loss_cls: 0.0756, decode.d1.loss_mask: 0.2562, decode.d1.loss_dice: 0.5152, decode.d2.loss_cls: 0.0890, decode.d2.loss_mask: 0.2454, decode.d2.loss_dice: 0.5193, decode.d3.loss_cls: 0.0819, decode.d3.loss_mask: 0.2552, decode.d3.loss_dice: 0.5254, decode.d4.loss_cls: 0.0635, decode.d4.loss_mask: 0.2548, decode.d4.loss_dice: 0.5154, decode.d5.loss_cls: 0.0768, decode.d5.loss_mask: 0.2544, decode.d5.loss_dice: 0.5142, decode.d6.loss_cls: 0.0604, decode.d6.loss_mask: 0.2532, decode.d6.loss_dice: 0.5221, decode.d7.loss_cls: 0.0563, decode.d7.loss_mask: 0.2533, decode.d7.loss_dice: 0.5180, decode.d8.loss_cls: 0.0640, decode.d8.loss_mask: 0.2532, decode.d8.loss_dice: 0.5078, loss: 8.5262
2023-09-29 09:28:09,431 - mmseg - INFO - Iter [27900/40000]	lr: 4.344e-07, eta: 10:41:10, time: 2.253, data_time: 0.026, memory: 21542, decode.loss_cls: 0.0666, decode.loss_mask: 0.2440, decode.loss_dice: 0.5251, decode.d0.loss_cls: 0.2229, decode.d0.loss_mask: 0.2476, decode.d0.loss_dice: 0.5401, decode.d1.loss_cls: 0.0588, decode.d1.loss_mask: 0.2444, decode.d1.loss_dice: 0.5374, decode.d2.loss_cls: 0.0591, decode.d2.loss_mask: 0.2457, decode.d2.loss_dice: 0.5253, decode.d3.loss_cls: 0.0732, decode.d3.loss_mask: 0.2446, decode.d3.loss_dice: 0.5304, decode.d4.loss_cls: 0.0622, decode.d4.loss_mask: 0.2453, decode.d4.loss_dice: 0.5348, decode.d5.loss_cls: 0.0732, decode.d5.loss_mask: 0.2447, decode.d5.loss_dice: 0.5239, decode.d6.loss_cls: 0.0644, decode.d6.loss_mask: 0.2433, decode.d6.loss_dice: 0.5231, decode.d7.loss_cls: 0.0597, decode.d7.loss_mask: 0.2447, decode.d7.loss_dice: 0.5169, decode.d8.loss_cls: 0.0645, decode.d8.loss_mask: 0.2445, decode.d8.loss_dice: 0.5340, loss: 8.5445
2023-09-29 09:30:01,484 - mmseg - INFO - Iter [27950/40000]	lr: 4.326e-07, eta: 10:38:11, time: 2.241, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0487, decode.loss_mask: 0.2495, decode.loss_dice: 0.5224, decode.d0.loss_cls: 0.2090, decode.d0.loss_mask: 0.2547, decode.d0.loss_dice: 0.5151, decode.d1.loss_cls: 0.0765, decode.d1.loss_mask: 0.2497, decode.d1.loss_dice: 0.5250, decode.d2.loss_cls: 0.0615, decode.d2.loss_mask: 0.2490, decode.d2.loss_dice: 0.5200, decode.d3.loss_cls: 0.0501, decode.d3.loss_mask: 0.2493, decode.d3.loss_dice: 0.5160, decode.d4.loss_cls: 0.0531, decode.d4.loss_mask: 0.2486, decode.d4.loss_dice: 0.5175, decode.d5.loss_cls: 0.0599, decode.d5.loss_mask: 0.2506, decode.d5.loss_dice: 0.5292, decode.d6.loss_cls: 0.0519, decode.d6.loss_mask: 0.2494, decode.d6.loss_dice: 0.5199, decode.d7.loss_cls: 0.0668, decode.d7.loss_mask: 0.2494, decode.d7.loss_dice: 0.5292, decode.d8.loss_cls: 0.0600, decode.d8.loss_mask: 0.2499, decode.d8.loss_dice: 0.5117, loss: 8.4436
2023-09-29 09:31:54,194 - mmseg - INFO - Saving checkpoint at 28000 iterations
2023-09-29 09:32:14,109 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 09:32:14,109 - mmseg - INFO - Iter [28000/40000]	lr: 4.308e-07, eta: 10:35:21, time: 2.653, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0686, decode.loss_mask: 0.2600, decode.loss_dice: 0.5573, decode.d0.loss_cls: 0.2017, decode.d0.loss_mask: 0.2645, decode.d0.loss_dice: 0.5802, decode.d1.loss_cls: 0.1076, decode.d1.loss_mask: 0.2590, decode.d1.loss_dice: 0.5608, decode.d2.loss_cls: 0.0881, decode.d2.loss_mask: 0.2598, decode.d2.loss_dice: 0.5627, decode.d3.loss_cls: 0.0912, decode.d3.loss_mask: 0.2600, decode.d3.loss_dice: 0.5645, decode.d4.loss_cls: 0.0761, decode.d4.loss_mask: 0.2609, decode.d4.loss_dice: 0.5561, decode.d5.loss_cls: 0.0661, decode.d5.loss_mask: 0.2603, decode.d5.loss_dice: 0.5614, decode.d6.loss_cls: 0.0666, decode.d6.loss_mask: 0.2609, decode.d6.loss_dice: 0.5560, decode.d7.loss_cls: 0.0687, decode.d7.loss_mask: 0.2604, decode.d7.loss_dice: 0.5582, decode.d8.loss_cls: 0.0523, decode.d8.loss_mask: 0.2609, decode.d8.loss_dice: 0.5690, loss: 9.1199
2023-09-29 09:49:29,223 - mmseg - INFO - per class results:
2023-09-29 09:49:29,224 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 92.92 | 96.83 |
|    Sidewalk   | 68.38 | 82.94 |
|  Construction | 82.24 | 94.08 |
|     Fence     | 33.61 | 37.61 |
|      Pole     | 57.45 | 70.74 |
| Traffic Light | 66.48 | 78.84 |
|  Traffic Sign |  72.3 | 79.05 |
|     Nature    | 88.48 | 93.77 |
|      Sky      | 96.55 | 98.01 |
|     Person    | 34.85 | 37.91 |
|     Rider     |  9.17 | 68.95 |
|      Car      | 91.64 | 95.01 |
|   background  | 96.15 | 97.87 |
+---------------+-------+-------+
2023-09-29 09:49:29,224 - mmseg - INFO - Summary:
2023-09-29 09:49:29,224 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.45 | 68.48 | 79.35 |
+-------+-------+-------+
2023-09-29 09:49:29,227 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 09:49:29,227 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9445, mIoU: 0.6848, mAcc: 0.7935, IoU.Road: 0.9292, IoU.Sidewalk: 0.6838, IoU.Construction: 0.8224, IoU.Fence: 0.3361, IoU.Pole: 0.5745, IoU.Traffic Light: 0.6648, IoU.Traffic Sign: 0.7230, IoU.Nature: 0.8848, IoU.Sky: 0.9655, IoU.Person: 0.3485, IoU.Rider: 0.0917, IoU.Car: 0.9164, IoU.background: 0.9615, Acc.Road: 0.9683, Acc.Sidewalk: 0.8294, Acc.Construction: 0.9408, Acc.Fence: 0.3761, Acc.Pole: 0.7074, Acc.Traffic Light: 0.7884, Acc.Traffic Sign: 0.7905, Acc.Nature: 0.9377, Acc.Sky: 0.9801, Acc.Person: 0.3791, Acc.Rider: 0.6895, Acc.Car: 0.9501, Acc.background: 0.9787
2023-09-29 09:51:22,518 - mmseg - INFO - Iter [28050/40000]	lr: 4.290e-07, eta: 10:39:43, time: 22.968, data_time: 20.732, memory: 21542, decode.loss_cls: 0.0722, decode.loss_mask: 0.2591, decode.loss_dice: 0.5427, decode.d0.loss_cls: 0.2346, decode.d0.loss_mask: 0.2634, decode.d0.loss_dice: 0.5527, decode.d1.loss_cls: 0.0941, decode.d1.loss_mask: 0.2602, decode.d1.loss_dice: 0.5463, decode.d2.loss_cls: 0.0815, decode.d2.loss_mask: 0.2562, decode.d2.loss_dice: 0.5420, decode.d3.loss_cls: 0.0742, decode.d3.loss_mask: 0.2573, decode.d3.loss_dice: 0.5409, decode.d4.loss_cls: 0.0740, decode.d4.loss_mask: 0.2629, decode.d4.loss_dice: 0.5402, decode.d5.loss_cls: 0.0686, decode.d5.loss_mask: 0.2637, decode.d5.loss_dice: 0.5527, decode.d6.loss_cls: 0.0710, decode.d6.loss_mask: 0.2654, decode.d6.loss_dice: 0.5538, decode.d7.loss_cls: 0.0638, decode.d7.loss_mask: 0.2640, decode.d7.loss_dice: 0.5402, decode.d8.loss_cls: 0.0719, decode.d8.loss_mask: 0.2582, decode.d8.loss_dice: 0.5424, loss: 8.9702
2023-09-29 09:53:15,616 - mmseg - INFO - Iter [28100/40000]	lr: 4.272e-07, eta: 10:36:43, time: 2.262, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0618, decode.loss_mask: 0.2718, decode.loss_dice: 0.5193, decode.d0.loss_cls: 0.2266, decode.d0.loss_mask: 0.2699, decode.d0.loss_dice: 0.5366, decode.d1.loss_cls: 0.0799, decode.d1.loss_mask: 0.2690, decode.d1.loss_dice: 0.5325, decode.d2.loss_cls: 0.0868, decode.d2.loss_mask: 0.2618, decode.d2.loss_dice: 0.5332, decode.d3.loss_cls: 0.0797, decode.d3.loss_mask: 0.2635, decode.d3.loss_dice: 0.5325, decode.d4.loss_cls: 0.0729, decode.d4.loss_mask: 0.2608, decode.d4.loss_dice: 0.5290, decode.d5.loss_cls: 0.0609, decode.d5.loss_mask: 0.2714, decode.d5.loss_dice: 0.5383, decode.d6.loss_cls: 0.0776, decode.d6.loss_mask: 0.2622, decode.d6.loss_dice: 0.5284, decode.d7.loss_cls: 0.0876, decode.d7.loss_mask: 0.2622, decode.d7.loss_dice: 0.5291, decode.d8.loss_cls: 0.0881, decode.d8.loss_mask: 0.2615, decode.d8.loss_dice: 0.5250, loss: 8.8799
2023-09-29 09:55:07,545 - mmseg - INFO - Iter [28150/40000]	lr: 4.254e-07, eta: 10:33:42, time: 2.238, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0591, decode.loss_mask: 0.2673, decode.loss_dice: 0.5750, decode.d0.loss_cls: 0.2326, decode.d0.loss_mask: 0.2733, decode.d0.loss_dice: 0.5766, decode.d1.loss_cls: 0.0634, decode.d1.loss_mask: 0.2760, decode.d1.loss_dice: 0.5649, decode.d2.loss_cls: 0.0579, decode.d2.loss_mask: 0.2751, decode.d2.loss_dice: 0.5630, decode.d3.loss_cls: 0.0677, decode.d3.loss_mask: 0.2751, decode.d3.loss_dice: 0.5730, decode.d4.loss_cls: 0.0510, decode.d4.loss_mask: 0.2740, decode.d4.loss_dice: 0.5776, decode.d5.loss_cls: 0.0699, decode.d5.loss_mask: 0.2680, decode.d5.loss_dice: 0.5830, decode.d6.loss_cls: 0.0615, decode.d6.loss_mask: 0.2685, decode.d6.loss_dice: 0.5756, decode.d7.loss_cls: 0.0778, decode.d7.loss_mask: 0.2666, decode.d7.loss_dice: 0.5744, decode.d8.loss_cls: 0.0543, decode.d8.loss_mask: 0.2692, decode.d8.loss_dice: 0.5777, loss: 9.2491
2023-09-29 09:56:59,417 - mmseg - INFO - Iter [28200/40000]	lr: 4.236e-07, eta: 10:30:41, time: 2.238, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0502, decode.loss_mask: 0.2515, decode.loss_dice: 0.5144, decode.d0.loss_cls: 0.2012, decode.d0.loss_mask: 0.2551, decode.d0.loss_dice: 0.5245, decode.d1.loss_cls: 0.0635, decode.d1.loss_mask: 0.2505, decode.d1.loss_dice: 0.5223, decode.d2.loss_cls: 0.0673, decode.d2.loss_mask: 0.2504, decode.d2.loss_dice: 0.5177, decode.d3.loss_cls: 0.0441, decode.d3.loss_mask: 0.2493, decode.d3.loss_dice: 0.5171, decode.d4.loss_cls: 0.0355, decode.d4.loss_mask: 0.2489, decode.d4.loss_dice: 0.5195, decode.d5.loss_cls: 0.0576, decode.d5.loss_mask: 0.2506, decode.d5.loss_dice: 0.5189, decode.d6.loss_cls: 0.0483, decode.d6.loss_mask: 0.2501, decode.d6.loss_dice: 0.5205, decode.d7.loss_cls: 0.0564, decode.d7.loss_mask: 0.2502, decode.d7.loss_dice: 0.5241, decode.d8.loss_cls: 0.0494, decode.d8.loss_mask: 0.2505, decode.d8.loss_dice: 0.5234, loss: 8.3830
2023-09-29 09:58:52,779 - mmseg - INFO - Iter [28250/40000]	lr: 4.218e-07, eta: 10:27:41, time: 2.267, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0888, decode.loss_mask: 0.2483, decode.loss_dice: 0.5484, decode.d0.loss_cls: 0.2368, decode.d0.loss_mask: 0.2552, decode.d0.loss_dice: 0.5538, decode.d1.loss_cls: 0.1069, decode.d1.loss_mask: 0.2488, decode.d1.loss_dice: 0.5551, decode.d2.loss_cls: 0.0969, decode.d2.loss_mask: 0.2482, decode.d2.loss_dice: 0.5556, decode.d3.loss_cls: 0.0984, decode.d3.loss_mask: 0.2488, decode.d3.loss_dice: 0.5476, decode.d4.loss_cls: 0.0783, decode.d4.loss_mask: 0.2527, decode.d4.loss_dice: 0.5605, decode.d5.loss_cls: 0.0896, decode.d5.loss_mask: 0.2530, decode.d5.loss_dice: 0.5580, decode.d6.loss_cls: 0.0886, decode.d6.loss_mask: 0.2522, decode.d6.loss_dice: 0.5604, decode.d7.loss_cls: 0.0715, decode.d7.loss_mask: 0.2543, decode.d7.loss_dice: 0.5500, decode.d8.loss_cls: 0.0838, decode.d8.loss_mask: 0.2511, decode.d8.loss_dice: 0.5557, loss: 9.0973
2023-09-29 10:00:45,585 - mmseg - INFO - Iter [28300/40000]	lr: 4.200e-07, eta: 10:24:41, time: 2.256, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0770, decode.loss_mask: 0.2733, decode.loss_dice: 0.5185, decode.d0.loss_cls: 0.2310, decode.d0.loss_mask: 0.2787, decode.d0.loss_dice: 0.5139, decode.d1.loss_cls: 0.0831, decode.d1.loss_mask: 0.2700, decode.d1.loss_dice: 0.5081, decode.d2.loss_cls: 0.0766, decode.d2.loss_mask: 0.2691, decode.d2.loss_dice: 0.4934, decode.d3.loss_cls: 0.0642, decode.d3.loss_mask: 0.2710, decode.d3.loss_dice: 0.4983, decode.d4.loss_cls: 0.0668, decode.d4.loss_mask: 0.2707, decode.d4.loss_dice: 0.5040, decode.d5.loss_cls: 0.0696, decode.d5.loss_mask: 0.2729, decode.d5.loss_dice: 0.5126, decode.d6.loss_cls: 0.0776, decode.d6.loss_mask: 0.2745, decode.d6.loss_dice: 0.5176, decode.d7.loss_cls: 0.0767, decode.d7.loss_mask: 0.2742, decode.d7.loss_dice: 0.5026, decode.d8.loss_cls: 0.0739, decode.d8.loss_mask: 0.2733, decode.d8.loss_dice: 0.5107, loss: 8.7038
2023-09-29 10:02:38,241 - mmseg - INFO - Iter [28350/40000]	lr: 4.182e-07, eta: 10:21:41, time: 2.253, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0669, decode.loss_mask: 0.2334, decode.loss_dice: 0.5274, decode.d0.loss_cls: 0.2031, decode.d0.loss_mask: 0.2372, decode.d0.loss_dice: 0.5244, decode.d1.loss_cls: 0.0899, decode.d1.loss_mask: 0.2357, decode.d1.loss_dice: 0.5314, decode.d2.loss_cls: 0.0719, decode.d2.loss_mask: 0.2343, decode.d2.loss_dice: 0.5157, decode.d3.loss_cls: 0.0636, decode.d3.loss_mask: 0.2320, decode.d3.loss_dice: 0.5137, decode.d4.loss_cls: 0.0576, decode.d4.loss_mask: 0.2333, decode.d4.loss_dice: 0.5115, decode.d5.loss_cls: 0.0641, decode.d5.loss_mask: 0.2344, decode.d5.loss_dice: 0.5258, decode.d6.loss_cls: 0.0582, decode.d6.loss_mask: 0.2324, decode.d6.loss_dice: 0.5125, decode.d7.loss_cls: 0.0649, decode.d7.loss_mask: 0.2323, decode.d7.loss_dice: 0.5026, decode.d8.loss_cls: 0.0589, decode.d8.loss_mask: 0.2327, decode.d8.loss_dice: 0.5051, loss: 8.3070
2023-09-29 10:04:30,588 - mmseg - INFO - Iter [28400/40000]	lr: 4.164e-07, eta: 10:18:42, time: 2.247, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0510, decode.loss_mask: 0.2832, decode.loss_dice: 0.5660, decode.d0.loss_cls: 0.2260, decode.d0.loss_mask: 0.2899, decode.d0.loss_dice: 0.5774, decode.d1.loss_cls: 0.0814, decode.d1.loss_mask: 0.2831, decode.d1.loss_dice: 0.5743, decode.d2.loss_cls: 0.0856, decode.d2.loss_mask: 0.2824, decode.d2.loss_dice: 0.5699, decode.d3.loss_cls: 0.0795, decode.d3.loss_mask: 0.2831, decode.d3.loss_dice: 0.5577, decode.d4.loss_cls: 0.0678, decode.d4.loss_mask: 0.2827, decode.d4.loss_dice: 0.5669, decode.d5.loss_cls: 0.0699, decode.d5.loss_mask: 0.2822, decode.d5.loss_dice: 0.5706, decode.d6.loss_cls: 0.0826, decode.d6.loss_mask: 0.2827, decode.d6.loss_dice: 0.5765, decode.d7.loss_cls: 0.0646, decode.d7.loss_mask: 0.2811, decode.d7.loss_dice: 0.5689, decode.d8.loss_cls: 0.0610, decode.d8.loss_mask: 0.2826, decode.d8.loss_dice: 0.5754, loss: 9.4058
2023-09-29 10:06:22,796 - mmseg - INFO - Iter [28450/40000]	lr: 4.146e-07, eta: 10:15:42, time: 2.244, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0455, decode.loss_mask: 0.2711, decode.loss_dice: 0.5641, decode.d0.loss_cls: 0.2287, decode.d0.loss_mask: 0.2742, decode.d0.loss_dice: 0.5608, decode.d1.loss_cls: 0.0839, decode.d1.loss_mask: 0.2708, decode.d1.loss_dice: 0.5625, decode.d2.loss_cls: 0.0561, decode.d2.loss_mask: 0.2699, decode.d2.loss_dice: 0.5525, decode.d3.loss_cls: 0.0611, decode.d3.loss_mask: 0.2701, decode.d3.loss_dice: 0.5525, decode.d4.loss_cls: 0.0597, decode.d4.loss_mask: 0.2710, decode.d4.loss_dice: 0.5577, decode.d5.loss_cls: 0.0481, decode.d5.loss_mask: 0.2702, decode.d5.loss_dice: 0.5547, decode.d6.loss_cls: 0.0705, decode.d6.loss_mask: 0.2711, decode.d6.loss_dice: 0.5463, decode.d7.loss_cls: 0.0622, decode.d7.loss_mask: 0.2704, decode.d7.loss_dice: 0.5479, decode.d8.loss_cls: 0.0565, decode.d8.loss_mask: 0.2707, decode.d8.loss_dice: 0.5526, loss: 9.0332
2023-09-29 10:08:15,764 - mmseg - INFO - Iter [28500/40000]	lr: 4.128e-07, eta: 10:12:43, time: 2.260, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0490, decode.loss_mask: 0.2754, decode.loss_dice: 0.5050, decode.d0.loss_cls: 0.2188, decode.d0.loss_mask: 0.2816, decode.d0.loss_dice: 0.5056, decode.d1.loss_cls: 0.0787, decode.d1.loss_mask: 0.2785, decode.d1.loss_dice: 0.5079, decode.d2.loss_cls: 0.0631, decode.d2.loss_mask: 0.2783, decode.d2.loss_dice: 0.4999, decode.d3.loss_cls: 0.0624, decode.d3.loss_mask: 0.2786, decode.d3.loss_dice: 0.4967, decode.d4.loss_cls: 0.0630, decode.d4.loss_mask: 0.2800, decode.d4.loss_dice: 0.5059, decode.d5.loss_cls: 0.0662, decode.d5.loss_mask: 0.2788, decode.d5.loss_dice: 0.5088, decode.d6.loss_cls: 0.0606, decode.d6.loss_mask: 0.2790, decode.d6.loss_dice: 0.5001, decode.d7.loss_cls: 0.0582, decode.d7.loss_mask: 0.2796, decode.d7.loss_dice: 0.4899, decode.d8.loss_cls: 0.0584, decode.d8.loss_mask: 0.2752, decode.d8.loss_dice: 0.5063, loss: 8.5896
2023-09-29 10:10:10,930 - mmseg - INFO - Iter [28550/40000]	lr: 4.110e-07, eta: 10:09:46, time: 2.303, data_time: 0.077, memory: 21542, decode.loss_cls: 0.0366, decode.loss_mask: 0.2473, decode.loss_dice: 0.5293, decode.d0.loss_cls: 0.1910, decode.d0.loss_mask: 0.2478, decode.d0.loss_dice: 0.5389, decode.d1.loss_cls: 0.0523, decode.d1.loss_mask: 0.2481, decode.d1.loss_dice: 0.5302, decode.d2.loss_cls: 0.0444, decode.d2.loss_mask: 0.2489, decode.d2.loss_dice: 0.5334, decode.d3.loss_cls: 0.0458, decode.d3.loss_mask: 0.2497, decode.d3.loss_dice: 0.5277, decode.d4.loss_cls: 0.0498, decode.d4.loss_mask: 0.2488, decode.d4.loss_dice: 0.5386, decode.d5.loss_cls: 0.0493, decode.d5.loss_mask: 0.2476, decode.d5.loss_dice: 0.5346, decode.d6.loss_cls: 0.0309, decode.d6.loss_mask: 0.2486, decode.d6.loss_dice: 0.5382, decode.d7.loss_cls: 0.0471, decode.d7.loss_mask: 0.2479, decode.d7.loss_dice: 0.5206, decode.d8.loss_cls: 0.0366, decode.d8.loss_mask: 0.2494, decode.d8.loss_dice: 0.5340, loss: 8.3932
2023-09-29 10:12:03,553 - mmseg - INFO - Iter [28600/40000]	lr: 4.092e-07, eta: 10:06:47, time: 2.252, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0578, decode.loss_mask: 0.2414, decode.loss_dice: 0.5201, decode.d0.loss_cls: 0.2125, decode.d0.loss_mask: 0.2437, decode.d0.loss_dice: 0.5383, decode.d1.loss_cls: 0.0788, decode.d1.loss_mask: 0.2424, decode.d1.loss_dice: 0.5317, decode.d2.loss_cls: 0.0745, decode.d2.loss_mask: 0.2415, decode.d2.loss_dice: 0.5264, decode.d3.loss_cls: 0.0626, decode.d3.loss_mask: 0.2411, decode.d3.loss_dice: 0.5220, decode.d4.loss_cls: 0.0624, decode.d4.loss_mask: 0.2428, decode.d4.loss_dice: 0.5288, decode.d5.loss_cls: 0.0684, decode.d5.loss_mask: 0.2418, decode.d5.loss_dice: 0.5240, decode.d6.loss_cls: 0.0702, decode.d6.loss_mask: 0.2421, decode.d6.loss_dice: 0.5080, decode.d7.loss_cls: 0.0704, decode.d7.loss_mask: 0.2419, decode.d7.loss_dice: 0.5132, decode.d8.loss_cls: 0.0598, decode.d8.loss_mask: 0.2400, decode.d8.loss_dice: 0.5236, loss: 8.4725
2023-09-29 10:13:56,126 - mmseg - INFO - Iter [28650/40000]	lr: 4.074e-07, eta: 10:03:49, time: 2.251, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0518, decode.loss_mask: 0.2425, decode.loss_dice: 0.5055, decode.d0.loss_cls: 0.1862, decode.d0.loss_mask: 0.2415, decode.d0.loss_dice: 0.5146, decode.d1.loss_cls: 0.0743, decode.d1.loss_mask: 0.2411, decode.d1.loss_dice: 0.5089, decode.d2.loss_cls: 0.0610, decode.d2.loss_mask: 0.2408, decode.d2.loss_dice: 0.5173, decode.d3.loss_cls: 0.0431, decode.d3.loss_mask: 0.2411, decode.d3.loss_dice: 0.5128, decode.d4.loss_cls: 0.0520, decode.d4.loss_mask: 0.2427, decode.d4.loss_dice: 0.5220, decode.d5.loss_cls: 0.0583, decode.d5.loss_mask: 0.2419, decode.d5.loss_dice: 0.5178, decode.d6.loss_cls: 0.0492, decode.d6.loss_mask: 0.2439, decode.d6.loss_dice: 0.5143, decode.d7.loss_cls: 0.0571, decode.d7.loss_mask: 0.2415, decode.d7.loss_dice: 0.4987, decode.d8.loss_cls: 0.0563, decode.d8.loss_mask: 0.2422, decode.d8.loss_dice: 0.5143, loss: 8.2347
2023-09-29 10:15:49,480 - mmseg - INFO - Iter [28700/40000]	lr: 4.056e-07, eta: 10:00:51, time: 2.267, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0531, decode.loss_mask: 0.2377, decode.loss_dice: 0.5008, decode.d0.loss_cls: 0.2428, decode.d0.loss_mask: 0.2423, decode.d0.loss_dice: 0.5129, decode.d1.loss_cls: 0.0846, decode.d1.loss_mask: 0.2374, decode.d1.loss_dice: 0.4991, decode.d2.loss_cls: 0.0571, decode.d2.loss_mask: 0.2377, decode.d2.loss_dice: 0.5014, decode.d3.loss_cls: 0.0533, decode.d3.loss_mask: 0.2377, decode.d3.loss_dice: 0.5018, decode.d4.loss_cls: 0.0691, decode.d4.loss_mask: 0.2375, decode.d4.loss_dice: 0.4993, decode.d5.loss_cls: 0.0709, decode.d5.loss_mask: 0.2381, decode.d5.loss_dice: 0.5050, decode.d6.loss_cls: 0.0584, decode.d6.loss_mask: 0.2379, decode.d6.loss_dice: 0.4959, decode.d7.loss_cls: 0.0592, decode.d7.loss_mask: 0.2387, decode.d7.loss_dice: 0.4990, decode.d8.loss_cls: 0.0610, decode.d8.loss_mask: 0.2377, decode.d8.loss_dice: 0.4934, loss: 8.2006
2023-09-29 10:17:42,356 - mmseg - INFO - Iter [28750/40000]	lr: 4.039e-07, eta: 9:57:53, time: 2.257, data_time: 0.026, memory: 21542, decode.loss_cls: 0.0495, decode.loss_mask: 0.2616, decode.loss_dice: 0.5168, decode.d0.loss_cls: 0.1982, decode.d0.loss_mask: 0.2642, decode.d0.loss_dice: 0.5207, decode.d1.loss_cls: 0.0610, decode.d1.loss_mask: 0.2630, decode.d1.loss_dice: 0.5234, decode.d2.loss_cls: 0.0620, decode.d2.loss_mask: 0.2623, decode.d2.loss_dice: 0.5308, decode.d3.loss_cls: 0.0499, decode.d3.loss_mask: 0.2624, decode.d3.loss_dice: 0.5143, decode.d4.loss_cls: 0.0587, decode.d4.loss_mask: 0.2622, decode.d4.loss_dice: 0.5184, decode.d5.loss_cls: 0.0557, decode.d5.loss_mask: 0.2622, decode.d5.loss_dice: 0.5211, decode.d6.loss_cls: 0.0440, decode.d6.loss_mask: 0.2618, decode.d6.loss_dice: 0.5195, decode.d7.loss_cls: 0.0532, decode.d7.loss_mask: 0.2619, decode.d7.loss_dice: 0.5172, decode.d8.loss_cls: 0.0512, decode.d8.loss_mask: 0.2627, decode.d8.loss_dice: 0.5165, loss: 8.5065
2023-09-29 10:19:35,321 - mmseg - INFO - Iter [28800/40000]	lr: 4.021e-07, eta: 9:54:56, time: 2.259, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0640, decode.loss_mask: 0.2873, decode.loss_dice: 0.5530, decode.d0.loss_cls: 0.2292, decode.d0.loss_mask: 0.2776, decode.d0.loss_dice: 0.5711, decode.d1.loss_cls: 0.1231, decode.d1.loss_mask: 0.2860, decode.d1.loss_dice: 0.5499, decode.d2.loss_cls: 0.0724, decode.d2.loss_mask: 0.2880, decode.d2.loss_dice: 0.5560, decode.d3.loss_cls: 0.0886, decode.d3.loss_mask: 0.2793, decode.d3.loss_dice: 0.5545, decode.d4.loss_cls: 0.0803, decode.d4.loss_mask: 0.2779, decode.d4.loss_dice: 0.5610, decode.d5.loss_cls: 0.0763, decode.d5.loss_mask: 0.2782, decode.d5.loss_dice: 0.5514, decode.d6.loss_cls: 0.1008, decode.d6.loss_mask: 0.2761, decode.d6.loss_dice: 0.5592, decode.d7.loss_cls: 0.0815, decode.d7.loss_mask: 0.2775, decode.d7.loss_dice: 0.5555, decode.d8.loss_cls: 0.0756, decode.d8.loss_mask: 0.2760, decode.d8.loss_dice: 0.5521, loss: 9.3592
2023-09-29 10:21:27,797 - mmseg - INFO - Iter [28850/40000]	lr: 4.003e-07, eta: 9:51:58, time: 2.250, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0580, decode.loss_mask: 0.2908, decode.loss_dice: 0.5422, decode.d0.loss_cls: 0.2213, decode.d0.loss_mask: 0.2985, decode.d0.loss_dice: 0.5413, decode.d1.loss_cls: 0.0768, decode.d1.loss_mask: 0.2892, decode.d1.loss_dice: 0.5427, decode.d2.loss_cls: 0.0822, decode.d2.loss_mask: 0.2898, decode.d2.loss_dice: 0.5437, decode.d3.loss_cls: 0.0774, decode.d3.loss_mask: 0.2909, decode.d3.loss_dice: 0.5369, decode.d4.loss_cls: 0.0748, decode.d4.loss_mask: 0.2914, decode.d4.loss_dice: 0.5478, decode.d5.loss_cls: 0.0691, decode.d5.loss_mask: 0.2890, decode.d5.loss_dice: 0.5397, decode.d6.loss_cls: 0.0730, decode.d6.loss_mask: 0.2916, decode.d6.loss_dice: 0.5337, decode.d7.loss_cls: 0.0642, decode.d7.loss_mask: 0.2915, decode.d7.loss_dice: 0.5421, decode.d8.loss_cls: 0.0691, decode.d8.loss_mask: 0.2896, decode.d8.loss_dice: 0.5339, loss: 9.1820
2023-09-29 10:23:20,361 - mmseg - INFO - Iter [28900/40000]	lr: 3.985e-07, eta: 9:49:01, time: 2.251, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0698, decode.loss_mask: 0.2589, decode.loss_dice: 0.5321, decode.d0.loss_cls: 0.2196, decode.d0.loss_mask: 0.2641, decode.d0.loss_dice: 0.5426, decode.d1.loss_cls: 0.0846, decode.d1.loss_mask: 0.2593, decode.d1.loss_dice: 0.5435, decode.d2.loss_cls: 0.0599, decode.d2.loss_mask: 0.2585, decode.d2.loss_dice: 0.5406, decode.d3.loss_cls: 0.0582, decode.d3.loss_mask: 0.2601, decode.d3.loss_dice: 0.5426, decode.d4.loss_cls: 0.0424, decode.d4.loss_mask: 0.2587, decode.d4.loss_dice: 0.5437, decode.d5.loss_cls: 0.0528, decode.d5.loss_mask: 0.2586, decode.d5.loss_dice: 0.5392, decode.d6.loss_cls: 0.0627, decode.d6.loss_mask: 0.2575, decode.d6.loss_dice: 0.5308, decode.d7.loss_cls: 0.0771, decode.d7.loss_mask: 0.2581, decode.d7.loss_dice: 0.5327, decode.d8.loss_cls: 0.0614, decode.d8.loss_mask: 0.2580, decode.d8.loss_dice: 0.5331, loss: 8.7613
2023-09-29 10:25:13,087 - mmseg - INFO - Iter [28950/40000]	lr: 3.967e-07, eta: 9:46:04, time: 2.255, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0707, decode.loss_mask: 0.2603, decode.loss_dice: 0.5389, decode.d0.loss_cls: 0.2314, decode.d0.loss_mask: 0.2614, decode.d0.loss_dice: 0.5391, decode.d1.loss_cls: 0.0605, decode.d1.loss_mask: 0.2576, decode.d1.loss_dice: 0.5421, decode.d2.loss_cls: 0.0725, decode.d2.loss_mask: 0.2612, decode.d2.loss_dice: 0.5440, decode.d3.loss_cls: 0.0704, decode.d3.loss_mask: 0.2583, decode.d3.loss_dice: 0.5442, decode.d4.loss_cls: 0.0597, decode.d4.loss_mask: 0.2575, decode.d4.loss_dice: 0.5401, decode.d5.loss_cls: 0.0781, decode.d5.loss_mask: 0.2612, decode.d5.loss_dice: 0.5387, decode.d6.loss_cls: 0.0729, decode.d6.loss_mask: 0.2605, decode.d6.loss_dice: 0.5302, decode.d7.loss_cls: 0.0703, decode.d7.loss_mask: 0.2589, decode.d7.loss_dice: 0.5420, decode.d8.loss_cls: 0.0645, decode.d8.loss_mask: 0.2591, decode.d8.loss_dice: 0.5438, loss: 8.8502
2023-09-29 10:27:06,266 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 10:27:06,267 - mmseg - INFO - Iter [29000/40000]	lr: 3.949e-07, eta: 9:43:08, time: 2.264, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0664, decode.loss_mask: 0.2500, decode.loss_dice: 0.5195, decode.d0.loss_cls: 0.2254, decode.d0.loss_mask: 0.2554, decode.d0.loss_dice: 0.5563, decode.d1.loss_cls: 0.0903, decode.d1.loss_mask: 0.2521, decode.d1.loss_dice: 0.5357, decode.d2.loss_cls: 0.0794, decode.d2.loss_mask: 0.2499, decode.d2.loss_dice: 0.5275, decode.d3.loss_cls: 0.0643, decode.d3.loss_mask: 0.2511, decode.d3.loss_dice: 0.5298, decode.d4.loss_cls: 0.0791, decode.d4.loss_mask: 0.2499, decode.d4.loss_dice: 0.5297, decode.d5.loss_cls: 0.0632, decode.d5.loss_mask: 0.2516, decode.d5.loss_dice: 0.5312, decode.d6.loss_cls: 0.0543, decode.d6.loss_mask: 0.2509, decode.d6.loss_dice: 0.5189, decode.d7.loss_cls: 0.0714, decode.d7.loss_mask: 0.2501, decode.d7.loss_dice: 0.5280, decode.d8.loss_cls: 0.0770, decode.d8.loss_mask: 0.2488, decode.d8.loss_dice: 0.5313, loss: 8.6885
2023-09-29 10:28:59,680 - mmseg - INFO - Iter [29050/40000]	lr: 3.931e-07, eta: 9:40:11, time: 2.268, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0477, decode.loss_mask: 0.2485, decode.loss_dice: 0.5544, decode.d0.loss_cls: 0.1963, decode.d0.loss_mask: 0.2530, decode.d0.loss_dice: 0.5450, decode.d1.loss_cls: 0.0599, decode.d1.loss_mask: 0.2512, decode.d1.loss_dice: 0.5502, decode.d2.loss_cls: 0.0619, decode.d2.loss_mask: 0.2490, decode.d2.loss_dice: 0.5381, decode.d3.loss_cls: 0.0735, decode.d3.loss_mask: 0.2479, decode.d3.loss_dice: 0.5326, decode.d4.loss_cls: 0.0509, decode.d4.loss_mask: 0.2501, decode.d4.loss_dice: 0.5437, decode.d5.loss_cls: 0.0679, decode.d5.loss_mask: 0.2489, decode.d5.loss_dice: 0.5422, decode.d6.loss_cls: 0.0706, decode.d6.loss_mask: 0.2497, decode.d6.loss_dice: 0.5423, decode.d7.loss_cls: 0.0606, decode.d7.loss_mask: 0.2482, decode.d7.loss_dice: 0.5452, decode.d8.loss_cls: 0.0485, decode.d8.loss_mask: 0.2482, decode.d8.loss_dice: 0.5488, loss: 8.6751
2023-09-29 10:30:51,761 - mmseg - INFO - Iter [29100/40000]	lr: 3.913e-07, eta: 9:37:15, time: 2.242, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0445, decode.loss_mask: 0.2455, decode.loss_dice: 0.5161, decode.d0.loss_cls: 0.1922, decode.d0.loss_mask: 0.2499, decode.d0.loss_dice: 0.5271, decode.d1.loss_cls: 0.0528, decode.d1.loss_mask: 0.2452, decode.d1.loss_dice: 0.5164, decode.d2.loss_cls: 0.0572, decode.d2.loss_mask: 0.2466, decode.d2.loss_dice: 0.5181, decode.d3.loss_cls: 0.0436, decode.d3.loss_mask: 0.2464, decode.d3.loss_dice: 0.5222, decode.d4.loss_cls: 0.0393, decode.d4.loss_mask: 0.2459, decode.d4.loss_dice: 0.5243, decode.d5.loss_cls: 0.0457, decode.d5.loss_mask: 0.2452, decode.d5.loss_dice: 0.5186, decode.d6.loss_cls: 0.0574, decode.d6.loss_mask: 0.2453, decode.d6.loss_dice: 0.5222, decode.d7.loss_cls: 0.0469, decode.d7.loss_mask: 0.2457, decode.d7.loss_dice: 0.5139, decode.d8.loss_cls: 0.0490, decode.d8.loss_mask: 0.2458, decode.d8.loss_dice: 0.5222, loss: 8.2914
2023-09-29 10:32:45,086 - mmseg - INFO - Iter [29150/40000]	lr: 3.895e-07, eta: 9:34:19, time: 2.266, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0723, decode.loss_mask: 0.2304, decode.loss_dice: 0.5567, decode.d0.loss_cls: 0.2175, decode.d0.loss_mask: 0.2309, decode.d0.loss_dice: 0.5599, decode.d1.loss_cls: 0.0790, decode.d1.loss_mask: 0.2294, decode.d1.loss_dice: 0.5444, decode.d2.loss_cls: 0.0796, decode.d2.loss_mask: 0.2300, decode.d2.loss_dice: 0.5480, decode.d3.loss_cls: 0.0518, decode.d3.loss_mask: 0.2296, decode.d3.loss_dice: 0.5452, decode.d4.loss_cls: 0.0611, decode.d4.loss_mask: 0.2290, decode.d4.loss_dice: 0.5531, decode.d5.loss_cls: 0.0627, decode.d5.loss_mask: 0.2295, decode.d5.loss_dice: 0.5514, decode.d6.loss_cls: 0.0459, decode.d6.loss_mask: 0.2299, decode.d6.loss_dice: 0.5535, decode.d7.loss_cls: 0.0664, decode.d7.loss_mask: 0.2289, decode.d7.loss_dice: 0.5526, decode.d8.loss_cls: 0.0631, decode.d8.loss_mask: 0.2288, decode.d8.loss_dice: 0.5442, loss: 8.6050
2023-09-29 10:34:38,186 - mmseg - INFO - Iter [29200/40000]	lr: 3.877e-07, eta: 9:31:23, time: 2.262, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0742, decode.loss_mask: 0.2677, decode.loss_dice: 0.5588, decode.d0.loss_cls: 0.2222, decode.d0.loss_mask: 0.2744, decode.d0.loss_dice: 0.5616, decode.d1.loss_cls: 0.1030, decode.d1.loss_mask: 0.2690, decode.d1.loss_dice: 0.5570, decode.d2.loss_cls: 0.0556, decode.d2.loss_mask: 0.2694, decode.d2.loss_dice: 0.5489, decode.d3.loss_cls: 0.0525, decode.d3.loss_mask: 0.2694, decode.d3.loss_dice: 0.5479, decode.d4.loss_cls: 0.0471, decode.d4.loss_mask: 0.2699, decode.d4.loss_dice: 0.5468, decode.d5.loss_cls: 0.0797, decode.d5.loss_mask: 0.2706, decode.d5.loss_dice: 0.5564, decode.d6.loss_cls: 0.0737, decode.d6.loss_mask: 0.2691, decode.d6.loss_dice: 0.5518, decode.d7.loss_cls: 0.0666, decode.d7.loss_mask: 0.2695, decode.d7.loss_dice: 0.5532, decode.d8.loss_cls: 0.0570, decode.d8.loss_mask: 0.2693, decode.d8.loss_dice: 0.5562, loss: 9.0686
2023-09-29 10:36:32,286 - mmseg - INFO - Iter [29250/40000]	lr: 3.859e-07, eta: 9:28:28, time: 2.282, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0601, decode.loss_mask: 0.2397, decode.loss_dice: 0.4921, decode.d0.loss_cls: 0.2242, decode.d0.loss_mask: 0.2438, decode.d0.loss_dice: 0.5048, decode.d1.loss_cls: 0.0578, decode.d1.loss_mask: 0.2412, decode.d1.loss_dice: 0.5025, decode.d2.loss_cls: 0.0697, decode.d2.loss_mask: 0.2399, decode.d2.loss_dice: 0.5001, decode.d3.loss_cls: 0.0623, decode.d3.loss_mask: 0.2406, decode.d3.loss_dice: 0.4925, decode.d4.loss_cls: 0.0795, decode.d4.loss_mask: 0.2403, decode.d4.loss_dice: 0.4963, decode.d5.loss_cls: 0.0880, decode.d5.loss_mask: 0.2394, decode.d5.loss_dice: 0.4978, decode.d6.loss_cls: 0.0704, decode.d6.loss_mask: 0.2399, decode.d6.loss_dice: 0.4936, decode.d7.loss_cls: 0.0575, decode.d7.loss_mask: 0.2408, decode.d7.loss_dice: 0.4934, decode.d8.loss_cls: 0.0616, decode.d8.loss_mask: 0.2393, decode.d8.loss_dice: 0.4914, loss: 8.2005
2023-09-29 10:38:25,664 - mmseg - INFO - Iter [29300/40000]	lr: 3.841e-07, eta: 9:25:33, time: 2.268, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0568, decode.loss_mask: 0.2621, decode.loss_dice: 0.5223, decode.d0.loss_cls: 0.1956, decode.d0.loss_mask: 0.2655, decode.d0.loss_dice: 0.5335, decode.d1.loss_cls: 0.0809, decode.d1.loss_mask: 0.2636, decode.d1.loss_dice: 0.5141, decode.d2.loss_cls: 0.0763, decode.d2.loss_mask: 0.2632, decode.d2.loss_dice: 0.5193, decode.d3.loss_cls: 0.0648, decode.d3.loss_mask: 0.2631, decode.d3.loss_dice: 0.5256, decode.d4.loss_cls: 0.0862, decode.d4.loss_mask: 0.2618, decode.d4.loss_dice: 0.5172, decode.d5.loss_cls: 0.0714, decode.d5.loss_mask: 0.2620, decode.d5.loss_dice: 0.5307, decode.d6.loss_cls: 0.0701, decode.d6.loss_mask: 0.2625, decode.d6.loss_dice: 0.5320, decode.d7.loss_cls: 0.0664, decode.d7.loss_mask: 0.2640, decode.d7.loss_dice: 0.5238, decode.d8.loss_cls: 0.0575, decode.d8.loss_mask: 0.2626, decode.d8.loss_dice: 0.5271, loss: 8.7019
2023-09-29 10:40:18,145 - mmseg - INFO - Iter [29350/40000]	lr: 3.823e-07, eta: 9:22:38, time: 2.250, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0641, decode.loss_mask: 0.2419, decode.loss_dice: 0.4643, decode.d0.loss_cls: 0.2320, decode.d0.loss_mask: 0.2464, decode.d0.loss_dice: 0.4821, decode.d1.loss_cls: 0.0679, decode.d1.loss_mask: 0.2442, decode.d1.loss_dice: 0.4665, decode.d2.loss_cls: 0.0580, decode.d2.loss_mask: 0.2418, decode.d2.loss_dice: 0.4750, decode.d3.loss_cls: 0.0598, decode.d3.loss_mask: 0.2426, decode.d3.loss_dice: 0.4768, decode.d4.loss_cls: 0.0541, decode.d4.loss_mask: 0.2417, decode.d4.loss_dice: 0.4749, decode.d5.loss_cls: 0.0726, decode.d5.loss_mask: 0.2427, decode.d5.loss_dice: 0.4718, decode.d6.loss_cls: 0.0548, decode.d6.loss_mask: 0.2410, decode.d6.loss_dice: 0.4781, decode.d7.loss_cls: 0.0530, decode.d7.loss_mask: 0.2417, decode.d7.loss_dice: 0.4723, decode.d8.loss_cls: 0.0532, decode.d8.loss_mask: 0.2417, decode.d8.loss_dice: 0.4715, loss: 7.9287
2023-09-29 10:42:10,814 - mmseg - INFO - Iter [29400/40000]	lr: 3.805e-07, eta: 9:19:43, time: 2.253, data_time: 0.035, memory: 21542, decode.loss_cls: 0.0590, decode.loss_mask: 0.2513, decode.loss_dice: 0.5679, decode.d0.loss_cls: 0.1930, decode.d0.loss_mask: 0.2563, decode.d0.loss_dice: 0.5762, decode.d1.loss_cls: 0.0898, decode.d1.loss_mask: 0.2534, decode.d1.loss_dice: 0.5639, decode.d2.loss_cls: 0.0843, decode.d2.loss_mask: 0.2515, decode.d2.loss_dice: 0.5664, decode.d3.loss_cls: 0.0657, decode.d3.loss_mask: 0.2513, decode.d3.loss_dice: 0.5662, decode.d4.loss_cls: 0.0653, decode.d4.loss_mask: 0.2504, decode.d4.loss_dice: 0.5686, decode.d5.loss_cls: 0.0742, decode.d5.loss_mask: 0.2511, decode.d5.loss_dice: 0.5663, decode.d6.loss_cls: 0.0636, decode.d6.loss_mask: 0.2514, decode.d6.loss_dice: 0.5798, decode.d7.loss_cls: 0.0755, decode.d7.loss_mask: 0.2499, decode.d7.loss_dice: 0.5646, decode.d8.loss_cls: 0.0810, decode.d8.loss_mask: 0.2500, decode.d8.loss_dice: 0.5610, loss: 9.0490
2023-09-29 10:44:03,640 - mmseg - INFO - Iter [29450/40000]	lr: 3.787e-07, eta: 9:16:48, time: 2.257, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0644, decode.loss_mask: 0.2246, decode.loss_dice: 0.5210, decode.d0.loss_cls: 0.2033, decode.d0.loss_mask: 0.2262, decode.d0.loss_dice: 0.5364, decode.d1.loss_cls: 0.0394, decode.d1.loss_mask: 0.2255, decode.d1.loss_dice: 0.5229, decode.d2.loss_cls: 0.0548, decode.d2.loss_mask: 0.2234, decode.d2.loss_dice: 0.5188, decode.d3.loss_cls: 0.0575, decode.d3.loss_mask: 0.2236, decode.d3.loss_dice: 0.5073, decode.d4.loss_cls: 0.0475, decode.d4.loss_mask: 0.2242, decode.d4.loss_dice: 0.5288, decode.d5.loss_cls: 0.0572, decode.d5.loss_mask: 0.2244, decode.d5.loss_dice: 0.5192, decode.d6.loss_cls: 0.0589, decode.d6.loss_mask: 0.2241, decode.d6.loss_dice: 0.5218, decode.d7.loss_cls: 0.0348, decode.d7.loss_mask: 0.2251, decode.d7.loss_dice: 0.5087, decode.d8.loss_cls: 0.0669, decode.d8.loss_mask: 0.2235, decode.d8.loss_dice: 0.5209, loss: 8.1352
2023-09-29 10:45:55,975 - mmseg - INFO - Iter [29500/40000]	lr: 3.769e-07, eta: 9:13:53, time: 2.247, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0513, decode.loss_mask: 0.2446, decode.loss_dice: 0.5208, decode.d0.loss_cls: 0.1979, decode.d0.loss_mask: 0.2457, decode.d0.loss_dice: 0.5458, decode.d1.loss_cls: 0.0832, decode.d1.loss_mask: 0.2431, decode.d1.loss_dice: 0.5301, decode.d2.loss_cls: 0.0728, decode.d2.loss_mask: 0.2432, decode.d2.loss_dice: 0.5270, decode.d3.loss_cls: 0.0497, decode.d3.loss_mask: 0.2434, decode.d3.loss_dice: 0.5223, decode.d4.loss_cls: 0.0585, decode.d4.loss_mask: 0.2424, decode.d4.loss_dice: 0.5284, decode.d5.loss_cls: 0.0641, decode.d5.loss_mask: 0.2433, decode.d5.loss_dice: 0.5264, decode.d6.loss_cls: 0.0515, decode.d6.loss_mask: 0.2430, decode.d6.loss_dice: 0.5283, decode.d7.loss_cls: 0.0502, decode.d7.loss_mask: 0.2422, decode.d7.loss_dice: 0.5239, decode.d8.loss_cls: 0.0545, decode.d8.loss_mask: 0.2424, decode.d8.loss_dice: 0.5308, loss: 8.4507
2023-09-29 10:47:48,349 - mmseg - INFO - Iter [29550/40000]	lr: 3.751e-07, eta: 9:10:59, time: 2.247, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0414, decode.loss_mask: 0.2526, decode.loss_dice: 0.5110, decode.d0.loss_cls: 0.2122, decode.d0.loss_mask: 0.2609, decode.d0.loss_dice: 0.5224, decode.d1.loss_cls: 0.0673, decode.d1.loss_mask: 0.2546, decode.d1.loss_dice: 0.5212, decode.d2.loss_cls: 0.0617, decode.d2.loss_mask: 0.2528, decode.d2.loss_dice: 0.5098, decode.d3.loss_cls: 0.0393, decode.d3.loss_mask: 0.2565, decode.d3.loss_dice: 0.5114, decode.d4.loss_cls: 0.0518, decode.d4.loss_mask: 0.2547, decode.d4.loss_dice: 0.5162, decode.d5.loss_cls: 0.0447, decode.d5.loss_mask: 0.2547, decode.d5.loss_dice: 0.5217, decode.d6.loss_cls: 0.0484, decode.d6.loss_mask: 0.2560, decode.d6.loss_dice: 0.5153, decode.d7.loss_cls: 0.0426, decode.d7.loss_mask: 0.2560, decode.d7.loss_dice: 0.5146, decode.d8.loss_cls: 0.0491, decode.d8.loss_mask: 0.2532, decode.d8.loss_dice: 0.5093, loss: 8.3635
2023-09-29 10:49:41,217 - mmseg - INFO - Iter [29600/40000]	lr: 3.733e-07, eta: 9:08:05, time: 2.257, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0583, decode.loss_mask: 0.2885, decode.loss_dice: 0.5604, decode.d0.loss_cls: 0.2541, decode.d0.loss_mask: 0.2887, decode.d0.loss_dice: 0.5667, decode.d1.loss_cls: 0.1088, decode.d1.loss_mask: 0.2845, decode.d1.loss_dice: 0.5623, decode.d2.loss_cls: 0.0702, decode.d2.loss_mask: 0.2901, decode.d2.loss_dice: 0.5663, decode.d3.loss_cls: 0.0791, decode.d3.loss_mask: 0.2902, decode.d3.loss_dice: 0.5470, decode.d4.loss_cls: 0.0864, decode.d4.loss_mask: 0.2867, decode.d4.loss_dice: 0.5513, decode.d5.loss_cls: 0.0726, decode.d5.loss_mask: 0.2892, decode.d5.loss_dice: 0.5573, decode.d6.loss_cls: 0.0793, decode.d6.loss_mask: 0.2895, decode.d6.loss_dice: 0.5640, decode.d7.loss_cls: 0.0757, decode.d7.loss_mask: 0.2878, decode.d7.loss_dice: 0.5700, decode.d8.loss_cls: 0.0892, decode.d8.loss_mask: 0.2896, decode.d8.loss_dice: 0.5638, loss: 9.4674
2023-09-29 10:51:36,702 - mmseg - INFO - Iter [29650/40000]	lr: 3.715e-07, eta: 9:05:12, time: 2.310, data_time: 0.081, memory: 21542, decode.loss_cls: 0.0577, decode.loss_mask: 0.2436, decode.loss_dice: 0.5172, decode.d0.loss_cls: 0.2059, decode.d0.loss_mask: 0.2509, decode.d0.loss_dice: 0.5252, decode.d1.loss_cls: 0.0793, decode.d1.loss_mask: 0.2466, decode.d1.loss_dice: 0.5201, decode.d2.loss_cls: 0.0676, decode.d2.loss_mask: 0.2450, decode.d2.loss_dice: 0.5223, decode.d3.loss_cls: 0.0688, decode.d3.loss_mask: 0.2451, decode.d3.loss_dice: 0.5176, decode.d4.loss_cls: 0.0674, decode.d4.loss_mask: 0.2448, decode.d4.loss_dice: 0.5200, decode.d5.loss_cls: 0.0751, decode.d5.loss_mask: 0.2455, decode.d5.loss_dice: 0.5412, decode.d6.loss_cls: 0.0618, decode.d6.loss_mask: 0.2448, decode.d6.loss_dice: 0.5186, decode.d7.loss_cls: 0.0819, decode.d7.loss_mask: 0.2439, decode.d7.loss_dice: 0.5283, decode.d8.loss_cls: 0.0624, decode.d8.loss_mask: 0.2431, decode.d8.loss_dice: 0.5148, loss: 8.5066
2023-09-29 10:53:29,401 - mmseg - INFO - Iter [29700/40000]	lr: 3.698e-07, eta: 9:02:18, time: 2.254, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0237, decode.loss_mask: 0.2359, decode.loss_dice: 0.5043, decode.d0.loss_cls: 0.2076, decode.d0.loss_mask: 0.2399, decode.d0.loss_dice: 0.5111, decode.d1.loss_cls: 0.0289, decode.d1.loss_mask: 0.2378, decode.d1.loss_dice: 0.5097, decode.d2.loss_cls: 0.0430, decode.d2.loss_mask: 0.2377, decode.d2.loss_dice: 0.5082, decode.d3.loss_cls: 0.0311, decode.d3.loss_mask: 0.2365, decode.d3.loss_dice: 0.4966, decode.d4.loss_cls: 0.0442, decode.d4.loss_mask: 0.2359, decode.d4.loss_dice: 0.5009, decode.d5.loss_cls: 0.0312, decode.d5.loss_mask: 0.2353, decode.d5.loss_dice: 0.5083, decode.d6.loss_cls: 0.0371, decode.d6.loss_mask: 0.2360, decode.d6.loss_dice: 0.5030, decode.d7.loss_cls: 0.0306, decode.d7.loss_mask: 0.2365, decode.d7.loss_dice: 0.4999, decode.d8.loss_cls: 0.0339, decode.d8.loss_mask: 0.2373, decode.d8.loss_dice: 0.4993, loss: 7.9211
2023-09-29 10:55:22,058 - mmseg - INFO - Iter [29750/40000]	lr: 3.680e-07, eta: 8:59:24, time: 2.253, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0629, decode.loss_mask: 0.2448, decode.loss_dice: 0.5153, decode.d0.loss_cls: 0.2172, decode.d0.loss_mask: 0.2484, decode.d0.loss_dice: 0.5433, decode.d1.loss_cls: 0.0677, decode.d1.loss_mask: 0.2457, decode.d1.loss_dice: 0.5322, decode.d2.loss_cls: 0.0725, decode.d2.loss_mask: 0.2450, decode.d2.loss_dice: 0.5172, decode.d3.loss_cls: 0.0947, decode.d3.loss_mask: 0.2441, decode.d3.loss_dice: 0.5217, decode.d4.loss_cls: 0.0774, decode.d4.loss_mask: 0.2453, decode.d4.loss_dice: 0.5183, decode.d5.loss_cls: 0.0806, decode.d5.loss_mask: 0.2439, decode.d5.loss_dice: 0.5226, decode.d6.loss_cls: 0.0856, decode.d6.loss_mask: 0.2444, decode.d6.loss_dice: 0.5163, decode.d7.loss_cls: 0.0623, decode.d7.loss_mask: 0.2447, decode.d7.loss_dice: 0.5153, decode.d8.loss_cls: 0.0666, decode.d8.loss_mask: 0.2442, decode.d8.loss_dice: 0.5191, loss: 8.5594
2023-09-29 10:57:14,728 - mmseg - INFO - Iter [29800/40000]	lr: 3.662e-07, eta: 8:56:31, time: 2.254, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0713, decode.loss_mask: 0.2526, decode.loss_dice: 0.5054, decode.d0.loss_cls: 0.2042, decode.d0.loss_mask: 0.2654, decode.d0.loss_dice: 0.5232, decode.d1.loss_cls: 0.0604, decode.d1.loss_mask: 0.2597, decode.d1.loss_dice: 0.5133, decode.d2.loss_cls: 0.0577, decode.d2.loss_mask: 0.2558, decode.d2.loss_dice: 0.5089, decode.d3.loss_cls: 0.0642, decode.d3.loss_mask: 0.2524, decode.d3.loss_dice: 0.5086, decode.d4.loss_cls: 0.0758, decode.d4.loss_mask: 0.2528, decode.d4.loss_dice: 0.5066, decode.d5.loss_cls: 0.0694, decode.d5.loss_mask: 0.2526, decode.d5.loss_dice: 0.5067, decode.d6.loss_cls: 0.0695, decode.d6.loss_mask: 0.2543, decode.d6.loss_dice: 0.5031, decode.d7.loss_cls: 0.0504, decode.d7.loss_mask: 0.2595, decode.d7.loss_dice: 0.5075, decode.d8.loss_cls: 0.0692, decode.d8.loss_mask: 0.2534, decode.d8.loss_dice: 0.5070, loss: 8.4411
2023-09-29 10:59:08,216 - mmseg - INFO - Iter [29850/40000]	lr: 3.644e-07, eta: 8:53:38, time: 2.270, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0538, decode.loss_mask: 0.2386, decode.loss_dice: 0.5101, decode.d0.loss_cls: 0.2268, decode.d0.loss_mask: 0.2394, decode.d0.loss_dice: 0.5280, decode.d1.loss_cls: 0.0839, decode.d1.loss_mask: 0.2376, decode.d1.loss_dice: 0.5208, decode.d2.loss_cls: 0.0596, decode.d2.loss_mask: 0.2392, decode.d2.loss_dice: 0.5162, decode.d3.loss_cls: 0.0485, decode.d3.loss_mask: 0.2385, decode.d3.loss_dice: 0.5181, decode.d4.loss_cls: 0.0589, decode.d4.loss_mask: 0.2387, decode.d4.loss_dice: 0.5172, decode.d5.loss_cls: 0.0512, decode.d5.loss_mask: 0.2387, decode.d5.loss_dice: 0.5051, decode.d6.loss_cls: 0.0516, decode.d6.loss_mask: 0.2403, decode.d6.loss_dice: 0.5175, decode.d7.loss_cls: 0.0573, decode.d7.loss_mask: 0.2390, decode.d7.loss_dice: 0.5062, decode.d8.loss_cls: 0.0511, decode.d8.loss_mask: 0.2385, decode.d8.loss_dice: 0.5100, loss: 8.2805
2023-09-29 11:01:00,906 - mmseg - INFO - Iter [29900/40000]	lr: 3.626e-07, eta: 8:50:45, time: 2.254, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0401, decode.loss_mask: 0.2572, decode.loss_dice: 0.5567, decode.d0.loss_cls: 0.1942, decode.d0.loss_mask: 0.2607, decode.d0.loss_dice: 0.5531, decode.d1.loss_cls: 0.0570, decode.d1.loss_mask: 0.2588, decode.d1.loss_dice: 0.5568, decode.d2.loss_cls: 0.0481, decode.d2.loss_mask: 0.2568, decode.d2.loss_dice: 0.5471, decode.d3.loss_cls: 0.0484, decode.d3.loss_mask: 0.2558, decode.d3.loss_dice: 0.5445, decode.d4.loss_cls: 0.0401, decode.d4.loss_mask: 0.2577, decode.d4.loss_dice: 0.5533, decode.d5.loss_cls: 0.0418, decode.d5.loss_mask: 0.2570, decode.d5.loss_dice: 0.5559, decode.d6.loss_cls: 0.0448, decode.d6.loss_mask: 0.2569, decode.d6.loss_dice: 0.5436, decode.d7.loss_cls: 0.0367, decode.d7.loss_mask: 0.2570, decode.d7.loss_dice: 0.5506, decode.d8.loss_cls: 0.0527, decode.d8.loss_mask: 0.2579, decode.d8.loss_dice: 0.5507, loss: 8.6919
2023-09-29 11:02:54,160 - mmseg - INFO - Iter [29950/40000]	lr: 3.608e-07, eta: 8:47:53, time: 2.265, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0636, decode.loss_mask: 0.2539, decode.loss_dice: 0.5071, decode.d0.loss_cls: 0.2208, decode.d0.loss_mask: 0.2578, decode.d0.loss_dice: 0.5088, decode.d1.loss_cls: 0.0693, decode.d1.loss_mask: 0.2554, decode.d1.loss_dice: 0.5027, decode.d2.loss_cls: 0.0656, decode.d2.loss_mask: 0.2531, decode.d2.loss_dice: 0.5066, decode.d3.loss_cls: 0.0566, decode.d3.loss_mask: 0.2530, decode.d3.loss_dice: 0.5027, decode.d4.loss_cls: 0.0601, decode.d4.loss_mask: 0.2533, decode.d4.loss_dice: 0.4980, decode.d5.loss_cls: 0.0568, decode.d5.loss_mask: 0.2535, decode.d5.loss_dice: 0.5048, decode.d6.loss_cls: 0.0547, decode.d6.loss_mask: 0.2522, decode.d6.loss_dice: 0.5022, decode.d7.loss_cls: 0.0468, decode.d7.loss_mask: 0.2525, decode.d7.loss_dice: 0.4983, decode.d8.loss_cls: 0.0472, decode.d8.loss_mask: 0.2529, decode.d8.loss_dice: 0.5016, loss: 8.3118
2023-09-29 11:04:46,690 - mmseg - INFO - Saving checkpoint at 30000 iterations
2023-09-29 11:05:06,364 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 11:05:06,364 - mmseg - INFO - Iter [30000/40000]	lr: 3.590e-07, eta: 8:45:07, time: 2.644, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0464, decode.loss_mask: 0.2976, decode.loss_dice: 0.5286, decode.d0.loss_cls: 0.2398, decode.d0.loss_mask: 0.2990, decode.d0.loss_dice: 0.5293, decode.d1.loss_cls: 0.0512, decode.d1.loss_mask: 0.2981, decode.d1.loss_dice: 0.5322, decode.d2.loss_cls: 0.0448, decode.d2.loss_mask: 0.2961, decode.d2.loss_dice: 0.5264, decode.d3.loss_cls: 0.0313, decode.d3.loss_mask: 0.2983, decode.d3.loss_dice: 0.5281, decode.d4.loss_cls: 0.0502, decode.d4.loss_mask: 0.2979, decode.d4.loss_dice: 0.5226, decode.d5.loss_cls: 0.0522, decode.d5.loss_mask: 0.2962, decode.d5.loss_dice: 0.5247, decode.d6.loss_cls: 0.0488, decode.d6.loss_mask: 0.2965, decode.d6.loss_dice: 0.5170, decode.d7.loss_cls: 0.0418, decode.d7.loss_mask: 0.2973, decode.d7.loss_dice: 0.5209, decode.d8.loss_cls: 0.0468, decode.d8.loss_mask: 0.2962, decode.d8.loss_dice: 0.5311, loss: 8.8877
2023-09-29 11:22:36,584 - mmseg - INFO - per class results:
2023-09-29 11:22:36,586 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 92.82 | 97.33 |
|    Sidewalk   | 69.99 | 81.53 |
|  Construction | 82.41 | 93.78 |
|     Fence     |  34.1 | 38.13 |
|      Pole     | 58.83 | 69.75 |
| Traffic Light | 67.19 |  80.0 |
|  Traffic Sign |  72.3 | 80.34 |
|     Nature    | 88.65 | 94.41 |
|      Sky      | 96.56 | 97.99 |
|     Person    | 34.97 | 38.07 |
|     Rider     |  9.07 | 71.46 |
|      Car      | 91.55 | 94.52 |
|   background  | 96.12 |  97.5 |
+---------------+-------+-------+
2023-09-29 11:22:36,586 - mmseg - INFO - Summary:
2023-09-29 11:22:36,586 - mmseg - INFO - 
+------+-------+------+
| aAcc |  mIoU | mAcc |
+------+-------+------+
| 94.5 | 68.81 | 79.6 |
+------+-------+------+
2023-09-29 11:22:36,593 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 11:22:36,593 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9450, mIoU: 0.6881, mAcc: 0.7960, IoU.Road: 0.9282, IoU.Sidewalk: 0.6999, IoU.Construction: 0.8241, IoU.Fence: 0.3410, IoU.Pole: 0.5883, IoU.Traffic Light: 0.6719, IoU.Traffic Sign: 0.7230, IoU.Nature: 0.8865, IoU.Sky: 0.9656, IoU.Person: 0.3497, IoU.Rider: 0.0907, IoU.Car: 0.9155, IoU.background: 0.9612, Acc.Road: 0.9733, Acc.Sidewalk: 0.8153, Acc.Construction: 0.9378, Acc.Fence: 0.3813, Acc.Pole: 0.6975, Acc.Traffic Light: 0.8000, Acc.Traffic Sign: 0.8034, Acc.Nature: 0.9441, Acc.Sky: 0.9799, Acc.Person: 0.3807, Acc.Rider: 0.7146, Acc.Car: 0.9452, Acc.background: 0.9750
2023-09-29 11:24:29,632 - mmseg - INFO - Iter [30050/40000]	lr: 3.572e-07, eta: 8:48:02, time: 23.265, data_time: 21.032, memory: 21542, decode.loss_cls: 0.0670, decode.loss_mask: 0.2812, decode.loss_dice: 0.5467, decode.d0.loss_cls: 0.2695, decode.d0.loss_mask: 0.2861, decode.d0.loss_dice: 0.5415, decode.d1.loss_cls: 0.0912, decode.d1.loss_mask: 0.2809, decode.d1.loss_dice: 0.5444, decode.d2.loss_cls: 0.0877, decode.d2.loss_mask: 0.2766, decode.d2.loss_dice: 0.5366, decode.d3.loss_cls: 0.0805, decode.d3.loss_mask: 0.2780, decode.d3.loss_dice: 0.5395, decode.d4.loss_cls: 0.0976, decode.d4.loss_mask: 0.2789, decode.d4.loss_dice: 0.5368, decode.d5.loss_cls: 0.0796, decode.d5.loss_mask: 0.2814, decode.d5.loss_dice: 0.5470, decode.d6.loss_cls: 0.0838, decode.d6.loss_mask: 0.2798, decode.d6.loss_dice: 0.5403, decode.d7.loss_cls: 0.0797, decode.d7.loss_mask: 0.2798, decode.d7.loss_dice: 0.5345, decode.d8.loss_cls: 0.0644, decode.d8.loss_mask: 0.2799, decode.d8.loss_dice: 0.5339, loss: 9.2050
2023-09-29 11:26:22,916 - mmseg - INFO - Iter [30100/40000]	lr: 3.554e-07, eta: 8:45:08, time: 2.266, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0754, decode.loss_mask: 0.2437, decode.loss_dice: 0.5090, decode.d0.loss_cls: 0.2578, decode.d0.loss_mask: 0.2451, decode.d0.loss_dice: 0.5014, decode.d1.loss_cls: 0.1010, decode.d1.loss_mask: 0.2416, decode.d1.loss_dice: 0.5035, decode.d2.loss_cls: 0.0733, decode.d2.loss_mask: 0.2415, decode.d2.loss_dice: 0.4994, decode.d3.loss_cls: 0.0754, decode.d3.loss_mask: 0.2412, decode.d3.loss_dice: 0.5036, decode.d4.loss_cls: 0.0824, decode.d4.loss_mask: 0.2424, decode.d4.loss_dice: 0.5070, decode.d5.loss_cls: 0.0902, decode.d5.loss_mask: 0.2430, decode.d5.loss_dice: 0.5070, decode.d6.loss_cls: 0.0702, decode.d6.loss_mask: 0.2437, decode.d6.loss_dice: 0.5022, decode.d7.loss_cls: 0.0755, decode.d7.loss_mask: 0.2447, decode.d7.loss_dice: 0.5050, decode.d8.loss_cls: 0.0865, decode.d8.loss_mask: 0.2428, decode.d8.loss_dice: 0.5064, loss: 8.4619
2023-09-29 11:28:16,436 - mmseg - INFO - Iter [30150/40000]	lr: 3.536e-07, eta: 8:42:14, time: 2.270, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0571, decode.loss_mask: 0.2665, decode.loss_dice: 0.5149, decode.d0.loss_cls: 0.2188, decode.d0.loss_mask: 0.2698, decode.d0.loss_dice: 0.5294, decode.d1.loss_cls: 0.0802, decode.d1.loss_mask: 0.2667, decode.d1.loss_dice: 0.5255, decode.d2.loss_cls: 0.0770, decode.d2.loss_mask: 0.2666, decode.d2.loss_dice: 0.5300, decode.d3.loss_cls: 0.0760, decode.d3.loss_mask: 0.2666, decode.d3.loss_dice: 0.5179, decode.d4.loss_cls: 0.0663, decode.d4.loss_mask: 0.2659, decode.d4.loss_dice: 0.5322, decode.d5.loss_cls: 0.0734, decode.d5.loss_mask: 0.2661, decode.d5.loss_dice: 0.5249, decode.d6.loss_cls: 0.0684, decode.d6.loss_mask: 0.2658, decode.d6.loss_dice: 0.5322, decode.d7.loss_cls: 0.0854, decode.d7.loss_mask: 0.2663, decode.d7.loss_dice: 0.5258, decode.d8.loss_cls: 0.0567, decode.d8.loss_mask: 0.2650, decode.d8.loss_dice: 0.5240, loss: 8.7813
2023-09-29 11:30:09,277 - mmseg - INFO - Iter [30200/40000]	lr: 3.518e-07, eta: 8:39:20, time: 2.257, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0747, decode.loss_mask: 0.2445, decode.loss_dice: 0.5372, decode.d0.loss_cls: 0.2132, decode.d0.loss_mask: 0.2488, decode.d0.loss_dice: 0.5528, decode.d1.loss_cls: 0.0834, decode.d1.loss_mask: 0.2452, decode.d1.loss_dice: 0.5478, decode.d2.loss_cls: 0.0742, decode.d2.loss_mask: 0.2444, decode.d2.loss_dice: 0.5446, decode.d3.loss_cls: 0.0630, decode.d3.loss_mask: 0.2451, decode.d3.loss_dice: 0.5364, decode.d4.loss_cls: 0.0678, decode.d4.loss_mask: 0.2404, decode.d4.loss_dice: 0.5486, decode.d5.loss_cls: 0.0580, decode.d5.loss_mask: 0.2449, decode.d5.loss_dice: 0.5475, decode.d6.loss_cls: 0.0663, decode.d6.loss_mask: 0.2443, decode.d6.loss_dice: 0.5404, decode.d7.loss_cls: 0.0599, decode.d7.loss_mask: 0.2446, decode.d7.loss_dice: 0.5446, decode.d8.loss_cls: 0.0649, decode.d8.loss_mask: 0.2440, decode.d8.loss_dice: 0.5408, loss: 8.7123
2023-09-29 11:32:01,697 - mmseg - INFO - Iter [30250/40000]	lr: 3.500e-07, eta: 8:36:26, time: 2.249, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0648, decode.loss_mask: 0.2890, decode.loss_dice: 0.5339, decode.d0.loss_cls: 0.2134, decode.d0.loss_mask: 0.2995, decode.d0.loss_dice: 0.5534, decode.d1.loss_cls: 0.0756, decode.d1.loss_mask: 0.2907, decode.d1.loss_dice: 0.5571, decode.d2.loss_cls: 0.0654, decode.d2.loss_mask: 0.2897, decode.d2.loss_dice: 0.5488, decode.d3.loss_cls: 0.0699, decode.d3.loss_mask: 0.2905, decode.d3.loss_dice: 0.5407, decode.d4.loss_cls: 0.0701, decode.d4.loss_mask: 0.2911, decode.d4.loss_dice: 0.5488, decode.d5.loss_cls: 0.0779, decode.d5.loss_mask: 0.2895, decode.d5.loss_dice: 0.5477, decode.d6.loss_cls: 0.0597, decode.d6.loss_mask: 0.2902, decode.d6.loss_dice: 0.5415, decode.d7.loss_cls: 0.0576, decode.d7.loss_mask: 0.2897, decode.d7.loss_dice: 0.5405, decode.d8.loss_cls: 0.0621, decode.d8.loss_mask: 0.2881, decode.d8.loss_dice: 0.5308, loss: 9.1677
2023-09-29 11:33:54,249 - mmseg - INFO - Iter [30300/40000]	lr: 3.482e-07, eta: 8:33:32, time: 2.251, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0642, decode.loss_mask: 0.2916, decode.loss_dice: 0.5577, decode.d0.loss_cls: 0.2207, decode.d0.loss_mask: 0.2940, decode.d0.loss_dice: 0.5534, decode.d1.loss_cls: 0.1071, decode.d1.loss_mask: 0.2908, decode.d1.loss_dice: 0.5546, decode.d2.loss_cls: 0.0722, decode.d2.loss_mask: 0.2914, decode.d2.loss_dice: 0.5441, decode.d3.loss_cls: 0.0918, decode.d3.loss_mask: 0.2936, decode.d3.loss_dice: 0.5540, decode.d4.loss_cls: 0.0711, decode.d4.loss_mask: 0.2922, decode.d4.loss_dice: 0.5483, decode.d5.loss_cls: 0.0758, decode.d5.loss_mask: 0.2907, decode.d5.loss_dice: 0.5452, decode.d6.loss_cls: 0.0692, decode.d6.loss_mask: 0.2938, decode.d6.loss_dice: 0.5509, decode.d7.loss_cls: 0.1012, decode.d7.loss_mask: 0.2910, decode.d7.loss_dice: 0.5571, decode.d8.loss_cls: 0.0755, decode.d8.loss_mask: 0.2913, decode.d8.loss_dice: 0.5478, loss: 9.3821
2023-09-29 11:35:46,549 - mmseg - INFO - Iter [30350/40000]	lr: 3.464e-07, eta: 8:30:38, time: 2.246, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0431, decode.loss_mask: 0.2732, decode.loss_dice: 0.5284, decode.d0.loss_cls: 0.2198, decode.d0.loss_mask: 0.2787, decode.d0.loss_dice: 0.5360, decode.d1.loss_cls: 0.0641, decode.d1.loss_mask: 0.2749, decode.d1.loss_dice: 0.5331, decode.d2.loss_cls: 0.0579, decode.d2.loss_mask: 0.2741, decode.d2.loss_dice: 0.5255, decode.d3.loss_cls: 0.0663, decode.d3.loss_mask: 0.2720, decode.d3.loss_dice: 0.5282, decode.d4.loss_cls: 0.0627, decode.d4.loss_mask: 0.2739, decode.d4.loss_dice: 0.5359, decode.d5.loss_cls: 0.0633, decode.d5.loss_mask: 0.2727, decode.d5.loss_dice: 0.5252, decode.d6.loss_cls: 0.0587, decode.d6.loss_mask: 0.2725, decode.d6.loss_dice: 0.5340, decode.d7.loss_cls: 0.0615, decode.d7.loss_mask: 0.2717, decode.d7.loss_dice: 0.5386, decode.d8.loss_cls: 0.0523, decode.d8.loss_mask: 0.2735, decode.d8.loss_dice: 0.5348, loss: 8.8065
2023-09-29 11:37:40,078 - mmseg - INFO - Iter [30400/40000]	lr: 3.446e-07, eta: 8:27:45, time: 2.270, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0642, decode.loss_mask: 0.2345, decode.loss_dice: 0.4985, decode.d0.loss_cls: 0.2451, decode.d0.loss_mask: 0.2367, decode.d0.loss_dice: 0.5126, decode.d1.loss_cls: 0.0793, decode.d1.loss_mask: 0.2353, decode.d1.loss_dice: 0.5003, decode.d2.loss_cls: 0.0825, decode.d2.loss_mask: 0.2350, decode.d2.loss_dice: 0.5041, decode.d3.loss_cls: 0.0695, decode.d3.loss_mask: 0.2335, decode.d3.loss_dice: 0.4984, decode.d4.loss_cls: 0.0732, decode.d4.loss_mask: 0.2343, decode.d4.loss_dice: 0.5052, decode.d5.loss_cls: 0.0749, decode.d5.loss_mask: 0.2337, decode.d5.loss_dice: 0.5074, decode.d6.loss_cls: 0.0589, decode.d6.loss_mask: 0.2339, decode.d6.loss_dice: 0.5021, decode.d7.loss_cls: 0.0681, decode.d7.loss_mask: 0.2337, decode.d7.loss_dice: 0.5060, decode.d8.loss_cls: 0.0743, decode.d8.loss_mask: 0.2343, decode.d8.loss_dice: 0.5022, loss: 8.2718
2023-09-29 11:39:33,468 - mmseg - INFO - Iter [30450/40000]	lr: 3.428e-07, eta: 8:24:52, time: 2.268, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0434, decode.loss_mask: 0.2439, decode.loss_dice: 0.5346, decode.d0.loss_cls: 0.2394, decode.d0.loss_mask: 0.2440, decode.d0.loss_dice: 0.5373, decode.d1.loss_cls: 0.0748, decode.d1.loss_mask: 0.2427, decode.d1.loss_dice: 0.5325, decode.d2.loss_cls: 0.0565, decode.d2.loss_mask: 0.2427, decode.d2.loss_dice: 0.5305, decode.d3.loss_cls: 0.0483, decode.d3.loss_mask: 0.2427, decode.d3.loss_dice: 0.5260, decode.d4.loss_cls: 0.0494, decode.d4.loss_mask: 0.2428, decode.d4.loss_dice: 0.5368, decode.d5.loss_cls: 0.0410, decode.d5.loss_mask: 0.2431, decode.d5.loss_dice: 0.5384, decode.d6.loss_cls: 0.0495, decode.d6.loss_mask: 0.2439, decode.d6.loss_dice: 0.5371, decode.d7.loss_cls: 0.0518, decode.d7.loss_mask: 0.2434, decode.d7.loss_dice: 0.5178, decode.d8.loss_cls: 0.0511, decode.d8.loss_mask: 0.2444, decode.d8.loss_dice: 0.5381, loss: 8.4679
2023-09-29 11:41:25,895 - mmseg - INFO - Iter [30500/40000]	lr: 3.410e-07, eta: 8:21:59, time: 2.248, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0612, decode.loss_mask: 0.2654, decode.loss_dice: 0.5278, decode.d0.loss_cls: 0.2087, decode.d0.loss_mask: 0.2738, decode.d0.loss_dice: 0.5446, decode.d1.loss_cls: 0.0679, decode.d1.loss_mask: 0.2659, decode.d1.loss_dice: 0.5272, decode.d2.loss_cls: 0.0571, decode.d2.loss_mask: 0.2652, decode.d2.loss_dice: 0.5261, decode.d3.loss_cls: 0.0619, decode.d3.loss_mask: 0.2631, decode.d3.loss_dice: 0.5303, decode.d4.loss_cls: 0.0658, decode.d4.loss_mask: 0.2656, decode.d4.loss_dice: 0.5397, decode.d5.loss_cls: 0.0555, decode.d5.loss_mask: 0.2659, decode.d5.loss_dice: 0.5412, decode.d6.loss_cls: 0.0487, decode.d6.loss_mask: 0.2654, decode.d6.loss_dice: 0.5357, decode.d7.loss_cls: 0.0491, decode.d7.loss_mask: 0.2655, decode.d7.loss_dice: 0.5299, decode.d8.loss_cls: 0.0473, decode.d8.loss_mask: 0.2664, decode.d8.loss_dice: 0.5332, loss: 8.7213
2023-09-29 11:43:18,503 - mmseg - INFO - Iter [30550/40000]	lr: 3.392e-07, eta: 8:19:07, time: 2.252, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0677, decode.loss_mask: 0.2709, decode.loss_dice: 0.5337, decode.d0.loss_cls: 0.2455, decode.d0.loss_mask: 0.2754, decode.d0.loss_dice: 0.5510, decode.d1.loss_cls: 0.0582, decode.d1.loss_mask: 0.2717, decode.d1.loss_dice: 0.5420, decode.d2.loss_cls: 0.0580, decode.d2.loss_mask: 0.2714, decode.d2.loss_dice: 0.5414, decode.d3.loss_cls: 0.0600, decode.d3.loss_mask: 0.2697, decode.d3.loss_dice: 0.5398, decode.d4.loss_cls: 0.0627, decode.d4.loss_mask: 0.2700, decode.d4.loss_dice: 0.5489, decode.d5.loss_cls: 0.0800, decode.d5.loss_mask: 0.2700, decode.d5.loss_dice: 0.5453, decode.d6.loss_cls: 0.0659, decode.d6.loss_mask: 0.2696, decode.d6.loss_dice: 0.5400, decode.d7.loss_cls: 0.0631, decode.d7.loss_mask: 0.2710, decode.d7.loss_dice: 0.5473, decode.d8.loss_cls: 0.0915, decode.d8.loss_mask: 0.2701, decode.d8.loss_dice: 0.5405, loss: 8.9924
2023-09-29 11:45:10,763 - mmseg - INFO - Iter [30600/40000]	lr: 3.374e-07, eta: 8:16:14, time: 2.245, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0723, decode.loss_mask: 0.2841, decode.loss_dice: 0.5415, decode.d0.loss_cls: 0.2332, decode.d0.loss_mask: 0.2960, decode.d0.loss_dice: 0.5586, decode.d1.loss_cls: 0.0894, decode.d1.loss_mask: 0.2927, decode.d1.loss_dice: 0.5521, decode.d2.loss_cls: 0.0634, decode.d2.loss_mask: 0.2932, decode.d2.loss_dice: 0.5431, decode.d3.loss_cls: 0.0617, decode.d3.loss_mask: 0.2903, decode.d3.loss_dice: 0.5370, decode.d4.loss_cls: 0.0487, decode.d4.loss_mask: 0.2936, decode.d4.loss_dice: 0.5427, decode.d5.loss_cls: 0.0752, decode.d5.loss_mask: 0.2860, decode.d5.loss_dice: 0.5467, decode.d6.loss_cls: 0.0682, decode.d6.loss_mask: 0.2840, decode.d6.loss_dice: 0.5347, decode.d7.loss_cls: 0.0963, decode.d7.loss_mask: 0.2866, decode.d7.loss_dice: 0.5378, decode.d8.loss_cls: 0.0779, decode.d8.loss_mask: 0.2804, decode.d8.loss_dice: 0.5398, loss: 9.2072
2023-09-29 11:47:02,734 - mmseg - INFO - Iter [30650/40000]	lr: 3.357e-07, eta: 8:13:22, time: 2.239, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0388, decode.loss_mask: 0.2632, decode.loss_dice: 0.5149, decode.d0.loss_cls: 0.2049, decode.d0.loss_mask: 0.2684, decode.d0.loss_dice: 0.5427, decode.d1.loss_cls: 0.0534, decode.d1.loss_mask: 0.2617, decode.d1.loss_dice: 0.5149, decode.d2.loss_cls: 0.0483, decode.d2.loss_mask: 0.2625, decode.d2.loss_dice: 0.5234, decode.d3.loss_cls: 0.0360, decode.d3.loss_mask: 0.2610, decode.d3.loss_dice: 0.5234, decode.d4.loss_cls: 0.0396, decode.d4.loss_mask: 0.2600, decode.d4.loss_dice: 0.5159, decode.d5.loss_cls: 0.0478, decode.d5.loss_mask: 0.2617, decode.d5.loss_dice: 0.5160, decode.d6.loss_cls: 0.0587, decode.d6.loss_mask: 0.2612, decode.d6.loss_dice: 0.5169, decode.d7.loss_cls: 0.0426, decode.d7.loss_mask: 0.2617, decode.d7.loss_dice: 0.5182, decode.d8.loss_cls: 0.0443, decode.d8.loss_mask: 0.2627, decode.d8.loss_dice: 0.5217, loss: 8.4464
2023-09-29 11:48:56,005 - mmseg - INFO - Iter [30700/40000]	lr: 3.339e-07, eta: 8:10:30, time: 2.265, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0595, decode.loss_mask: 0.2691, decode.loss_dice: 0.5369, decode.d0.loss_cls: 0.2097, decode.d0.loss_mask: 0.2733, decode.d0.loss_dice: 0.5468, decode.d1.loss_cls: 0.0827, decode.d1.loss_mask: 0.2710, decode.d1.loss_dice: 0.5495, decode.d2.loss_cls: 0.0590, decode.d2.loss_mask: 0.2712, decode.d2.loss_dice: 0.5522, decode.d3.loss_cls: 0.0600, decode.d3.loss_mask: 0.2705, decode.d3.loss_dice: 0.5490, decode.d4.loss_cls: 0.0432, decode.d4.loss_mask: 0.2698, decode.d4.loss_dice: 0.5489, decode.d5.loss_cls: 0.0631, decode.d5.loss_mask: 0.2693, decode.d5.loss_dice: 0.5412, decode.d6.loss_cls: 0.0558, decode.d6.loss_mask: 0.2667, decode.d6.loss_dice: 0.5422, decode.d7.loss_cls: 0.0698, decode.d7.loss_mask: 0.2666, decode.d7.loss_dice: 0.5414, decode.d8.loss_cls: 0.0607, decode.d8.loss_mask: 0.2669, decode.d8.loss_dice: 0.5440, loss: 8.9103
2023-09-29 11:50:51,613 - mmseg - INFO - Iter [30750/40000]	lr: 3.321e-07, eta: 8:07:39, time: 2.312, data_time: 0.074, memory: 21542, decode.loss_cls: 0.0633, decode.loss_mask: 0.2695, decode.loss_dice: 0.5372, decode.d0.loss_cls: 0.2113, decode.d0.loss_mask: 0.2688, decode.d0.loss_dice: 0.5448, decode.d1.loss_cls: 0.0926, decode.d1.loss_mask: 0.2701, decode.d1.loss_dice: 0.5420, decode.d2.loss_cls: 0.0747, decode.d2.loss_mask: 0.2682, decode.d2.loss_dice: 0.5366, decode.d3.loss_cls: 0.0562, decode.d3.loss_mask: 0.2691, decode.d3.loss_dice: 0.5356, decode.d4.loss_cls: 0.0633, decode.d4.loss_mask: 0.2675, decode.d4.loss_dice: 0.5369, decode.d5.loss_cls: 0.0616, decode.d5.loss_mask: 0.2683, decode.d5.loss_dice: 0.5409, decode.d6.loss_cls: 0.0519, decode.d6.loss_mask: 0.2672, decode.d6.loss_dice: 0.5325, decode.d7.loss_cls: 0.0573, decode.d7.loss_mask: 0.2679, decode.d7.loss_dice: 0.5384, decode.d8.loss_cls: 0.0495, decode.d8.loss_mask: 0.2694, decode.d8.loss_dice: 0.5378, loss: 8.8501
2023-09-29 11:52:44,695 - mmseg - INFO - Iter [30800/40000]	lr: 3.303e-07, eta: 8:04:47, time: 2.262, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0477, decode.loss_mask: 0.2607, decode.loss_dice: 0.4915, decode.d0.loss_cls: 0.2112, decode.d0.loss_mask: 0.2645, decode.d0.loss_dice: 0.5142, decode.d1.loss_cls: 0.0549, decode.d1.loss_mask: 0.2622, decode.d1.loss_dice: 0.4854, decode.d2.loss_cls: 0.0646, decode.d2.loss_mask: 0.2598, decode.d2.loss_dice: 0.4896, decode.d3.loss_cls: 0.0565, decode.d3.loss_mask: 0.2584, decode.d3.loss_dice: 0.4904, decode.d4.loss_cls: 0.0508, decode.d4.loss_mask: 0.2585, decode.d4.loss_dice: 0.4884, decode.d5.loss_cls: 0.0501, decode.d5.loss_mask: 0.2615, decode.d5.loss_dice: 0.4856, decode.d6.loss_cls: 0.0603, decode.d6.loss_mask: 0.2591, decode.d6.loss_dice: 0.4888, decode.d7.loss_cls: 0.0535, decode.d7.loss_mask: 0.2615, decode.d7.loss_dice: 0.4898, decode.d8.loss_cls: 0.0441, decode.d8.loss_mask: 0.2601, decode.d8.loss_dice: 0.4875, loss: 8.2112
2023-09-29 11:54:37,481 - mmseg - INFO - Iter [30850/40000]	lr: 3.285e-07, eta: 8:01:55, time: 2.256, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0631, decode.loss_mask: 0.2339, decode.loss_dice: 0.5080, decode.d0.loss_cls: 0.2203, decode.d0.loss_mask: 0.2377, decode.d0.loss_dice: 0.5105, decode.d1.loss_cls: 0.0800, decode.d1.loss_mask: 0.2354, decode.d1.loss_dice: 0.5031, decode.d2.loss_cls: 0.0650, decode.d2.loss_mask: 0.2333, decode.d2.loss_dice: 0.5024, decode.d3.loss_cls: 0.0708, decode.d3.loss_mask: 0.2337, decode.d3.loss_dice: 0.5015, decode.d4.loss_cls: 0.0518, decode.d4.loss_mask: 0.2339, decode.d4.loss_dice: 0.5196, decode.d5.loss_cls: 0.0642, decode.d5.loss_mask: 0.2341, decode.d5.loss_dice: 0.5177, decode.d6.loss_cls: 0.0507, decode.d6.loss_mask: 0.2329, decode.d6.loss_dice: 0.4979, decode.d7.loss_cls: 0.0643, decode.d7.loss_mask: 0.2332, decode.d7.loss_dice: 0.5077, decode.d8.loss_cls: 0.0545, decode.d8.loss_mask: 0.2335, decode.d8.loss_dice: 0.5083, loss: 8.2030
2023-09-29 11:56:29,969 - mmseg - INFO - Iter [30900/40000]	lr: 3.267e-07, eta: 7:59:04, time: 2.250, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0608, decode.loss_mask: 0.2510, decode.loss_dice: 0.5109, decode.d0.loss_cls: 0.2480, decode.d0.loss_mask: 0.2454, decode.d0.loss_dice: 0.5379, decode.d1.loss_cls: 0.0607, decode.d1.loss_mask: 0.2501, decode.d1.loss_dice: 0.5150, decode.d2.loss_cls: 0.0823, decode.d2.loss_mask: 0.2516, decode.d2.loss_dice: 0.5046, decode.d3.loss_cls: 0.0674, decode.d3.loss_mask: 0.2548, decode.d3.loss_dice: 0.5157, decode.d4.loss_cls: 0.0656, decode.d4.loss_mask: 0.2567, decode.d4.loss_dice: 0.5161, decode.d5.loss_cls: 0.0767, decode.d5.loss_mask: 0.2552, decode.d5.loss_dice: 0.5185, decode.d6.loss_cls: 0.0649, decode.d6.loss_mask: 0.2545, decode.d6.loss_dice: 0.5079, decode.d7.loss_cls: 0.0663, decode.d7.loss_mask: 0.2556, decode.d7.loss_dice: 0.5150, decode.d8.loss_cls: 0.0599, decode.d8.loss_mask: 0.2548, decode.d8.loss_dice: 0.5071, loss: 8.5308
2023-09-29 11:58:23,116 - mmseg - INFO - Iter [30950/40000]	lr: 3.249e-07, eta: 7:56:13, time: 2.263, data_time: 0.035, memory: 21542, decode.loss_cls: 0.0562, decode.loss_mask: 0.2599, decode.loss_dice: 0.5194, decode.d0.loss_cls: 0.2095, decode.d0.loss_mask: 0.2640, decode.d0.loss_dice: 0.5247, decode.d1.loss_cls: 0.0649, decode.d1.loss_mask: 0.2619, decode.d1.loss_dice: 0.5251, decode.d2.loss_cls: 0.0669, decode.d2.loss_mask: 0.2598, decode.d2.loss_dice: 0.5144, decode.d3.loss_cls: 0.0466, decode.d3.loss_mask: 0.2611, decode.d3.loss_dice: 0.5348, decode.d4.loss_cls: 0.0626, decode.d4.loss_mask: 0.2595, decode.d4.loss_dice: 0.5253, decode.d5.loss_cls: 0.0506, decode.d5.loss_mask: 0.2595, decode.d5.loss_dice: 0.5136, decode.d6.loss_cls: 0.0473, decode.d6.loss_mask: 0.2597, decode.d6.loss_dice: 0.5123, decode.d7.loss_cls: 0.0475, decode.d7.loss_mask: 0.2602, decode.d7.loss_dice: 0.5226, decode.d8.loss_cls: 0.0461, decode.d8.loss_mask: 0.2607, decode.d8.loss_dice: 0.5201, loss: 8.5164
2023-09-29 12:00:15,447 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 12:00:15,447 - mmseg - INFO - Iter [31000/40000]	lr: 3.231e-07, eta: 7:53:22, time: 2.247, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0521, decode.loss_mask: 0.2495, decode.loss_dice: 0.5384, decode.d0.loss_cls: 0.2241, decode.d0.loss_mask: 0.2551, decode.d0.loss_dice: 0.5579, decode.d1.loss_cls: 0.0639, decode.d1.loss_mask: 0.2517, decode.d1.loss_dice: 0.5394, decode.d2.loss_cls: 0.0477, decode.d2.loss_mask: 0.2504, decode.d2.loss_dice: 0.5437, decode.d3.loss_cls: 0.0535, decode.d3.loss_mask: 0.2497, decode.d3.loss_dice: 0.5425, decode.d4.loss_cls: 0.0489, decode.d4.loss_mask: 0.2495, decode.d4.loss_dice: 0.5404, decode.d5.loss_cls: 0.0515, decode.d5.loss_mask: 0.2500, decode.d5.loss_dice: 0.5427, decode.d6.loss_cls: 0.0553, decode.d6.loss_mask: 0.2498, decode.d6.loss_dice: 0.5431, decode.d7.loss_cls: 0.0551, decode.d7.loss_mask: 0.2502, decode.d7.loss_dice: 0.5389, decode.d8.loss_cls: 0.0532, decode.d8.loss_mask: 0.2510, decode.d8.loss_dice: 0.5354, loss: 8.6346
2023-09-29 12:02:07,555 - mmseg - INFO - Iter [31050/40000]	lr: 3.213e-07, eta: 7:50:31, time: 2.242, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0584, decode.loss_mask: 0.2600, decode.loss_dice: 0.5142, decode.d0.loss_cls: 0.2187, decode.d0.loss_mask: 0.2659, decode.d0.loss_dice: 0.5242, decode.d1.loss_cls: 0.0681, decode.d1.loss_mask: 0.2613, decode.d1.loss_dice: 0.5157, decode.d2.loss_cls: 0.0739, decode.d2.loss_mask: 0.2593, decode.d2.loss_dice: 0.5161, decode.d3.loss_cls: 0.0731, decode.d3.loss_mask: 0.2601, decode.d3.loss_dice: 0.5262, decode.d4.loss_cls: 0.0515, decode.d4.loss_mask: 0.2599, decode.d4.loss_dice: 0.5234, decode.d5.loss_cls: 0.0490, decode.d5.loss_mask: 0.2593, decode.d5.loss_dice: 0.5178, decode.d6.loss_cls: 0.0512, decode.d6.loss_mask: 0.2605, decode.d6.loss_dice: 0.5139, decode.d7.loss_cls: 0.0509, decode.d7.loss_mask: 0.2601, decode.d7.loss_dice: 0.5227, decode.d8.loss_cls: 0.0527, decode.d8.loss_mask: 0.2581, decode.d8.loss_dice: 0.5137, loss: 8.5400
2023-09-29 12:04:00,294 - mmseg - INFO - Iter [31100/40000]	lr: 3.195e-07, eta: 7:47:40, time: 2.255, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0729, decode.loss_mask: 0.2594, decode.loss_dice: 0.5538, decode.d0.loss_cls: 0.2109, decode.d0.loss_mask: 0.2633, decode.d0.loss_dice: 0.5738, decode.d1.loss_cls: 0.0858, decode.d1.loss_mask: 0.2625, decode.d1.loss_dice: 0.5592, decode.d2.loss_cls: 0.0921, decode.d2.loss_mask: 0.2624, decode.d2.loss_dice: 0.5616, decode.d3.loss_cls: 0.0900, decode.d3.loss_mask: 0.2592, decode.d3.loss_dice: 0.5561, decode.d4.loss_cls: 0.0949, decode.d4.loss_mask: 0.2589, decode.d4.loss_dice: 0.5514, decode.d5.loss_cls: 0.0923, decode.d5.loss_mask: 0.2607, decode.d5.loss_dice: 0.5520, decode.d6.loss_cls: 0.0641, decode.d6.loss_mask: 0.2609, decode.d6.loss_dice: 0.5548, decode.d7.loss_cls: 0.0785, decode.d7.loss_mask: 0.2592, decode.d7.loss_dice: 0.5513, decode.d8.loss_cls: 0.0766, decode.d8.loss_mask: 0.2585, decode.d8.loss_dice: 0.5523, loss: 9.1293
2023-09-29 12:05:53,101 - mmseg - INFO - Iter [31150/40000]	lr: 3.177e-07, eta: 7:44:50, time: 2.256, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0668, decode.loss_mask: 0.2583, decode.loss_dice: 0.5347, decode.d0.loss_cls: 0.2339, decode.d0.loss_mask: 0.2592, decode.d0.loss_dice: 0.5443, decode.d1.loss_cls: 0.0739, decode.d1.loss_mask: 0.2601, decode.d1.loss_dice: 0.5438, decode.d2.loss_cls: 0.0657, decode.d2.loss_mask: 0.2587, decode.d2.loss_dice: 0.5383, decode.d3.loss_cls: 0.0438, decode.d3.loss_mask: 0.2582, decode.d3.loss_dice: 0.5414, decode.d4.loss_cls: 0.0646, decode.d4.loss_mask: 0.2577, decode.d4.loss_dice: 0.5333, decode.d5.loss_cls: 0.0615, decode.d5.loss_mask: 0.2589, decode.d5.loss_dice: 0.5372, decode.d6.loss_cls: 0.0677, decode.d6.loss_mask: 0.2587, decode.d6.loss_dice: 0.5344, decode.d7.loss_cls: 0.0592, decode.d7.loss_mask: 0.2579, decode.d7.loss_dice: 0.5305, decode.d8.loss_cls: 0.0570, decode.d8.loss_mask: 0.2570, decode.d8.loss_dice: 0.5263, loss: 8.7430
2023-09-29 12:07:46,410 - mmseg - INFO - Iter [31200/40000]	lr: 3.159e-07, eta: 7:42:00, time: 2.266, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0545, decode.loss_mask: 0.2842, decode.loss_dice: 0.5360, decode.d0.loss_cls: 0.2115, decode.d0.loss_mask: 0.2984, decode.d0.loss_dice: 0.5505, decode.d1.loss_cls: 0.0783, decode.d1.loss_mask: 0.2868, decode.d1.loss_dice: 0.5411, decode.d2.loss_cls: 0.0583, decode.d2.loss_mask: 0.2855, decode.d2.loss_dice: 0.5446, decode.d3.loss_cls: 0.0584, decode.d3.loss_mask: 0.2841, decode.d3.loss_dice: 0.5429, decode.d4.loss_cls: 0.0582, decode.d4.loss_mask: 0.2828, decode.d4.loss_dice: 0.5423, decode.d5.loss_cls: 0.0581, decode.d5.loss_mask: 0.2844, decode.d5.loss_dice: 0.5336, decode.d6.loss_cls: 0.0540, decode.d6.loss_mask: 0.2842, decode.d6.loss_dice: 0.5375, decode.d7.loss_cls: 0.0557, decode.d7.loss_mask: 0.2850, decode.d7.loss_dice: 0.5435, decode.d8.loss_cls: 0.0596, decode.d8.loss_mask: 0.2852, decode.d8.loss_dice: 0.5383, loss: 9.0175
2023-09-29 12:09:39,199 - mmseg - INFO - Iter [31250/40000]	lr: 3.141e-07, eta: 7:39:10, time: 2.256, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0867, decode.loss_mask: 0.2464, decode.loss_dice: 0.5150, decode.d0.loss_cls: 0.2046, decode.d0.loss_mask: 0.2525, decode.d0.loss_dice: 0.5329, decode.d1.loss_cls: 0.1045, decode.d1.loss_mask: 0.2502, decode.d1.loss_dice: 0.5221, decode.d2.loss_cls: 0.0971, decode.d2.loss_mask: 0.2447, decode.d2.loss_dice: 0.5240, decode.d3.loss_cls: 0.0900, decode.d3.loss_mask: 0.2455, decode.d3.loss_dice: 0.5205, decode.d4.loss_cls: 0.0842, decode.d4.loss_mask: 0.2450, decode.d4.loss_dice: 0.5153, decode.d5.loss_cls: 0.0957, decode.d5.loss_mask: 0.2457, decode.d5.loss_dice: 0.5131, decode.d6.loss_cls: 0.0941, decode.d6.loss_mask: 0.2447, decode.d6.loss_dice: 0.5154, decode.d7.loss_cls: 0.0901, decode.d7.loss_mask: 0.2448, decode.d7.loss_dice: 0.5219, decode.d8.loss_cls: 0.0880, decode.d8.loss_mask: 0.2443, decode.d8.loss_dice: 0.5155, loss: 8.6945
2023-09-29 12:11:31,563 - mmseg - INFO - Iter [31300/40000]	lr: 3.123e-07, eta: 7:36:20, time: 2.247, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0670, decode.loss_mask: 0.2682, decode.loss_dice: 0.5298, decode.d0.loss_cls: 0.2271, decode.d0.loss_mask: 0.2800, decode.d0.loss_dice: 0.5455, decode.d1.loss_cls: 0.0657, decode.d1.loss_mask: 0.2683, decode.d1.loss_dice: 0.5334, decode.d2.loss_cls: 0.0736, decode.d2.loss_mask: 0.2682, decode.d2.loss_dice: 0.5338, decode.d3.loss_cls: 0.0590, decode.d3.loss_mask: 0.2686, decode.d3.loss_dice: 0.5295, decode.d4.loss_cls: 0.0643, decode.d4.loss_mask: 0.2695, decode.d4.loss_dice: 0.5340, decode.d5.loss_cls: 0.0623, decode.d5.loss_mask: 0.2692, decode.d5.loss_dice: 0.5366, decode.d6.loss_cls: 0.0805, decode.d6.loss_mask: 0.2686, decode.d6.loss_dice: 0.5297, decode.d7.loss_cls: 0.0512, decode.d7.loss_mask: 0.2675, decode.d7.loss_dice: 0.5361, decode.d8.loss_cls: 0.0568, decode.d8.loss_mask: 0.2688, decode.d8.loss_dice: 0.5318, loss: 8.8448
2023-09-29 12:13:24,461 - mmseg - INFO - Iter [31350/40000]	lr: 3.105e-07, eta: 7:33:30, time: 2.258, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0779, decode.loss_mask: 0.2411, decode.loss_dice: 0.5477, decode.d0.loss_cls: 0.2073, decode.d0.loss_mask: 0.2462, decode.d0.loss_dice: 0.5610, decode.d1.loss_cls: 0.0754, decode.d1.loss_mask: 0.2423, decode.d1.loss_dice: 0.5689, decode.d2.loss_cls: 0.0748, decode.d2.loss_mask: 0.2422, decode.d2.loss_dice: 0.5495, decode.d3.loss_cls: 0.0758, decode.d3.loss_mask: 0.2433, decode.d3.loss_dice: 0.5573, decode.d4.loss_cls: 0.0674, decode.d4.loss_mask: 0.2434, decode.d4.loss_dice: 0.5570, decode.d5.loss_cls: 0.0785, decode.d5.loss_mask: 0.2414, decode.d5.loss_dice: 0.5474, decode.d6.loss_cls: 0.0680, decode.d6.loss_mask: 0.2421, decode.d6.loss_dice: 0.5613, decode.d7.loss_cls: 0.0742, decode.d7.loss_mask: 0.2427, decode.d7.loss_dice: 0.5491, decode.d8.loss_cls: 0.0684, decode.d8.loss_mask: 0.2417, decode.d8.loss_dice: 0.5501, loss: 8.8436
2023-09-29 12:15:17,358 - mmseg - INFO - Iter [31400/40000]	lr: 3.087e-07, eta: 7:30:41, time: 2.258, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0581, decode.loss_mask: 0.2373, decode.loss_dice: 0.5312, decode.d0.loss_cls: 0.2109, decode.d0.loss_mask: 0.2409, decode.d0.loss_dice: 0.5395, decode.d1.loss_cls: 0.0716, decode.d1.loss_mask: 0.2424, decode.d1.loss_dice: 0.5452, decode.d2.loss_cls: 0.0846, decode.d2.loss_mask: 0.2376, decode.d2.loss_dice: 0.5336, decode.d3.loss_cls: 0.0696, decode.d3.loss_mask: 0.2362, decode.d3.loss_dice: 0.5207, decode.d4.loss_cls: 0.0757, decode.d4.loss_mask: 0.2421, decode.d4.loss_dice: 0.5347, decode.d5.loss_cls: 0.0783, decode.d5.loss_mask: 0.2366, decode.d5.loss_dice: 0.5261, decode.d6.loss_cls: 0.0671, decode.d6.loss_mask: 0.2358, decode.d6.loss_dice: 0.5393, decode.d7.loss_cls: 0.0705, decode.d7.loss_mask: 0.2352, decode.d7.loss_dice: 0.5289, decode.d8.loss_cls: 0.0750, decode.d8.loss_mask: 0.2356, decode.d8.loss_dice: 0.5303, loss: 8.5706
2023-09-29 12:17:10,094 - mmseg - INFO - Iter [31450/40000]	lr: 3.069e-07, eta: 7:27:52, time: 2.255, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0429, decode.loss_mask: 0.2584, decode.loss_dice: 0.5076, decode.d0.loss_cls: 0.2087, decode.d0.loss_mask: 0.2595, decode.d0.loss_dice: 0.5112, decode.d1.loss_cls: 0.0429, decode.d1.loss_mask: 0.2571, decode.d1.loss_dice: 0.5138, decode.d2.loss_cls: 0.0447, decode.d2.loss_mask: 0.2595, decode.d2.loss_dice: 0.5064, decode.d3.loss_cls: 0.0476, decode.d3.loss_mask: 0.2588, decode.d3.loss_dice: 0.5143, decode.d4.loss_cls: 0.0368, decode.d4.loss_mask: 0.2605, decode.d4.loss_dice: 0.5055, decode.d5.loss_cls: 0.0387, decode.d5.loss_mask: 0.2588, decode.d5.loss_dice: 0.5049, decode.d6.loss_cls: 0.0455, decode.d6.loss_mask: 0.2586, decode.d6.loss_dice: 0.5137, decode.d7.loss_cls: 0.0363, decode.d7.loss_mask: 0.2583, decode.d7.loss_dice: 0.5178, decode.d8.loss_cls: 0.0465, decode.d8.loss_mask: 0.2584, decode.d8.loss_dice: 0.5054, loss: 8.2788
2023-09-29 12:19:02,718 - mmseg - INFO - Iter [31500/40000]	lr: 3.051e-07, eta: 7:25:02, time: 2.252, data_time: 0.024, memory: 21542, decode.loss_cls: 0.0268, decode.loss_mask: 0.2441, decode.loss_dice: 0.4573, decode.d0.loss_cls: 0.2111, decode.d0.loss_mask: 0.2468, decode.d0.loss_dice: 0.4584, decode.d1.loss_cls: 0.0546, decode.d1.loss_mask: 0.2431, decode.d1.loss_dice: 0.4607, decode.d2.loss_cls: 0.0337, decode.d2.loss_mask: 0.2449, decode.d2.loss_dice: 0.4560, decode.d3.loss_cls: 0.0349, decode.d3.loss_mask: 0.2444, decode.d3.loss_dice: 0.4656, decode.d4.loss_cls: 0.0318, decode.d4.loss_mask: 0.2448, decode.d4.loss_dice: 0.4656, decode.d5.loss_cls: 0.0389, decode.d5.loss_mask: 0.2432, decode.d5.loss_dice: 0.4544, decode.d6.loss_cls: 0.0287, decode.d6.loss_mask: 0.2443, decode.d6.loss_dice: 0.4655, decode.d7.loss_cls: 0.0414, decode.d7.loss_mask: 0.2440, decode.d7.loss_dice: 0.4626, decode.d8.loss_cls: 0.0367, decode.d8.loss_mask: 0.2460, decode.d8.loss_dice: 0.4523, loss: 7.5823
2023-09-29 12:20:55,877 - mmseg - INFO - Iter [31550/40000]	lr: 3.033e-07, eta: 7:22:14, time: 2.263, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0732, decode.loss_mask: 0.2556, decode.loss_dice: 0.5618, decode.d0.loss_cls: 0.1994, decode.d0.loss_mask: 0.2596, decode.d0.loss_dice: 0.5806, decode.d1.loss_cls: 0.0720, decode.d1.loss_mask: 0.2568, decode.d1.loss_dice: 0.5784, decode.d2.loss_cls: 0.0705, decode.d2.loss_mask: 0.2557, decode.d2.loss_dice: 0.5691, decode.d3.loss_cls: 0.0694, decode.d3.loss_mask: 0.2556, decode.d3.loss_dice: 0.5685, decode.d4.loss_cls: 0.0747, decode.d4.loss_mask: 0.2562, decode.d4.loss_dice: 0.5709, decode.d5.loss_cls: 0.0741, decode.d5.loss_mask: 0.2585, decode.d5.loss_dice: 0.5679, decode.d6.loss_cls: 0.0707, decode.d6.loss_mask: 0.2553, decode.d6.loss_dice: 0.5665, decode.d7.loss_cls: 0.0727, decode.d7.loss_mask: 0.2554, decode.d7.loss_dice: 0.5569, decode.d8.loss_cls: 0.0792, decode.d8.loss_mask: 0.2562, decode.d8.loss_dice: 0.5659, loss: 9.1076
2023-09-29 12:22:48,167 - mmseg - INFO - Iter [31600/40000]	lr: 3.016e-07, eta: 7:19:25, time: 2.246, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0489, decode.loss_mask: 0.2532, decode.loss_dice: 0.5107, decode.d0.loss_cls: 0.2103, decode.d0.loss_mask: 0.2554, decode.d0.loss_dice: 0.5229, decode.d1.loss_cls: 0.0554, decode.d1.loss_mask: 0.2523, decode.d1.loss_dice: 0.5189, decode.d2.loss_cls: 0.0424, decode.d2.loss_mask: 0.2528, decode.d2.loss_dice: 0.5184, decode.d3.loss_cls: 0.0432, decode.d3.loss_mask: 0.2533, decode.d3.loss_dice: 0.5149, decode.d4.loss_cls: 0.0485, decode.d4.loss_mask: 0.2526, decode.d4.loss_dice: 0.5154, decode.d5.loss_cls: 0.0535, decode.d5.loss_mask: 0.2527, decode.d5.loss_dice: 0.5089, decode.d6.loss_cls: 0.0463, decode.d6.loss_mask: 0.2533, decode.d6.loss_dice: 0.5232, decode.d7.loss_cls: 0.0574, decode.d7.loss_mask: 0.2527, decode.d7.loss_dice: 0.5183, decode.d8.loss_cls: 0.0387, decode.d8.loss_mask: 0.2529, decode.d8.loss_dice: 0.5163, loss: 8.3434
2023-09-29 12:24:41,338 - mmseg - INFO - Iter [31650/40000]	lr: 2.998e-07, eta: 7:16:36, time: 2.263, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0683, decode.loss_mask: 0.2496, decode.loss_dice: 0.5263, decode.d0.loss_cls: 0.1986, decode.d0.loss_mask: 0.2565, decode.d0.loss_dice: 0.5593, decode.d1.loss_cls: 0.0870, decode.d1.loss_mask: 0.2510, decode.d1.loss_dice: 0.5460, decode.d2.loss_cls: 0.0645, decode.d2.loss_mask: 0.2514, decode.d2.loss_dice: 0.5440, decode.d3.loss_cls: 0.0567, decode.d3.loss_mask: 0.2515, decode.d3.loss_dice: 0.5416, decode.d4.loss_cls: 0.0439, decode.d4.loss_mask: 0.2497, decode.d4.loss_dice: 0.5449, decode.d5.loss_cls: 0.0601, decode.d5.loss_mask: 0.2500, decode.d5.loss_dice: 0.5419, decode.d6.loss_cls: 0.0699, decode.d6.loss_mask: 0.2505, decode.d6.loss_dice: 0.5336, decode.d7.loss_cls: 0.0649, decode.d7.loss_mask: 0.2498, decode.d7.loss_dice: 0.5522, decode.d8.loss_cls: 0.0685, decode.d8.loss_mask: 0.2495, decode.d8.loss_dice: 0.5384, loss: 8.7202
2023-09-29 12:26:34,706 - mmseg - INFO - Iter [31700/40000]	lr: 2.980e-07, eta: 7:13:48, time: 2.267, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0472, decode.loss_mask: 0.2403, decode.loss_dice: 0.5158, decode.d0.loss_cls: 0.2128, decode.d0.loss_mask: 0.2415, decode.d0.loss_dice: 0.5450, decode.d1.loss_cls: 0.0498, decode.d1.loss_mask: 0.2401, decode.d1.loss_dice: 0.5433, decode.d2.loss_cls: 0.0475, decode.d2.loss_mask: 0.2397, decode.d2.loss_dice: 0.5211, decode.d3.loss_cls: 0.0501, decode.d3.loss_mask: 0.2393, decode.d3.loss_dice: 0.5272, decode.d4.loss_cls: 0.0446, decode.d4.loss_mask: 0.2404, decode.d4.loss_dice: 0.5258, decode.d5.loss_cls: 0.0702, decode.d5.loss_mask: 0.2413, decode.d5.loss_dice: 0.5242, decode.d6.loss_cls: 0.0490, decode.d6.loss_mask: 0.2405, decode.d6.loss_dice: 0.5286, decode.d7.loss_cls: 0.0433, decode.d7.loss_mask: 0.2399, decode.d7.loss_dice: 0.5208, decode.d8.loss_cls: 0.0561, decode.d8.loss_mask: 0.2403, decode.d8.loss_dice: 0.5246, loss: 8.3502
2023-09-29 12:28:27,431 - mmseg - INFO - Iter [31750/40000]	lr: 2.962e-07, eta: 7:11:00, time: 2.255, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0557, decode.loss_mask: 0.2342, decode.loss_dice: 0.4814, decode.d0.loss_cls: 0.2167, decode.d0.loss_mask: 0.2349, decode.d0.loss_dice: 0.4869, decode.d1.loss_cls: 0.0655, decode.d1.loss_mask: 0.2347, decode.d1.loss_dice: 0.4750, decode.d2.loss_cls: 0.0565, decode.d2.loss_mask: 0.2340, decode.d2.loss_dice: 0.4746, decode.d3.loss_cls: 0.0423, decode.d3.loss_mask: 0.2357, decode.d3.loss_dice: 0.4790, decode.d4.loss_cls: 0.0480, decode.d4.loss_mask: 0.2363, decode.d4.loss_dice: 0.4798, decode.d5.loss_cls: 0.0449, decode.d5.loss_mask: 0.2355, decode.d5.loss_dice: 0.4773, decode.d6.loss_cls: 0.0579, decode.d6.loss_mask: 0.2346, decode.d6.loss_dice: 0.4846, decode.d7.loss_cls: 0.0457, decode.d7.loss_mask: 0.2357, decode.d7.loss_dice: 0.4799, decode.d8.loss_cls: 0.0520, decode.d8.loss_mask: 0.2365, decode.d8.loss_dice: 0.4802, loss: 7.8357
2023-09-29 12:30:20,360 - mmseg - INFO - Iter [31800/40000]	lr: 2.944e-07, eta: 7:08:12, time: 2.258, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0694, decode.loss_mask: 0.2685, decode.loss_dice: 0.5469, decode.d0.loss_cls: 0.1956, decode.d0.loss_mask: 0.2714, decode.d0.loss_dice: 0.5640, decode.d1.loss_cls: 0.0696, decode.d1.loss_mask: 0.2698, decode.d1.loss_dice: 0.5491, decode.d2.loss_cls: 0.0458, decode.d2.loss_mask: 0.2679, decode.d2.loss_dice: 0.5441, decode.d3.loss_cls: 0.0598, decode.d3.loss_mask: 0.2693, decode.d3.loss_dice: 0.5472, decode.d4.loss_cls: 0.0637, decode.d4.loss_mask: 0.2678, decode.d4.loss_dice: 0.5443, decode.d5.loss_cls: 0.0555, decode.d5.loss_mask: 0.2686, decode.d5.loss_dice: 0.5408, decode.d6.loss_cls: 0.0458, decode.d6.loss_mask: 0.2675, decode.d6.loss_dice: 0.5474, decode.d7.loss_cls: 0.0414, decode.d7.loss_mask: 0.2700, decode.d7.loss_dice: 0.5532, decode.d8.loss_cls: 0.0539, decode.d8.loss_mask: 0.2684, decode.d8.loss_dice: 0.5466, loss: 8.8732
2023-09-29 12:32:15,439 - mmseg - INFO - Iter [31850/40000]	lr: 2.926e-07, eta: 7:05:24, time: 2.302, data_time: 0.075, memory: 21542, decode.loss_cls: 0.0786, decode.loss_mask: 0.2529, decode.loss_dice: 0.5089, decode.d0.loss_cls: 0.2748, decode.d0.loss_mask: 0.2701, decode.d0.loss_dice: 0.5159, decode.d1.loss_cls: 0.0959, decode.d1.loss_mask: 0.2656, decode.d1.loss_dice: 0.5175, decode.d2.loss_cls: 0.0930, decode.d2.loss_mask: 0.2578, decode.d2.loss_dice: 0.5118, decode.d3.loss_cls: 0.0961, decode.d3.loss_mask: 0.2538, decode.d3.loss_dice: 0.5125, decode.d4.loss_cls: 0.0868, decode.d4.loss_mask: 0.2581, decode.d4.loss_dice: 0.5120, decode.d5.loss_cls: 0.0793, decode.d5.loss_mask: 0.2601, decode.d5.loss_dice: 0.5139, decode.d6.loss_cls: 0.0758, decode.d6.loss_mask: 0.2551, decode.d6.loss_dice: 0.5025, decode.d7.loss_cls: 0.0969, decode.d7.loss_mask: 0.2590, decode.d7.loss_dice: 0.5029, decode.d8.loss_cls: 0.0901, decode.d8.loss_mask: 0.2599, decode.d8.loss_dice: 0.5154, loss: 8.7731
2023-09-29 12:34:08,405 - mmseg - INFO - Iter [31900/40000]	lr: 2.908e-07, eta: 7:02:37, time: 2.259, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0714, decode.loss_mask: 0.2501, decode.loss_dice: 0.4663, decode.d0.loss_cls: 0.2155, decode.d0.loss_mask: 0.2506, decode.d0.loss_dice: 0.4842, decode.d1.loss_cls: 0.0745, decode.d1.loss_mask: 0.2497, decode.d1.loss_dice: 0.4651, decode.d2.loss_cls: 0.0673, decode.d2.loss_mask: 0.2466, decode.d2.loss_dice: 0.4616, decode.d3.loss_cls: 0.0964, decode.d3.loss_mask: 0.2462, decode.d3.loss_dice: 0.4643, decode.d4.loss_cls: 0.0730, decode.d4.loss_mask: 0.2475, decode.d4.loss_dice: 0.4639, decode.d5.loss_cls: 0.0716, decode.d5.loss_mask: 0.2487, decode.d5.loss_dice: 0.4631, decode.d6.loss_cls: 0.0800, decode.d6.loss_mask: 0.2469, decode.d6.loss_dice: 0.4581, decode.d7.loss_cls: 0.0731, decode.d7.loss_mask: 0.2468, decode.d7.loss_dice: 0.4530, decode.d8.loss_cls: 0.0734, decode.d8.loss_mask: 0.2480, decode.d8.loss_dice: 0.4640, loss: 8.0208
2023-09-29 12:36:00,909 - mmseg - INFO - Iter [31950/40000]	lr: 2.890e-07, eta: 6:59:49, time: 2.250, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0657, decode.loss_mask: 0.2829, decode.loss_dice: 0.5285, decode.d0.loss_cls: 0.2221, decode.d0.loss_mask: 0.2813, decode.d0.loss_dice: 0.5329, decode.d1.loss_cls: 0.0679, decode.d1.loss_mask: 0.2828, decode.d1.loss_dice: 0.5383, decode.d2.loss_cls: 0.0427, decode.d2.loss_mask: 0.2832, decode.d2.loss_dice: 0.5309, decode.d3.loss_cls: 0.0441, decode.d3.loss_mask: 0.2832, decode.d3.loss_dice: 0.5316, decode.d4.loss_cls: 0.0490, decode.d4.loss_mask: 0.2818, decode.d4.loss_dice: 0.5290, decode.d5.loss_cls: 0.0453, decode.d5.loss_mask: 0.2840, decode.d5.loss_dice: 0.5321, decode.d6.loss_cls: 0.0509, decode.d6.loss_mask: 0.2840, decode.d6.loss_dice: 0.5387, decode.d7.loss_cls: 0.0519, decode.d7.loss_mask: 0.2813, decode.d7.loss_dice: 0.5332, decode.d8.loss_cls: 0.0504, decode.d8.loss_mask: 0.2818, decode.d8.loss_dice: 0.5291, loss: 8.8405
2023-09-29 12:37:54,180 - mmseg - INFO - Saving checkpoint at 32000 iterations
2023-09-29 12:38:14,204 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 12:38:14,204 - mmseg - INFO - Iter [32000/40000]	lr: 2.872e-07, eta: 6:57:07, time: 2.666, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0727, decode.loss_mask: 0.2591, decode.loss_dice: 0.5156, decode.d0.loss_cls: 0.2270, decode.d0.loss_mask: 0.2627, decode.d0.loss_dice: 0.5343, decode.d1.loss_cls: 0.0947, decode.d1.loss_mask: 0.2599, decode.d1.loss_dice: 0.5233, decode.d2.loss_cls: 0.0762, decode.d2.loss_mask: 0.2589, decode.d2.loss_dice: 0.5151, decode.d3.loss_cls: 0.0529, decode.d3.loss_mask: 0.2589, decode.d3.loss_dice: 0.5100, decode.d4.loss_cls: 0.0602, decode.d4.loss_mask: 0.2582, decode.d4.loss_dice: 0.5067, decode.d5.loss_cls: 0.0712, decode.d5.loss_mask: 0.2585, decode.d5.loss_dice: 0.5175, decode.d6.loss_cls: 0.0661, decode.d6.loss_mask: 0.2595, decode.d6.loss_dice: 0.5187, decode.d7.loss_cls: 0.0708, decode.d7.loss_mask: 0.2588, decode.d7.loss_dice: 0.5204, decode.d8.loss_cls: 0.0630, decode.d8.loss_mask: 0.2603, decode.d8.loss_dice: 0.5216, loss: 8.6327
2023-09-29 12:55:30,850 - mmseg - INFO - per class results:
2023-09-29 12:55:30,868 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 92.89 |  96.9 |
|    Sidewalk   |  69.5 | 81.63 |
|  Construction | 82.25 | 94.36 |
|     Fence     | 33.99 | 37.81 |
|      Pole     |  57.7 | 68.61 |
| Traffic Light | 67.47 | 80.09 |
|  Traffic Sign | 72.01 | 80.89 |
|     Nature    | 88.48 | 93.76 |
|      Sky      | 96.62 | 98.01 |
|     Person    | 34.23 | 36.99 |
|     Rider     |  8.95 | 72.27 |
|      Car      | 91.44 | 94.64 |
|   background  | 96.16 | 97.78 |
+---------------+-------+-------+
2023-09-29 12:55:30,868 - mmseg - INFO - Summary:
2023-09-29 12:55:30,868 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.47 | 68.59 | 79.52 |
+-------+-------+-------+
2023-09-29 12:55:30,871 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 12:55:30,872 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9447, mIoU: 0.6859, mAcc: 0.7952, IoU.Road: 0.9289, IoU.Sidewalk: 0.6950, IoU.Construction: 0.8225, IoU.Fence: 0.3399, IoU.Pole: 0.5770, IoU.Traffic Light: 0.6747, IoU.Traffic Sign: 0.7201, IoU.Nature: 0.8848, IoU.Sky: 0.9662, IoU.Person: 0.3423, IoU.Rider: 0.0895, IoU.Car: 0.9144, IoU.background: 0.9616, Acc.Road: 0.9690, Acc.Sidewalk: 0.8163, Acc.Construction: 0.9436, Acc.Fence: 0.3781, Acc.Pole: 0.6861, Acc.Traffic Light: 0.8009, Acc.Traffic Sign: 0.8089, Acc.Nature: 0.9376, Acc.Sky: 0.9801, Acc.Person: 0.3699, Acc.Rider: 0.7227, Acc.Car: 0.9464, Acc.background: 0.9778
2023-09-29 12:57:23,888 - mmseg - INFO - Iter [32050/40000]	lr: 2.854e-07, eta: 6:58:37, time: 22.993, data_time: 20.765, memory: 21542, decode.loss_cls: 0.0446, decode.loss_mask: 0.2526, decode.loss_dice: 0.5160, decode.d0.loss_cls: 0.2123, decode.d0.loss_mask: 0.2528, decode.d0.loss_dice: 0.5494, decode.d1.loss_cls: 0.0507, decode.d1.loss_mask: 0.2530, decode.d1.loss_dice: 0.5238, decode.d2.loss_cls: 0.0704, decode.d2.loss_mask: 0.2535, decode.d2.loss_dice: 0.5321, decode.d3.loss_cls: 0.0550, decode.d3.loss_mask: 0.2526, decode.d3.loss_dice: 0.5120, decode.d4.loss_cls: 0.0611, decode.d4.loss_mask: 0.2527, decode.d4.loss_dice: 0.5204, decode.d5.loss_cls: 0.0753, decode.d5.loss_mask: 0.2517, decode.d5.loss_dice: 0.5280, decode.d6.loss_cls: 0.0400, decode.d6.loss_mask: 0.2529, decode.d6.loss_dice: 0.5261, decode.d7.loss_cls: 0.0544, decode.d7.loss_mask: 0.2537, decode.d7.loss_dice: 0.5286, decode.d8.loss_cls: 0.0528, decode.d8.loss_mask: 0.2533, decode.d8.loss_dice: 0.5183, loss: 8.5000
2023-09-29 12:59:16,922 - mmseg - INFO - Iter [32100/40000]	lr: 2.836e-07, eta: 6:55:48, time: 2.261, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0592, decode.loss_mask: 0.2456, decode.loss_dice: 0.5174, decode.d0.loss_cls: 0.1942, decode.d0.loss_mask: 0.2452, decode.d0.loss_dice: 0.5140, decode.d1.loss_cls: 0.0668, decode.d1.loss_mask: 0.2453, decode.d1.loss_dice: 0.5065, decode.d2.loss_cls: 0.0473, decode.d2.loss_mask: 0.2448, decode.d2.loss_dice: 0.5096, decode.d3.loss_cls: 0.0537, decode.d3.loss_mask: 0.2441, decode.d3.loss_dice: 0.5062, decode.d4.loss_cls: 0.0590, decode.d4.loss_mask: 0.2451, decode.d4.loss_dice: 0.5112, decode.d5.loss_cls: 0.0456, decode.d5.loss_mask: 0.2453, decode.d5.loss_dice: 0.5131, decode.d6.loss_cls: 0.0452, decode.d6.loss_mask: 0.2454, decode.d6.loss_dice: 0.5103, decode.d7.loss_cls: 0.0486, decode.d7.loss_mask: 0.2459, decode.d7.loss_dice: 0.5141, decode.d8.loss_cls: 0.0461, decode.d8.loss_mask: 0.2447, decode.d8.loss_dice: 0.5138, loss: 8.2332
2023-09-29 13:01:09,621 - mmseg - INFO - Iter [32150/40000]	lr: 2.818e-07, eta: 6:52:59, time: 2.254, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0412, decode.loss_mask: 0.2500, decode.loss_dice: 0.5125, decode.d0.loss_cls: 0.1906, decode.d0.loss_mask: 0.2553, decode.d0.loss_dice: 0.5280, decode.d1.loss_cls: 0.0706, decode.d1.loss_mask: 0.2505, decode.d1.loss_dice: 0.5250, decode.d2.loss_cls: 0.0562, decode.d2.loss_mask: 0.2510, decode.d2.loss_dice: 0.5210, decode.d3.loss_cls: 0.0486, decode.d3.loss_mask: 0.2496, decode.d3.loss_dice: 0.5184, decode.d4.loss_cls: 0.0462, decode.d4.loss_mask: 0.2507, decode.d4.loss_dice: 0.5257, decode.d5.loss_cls: 0.0419, decode.d5.loss_mask: 0.2507, decode.d5.loss_dice: 0.5214, decode.d6.loss_cls: 0.0574, decode.d6.loss_mask: 0.2504, decode.d6.loss_dice: 0.5123, decode.d7.loss_cls: 0.0510, decode.d7.loss_mask: 0.2506, decode.d7.loss_dice: 0.5249, decode.d8.loss_cls: 0.0500, decode.d8.loss_mask: 0.2506, decode.d8.loss_dice: 0.5212, loss: 8.3735
2023-09-29 13:03:02,659 - mmseg - INFO - Iter [32200/40000]	lr: 2.800e-07, eta: 6:50:10, time: 2.261, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0839, decode.loss_mask: 0.2896, decode.loss_dice: 0.5146, decode.d0.loss_cls: 0.2290, decode.d0.loss_mask: 0.2871, decode.d0.loss_dice: 0.5206, decode.d1.loss_cls: 0.0864, decode.d1.loss_mask: 0.2909, decode.d1.loss_dice: 0.5186, decode.d2.loss_cls: 0.0939, decode.d2.loss_mask: 0.2792, decode.d2.loss_dice: 0.5107, decode.d3.loss_cls: 0.0805, decode.d3.loss_mask: 0.2903, decode.d3.loss_dice: 0.5191, decode.d4.loss_cls: 0.0852, decode.d4.loss_mask: 0.2867, decode.d4.loss_dice: 0.5190, decode.d5.loss_cls: 0.0947, decode.d5.loss_mask: 0.2830, decode.d5.loss_dice: 0.5130, decode.d6.loss_cls: 0.0594, decode.d6.loss_mask: 0.2855, decode.d6.loss_dice: 0.5097, decode.d7.loss_cls: 0.0770, decode.d7.loss_mask: 0.2866, decode.d7.loss_dice: 0.5219, decode.d8.loss_cls: 0.0799, decode.d8.loss_mask: 0.2900, decode.d8.loss_dice: 0.5180, loss: 9.0038
2023-09-29 13:04:56,734 - mmseg - INFO - Iter [32250/40000]	lr: 2.782e-07, eta: 6:47:22, time: 2.281, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0635, decode.loss_mask: 0.2441, decode.loss_dice: 0.5256, decode.d0.loss_cls: 0.2075, decode.d0.loss_mask: 0.2512, decode.d0.loss_dice: 0.5427, decode.d1.loss_cls: 0.0599, decode.d1.loss_mask: 0.2436, decode.d1.loss_dice: 0.5280, decode.d2.loss_cls: 0.0614, decode.d2.loss_mask: 0.2442, decode.d2.loss_dice: 0.5220, decode.d3.loss_cls: 0.0391, decode.d3.loss_mask: 0.2469, decode.d3.loss_dice: 0.5239, decode.d4.loss_cls: 0.0432, decode.d4.loss_mask: 0.2439, decode.d4.loss_dice: 0.5183, decode.d5.loss_cls: 0.0386, decode.d5.loss_mask: 0.2435, decode.d5.loss_dice: 0.5291, decode.d6.loss_cls: 0.0615, decode.d6.loss_mask: 0.2432, decode.d6.loss_dice: 0.5216, decode.d7.loss_cls: 0.0536, decode.d7.loss_mask: 0.2443, decode.d7.loss_dice: 0.5192, decode.d8.loss_cls: 0.0498, decode.d8.loss_mask: 0.2434, decode.d8.loss_dice: 0.5144, loss: 8.3711
2023-09-29 13:06:49,810 - mmseg - INFO - Iter [32300/40000]	lr: 2.764e-07, eta: 6:44:33, time: 2.262, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0544, decode.loss_mask: 0.2600, decode.loss_dice: 0.5081, decode.d0.loss_cls: 0.2074, decode.d0.loss_mask: 0.2547, decode.d0.loss_dice: 0.5207, decode.d1.loss_cls: 0.0472, decode.d1.loss_mask: 0.2602, decode.d1.loss_dice: 0.5138, decode.d2.loss_cls: 0.0652, decode.d2.loss_mask: 0.2591, decode.d2.loss_dice: 0.5126, decode.d3.loss_cls: 0.0399, decode.d3.loss_mask: 0.2585, decode.d3.loss_dice: 0.5031, decode.d4.loss_cls: 0.0520, decode.d4.loss_mask: 0.2594, decode.d4.loss_dice: 0.5121, decode.d5.loss_cls: 0.0451, decode.d5.loss_mask: 0.2582, decode.d5.loss_dice: 0.5148, decode.d6.loss_cls: 0.0453, decode.d6.loss_mask: 0.2585, decode.d6.loss_dice: 0.5077, decode.d7.loss_cls: 0.0395, decode.d7.loss_mask: 0.2593, decode.d7.loss_dice: 0.5047, decode.d8.loss_cls: 0.0522, decode.d8.loss_mask: 0.2580, decode.d8.loss_dice: 0.5059, loss: 8.3375
2023-09-29 13:08:43,276 - mmseg - INFO - Iter [32350/40000]	lr: 2.746e-07, eta: 6:41:45, time: 2.269, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0597, decode.loss_mask: 0.2302, decode.loss_dice: 0.4618, decode.d0.loss_cls: 0.2040, decode.d0.loss_mask: 0.2327, decode.d0.loss_dice: 0.4690, decode.d1.loss_cls: 0.0797, decode.d1.loss_mask: 0.2307, decode.d1.loss_dice: 0.4638, decode.d2.loss_cls: 0.0578, decode.d2.loss_mask: 0.2300, decode.d2.loss_dice: 0.4580, decode.d3.loss_cls: 0.0443, decode.d3.loss_mask: 0.2294, decode.d3.loss_dice: 0.4613, decode.d4.loss_cls: 0.0606, decode.d4.loss_mask: 0.2302, decode.d4.loss_dice: 0.4551, decode.d5.loss_cls: 0.0700, decode.d5.loss_mask: 0.2299, decode.d5.loss_dice: 0.4545, decode.d6.loss_cls: 0.0454, decode.d6.loss_mask: 0.2304, decode.d6.loss_dice: 0.4564, decode.d7.loss_cls: 0.0526, decode.d7.loss_mask: 0.2300, decode.d7.loss_dice: 0.4587, decode.d8.loss_cls: 0.0515, decode.d8.loss_mask: 0.2310, decode.d8.loss_dice: 0.4548, loss: 7.6234
2023-09-29 13:10:36,703 - mmseg - INFO - Iter [32400/40000]	lr: 2.728e-07, eta: 6:38:58, time: 2.268, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0990, decode.loss_mask: 0.2815, decode.loss_dice: 0.5425, decode.d0.loss_cls: 0.2553, decode.d0.loss_mask: 0.2793, decode.d0.loss_dice: 0.5717, decode.d1.loss_cls: 0.1155, decode.d1.loss_mask: 0.2800, decode.d1.loss_dice: 0.5581, decode.d2.loss_cls: 0.1043, decode.d2.loss_mask: 0.2718, decode.d2.loss_dice: 0.5377, decode.d3.loss_cls: 0.0933, decode.d3.loss_mask: 0.2764, decode.d3.loss_dice: 0.5418, decode.d4.loss_cls: 0.1006, decode.d4.loss_mask: 0.2804, decode.d4.loss_dice: 0.5421, decode.d5.loss_cls: 0.0981, decode.d5.loss_mask: 0.2787, decode.d5.loss_dice: 0.5419, decode.d6.loss_cls: 0.0884, decode.d6.loss_mask: 0.2773, decode.d6.loss_dice: 0.5485, decode.d7.loss_cls: 0.1095, decode.d7.loss_mask: 0.2791, decode.d7.loss_dice: 0.5456, decode.d8.loss_cls: 0.1027, decode.d8.loss_mask: 0.2785, decode.d8.loss_dice: 0.5457, loss: 9.4252
2023-09-29 13:12:29,148 - mmseg - INFO - Iter [32450/40000]	lr: 2.710e-07, eta: 6:36:10, time: 2.249, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0531, decode.loss_mask: 0.2402, decode.loss_dice: 0.4894, decode.d0.loss_cls: 0.1941, decode.d0.loss_mask: 0.2437, decode.d0.loss_dice: 0.4975, decode.d1.loss_cls: 0.0530, decode.d1.loss_mask: 0.2444, decode.d1.loss_dice: 0.4952, decode.d2.loss_cls: 0.0589, decode.d2.loss_mask: 0.2388, decode.d2.loss_dice: 0.4804, decode.d3.loss_cls: 0.0549, decode.d3.loss_mask: 0.2384, decode.d3.loss_dice: 0.4832, decode.d4.loss_cls: 0.0392, decode.d4.loss_mask: 0.2457, decode.d4.loss_dice: 0.4949, decode.d5.loss_cls: 0.0588, decode.d5.loss_mask: 0.2380, decode.d5.loss_dice: 0.4955, decode.d6.loss_cls: 0.0513, decode.d6.loss_mask: 0.2383, decode.d6.loss_dice: 0.4902, decode.d7.loss_cls: 0.0433, decode.d7.loss_mask: 0.2387, decode.d7.loss_dice: 0.4887, decode.d8.loss_cls: 0.0530, decode.d8.loss_mask: 0.2402, decode.d8.loss_dice: 0.4875, loss: 7.9685
2023-09-29 13:14:22,187 - mmseg - INFO - Iter [32500/40000]	lr: 2.692e-07, eta: 6:33:22, time: 2.261, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0801, decode.loss_mask: 0.2319, decode.loss_dice: 0.5156, decode.d0.loss_cls: 0.2045, decode.d0.loss_mask: 0.2375, decode.d0.loss_dice: 0.5285, decode.d1.loss_cls: 0.0941, decode.d1.loss_mask: 0.2328, decode.d1.loss_dice: 0.5061, decode.d2.loss_cls: 0.0800, decode.d2.loss_mask: 0.2324, decode.d2.loss_dice: 0.4899, decode.d3.loss_cls: 0.0759, decode.d3.loss_mask: 0.2314, decode.d3.loss_dice: 0.5114, decode.d4.loss_cls: 0.0836, decode.d4.loss_mask: 0.2325, decode.d4.loss_dice: 0.5153, decode.d5.loss_cls: 0.0874, decode.d5.loss_mask: 0.2314, decode.d5.loss_dice: 0.5131, decode.d6.loss_cls: 0.0666, decode.d6.loss_mask: 0.2327, decode.d6.loss_dice: 0.5144, decode.d7.loss_cls: 0.0728, decode.d7.loss_mask: 0.2322, decode.d7.loss_dice: 0.5186, decode.d8.loss_cls: 0.0810, decode.d8.loss_mask: 0.2314, decode.d8.loss_dice: 0.4988, loss: 8.3638
2023-09-29 13:16:19,222 - mmseg - INFO - Iter [32550/40000]	lr: 2.675e-07, eta: 6:30:35, time: 2.341, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0625, decode.loss_mask: 0.2322, decode.loss_dice: 0.5104, decode.d0.loss_cls: 0.2035, decode.d0.loss_mask: 0.2352, decode.d0.loss_dice: 0.5298, decode.d1.loss_cls: 0.0809, decode.d1.loss_mask: 0.2315, decode.d1.loss_dice: 0.5070, decode.d2.loss_cls: 0.0655, decode.d2.loss_mask: 0.2321, decode.d2.loss_dice: 0.5110, decode.d3.loss_cls: 0.0715, decode.d3.loss_mask: 0.2313, decode.d3.loss_dice: 0.5005, decode.d4.loss_cls: 0.0630, decode.d4.loss_mask: 0.2315, decode.d4.loss_dice: 0.5061, decode.d5.loss_cls: 0.0630, decode.d5.loss_mask: 0.2313, decode.d5.loss_dice: 0.5080, decode.d6.loss_cls: 0.0853, decode.d6.loss_mask: 0.2306, decode.d6.loss_dice: 0.5063, decode.d7.loss_cls: 0.0682, decode.d7.loss_mask: 0.2319, decode.d7.loss_dice: 0.5040, decode.d8.loss_cls: 0.0658, decode.d8.loss_mask: 0.2316, decode.d8.loss_dice: 0.5070, loss: 8.2386
2023-09-29 13:18:11,625 - mmseg - INFO - Iter [32600/40000]	lr: 2.657e-07, eta: 6:27:48, time: 2.248, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0646, decode.loss_mask: 0.2659, decode.loss_dice: 0.5088, decode.d0.loss_cls: 0.2291, decode.d0.loss_mask: 0.2673, decode.d0.loss_dice: 0.5366, decode.d1.loss_cls: 0.0934, decode.d1.loss_mask: 0.2657, decode.d1.loss_dice: 0.5212, decode.d2.loss_cls: 0.0603, decode.d2.loss_mask: 0.2655, decode.d2.loss_dice: 0.5209, decode.d3.loss_cls: 0.0538, decode.d3.loss_mask: 0.2650, decode.d3.loss_dice: 0.5196, decode.d4.loss_cls: 0.0834, decode.d4.loss_mask: 0.2654, decode.d4.loss_dice: 0.5037, decode.d5.loss_cls: 0.0676, decode.d5.loss_mask: 0.2673, decode.d5.loss_dice: 0.5134, decode.d6.loss_cls: 0.0665, decode.d6.loss_mask: 0.2664, decode.d6.loss_dice: 0.5109, decode.d7.loss_cls: 0.0597, decode.d7.loss_mask: 0.2666, decode.d7.loss_dice: 0.5113, decode.d8.loss_cls: 0.0896, decode.d8.loss_mask: 0.2652, decode.d8.loss_dice: 0.5095, loss: 8.6844
2023-09-29 13:20:04,234 - mmseg - INFO - Iter [32650/40000]	lr: 2.639e-07, eta: 6:25:01, time: 2.252, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0560, decode.loss_mask: 0.2402, decode.loss_dice: 0.5097, decode.d0.loss_cls: 0.2270, decode.d0.loss_mask: 0.2420, decode.d0.loss_dice: 0.5237, decode.d1.loss_cls: 0.0905, decode.d1.loss_mask: 0.2407, decode.d1.loss_dice: 0.5071, decode.d2.loss_cls: 0.0748, decode.d2.loss_mask: 0.2404, decode.d2.loss_dice: 0.5007, decode.d3.loss_cls: 0.0812, decode.d3.loss_mask: 0.2394, decode.d3.loss_dice: 0.4993, decode.d4.loss_cls: 0.0818, decode.d4.loss_mask: 0.2398, decode.d4.loss_dice: 0.5122, decode.d5.loss_cls: 0.0702, decode.d5.loss_mask: 0.2401, decode.d5.loss_dice: 0.5053, decode.d6.loss_cls: 0.0690, decode.d6.loss_mask: 0.2409, decode.d6.loss_dice: 0.5061, decode.d7.loss_cls: 0.0620, decode.d7.loss_mask: 0.2398, decode.d7.loss_dice: 0.4991, decode.d8.loss_cls: 0.0526, decode.d8.loss_mask: 0.2397, decode.d8.loss_dice: 0.5029, loss: 8.3342
2023-09-29 13:21:57,165 - mmseg - INFO - Iter [32700/40000]	lr: 2.621e-07, eta: 6:22:14, time: 2.259, data_time: 0.026, memory: 21542, decode.loss_cls: 0.0456, decode.loss_mask: 0.2379, decode.loss_dice: 0.5011, decode.d0.loss_cls: 0.2107, decode.d0.loss_mask: 0.2393, decode.d0.loss_dice: 0.5222, decode.d1.loss_cls: 0.0446, decode.d1.loss_mask: 0.2389, decode.d1.loss_dice: 0.5109, decode.d2.loss_cls: 0.0420, decode.d2.loss_mask: 0.2389, decode.d2.loss_dice: 0.4991, decode.d3.loss_cls: 0.0503, decode.d3.loss_mask: 0.2386, decode.d3.loss_dice: 0.5036, decode.d4.loss_cls: 0.0476, decode.d4.loss_mask: 0.2380, decode.d4.loss_dice: 0.5040, decode.d5.loss_cls: 0.0509, decode.d5.loss_mask: 0.2385, decode.d5.loss_dice: 0.4949, decode.d6.loss_cls: 0.0533, decode.d6.loss_mask: 0.2395, decode.d6.loss_dice: 0.5005, decode.d7.loss_cls: 0.0522, decode.d7.loss_mask: 0.2389, decode.d7.loss_dice: 0.4940, decode.d8.loss_cls: 0.0392, decode.d8.loss_mask: 0.2393, decode.d8.loss_dice: 0.5096, loss: 8.0639
2023-09-29 13:23:49,358 - mmseg - INFO - Iter [32750/40000]	lr: 2.603e-07, eta: 6:19:27, time: 2.244, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0576, decode.loss_mask: 0.2529, decode.loss_dice: 0.5180, decode.d0.loss_cls: 0.2099, decode.d0.loss_mask: 0.2561, decode.d0.loss_dice: 0.5470, decode.d1.loss_cls: 0.0611, decode.d1.loss_mask: 0.2564, decode.d1.loss_dice: 0.5268, decode.d2.loss_cls: 0.0753, decode.d2.loss_mask: 0.2541, decode.d2.loss_dice: 0.5275, decode.d3.loss_cls: 0.0417, decode.d3.loss_mask: 0.2547, decode.d3.loss_dice: 0.5155, decode.d4.loss_cls: 0.0590, decode.d4.loss_mask: 0.2559, decode.d4.loss_dice: 0.5151, decode.d5.loss_cls: 0.0455, decode.d5.loss_mask: 0.2539, decode.d5.loss_dice: 0.5227, decode.d6.loss_cls: 0.0483, decode.d6.loss_mask: 0.2539, decode.d6.loss_dice: 0.5225, decode.d7.loss_cls: 0.0609, decode.d7.loss_mask: 0.2547, decode.d7.loss_dice: 0.5174, decode.d8.loss_cls: 0.0560, decode.d8.loss_mask: 0.2538, decode.d8.loss_dice: 0.5215, loss: 8.4957
2023-09-29 13:25:41,424 - mmseg - INFO - Iter [32800/40000]	lr: 2.585e-07, eta: 6:16:40, time: 2.241, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0564, decode.loss_mask: 0.2791, decode.loss_dice: 0.5440, decode.d0.loss_cls: 0.2346, decode.d0.loss_mask: 0.2864, decode.d0.loss_dice: 0.5546, decode.d1.loss_cls: 0.0735, decode.d1.loss_mask: 0.2816, decode.d1.loss_dice: 0.5461, decode.d2.loss_cls: 0.0713, decode.d2.loss_mask: 0.2786, decode.d2.loss_dice: 0.5280, decode.d3.loss_cls: 0.0667, decode.d3.loss_mask: 0.2799, decode.d3.loss_dice: 0.5412, decode.d4.loss_cls: 0.0860, decode.d4.loss_mask: 0.2785, decode.d4.loss_dice: 0.5334, decode.d5.loss_cls: 0.0642, decode.d5.loss_mask: 0.2782, decode.d5.loss_dice: 0.5343, decode.d6.loss_cls: 0.0644, decode.d6.loss_mask: 0.2788, decode.d6.loss_dice: 0.5352, decode.d7.loss_cls: 0.0867, decode.d7.loss_mask: 0.2796, decode.d7.loss_dice: 0.5377, decode.d8.loss_cls: 0.0509, decode.d8.loss_mask: 0.2807, decode.d8.loss_dice: 0.5488, loss: 9.0595
2023-09-29 13:27:34,725 - mmseg - INFO - Iter [32850/40000]	lr: 2.567e-07, eta: 6:13:53, time: 2.266, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0666, decode.loss_mask: 0.2693, decode.loss_dice: 0.5018, decode.d0.loss_cls: 0.2219, decode.d0.loss_mask: 0.2715, decode.d0.loss_dice: 0.5007, decode.d1.loss_cls: 0.0593, decode.d1.loss_mask: 0.2680, decode.d1.loss_dice: 0.4954, decode.d2.loss_cls: 0.0715, decode.d2.loss_mask: 0.2663, decode.d2.loss_dice: 0.4917, decode.d3.loss_cls: 0.0691, decode.d3.loss_mask: 0.2701, decode.d3.loss_dice: 0.5007, decode.d4.loss_cls: 0.0508, decode.d4.loss_mask: 0.2689, decode.d4.loss_dice: 0.4956, decode.d5.loss_cls: 0.0688, decode.d5.loss_mask: 0.2683, decode.d5.loss_dice: 0.4915, decode.d6.loss_cls: 0.0529, decode.d6.loss_mask: 0.2681, decode.d6.loss_dice: 0.4824, decode.d7.loss_cls: 0.0637, decode.d7.loss_mask: 0.2674, decode.d7.loss_dice: 0.4969, decode.d8.loss_cls: 0.0562, decode.d8.loss_mask: 0.2696, decode.d8.loss_dice: 0.4961, loss: 8.4212
2023-09-29 13:29:28,448 - mmseg - INFO - Iter [32900/40000]	lr: 2.549e-07, eta: 6:11:07, time: 2.275, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0542, decode.loss_mask: 0.2479, decode.loss_dice: 0.5227, decode.d0.loss_cls: 0.2327, decode.d0.loss_mask: 0.2530, decode.d0.loss_dice: 0.5492, decode.d1.loss_cls: 0.0756, decode.d1.loss_mask: 0.2488, decode.d1.loss_dice: 0.5280, decode.d2.loss_cls: 0.0826, decode.d2.loss_mask: 0.2477, decode.d2.loss_dice: 0.5232, decode.d3.loss_cls: 0.0499, decode.d3.loss_mask: 0.2488, decode.d3.loss_dice: 0.5194, decode.d4.loss_cls: 0.0602, decode.d4.loss_mask: 0.2490, decode.d4.loss_dice: 0.5163, decode.d5.loss_cls: 0.0748, decode.d5.loss_mask: 0.2488, decode.d5.loss_dice: 0.5190, decode.d6.loss_cls: 0.0625, decode.d6.loss_mask: 0.2479, decode.d6.loss_dice: 0.5320, decode.d7.loss_cls: 0.0576, decode.d7.loss_mask: 0.2475, decode.d7.loss_dice: 0.5161, decode.d8.loss_cls: 0.0629, decode.d8.loss_mask: 0.2462, decode.d8.loss_dice: 0.5271, loss: 8.5513
2023-09-29 13:31:23,034 - mmseg - INFO - Iter [32950/40000]	lr: 2.531e-07, eta: 6:08:21, time: 2.292, data_time: 0.074, memory: 21542, decode.loss_cls: 0.0503, decode.loss_mask: 0.2692, decode.loss_dice: 0.4998, decode.d0.loss_cls: 0.1920, decode.d0.loss_mask: 0.2701, decode.d0.loss_dice: 0.5222, decode.d1.loss_cls: 0.0644, decode.d1.loss_mask: 0.2680, decode.d1.loss_dice: 0.5127, decode.d2.loss_cls: 0.0521, decode.d2.loss_mask: 0.2684, decode.d2.loss_dice: 0.5030, decode.d3.loss_cls: 0.0490, decode.d3.loss_mask: 0.2688, decode.d3.loss_dice: 0.5116, decode.d4.loss_cls: 0.0455, decode.d4.loss_mask: 0.2684, decode.d4.loss_dice: 0.5035, decode.d5.loss_cls: 0.0520, decode.d5.loss_mask: 0.2696, decode.d5.loss_dice: 0.5127, decode.d6.loss_cls: 0.0551, decode.d6.loss_mask: 0.2681, decode.d6.loss_dice: 0.5058, decode.d7.loss_cls: 0.0482, decode.d7.loss_mask: 0.2697, decode.d7.loss_dice: 0.5083, decode.d8.loss_cls: 0.0379, decode.d8.loss_mask: 0.2674, decode.d8.loss_dice: 0.5058, loss: 8.4196
2023-09-29 13:33:16,407 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 13:33:16,408 - mmseg - INFO - Iter [33000/40000]	lr: 2.513e-07, eta: 6:05:35, time: 2.267, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0373, decode.loss_mask: 0.2601, decode.loss_dice: 0.5044, decode.d0.loss_cls: 0.2070, decode.d0.loss_mask: 0.2632, decode.d0.loss_dice: 0.5102, decode.d1.loss_cls: 0.0720, decode.d1.loss_mask: 0.2614, decode.d1.loss_dice: 0.5061, decode.d2.loss_cls: 0.0539, decode.d2.loss_mask: 0.2598, decode.d2.loss_dice: 0.5088, decode.d3.loss_cls: 0.0358, decode.d3.loss_mask: 0.2599, decode.d3.loss_dice: 0.4995, decode.d4.loss_cls: 0.0481, decode.d4.loss_mask: 0.2596, decode.d4.loss_dice: 0.5145, decode.d5.loss_cls: 0.0386, decode.d5.loss_mask: 0.2609, decode.d5.loss_dice: 0.5073, decode.d6.loss_cls: 0.0393, decode.d6.loss_mask: 0.2599, decode.d6.loss_dice: 0.5116, decode.d7.loss_cls: 0.0470, decode.d7.loss_mask: 0.2607, decode.d7.loss_dice: 0.5052, decode.d8.loss_cls: 0.0550, decode.d8.loss_mask: 0.2601, decode.d8.loss_dice: 0.5067, loss: 8.3141
2023-09-29 13:35:09,685 - mmseg - INFO - Iter [33050/40000]	lr: 2.495e-07, eta: 6:02:49, time: 2.266, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0258, decode.loss_mask: 0.2120, decode.loss_dice: 0.4652, decode.d0.loss_cls: 0.1876, decode.d0.loss_mask: 0.2110, decode.d0.loss_dice: 0.4735, decode.d1.loss_cls: 0.0451, decode.d1.loss_mask: 0.2128, decode.d1.loss_dice: 0.4679, decode.d2.loss_cls: 0.0352, decode.d2.loss_mask: 0.2104, decode.d2.loss_dice: 0.4676, decode.d3.loss_cls: 0.0237, decode.d3.loss_mask: 0.2130, decode.d3.loss_dice: 0.4712, decode.d4.loss_cls: 0.0259, decode.d4.loss_mask: 0.2121, decode.d4.loss_dice: 0.4691, decode.d5.loss_cls: 0.0254, decode.d5.loss_mask: 0.2129, decode.d5.loss_dice: 0.4713, decode.d6.loss_cls: 0.0230, decode.d6.loss_mask: 0.2121, decode.d6.loss_dice: 0.4619, decode.d7.loss_cls: 0.0224, decode.d7.loss_mask: 0.2123, decode.d7.loss_dice: 0.4680, decode.d8.loss_cls: 0.0419, decode.d8.loss_mask: 0.2132, decode.d8.loss_dice: 0.4731, loss: 7.2665
2023-09-29 13:37:02,979 - mmseg - INFO - Iter [33100/40000]	lr: 2.477e-07, eta: 6:00:04, time: 2.266, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0869, decode.loss_mask: 0.2555, decode.loss_dice: 0.5050, decode.d0.loss_cls: 0.2142, decode.d0.loss_mask: 0.2573, decode.d0.loss_dice: 0.5222, decode.d1.loss_cls: 0.0633, decode.d1.loss_mask: 0.2571, decode.d1.loss_dice: 0.5241, decode.d2.loss_cls: 0.0748, decode.d2.loss_mask: 0.2563, decode.d2.loss_dice: 0.5166, decode.d3.loss_cls: 0.0762, decode.d3.loss_mask: 0.2553, decode.d3.loss_dice: 0.5023, decode.d4.loss_cls: 0.0594, decode.d4.loss_mask: 0.2566, decode.d4.loss_dice: 0.5174, decode.d5.loss_cls: 0.0586, decode.d5.loss_mask: 0.2565, decode.d5.loss_dice: 0.5112, decode.d6.loss_cls: 0.0594, decode.d6.loss_mask: 0.2555, decode.d6.loss_dice: 0.5072, decode.d7.loss_cls: 0.0906, decode.d7.loss_mask: 0.2554, decode.d7.loss_dice: 0.4960, decode.d8.loss_cls: 0.0558, decode.d8.loss_mask: 0.2568, decode.d8.loss_dice: 0.5070, loss: 8.5105
2023-09-29 13:38:56,704 - mmseg - INFO - Iter [33150/40000]	lr: 2.459e-07, eta: 5:57:18, time: 2.274, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0501, decode.loss_mask: 0.2430, decode.loss_dice: 0.5211, decode.d0.loss_cls: 0.2288, decode.d0.loss_mask: 0.2437, decode.d0.loss_dice: 0.5200, decode.d1.loss_cls: 0.0939, decode.d1.loss_mask: 0.2424, decode.d1.loss_dice: 0.5113, decode.d2.loss_cls: 0.0597, decode.d2.loss_mask: 0.2420, decode.d2.loss_dice: 0.5139, decode.d3.loss_cls: 0.0594, decode.d3.loss_mask: 0.2420, decode.d3.loss_dice: 0.5154, decode.d4.loss_cls: 0.0667, decode.d4.loss_mask: 0.2422, decode.d4.loss_dice: 0.5059, decode.d5.loss_cls: 0.0693, decode.d5.loss_mask: 0.2416, decode.d5.loss_dice: 0.5170, decode.d6.loss_cls: 0.0555, decode.d6.loss_mask: 0.2423, decode.d6.loss_dice: 0.5181, decode.d7.loss_cls: 0.0592, decode.d7.loss_mask: 0.2418, decode.d7.loss_dice: 0.5061, decode.d8.loss_cls: 0.0859, decode.d8.loss_mask: 0.2429, decode.d8.loss_dice: 0.5180, loss: 8.3991
2023-09-29 13:40:49,359 - mmseg - INFO - Iter [33200/40000]	lr: 2.441e-07, eta: 5:54:33, time: 2.253, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0932, decode.loss_mask: 0.2413, decode.loss_dice: 0.5168, decode.d0.loss_cls: 0.2190, decode.d0.loss_mask: 0.2480, decode.d0.loss_dice: 0.5373, decode.d1.loss_cls: 0.0876, decode.d1.loss_mask: 0.2427, decode.d1.loss_dice: 0.5276, decode.d2.loss_cls: 0.0898, decode.d2.loss_mask: 0.2414, decode.d2.loss_dice: 0.5109, decode.d3.loss_cls: 0.0685, decode.d3.loss_mask: 0.2421, decode.d3.loss_dice: 0.5162, decode.d4.loss_cls: 0.0940, decode.d4.loss_mask: 0.2415, decode.d4.loss_dice: 0.5247, decode.d5.loss_cls: 0.0710, decode.d5.loss_mask: 0.2416, decode.d5.loss_dice: 0.5135, decode.d6.loss_cls: 0.0706, decode.d6.loss_mask: 0.2412, decode.d6.loss_dice: 0.5254, decode.d7.loss_cls: 0.0708, decode.d7.loss_mask: 0.2427, decode.d7.loss_dice: 0.5288, decode.d8.loss_cls: 0.0779, decode.d8.loss_mask: 0.2420, decode.d8.loss_dice: 0.5168, loss: 8.5848
2023-09-29 13:42:42,342 - mmseg - INFO - Iter [33250/40000]	lr: 2.423e-07, eta: 5:51:48, time: 2.260, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0453, decode.loss_mask: 0.2251, decode.loss_dice: 0.4794, decode.d0.loss_cls: 0.2156, decode.d0.loss_mask: 0.2285, decode.d0.loss_dice: 0.4959, decode.d1.loss_cls: 0.0747, decode.d1.loss_mask: 0.2272, decode.d1.loss_dice: 0.4787, decode.d2.loss_cls: 0.0366, decode.d2.loss_mask: 0.2263, decode.d2.loss_dice: 0.4804, decode.d3.loss_cls: 0.0595, decode.d3.loss_mask: 0.2251, decode.d3.loss_dice: 0.4798, decode.d4.loss_cls: 0.0462, decode.d4.loss_mask: 0.2254, decode.d4.loss_dice: 0.4820, decode.d5.loss_cls: 0.0533, decode.d5.loss_mask: 0.2257, decode.d5.loss_dice: 0.4774, decode.d6.loss_cls: 0.0554, decode.d6.loss_mask: 0.2249, decode.d6.loss_dice: 0.4820, decode.d7.loss_cls: 0.0426, decode.d7.loss_mask: 0.2261, decode.d7.loss_dice: 0.4878, decode.d8.loss_cls: 0.0384, decode.d8.loss_mask: 0.2257, decode.d8.loss_dice: 0.4761, loss: 7.7470
2023-09-29 13:44:35,222 - mmseg - INFO - Iter [33300/40000]	lr: 2.405e-07, eta: 5:49:03, time: 2.258, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0639, decode.loss_mask: 0.2308, decode.loss_dice: 0.5152, decode.d0.loss_cls: 0.2109, decode.d0.loss_mask: 0.2339, decode.d0.loss_dice: 0.5233, decode.d1.loss_cls: 0.0859, decode.d1.loss_mask: 0.2287, decode.d1.loss_dice: 0.5198, decode.d2.loss_cls: 0.0825, decode.d2.loss_mask: 0.2318, decode.d2.loss_dice: 0.5193, decode.d3.loss_cls: 0.0576, decode.d3.loss_mask: 0.2303, decode.d3.loss_dice: 0.5087, decode.d4.loss_cls: 0.0564, decode.d4.loss_mask: 0.2301, decode.d4.loss_dice: 0.5203, decode.d5.loss_cls: 0.0612, decode.d5.loss_mask: 0.2312, decode.d5.loss_dice: 0.5215, decode.d6.loss_cls: 0.0519, decode.d6.loss_mask: 0.2309, decode.d6.loss_dice: 0.5186, decode.d7.loss_cls: 0.0532, decode.d7.loss_mask: 0.2301, decode.d7.loss_dice: 0.5159, decode.d8.loss_cls: 0.0692, decode.d8.loss_mask: 0.2306, decode.d8.loss_dice: 0.5210, loss: 8.2846
2023-09-29 13:46:28,046 - mmseg - INFO - Iter [33350/40000]	lr: 2.387e-07, eta: 5:46:18, time: 2.257, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0813, decode.loss_mask: 0.2928, decode.loss_dice: 0.5367, decode.d0.loss_cls: 0.2303, decode.d0.loss_mask: 0.3014, decode.d0.loss_dice: 0.5702, decode.d1.loss_cls: 0.1301, decode.d1.loss_mask: 0.2950, decode.d1.loss_dice: 0.5444, decode.d2.loss_cls: 0.0787, decode.d2.loss_mask: 0.2967, decode.d2.loss_dice: 0.5471, decode.d3.loss_cls: 0.0790, decode.d3.loss_mask: 0.2952, decode.d3.loss_dice: 0.5416, decode.d4.loss_cls: 0.0868, decode.d4.loss_mask: 0.2974, decode.d4.loss_dice: 0.5489, decode.d5.loss_cls: 0.1042, decode.d5.loss_mask: 0.2947, decode.d5.loss_dice: 0.5459, decode.d6.loss_cls: 0.0807, decode.d6.loss_mask: 0.2946, decode.d6.loss_dice: 0.5480, decode.d7.loss_cls: 0.0879, decode.d7.loss_mask: 0.2925, decode.d7.loss_dice: 0.5489, decode.d8.loss_cls: 0.0818, decode.d8.loss_mask: 0.2934, decode.d8.loss_dice: 0.5513, loss: 9.4773
2023-09-29 13:48:21,156 - mmseg - INFO - Iter [33400/40000]	lr: 2.369e-07, eta: 5:43:33, time: 2.262, data_time: 0.023, memory: 21542, decode.loss_cls: 0.0766, decode.loss_mask: 0.2573, decode.loss_dice: 0.5544, decode.d0.loss_cls: 0.2780, decode.d0.loss_mask: 0.2617, decode.d0.loss_dice: 0.5708, decode.d1.loss_cls: 0.0963, decode.d1.loss_mask: 0.2561, decode.d1.loss_dice: 0.5612, decode.d2.loss_cls: 0.0735, decode.d2.loss_mask: 0.2582, decode.d2.loss_dice: 0.5426, decode.d3.loss_cls: 0.0729, decode.d3.loss_mask: 0.2568, decode.d3.loss_dice: 0.5585, decode.d4.loss_cls: 0.0840, decode.d4.loss_mask: 0.2585, decode.d4.loss_dice: 0.5529, decode.d5.loss_cls: 0.0706, decode.d5.loss_mask: 0.2591, decode.d5.loss_dice: 0.5572, decode.d6.loss_cls: 0.0897, decode.d6.loss_mask: 0.2582, decode.d6.loss_dice: 0.5569, decode.d7.loss_cls: 0.0748, decode.d7.loss_mask: 0.2580, decode.d7.loss_dice: 0.5524, decode.d8.loss_cls: 0.0912, decode.d8.loss_mask: 0.2571, decode.d8.loss_dice: 0.5463, loss: 9.1417
2023-09-29 13:50:14,493 - mmseg - INFO - Iter [33450/40000]	lr: 2.351e-07, eta: 5:40:48, time: 2.267, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0814, decode.loss_mask: 0.2327, decode.loss_dice: 0.5308, decode.d0.loss_cls: 0.2480, decode.d0.loss_mask: 0.2327, decode.d0.loss_dice: 0.5513, decode.d1.loss_cls: 0.0895, decode.d1.loss_mask: 0.2320, decode.d1.loss_dice: 0.5329, decode.d2.loss_cls: 0.1051, decode.d2.loss_mask: 0.2311, decode.d2.loss_dice: 0.5268, decode.d3.loss_cls: 0.0884, decode.d3.loss_mask: 0.2308, decode.d3.loss_dice: 0.5360, decode.d4.loss_cls: 0.1028, decode.d4.loss_mask: 0.2293, decode.d4.loss_dice: 0.5189, decode.d5.loss_cls: 0.0828, decode.d5.loss_mask: 0.2307, decode.d5.loss_dice: 0.5258, decode.d6.loss_cls: 0.0962, decode.d6.loss_mask: 0.2317, decode.d6.loss_dice: 0.5388, decode.d7.loss_cls: 0.0820, decode.d7.loss_mask: 0.2307, decode.d7.loss_dice: 0.5181, decode.d8.loss_cls: 0.0759, decode.d8.loss_mask: 0.2319, decode.d8.loss_dice: 0.5362, loss: 8.6813
2023-09-29 13:52:06,744 - mmseg - INFO - Iter [33500/40000]	lr: 2.334e-07, eta: 5:38:04, time: 2.245, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0698, decode.loss_mask: 0.2447, decode.loss_dice: 0.5075, decode.d0.loss_cls: 0.2386, decode.d0.loss_mask: 0.2523, decode.d0.loss_dice: 0.5188, decode.d1.loss_cls: 0.0719, decode.d1.loss_mask: 0.2474, decode.d1.loss_dice: 0.5186, decode.d2.loss_cls: 0.0700, decode.d2.loss_mask: 0.2462, decode.d2.loss_dice: 0.5131, decode.d3.loss_cls: 0.0670, decode.d3.loss_mask: 0.2452, decode.d3.loss_dice: 0.5059, decode.d4.loss_cls: 0.0694, decode.d4.loss_mask: 0.2480, decode.d4.loss_dice: 0.5159, decode.d5.loss_cls: 0.0776, decode.d5.loss_mask: 0.2451, decode.d5.loss_dice: 0.5107, decode.d6.loss_cls: 0.0730, decode.d6.loss_mask: 0.2465, decode.d6.loss_dice: 0.5110, decode.d7.loss_cls: 0.0679, decode.d7.loss_mask: 0.2467, decode.d7.loss_dice: 0.5029, decode.d8.loss_cls: 0.0573, decode.d8.loss_mask: 0.2472, decode.d8.loss_dice: 0.4949, loss: 8.4311
2023-09-29 13:53:59,502 - mmseg - INFO - Iter [33550/40000]	lr: 2.316e-07, eta: 5:35:19, time: 2.255, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0594, decode.loss_mask: 0.2640, decode.loss_dice: 0.5656, decode.d0.loss_cls: 0.2421, decode.d0.loss_mask: 0.2666, decode.d0.loss_dice: 0.5522, decode.d1.loss_cls: 0.0856, decode.d1.loss_mask: 0.2638, decode.d1.loss_dice: 0.5407, decode.d2.loss_cls: 0.0655, decode.d2.loss_mask: 0.2629, decode.d2.loss_dice: 0.5514, decode.d3.loss_cls: 0.0747, decode.d3.loss_mask: 0.2636, decode.d3.loss_dice: 0.5513, decode.d4.loss_cls: 0.0833, decode.d4.loss_mask: 0.2627, decode.d4.loss_dice: 0.5531, decode.d5.loss_cls: 0.0705, decode.d5.loss_mask: 0.2646, decode.d5.loss_dice: 0.5537, decode.d6.loss_cls: 0.0738, decode.d6.loss_mask: 0.2637, decode.d6.loss_dice: 0.5478, decode.d7.loss_cls: 0.0709, decode.d7.loss_mask: 0.2641, decode.d7.loss_dice: 0.5542, decode.d8.loss_cls: 0.0836, decode.d8.loss_mask: 0.2635, decode.d8.loss_dice: 0.5483, loss: 9.0672
2023-09-29 13:55:52,594 - mmseg - INFO - Iter [33600/40000]	lr: 2.298e-07, eta: 5:32:35, time: 2.262, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0695, decode.loss_mask: 0.2771, decode.loss_dice: 0.5140, decode.d0.loss_cls: 0.2004, decode.d0.loss_mask: 0.2960, decode.d0.loss_dice: 0.5304, decode.d1.loss_cls: 0.0831, decode.d1.loss_mask: 0.2929, decode.d1.loss_dice: 0.5242, decode.d2.loss_cls: 0.0609, decode.d2.loss_mask: 0.2940, decode.d2.loss_dice: 0.5136, decode.d3.loss_cls: 0.0625, decode.d3.loss_mask: 0.2912, decode.d3.loss_dice: 0.5170, decode.d4.loss_cls: 0.0556, decode.d4.loss_mask: 0.2920, decode.d4.loss_dice: 0.5173, decode.d5.loss_cls: 0.0641, decode.d5.loss_mask: 0.2905, decode.d5.loss_dice: 0.5128, decode.d6.loss_cls: 0.0666, decode.d6.loss_mask: 0.2856, decode.d6.loss_dice: 0.5123, decode.d7.loss_cls: 0.0601, decode.d7.loss_mask: 0.2931, decode.d7.loss_dice: 0.5162, decode.d8.loss_cls: 0.0775, decode.d8.loss_mask: 0.2843, decode.d8.loss_dice: 0.5159, loss: 8.8707
2023-09-29 13:57:44,907 - mmseg - INFO - Iter [33650/40000]	lr: 2.280e-07, eta: 5:29:51, time: 2.246, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0533, decode.loss_mask: 0.2718, decode.loss_dice: 0.5642, decode.d0.loss_cls: 0.2296, decode.d0.loss_mask: 0.2767, decode.d0.loss_dice: 0.5643, decode.d1.loss_cls: 0.0563, decode.d1.loss_mask: 0.2728, decode.d1.loss_dice: 0.5608, decode.d2.loss_cls: 0.0535, decode.d2.loss_mask: 0.2710, decode.d2.loss_dice: 0.5448, decode.d3.loss_cls: 0.0577, decode.d3.loss_mask: 0.2715, decode.d3.loss_dice: 0.5498, decode.d4.loss_cls: 0.0585, decode.d4.loss_mask: 0.2725, decode.d4.loss_dice: 0.5619, decode.d5.loss_cls: 0.0665, decode.d5.loss_mask: 0.2714, decode.d5.loss_dice: 0.5476, decode.d6.loss_cls: 0.0548, decode.d6.loss_mask: 0.2705, decode.d6.loss_dice: 0.5445, decode.d7.loss_cls: 0.0637, decode.d7.loss_mask: 0.2705, decode.d7.loss_dice: 0.5502, decode.d8.loss_cls: 0.0700, decode.d8.loss_mask: 0.2724, decode.d8.loss_dice: 0.5537, loss: 9.0268
2023-09-29 13:59:38,190 - mmseg - INFO - Iter [33700/40000]	lr: 2.262e-07, eta: 5:27:07, time: 2.266, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0537, decode.loss_mask: 0.2537, decode.loss_dice: 0.5178, decode.d0.loss_cls: 0.2074, decode.d0.loss_mask: 0.2588, decode.d0.loss_dice: 0.5229, decode.d1.loss_cls: 0.0664, decode.d1.loss_mask: 0.2546, decode.d1.loss_dice: 0.5133, decode.d2.loss_cls: 0.0573, decode.d2.loss_mask: 0.2543, decode.d2.loss_dice: 0.5085, decode.d3.loss_cls: 0.0426, decode.d3.loss_mask: 0.2532, decode.d3.loss_dice: 0.5205, decode.d4.loss_cls: 0.0448, decode.d4.loss_mask: 0.2524, decode.d4.loss_dice: 0.5196, decode.d5.loss_cls: 0.0616, decode.d5.loss_mask: 0.2531, decode.d5.loss_dice: 0.5050, decode.d6.loss_cls: 0.0428, decode.d6.loss_mask: 0.2538, decode.d6.loss_dice: 0.5219, decode.d7.loss_cls: 0.0547, decode.d7.loss_mask: 0.2522, decode.d7.loss_dice: 0.5140, decode.d8.loss_cls: 0.0572, decode.d8.loss_mask: 0.2540, decode.d8.loss_dice: 0.5254, loss: 8.3974
2023-09-29 14:01:31,753 - mmseg - INFO - Iter [33750/40000]	lr: 2.244e-07, eta: 5:24:24, time: 2.271, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0865, decode.loss_mask: 0.2542, decode.loss_dice: 0.5215, decode.d0.loss_cls: 0.2086, decode.d0.loss_mask: 0.2556, decode.d0.loss_dice: 0.5393, decode.d1.loss_cls: 0.0940, decode.d1.loss_mask: 0.2524, decode.d1.loss_dice: 0.5240, decode.d2.loss_cls: 0.0950, decode.d2.loss_mask: 0.2532, decode.d2.loss_dice: 0.5175, decode.d3.loss_cls: 0.1138, decode.d3.loss_mask: 0.2545, decode.d3.loss_dice: 0.5287, decode.d4.loss_cls: 0.1022, decode.d4.loss_mask: 0.2539, decode.d4.loss_dice: 0.5204, decode.d5.loss_cls: 0.0951, decode.d5.loss_mask: 0.2541, decode.d5.loss_dice: 0.5234, decode.d6.loss_cls: 0.0760, decode.d6.loss_mask: 0.2531, decode.d6.loss_dice: 0.5237, decode.d7.loss_cls: 0.1055, decode.d7.loss_mask: 0.2547, decode.d7.loss_dice: 0.5262, decode.d8.loss_cls: 0.1005, decode.d8.loss_mask: 0.2554, decode.d8.loss_dice: 0.5277, loss: 8.8707
2023-09-29 14:03:25,099 - mmseg - INFO - Iter [33800/40000]	lr: 2.226e-07, eta: 5:21:40, time: 2.267, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0376, decode.loss_mask: 0.2279, decode.loss_dice: 0.4946, decode.d0.loss_cls: 0.2020, decode.d0.loss_mask: 0.2298, decode.d0.loss_dice: 0.5067, decode.d1.loss_cls: 0.0440, decode.d1.loss_mask: 0.2284, decode.d1.loss_dice: 0.5028, decode.d2.loss_cls: 0.0371, decode.d2.loss_mask: 0.2292, decode.d2.loss_dice: 0.5012, decode.d3.loss_cls: 0.0349, decode.d3.loss_mask: 0.2282, decode.d3.loss_dice: 0.5089, decode.d4.loss_cls: 0.0289, decode.d4.loss_mask: 0.2280, decode.d4.loss_dice: 0.4970, decode.d5.loss_cls: 0.0359, decode.d5.loss_mask: 0.2292, decode.d5.loss_dice: 0.4950, decode.d6.loss_cls: 0.0400, decode.d6.loss_mask: 0.2275, decode.d6.loss_dice: 0.4994, decode.d7.loss_cls: 0.0400, decode.d7.loss_mask: 0.2282, decode.d7.loss_dice: 0.5002, decode.d8.loss_cls: 0.0350, decode.d8.loss_mask: 0.2279, decode.d8.loss_dice: 0.5039, loss: 7.8295
2023-09-29 14:05:18,697 - mmseg - INFO - Iter [33850/40000]	lr: 2.208e-07, eta: 5:18:57, time: 2.272, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0773, decode.loss_mask: 0.2401, decode.loss_dice: 0.5189, decode.d0.loss_cls: 0.2234, decode.d0.loss_mask: 0.2437, decode.d0.loss_dice: 0.5279, decode.d1.loss_cls: 0.0849, decode.d1.loss_mask: 0.2410, decode.d1.loss_dice: 0.5120, decode.d2.loss_cls: 0.0971, decode.d2.loss_mask: 0.2395, decode.d2.loss_dice: 0.5165, decode.d3.loss_cls: 0.0858, decode.d3.loss_mask: 0.2398, decode.d3.loss_dice: 0.5179, decode.d4.loss_cls: 0.0658, decode.d4.loss_mask: 0.2409, decode.d4.loss_dice: 0.5185, decode.d5.loss_cls: 0.0870, decode.d5.loss_mask: 0.2389, decode.d5.loss_dice: 0.5149, decode.d6.loss_cls: 0.0917, decode.d6.loss_mask: 0.2390, decode.d6.loss_dice: 0.5105, decode.d7.loss_cls: 0.0845, decode.d7.loss_mask: 0.2377, decode.d7.loss_dice: 0.5106, decode.d8.loss_cls: 0.0919, decode.d8.loss_mask: 0.2383, decode.d8.loss_dice: 0.5106, loss: 8.5464
2023-09-29 14:07:12,161 - mmseg - INFO - Iter [33900/40000]	lr: 2.190e-07, eta: 5:16:14, time: 2.269, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0432, decode.loss_mask: 0.2415, decode.loss_dice: 0.4985, decode.d0.loss_cls: 0.1985, decode.d0.loss_mask: 0.2444, decode.d0.loss_dice: 0.5160, decode.d1.loss_cls: 0.0590, decode.d1.loss_mask: 0.2439, decode.d1.loss_dice: 0.4986, decode.d2.loss_cls: 0.0558, decode.d2.loss_mask: 0.2416, decode.d2.loss_dice: 0.5013, decode.d3.loss_cls: 0.0497, decode.d3.loss_mask: 0.2400, decode.d3.loss_dice: 0.4948, decode.d4.loss_cls: 0.0563, decode.d4.loss_mask: 0.2416, decode.d4.loss_dice: 0.4996, decode.d5.loss_cls: 0.0544, decode.d5.loss_mask: 0.2410, decode.d5.loss_dice: 0.5005, decode.d6.loss_cls: 0.0490, decode.d6.loss_mask: 0.2420, decode.d6.loss_dice: 0.4971, decode.d7.loss_cls: 0.0476, decode.d7.loss_mask: 0.2411, decode.d7.loss_dice: 0.5040, decode.d8.loss_cls: 0.0445, decode.d8.loss_mask: 0.2412, decode.d8.loss_dice: 0.4948, loss: 8.0813
2023-09-29 14:09:04,943 - mmseg - INFO - Iter [33950/40000]	lr: 2.172e-07, eta: 5:13:31, time: 2.256, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0665, decode.loss_mask: 0.2732, decode.loss_dice: 0.5328, decode.d0.loss_cls: 0.2066, decode.d0.loss_mask: 0.2766, decode.d0.loss_dice: 0.5527, decode.d1.loss_cls: 0.1024, decode.d1.loss_mask: 0.2750, decode.d1.loss_dice: 0.5425, decode.d2.loss_cls: 0.0926, decode.d2.loss_mask: 0.2738, decode.d2.loss_dice: 0.5312, decode.d3.loss_cls: 0.0744, decode.d3.loss_mask: 0.2734, decode.d3.loss_dice: 0.5397, decode.d4.loss_cls: 0.0816, decode.d4.loss_mask: 0.2730, decode.d4.loss_dice: 0.5477, decode.d5.loss_cls: 0.0614, decode.d5.loss_mask: 0.2743, decode.d5.loss_dice: 0.5378, decode.d6.loss_cls: 0.0776, decode.d6.loss_mask: 0.2743, decode.d6.loss_dice: 0.5417, decode.d7.loss_cls: 0.0887, decode.d7.loss_mask: 0.2748, decode.d7.loss_dice: 0.5415, decode.d8.loss_cls: 0.0672, decode.d8.loss_mask: 0.2752, decode.d8.loss_dice: 0.5372, loss: 9.0677
2023-09-29 14:10:57,650 - mmseg - INFO - Saving checkpoint at 34000 iterations
2023-09-29 14:11:17,879 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 14:11:17,879 - mmseg - INFO - Iter [34000/40000]	lr: 2.154e-07, eta: 5:10:51, time: 2.659, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0337, decode.loss_mask: 0.2488, decode.loss_dice: 0.5121, decode.d0.loss_cls: 0.2052, decode.d0.loss_mask: 0.2536, decode.d0.loss_dice: 0.5288, decode.d1.loss_cls: 0.0394, decode.d1.loss_mask: 0.2508, decode.d1.loss_dice: 0.5139, decode.d2.loss_cls: 0.0508, decode.d2.loss_mask: 0.2497, decode.d2.loss_dice: 0.5162, decode.d3.loss_cls: 0.0368, decode.d3.loss_mask: 0.2500, decode.d3.loss_dice: 0.5123, decode.d4.loss_cls: 0.0377, decode.d4.loss_mask: 0.2494, decode.d4.loss_dice: 0.5180, decode.d5.loss_cls: 0.0363, decode.d5.loss_mask: 0.2513, decode.d5.loss_dice: 0.5148, decode.d6.loss_cls: 0.0345, decode.d6.loss_mask: 0.2502, decode.d6.loss_dice: 0.5159, decode.d7.loss_cls: 0.0404, decode.d7.loss_mask: 0.2498, decode.d7.loss_dice: 0.5200, decode.d8.loss_cls: 0.0294, decode.d8.loss_mask: 0.2498, decode.d8.loss_dice: 0.5088, loss: 8.2087
2023-09-29 14:28:35,351 - mmseg - INFO - per class results:
2023-09-29 14:28:35,353 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     |  92.9 | 97.04 |
|    Sidewalk   | 69.57 | 82.33 |
|  Construction | 82.49 | 94.12 |
|     Fence     | 34.14 | 37.86 |
|      Pole     |  57.6 | 70.31 |
| Traffic Light | 67.85 | 80.04 |
|  Traffic Sign | 72.09 | 81.27 |
|     Nature    | 88.73 | 94.29 |
|      Sky      | 96.64 | 97.94 |
|     Person    | 33.97 | 36.54 |
|     Rider     |  9.06 | 72.74 |
|      Car      | 91.64 |  94.9 |
|   background  | 96.19 | 97.72 |
+---------------+-------+-------+
2023-09-29 14:28:35,354 - mmseg - INFO - Summary:
2023-09-29 14:28:35,354 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.54 | 68.68 | 79.78 |
+-------+-------+-------+
2023-09-29 14:28:35,357 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 14:28:35,358 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9454, mIoU: 0.6868, mAcc: 0.7978, IoU.Road: 0.9290, IoU.Sidewalk: 0.6957, IoU.Construction: 0.8249, IoU.Fence: 0.3414, IoU.Pole: 0.5760, IoU.Traffic Light: 0.6785, IoU.Traffic Sign: 0.7209, IoU.Nature: 0.8873, IoU.Sky: 0.9664, IoU.Person: 0.3397, IoU.Rider: 0.0906, IoU.Car: 0.9164, IoU.background: 0.9619, Acc.Road: 0.9704, Acc.Sidewalk: 0.8233, Acc.Construction: 0.9412, Acc.Fence: 0.3786, Acc.Pole: 0.7031, Acc.Traffic Light: 0.8004, Acc.Traffic Sign: 0.8127, Acc.Nature: 0.9429, Acc.Sky: 0.9794, Acc.Person: 0.3654, Acc.Rider: 0.7274, Acc.Car: 0.9490, Acc.background: 0.9772
2023-09-29 14:30:30,652 - mmseg - INFO - Iter [34050/40000]	lr: 2.136e-07, eta: 5:11:10, time: 23.055, data_time: 20.825, memory: 21542, decode.loss_cls: 0.0498, decode.loss_mask: 0.2410, decode.loss_dice: 0.5310, decode.d0.loss_cls: 0.2205, decode.d0.loss_mask: 0.2444, decode.d0.loss_dice: 0.5547, decode.d1.loss_cls: 0.0843, decode.d1.loss_mask: 0.2427, decode.d1.loss_dice: 0.5351, decode.d2.loss_cls: 0.0670, decode.d2.loss_mask: 0.2406, decode.d2.loss_dice: 0.5256, decode.d3.loss_cls: 0.0719, decode.d3.loss_mask: 0.2418, decode.d3.loss_dice: 0.5274, decode.d4.loss_cls: 0.0655, decode.d4.loss_mask: 0.2421, decode.d4.loss_dice: 0.5329, decode.d5.loss_cls: 0.0645, decode.d5.loss_mask: 0.2418, decode.d5.loss_dice: 0.5267, decode.d6.loss_cls: 0.0638, decode.d6.loss_mask: 0.2415, decode.d6.loss_dice: 0.5351, decode.d7.loss_cls: 0.0683, decode.d7.loss_mask: 0.2428, decode.d7.loss_dice: 0.5339, decode.d8.loss_cls: 0.0650, decode.d8.loss_mask: 0.2412, decode.d8.loss_dice: 0.5287, loss: 8.5717
2023-09-29 14:32:24,485 - mmseg - INFO - Iter [34100/40000]	lr: 2.118e-07, eta: 5:08:26, time: 2.277, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0802, decode.loss_mask: 0.2677, decode.loss_dice: 0.5492, decode.d0.loss_cls: 0.1994, decode.d0.loss_mask: 0.2737, decode.d0.loss_dice: 0.5657, decode.d1.loss_cls: 0.0805, decode.d1.loss_mask: 0.2705, decode.d1.loss_dice: 0.5682, decode.d2.loss_cls: 0.0594, decode.d2.loss_mask: 0.2692, decode.d2.loss_dice: 0.5588, decode.d3.loss_cls: 0.0731, decode.d3.loss_mask: 0.2680, decode.d3.loss_dice: 0.5508, decode.d4.loss_cls: 0.0557, decode.d4.loss_mask: 0.2714, decode.d4.loss_dice: 0.5578, decode.d5.loss_cls: 0.0621, decode.d5.loss_mask: 0.2723, decode.d5.loss_dice: 0.5574, decode.d6.loss_cls: 0.0641, decode.d6.loss_mask: 0.2689, decode.d6.loss_dice: 0.5508, decode.d7.loss_cls: 0.0546, decode.d7.loss_mask: 0.2700, decode.d7.loss_dice: 0.5578, decode.d8.loss_cls: 0.0790, decode.d8.loss_mask: 0.2687, decode.d8.loss_dice: 0.5453, loss: 9.0703
2023-09-29 14:34:17,035 - mmseg - INFO - Iter [34150/40000]	lr: 2.100e-07, eta: 5:05:41, time: 2.251, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0564, decode.loss_mask: 0.2680, decode.loss_dice: 0.5433, decode.d0.loss_cls: 0.2037, decode.d0.loss_mask: 0.2736, decode.d0.loss_dice: 0.5587, decode.d1.loss_cls: 0.0913, decode.d1.loss_mask: 0.2687, decode.d1.loss_dice: 0.5462, decode.d2.loss_cls: 0.0790, decode.d2.loss_mask: 0.2674, decode.d2.loss_dice: 0.5344, decode.d3.loss_cls: 0.0555, decode.d3.loss_mask: 0.2682, decode.d3.loss_dice: 0.5421, decode.d4.loss_cls: 0.0526, decode.d4.loss_mask: 0.2682, decode.d4.loss_dice: 0.5398, decode.d5.loss_cls: 0.0665, decode.d5.loss_mask: 0.2669, decode.d5.loss_dice: 0.5417, decode.d6.loss_cls: 0.0576, decode.d6.loss_mask: 0.2692, decode.d6.loss_dice: 0.5421, decode.d7.loss_cls: 0.0518, decode.d7.loss_mask: 0.2678, decode.d7.loss_dice: 0.5316, decode.d8.loss_cls: 0.0487, decode.d8.loss_mask: 0.2679, decode.d8.loss_dice: 0.5382, loss: 8.8671
2023-09-29 14:36:10,199 - mmseg - INFO - Iter [34200/40000]	lr: 2.082e-07, eta: 5:02:57, time: 2.263, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0462, decode.loss_mask: 0.2415, decode.loss_dice: 0.4993, decode.d0.loss_cls: 0.1972, decode.d0.loss_mask: 0.2425, decode.d0.loss_dice: 0.5132, decode.d1.loss_cls: 0.0540, decode.d1.loss_mask: 0.2400, decode.d1.loss_dice: 0.4985, decode.d2.loss_cls: 0.0422, decode.d2.loss_mask: 0.2384, decode.d2.loss_dice: 0.5003, decode.d3.loss_cls: 0.0407, decode.d3.loss_mask: 0.2409, decode.d3.loss_dice: 0.4890, decode.d4.loss_cls: 0.0403, decode.d4.loss_mask: 0.2402, decode.d4.loss_dice: 0.5035, decode.d5.loss_cls: 0.0404, decode.d5.loss_mask: 0.2438, decode.d5.loss_dice: 0.5009, decode.d6.loss_cls: 0.0373, decode.d6.loss_mask: 0.2422, decode.d6.loss_dice: 0.4927, decode.d7.loss_cls: 0.0353, decode.d7.loss_mask: 0.2440, decode.d7.loss_dice: 0.4961, decode.d8.loss_cls: 0.0410, decode.d8.loss_mask: 0.2411, decode.d8.loss_dice: 0.4934, loss: 7.9759
2023-09-29 14:38:03,655 - mmseg - INFO - Iter [34250/40000]	lr: 2.064e-07, eta: 5:00:13, time: 2.269, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0537, decode.loss_mask: 0.2477, decode.loss_dice: 0.4935, decode.d0.loss_cls: 0.2005, decode.d0.loss_mask: 0.2536, decode.d0.loss_dice: 0.5005, decode.d1.loss_cls: 0.0564, decode.d1.loss_mask: 0.2496, decode.d1.loss_dice: 0.4949, decode.d2.loss_cls: 0.0607, decode.d2.loss_mask: 0.2480, decode.d2.loss_dice: 0.4942, decode.d3.loss_cls: 0.0509, decode.d3.loss_mask: 0.2487, decode.d3.loss_dice: 0.4887, decode.d4.loss_cls: 0.0484, decode.d4.loss_mask: 0.2488, decode.d4.loss_dice: 0.5020, decode.d5.loss_cls: 0.0526, decode.d5.loss_mask: 0.2486, decode.d5.loss_dice: 0.4937, decode.d6.loss_cls: 0.0527, decode.d6.loss_mask: 0.2472, decode.d6.loss_dice: 0.4912, decode.d7.loss_cls: 0.0511, decode.d7.loss_mask: 0.2477, decode.d7.loss_dice: 0.4974, decode.d8.loss_cls: 0.0527, decode.d8.loss_mask: 0.2485, decode.d8.loss_dice: 0.4917, loss: 8.1161
2023-09-29 14:39:57,474 - mmseg - INFO - Iter [34300/40000]	lr: 2.046e-07, eta: 4:57:29, time: 2.276, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0401, decode.loss_mask: 0.2488, decode.loss_dice: 0.5195, decode.d0.loss_cls: 0.1861, decode.d0.loss_mask: 0.2496, decode.d0.loss_dice: 0.5276, decode.d1.loss_cls: 0.0451, decode.d1.loss_mask: 0.2483, decode.d1.loss_dice: 0.5148, decode.d2.loss_cls: 0.0477, decode.d2.loss_mask: 0.2483, decode.d2.loss_dice: 0.5178, decode.d3.loss_cls: 0.0587, decode.d3.loss_mask: 0.2488, decode.d3.loss_dice: 0.5138, decode.d4.loss_cls: 0.0547, decode.d4.loss_mask: 0.2477, decode.d4.loss_dice: 0.5207, decode.d5.loss_cls: 0.0544, decode.d5.loss_mask: 0.2477, decode.d5.loss_dice: 0.5219, decode.d6.loss_cls: 0.0378, decode.d6.loss_mask: 0.2502, decode.d6.loss_dice: 0.5207, decode.d7.loss_cls: 0.0534, decode.d7.loss_mask: 0.2473, decode.d7.loss_dice: 0.5073, decode.d8.loss_cls: 0.0450, decode.d8.loss_mask: 0.2485, decode.d8.loss_dice: 0.5145, loss: 8.2868
2023-09-29 14:41:51,019 - mmseg - INFO - Iter [34350/40000]	lr: 2.028e-07, eta: 4:54:46, time: 2.269, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0662, decode.loss_mask: 0.2533, decode.loss_dice: 0.5437, decode.d0.loss_cls: 0.1709, decode.d0.loss_mask: 0.2574, decode.d0.loss_dice: 0.5575, decode.d1.loss_cls: 0.0636, decode.d1.loss_mask: 0.2539, decode.d1.loss_dice: 0.5547, decode.d2.loss_cls: 0.0779, decode.d2.loss_mask: 0.2524, decode.d2.loss_dice: 0.5472, decode.d3.loss_cls: 0.0741, decode.d3.loss_mask: 0.2545, decode.d3.loss_dice: 0.5481, decode.d4.loss_cls: 0.0595, decode.d4.loss_mask: 0.2532, decode.d4.loss_dice: 0.5450, decode.d5.loss_cls: 0.0570, decode.d5.loss_mask: 0.2542, decode.d5.loss_dice: 0.5454, decode.d6.loss_cls: 0.0619, decode.d6.loss_mask: 0.2535, decode.d6.loss_dice: 0.5526, decode.d7.loss_cls: 0.0565, decode.d7.loss_mask: 0.2543, decode.d7.loss_dice: 0.5486, decode.d8.loss_cls: 0.0539, decode.d8.loss_mask: 0.2556, decode.d8.loss_dice: 0.5439, loss: 8.7706
2023-09-29 14:43:43,739 - mmseg - INFO - Iter [34400/40000]	lr: 2.010e-07, eta: 4:52:02, time: 2.256, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0558, decode.loss_mask: 0.2464, decode.loss_dice: 0.5003, decode.d0.loss_cls: 0.2048, decode.d0.loss_mask: 0.2489, decode.d0.loss_dice: 0.5210, decode.d1.loss_cls: 0.0719, decode.d1.loss_mask: 0.2465, decode.d1.loss_dice: 0.5116, decode.d2.loss_cls: 0.0631, decode.d2.loss_mask: 0.2454, decode.d2.loss_dice: 0.5054, decode.d3.loss_cls: 0.0613, decode.d3.loss_mask: 0.2453, decode.d3.loss_dice: 0.4945, decode.d4.loss_cls: 0.0603, decode.d4.loss_mask: 0.2469, decode.d4.loss_dice: 0.5112, decode.d5.loss_cls: 0.0551, decode.d5.loss_mask: 0.2449, decode.d5.loss_dice: 0.5032, decode.d6.loss_cls: 0.0557, decode.d6.loss_mask: 0.2462, decode.d6.loss_dice: 0.5039, decode.d7.loss_cls: 0.0454, decode.d7.loss_mask: 0.2455, decode.d7.loss_dice: 0.5040, decode.d8.loss_cls: 0.0521, decode.d8.loss_mask: 0.2474, decode.d8.loss_dice: 0.5041, loss: 8.2483
2023-09-29 14:45:36,158 - mmseg - INFO - Iter [34450/40000]	lr: 1.993e-07, eta: 4:49:19, time: 2.248, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0678, decode.loss_mask: 0.2670, decode.loss_dice: 0.5037, decode.d0.loss_cls: 0.2223, decode.d0.loss_mask: 0.2717, decode.d0.loss_dice: 0.5085, decode.d1.loss_cls: 0.0797, decode.d1.loss_mask: 0.2669, decode.d1.loss_dice: 0.5019, decode.d2.loss_cls: 0.0592, decode.d2.loss_mask: 0.2664, decode.d2.loss_dice: 0.5175, decode.d3.loss_cls: 0.0618, decode.d3.loss_mask: 0.2693, decode.d3.loss_dice: 0.5192, decode.d4.loss_cls: 0.0819, decode.d4.loss_mask: 0.2685, decode.d4.loss_dice: 0.5063, decode.d5.loss_cls: 0.0560, decode.d5.loss_mask: 0.2686, decode.d5.loss_dice: 0.5084, decode.d6.loss_cls: 0.0596, decode.d6.loss_mask: 0.2697, decode.d6.loss_dice: 0.4967, decode.d7.loss_cls: 0.0763, decode.d7.loss_mask: 0.2691, decode.d7.loss_dice: 0.5138, decode.d8.loss_cls: 0.0644, decode.d8.loss_mask: 0.2684, decode.d8.loss_dice: 0.5041, loss: 8.5947
2023-09-29 14:47:29,040 - mmseg - INFO - Iter [34500/40000]	lr: 1.975e-07, eta: 4:46:35, time: 2.258, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0684, decode.loss_mask: 0.2364, decode.loss_dice: 0.5216, decode.d0.loss_cls: 0.2432, decode.d0.loss_mask: 0.2392, decode.d0.loss_dice: 0.5455, decode.d1.loss_cls: 0.0878, decode.d1.loss_mask: 0.2367, decode.d1.loss_dice: 0.5257, decode.d2.loss_cls: 0.0813, decode.d2.loss_mask: 0.2371, decode.d2.loss_dice: 0.5243, decode.d3.loss_cls: 0.0820, decode.d3.loss_mask: 0.2364, decode.d3.loss_dice: 0.5163, decode.d4.loss_cls: 0.0716, decode.d4.loss_mask: 0.2373, decode.d4.loss_dice: 0.5290, decode.d5.loss_cls: 0.0682, decode.d5.loss_mask: 0.2350, decode.d5.loss_dice: 0.5238, decode.d6.loss_cls: 0.0997, decode.d6.loss_mask: 0.2365, decode.d6.loss_dice: 0.5243, decode.d7.loss_cls: 0.0757, decode.d7.loss_mask: 0.2369, decode.d7.loss_dice: 0.5191, decode.d8.loss_cls: 0.0713, decode.d8.loss_mask: 0.2357, decode.d8.loss_dice: 0.5277, loss: 8.5739
2023-09-29 14:49:21,852 - mmseg - INFO - Iter [34550/40000]	lr: 1.957e-07, eta: 4:43:52, time: 2.256, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0735, decode.loss_mask: 0.2385, decode.loss_dice: 0.4946, decode.d0.loss_cls: 0.2120, decode.d0.loss_mask: 0.2447, decode.d0.loss_dice: 0.5179, decode.d1.loss_cls: 0.0836, decode.d1.loss_mask: 0.2381, decode.d1.loss_dice: 0.4921, decode.d2.loss_cls: 0.0784, decode.d2.loss_mask: 0.2381, decode.d2.loss_dice: 0.4887, decode.d3.loss_cls: 0.0660, decode.d3.loss_mask: 0.2392, decode.d3.loss_dice: 0.4912, decode.d4.loss_cls: 0.0797, decode.d4.loss_mask: 0.2391, decode.d4.loss_dice: 0.4890, decode.d5.loss_cls: 0.0755, decode.d5.loss_mask: 0.2397, decode.d5.loss_dice: 0.4857, decode.d6.loss_cls: 0.0666, decode.d6.loss_mask: 0.2400, decode.d6.loss_dice: 0.4949, decode.d7.loss_cls: 0.0805, decode.d7.loss_mask: 0.2392, decode.d7.loss_dice: 0.4933, decode.d8.loss_cls: 0.0847, decode.d8.loss_mask: 0.2394, decode.d8.loss_dice: 0.4793, loss: 8.2230
2023-09-29 14:51:15,712 - mmseg - INFO - Iter [34600/40000]	lr: 1.939e-07, eta: 4:41:09, time: 2.277, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0501, decode.loss_mask: 0.2420, decode.loss_dice: 0.5344, decode.d0.loss_cls: 0.2365, decode.d0.loss_mask: 0.2411, decode.d0.loss_dice: 0.5599, decode.d1.loss_cls: 0.1036, decode.d1.loss_mask: 0.2410, decode.d1.loss_dice: 0.5328, decode.d2.loss_cls: 0.0716, decode.d2.loss_mask: 0.2426, decode.d2.loss_dice: 0.5217, decode.d3.loss_cls: 0.0602, decode.d3.loss_mask: 0.2421, decode.d3.loss_dice: 0.5230, decode.d4.loss_cls: 0.0620, decode.d4.loss_mask: 0.2417, decode.d4.loss_dice: 0.5242, decode.d5.loss_cls: 0.0624, decode.d5.loss_mask: 0.2412, decode.d5.loss_dice: 0.5269, decode.d6.loss_cls: 0.0558, decode.d6.loss_mask: 0.2417, decode.d6.loss_dice: 0.5264, decode.d7.loss_cls: 0.0552, decode.d7.loss_mask: 0.2418, decode.d7.loss_dice: 0.5330, decode.d8.loss_cls: 0.0626, decode.d8.loss_mask: 0.2425, decode.d8.loss_dice: 0.5300, loss: 8.5500
2023-09-29 14:53:08,999 - mmseg - INFO - Iter [34650/40000]	lr: 1.921e-07, eta: 4:38:26, time: 2.266, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0770, decode.loss_mask: 0.2316, decode.loss_dice: 0.5385, decode.d0.loss_cls: 0.1987, decode.d0.loss_mask: 0.2310, decode.d0.loss_dice: 0.5587, decode.d1.loss_cls: 0.0693, decode.d1.loss_mask: 0.2332, decode.d1.loss_dice: 0.5442, decode.d2.loss_cls: 0.0523, decode.d2.loss_mask: 0.2326, decode.d2.loss_dice: 0.5238, decode.d3.loss_cls: 0.0631, decode.d3.loss_mask: 0.2323, decode.d3.loss_dice: 0.5396, decode.d4.loss_cls: 0.0571, decode.d4.loss_mask: 0.2329, decode.d4.loss_dice: 0.5298, decode.d5.loss_cls: 0.0671, decode.d5.loss_mask: 0.2319, decode.d5.loss_dice: 0.5365, decode.d6.loss_cls: 0.0517, decode.d6.loss_mask: 0.2323, decode.d6.loss_dice: 0.5318, decode.d7.loss_cls: 0.0683, decode.d7.loss_mask: 0.2325, decode.d7.loss_dice: 0.5329, decode.d8.loss_cls: 0.0750, decode.d8.loss_mask: 0.2312, decode.d8.loss_dice: 0.5356, loss: 8.4725
2023-09-29 14:55:01,718 - mmseg - INFO - Iter [34700/40000]	lr: 1.903e-07, eta: 4:35:44, time: 2.254, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0589, decode.loss_mask: 0.2472, decode.loss_dice: 0.4658, decode.d0.loss_cls: 0.2421, decode.d0.loss_mask: 0.2477, decode.d0.loss_dice: 0.4764, decode.d1.loss_cls: 0.0648, decode.d1.loss_mask: 0.2469, decode.d1.loss_dice: 0.4670, decode.d2.loss_cls: 0.0647, decode.d2.loss_mask: 0.2467, decode.d2.loss_dice: 0.4635, decode.d3.loss_cls: 0.0502, decode.d3.loss_mask: 0.2475, decode.d3.loss_dice: 0.4583, decode.d4.loss_cls: 0.0571, decode.d4.loss_mask: 0.2469, decode.d4.loss_dice: 0.4679, decode.d5.loss_cls: 0.0465, decode.d5.loss_mask: 0.2472, decode.d5.loss_dice: 0.4645, decode.d6.loss_cls: 0.0582, decode.d6.loss_mask: 0.2455, decode.d6.loss_dice: 0.4615, decode.d7.loss_cls: 0.0713, decode.d7.loss_mask: 0.2480, decode.d7.loss_dice: 0.4670, decode.d8.loss_cls: 0.0774, decode.d8.loss_mask: 0.2466, decode.d8.loss_dice: 0.4682, loss: 7.9211
2023-09-29 14:56:55,101 - mmseg - INFO - Iter [34750/40000]	lr: 1.885e-07, eta: 4:33:01, time: 2.268, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0769, decode.loss_mask: 0.2609, decode.loss_dice: 0.5324, decode.d0.loss_cls: 0.2560, decode.d0.loss_mask: 0.2592, decode.d0.loss_dice: 0.5364, decode.d1.loss_cls: 0.0553, decode.d1.loss_mask: 0.2591, decode.d1.loss_dice: 0.5177, decode.d2.loss_cls: 0.0738, decode.d2.loss_mask: 0.2607, decode.d2.loss_dice: 0.5175, decode.d3.loss_cls: 0.0771, decode.d3.loss_mask: 0.2623, decode.d3.loss_dice: 0.5328, decode.d4.loss_cls: 0.0815, decode.d4.loss_mask: 0.2586, decode.d4.loss_dice: 0.5197, decode.d5.loss_cls: 0.0617, decode.d5.loss_mask: 0.2604, decode.d5.loss_dice: 0.5169, decode.d6.loss_cls: 0.0612, decode.d6.loss_mask: 0.2614, decode.d6.loss_dice: 0.5209, decode.d7.loss_cls: 0.0607, decode.d7.loss_mask: 0.2613, decode.d7.loss_dice: 0.5175, decode.d8.loss_cls: 0.0481, decode.d8.loss_mask: 0.2618, decode.d8.loss_dice: 0.5233, loss: 8.6930
2023-09-29 14:58:48,208 - mmseg - INFO - Iter [34800/40000]	lr: 1.867e-07, eta: 4:30:19, time: 2.262, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0415, decode.loss_mask: 0.2378, decode.loss_dice: 0.4942, decode.d0.loss_cls: 0.2168, decode.d0.loss_mask: 0.2379, decode.d0.loss_dice: 0.5088, decode.d1.loss_cls: 0.0682, decode.d1.loss_mask: 0.2381, decode.d1.loss_dice: 0.4978, decode.d2.loss_cls: 0.0494, decode.d2.loss_mask: 0.2403, decode.d2.loss_dice: 0.5169, decode.d3.loss_cls: 0.0463, decode.d3.loss_mask: 0.2396, decode.d3.loss_dice: 0.5053, decode.d4.loss_cls: 0.0395, decode.d4.loss_mask: 0.2389, decode.d4.loss_dice: 0.5017, decode.d5.loss_cls: 0.0475, decode.d5.loss_mask: 0.2390, decode.d5.loss_dice: 0.5075, decode.d6.loss_cls: 0.0317, decode.d6.loss_mask: 0.2378, decode.d6.loss_dice: 0.4997, decode.d7.loss_cls: 0.0416, decode.d7.loss_mask: 0.2373, decode.d7.loss_dice: 0.5013, decode.d8.loss_cls: 0.0299, decode.d8.loss_mask: 0.2380, decode.d8.loss_dice: 0.4995, loss: 8.0298
2023-09-29 15:00:40,661 - mmseg - INFO - Iter [34850/40000]	lr: 1.849e-07, eta: 4:27:36, time: 2.249, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0754, decode.loss_mask: 0.2691, decode.loss_dice: 0.5495, decode.d0.loss_cls: 0.2163, decode.d0.loss_mask: 0.2746, decode.d0.loss_dice: 0.5660, decode.d1.loss_cls: 0.0975, decode.d1.loss_mask: 0.2693, decode.d1.loss_dice: 0.5556, decode.d2.loss_cls: 0.0851, decode.d2.loss_mask: 0.2694, decode.d2.loss_dice: 0.5432, decode.d3.loss_cls: 0.0752, decode.d3.loss_mask: 0.2695, decode.d3.loss_dice: 0.5507, decode.d4.loss_cls: 0.0643, decode.d4.loss_mask: 0.2690, decode.d4.loss_dice: 0.5521, decode.d5.loss_cls: 0.0692, decode.d5.loss_mask: 0.2694, decode.d5.loss_dice: 0.5439, decode.d6.loss_cls: 0.0612, decode.d6.loss_mask: 0.2688, decode.d6.loss_dice: 0.5444, decode.d7.loss_cls: 0.0827, decode.d7.loss_mask: 0.2671, decode.d7.loss_dice: 0.5359, decode.d8.loss_cls: 0.0694, decode.d8.loss_mask: 0.2686, decode.d8.loss_dice: 0.5433, loss: 9.0758
2023-09-29 15:02:33,617 - mmseg - INFO - Iter [34900/40000]	lr: 1.831e-07, eta: 4:24:54, time: 2.259, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0612, decode.loss_mask: 0.2441, decode.loss_dice: 0.5379, decode.d0.loss_cls: 0.2162, decode.d0.loss_mask: 0.2452, decode.d0.loss_dice: 0.5480, decode.d1.loss_cls: 0.0755, decode.d1.loss_mask: 0.2439, decode.d1.loss_dice: 0.5361, decode.d2.loss_cls: 0.0655, decode.d2.loss_mask: 0.2451, decode.d2.loss_dice: 0.5246, decode.d3.loss_cls: 0.0739, decode.d3.loss_mask: 0.2432, decode.d3.loss_dice: 0.5340, decode.d4.loss_cls: 0.0674, decode.d4.loss_mask: 0.2429, decode.d4.loss_dice: 0.5305, decode.d5.loss_cls: 0.0721, decode.d5.loss_mask: 0.2432, decode.d5.loss_dice: 0.5320, decode.d6.loss_cls: 0.0627, decode.d6.loss_mask: 0.2429, decode.d6.loss_dice: 0.5418, decode.d7.loss_cls: 0.0665, decode.d7.loss_mask: 0.2424, decode.d7.loss_dice: 0.5300, decode.d8.loss_cls: 0.0749, decode.d8.loss_mask: 0.2435, decode.d8.loss_dice: 0.5372, loss: 8.6246
2023-09-29 15:04:26,650 - mmseg - INFO - Iter [34950/40000]	lr: 1.813e-07, eta: 4:22:12, time: 2.261, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0634, decode.loss_mask: 0.2645, decode.loss_dice: 0.5180, decode.d0.loss_cls: 0.2152, decode.d0.loss_mask: 0.2679, decode.d0.loss_dice: 0.5345, decode.d1.loss_cls: 0.0827, decode.d1.loss_mask: 0.2656, decode.d1.loss_dice: 0.5268, decode.d2.loss_cls: 0.0682, decode.d2.loss_mask: 0.2656, decode.d2.loss_dice: 0.5215, decode.d3.loss_cls: 0.0654, decode.d3.loss_mask: 0.2652, decode.d3.loss_dice: 0.5163, decode.d4.loss_cls: 0.0764, decode.d4.loss_mask: 0.2637, decode.d4.loss_dice: 0.5232, decode.d5.loss_cls: 0.0607, decode.d5.loss_mask: 0.2656, decode.d5.loss_dice: 0.5165, decode.d6.loss_cls: 0.0557, decode.d6.loss_mask: 0.2657, decode.d6.loss_dice: 0.5245, decode.d7.loss_cls: 0.0691, decode.d7.loss_mask: 0.2654, decode.d7.loss_dice: 0.5263, decode.d8.loss_cls: 0.0809, decode.d8.loss_mask: 0.2630, decode.d8.loss_dice: 0.5246, loss: 8.7221
2023-09-29 15:06:19,959 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 15:06:19,960 - mmseg - INFO - Iter [35000/40000]	lr: 1.795e-07, eta: 4:19:30, time: 2.266, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0672, decode.loss_mask: 0.2477, decode.loss_dice: 0.5315, decode.d0.loss_cls: 0.1927, decode.d0.loss_mask: 0.2495, decode.d0.loss_dice: 0.5230, decode.d1.loss_cls: 0.0750, decode.d1.loss_mask: 0.2494, decode.d1.loss_dice: 0.5281, decode.d2.loss_cls: 0.0792, decode.d2.loss_mask: 0.2480, decode.d2.loss_dice: 0.5302, decode.d3.loss_cls: 0.0767, decode.d3.loss_mask: 0.2483, decode.d3.loss_dice: 0.5299, decode.d4.loss_cls: 0.0702, decode.d4.loss_mask: 0.2468, decode.d4.loss_dice: 0.5351, decode.d5.loss_cls: 0.0633, decode.d5.loss_mask: 0.2474, decode.d5.loss_dice: 0.5275, decode.d6.loss_cls: 0.0483, decode.d6.loss_mask: 0.2464, decode.d6.loss_dice: 0.5226, decode.d7.loss_cls: 0.0568, decode.d7.loss_mask: 0.2470, decode.d7.loss_dice: 0.5220, decode.d8.loss_cls: 0.0658, decode.d8.loss_mask: 0.2471, decode.d8.loss_dice: 0.5284, loss: 8.5510
2023-09-29 15:08:12,685 - mmseg - INFO - Iter [35050/40000]	lr: 1.777e-07, eta: 4:16:48, time: 2.255, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0552, decode.loss_mask: 0.2565, decode.loss_dice: 0.5024, decode.d0.loss_cls: 0.2449, decode.d0.loss_mask: 0.2589, decode.d0.loss_dice: 0.5032, decode.d1.loss_cls: 0.0762, decode.d1.loss_mask: 0.2571, decode.d1.loss_dice: 0.4933, decode.d2.loss_cls: 0.0522, decode.d2.loss_mask: 0.2563, decode.d2.loss_dice: 0.5013, decode.d3.loss_cls: 0.0548, decode.d3.loss_mask: 0.2568, decode.d3.loss_dice: 0.4950, decode.d4.loss_cls: 0.0802, decode.d4.loss_mask: 0.2571, decode.d4.loss_dice: 0.4953, decode.d5.loss_cls: 0.0674, decode.d5.loss_mask: 0.2565, decode.d5.loss_dice: 0.4927, decode.d6.loss_cls: 0.0570, decode.d6.loss_mask: 0.2569, decode.d6.loss_dice: 0.4915, decode.d7.loss_cls: 0.0645, decode.d7.loss_mask: 0.2570, decode.d7.loss_dice: 0.4989, decode.d8.loss_cls: 0.0565, decode.d8.loss_mask: 0.2571, decode.d8.loss_dice: 0.4966, loss: 8.3491
2023-09-29 15:10:05,225 - mmseg - INFO - Iter [35100/40000]	lr: 1.759e-07, eta: 4:14:07, time: 2.251, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0468, decode.loss_mask: 0.2379, decode.loss_dice: 0.5032, decode.d0.loss_cls: 0.2009, decode.d0.loss_mask: 0.2352, decode.d0.loss_dice: 0.5103, decode.d1.loss_cls: 0.0659, decode.d1.loss_mask: 0.2372, decode.d1.loss_dice: 0.5005, decode.d2.loss_cls: 0.0474, decode.d2.loss_mask: 0.2370, decode.d2.loss_dice: 0.4920, decode.d3.loss_cls: 0.0632, decode.d3.loss_mask: 0.2281, decode.d3.loss_dice: 0.5022, decode.d4.loss_cls: 0.0454, decode.d4.loss_mask: 0.2316, decode.d4.loss_dice: 0.4976, decode.d5.loss_cls: 0.0455, decode.d5.loss_mask: 0.2390, decode.d5.loss_dice: 0.4973, decode.d6.loss_cls: 0.0495, decode.d6.loss_mask: 0.2304, decode.d6.loss_dice: 0.5014, decode.d7.loss_cls: 0.0522, decode.d7.loss_mask: 0.2276, decode.d7.loss_dice: 0.4993, decode.d8.loss_cls: 0.0417, decode.d8.loss_mask: 0.2346, decode.d8.loss_dice: 0.5051, loss: 8.0058
2023-09-29 15:12:01,085 - mmseg - INFO - Iter [35150/40000]	lr: 1.741e-07, eta: 4:11:26, time: 2.317, data_time: 0.082, memory: 21542, decode.loss_cls: 0.0590, decode.loss_mask: 0.2299, decode.loss_dice: 0.5069, decode.d0.loss_cls: 0.1892, decode.d0.loss_mask: 0.2340, decode.d0.loss_dice: 0.5085, decode.d1.loss_cls: 0.0778, decode.d1.loss_mask: 0.2327, decode.d1.loss_dice: 0.5037, decode.d2.loss_cls: 0.0510, decode.d2.loss_mask: 0.2309, decode.d2.loss_dice: 0.5003, decode.d3.loss_cls: 0.0640, decode.d3.loss_mask: 0.2306, decode.d3.loss_dice: 0.5061, decode.d4.loss_cls: 0.0493, decode.d4.loss_mask: 0.2307, decode.d4.loss_dice: 0.5025, decode.d5.loss_cls: 0.0716, decode.d5.loss_mask: 0.2299, decode.d5.loss_dice: 0.5032, decode.d6.loss_cls: 0.0611, decode.d6.loss_mask: 0.2315, decode.d6.loss_dice: 0.5024, decode.d7.loss_cls: 0.0504, decode.d7.loss_mask: 0.2304, decode.d7.loss_dice: 0.4919, decode.d8.loss_cls: 0.0526, decode.d8.loss_mask: 0.2306, decode.d8.loss_dice: 0.4949, loss: 8.0576
2023-09-29 15:13:53,712 - mmseg - INFO - Iter [35200/40000]	lr: 1.723e-07, eta: 4:08:44, time: 2.253, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0758, decode.loss_mask: 0.2580, decode.loss_dice: 0.4864, decode.d0.loss_cls: 0.2292, decode.d0.loss_mask: 0.2583, decode.d0.loss_dice: 0.5026, decode.d1.loss_cls: 0.0699, decode.d1.loss_mask: 0.2565, decode.d1.loss_dice: 0.4989, decode.d2.loss_cls: 0.0790, decode.d2.loss_mask: 0.2562, decode.d2.loss_dice: 0.4865, decode.d3.loss_cls: 0.0720, decode.d3.loss_mask: 0.2580, decode.d3.loss_dice: 0.4919, decode.d4.loss_cls: 0.0878, decode.d4.loss_mask: 0.2572, decode.d4.loss_dice: 0.4927, decode.d5.loss_cls: 0.0751, decode.d5.loss_mask: 0.2573, decode.d5.loss_dice: 0.5006, decode.d6.loss_cls: 0.0726, decode.d6.loss_mask: 0.2577, decode.d6.loss_dice: 0.4890, decode.d7.loss_cls: 0.0632, decode.d7.loss_mask: 0.2565, decode.d7.loss_dice: 0.4879, decode.d8.loss_cls: 0.0716, decode.d8.loss_mask: 0.2567, decode.d8.loss_dice: 0.4817, loss: 8.3870
2023-09-29 15:15:47,126 - mmseg - INFO - Iter [35250/40000]	lr: 1.705e-07, eta: 4:06:03, time: 2.268, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0427, decode.loss_mask: 0.2205, decode.loss_dice: 0.5074, decode.d0.loss_cls: 0.1837, decode.d0.loss_mask: 0.2195, decode.d0.loss_dice: 0.5090, decode.d1.loss_cls: 0.0450, decode.d1.loss_mask: 0.2189, decode.d1.loss_dice: 0.5030, decode.d2.loss_cls: 0.0419, decode.d2.loss_mask: 0.2202, decode.d2.loss_dice: 0.5064, decode.d3.loss_cls: 0.0439, decode.d3.loss_mask: 0.2203, decode.d3.loss_dice: 0.5096, decode.d4.loss_cls: 0.0730, decode.d4.loss_mask: 0.2204, decode.d4.loss_dice: 0.4923, decode.d5.loss_cls: 0.0480, decode.d5.loss_mask: 0.2208, decode.d5.loss_dice: 0.4999, decode.d6.loss_cls: 0.0382, decode.d6.loss_mask: 0.2207, decode.d6.loss_dice: 0.5118, decode.d7.loss_cls: 0.0489, decode.d7.loss_mask: 0.2199, decode.d7.loss_dice: 0.4934, decode.d8.loss_cls: 0.0336, decode.d8.loss_mask: 0.2208, decode.d8.loss_dice: 0.4969, loss: 7.8307
2023-09-29 15:17:39,867 - mmseg - INFO - Iter [35300/40000]	lr: 1.687e-07, eta: 4:03:22, time: 2.255, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0268, decode.loss_mask: 0.2555, decode.loss_dice: 0.4944, decode.d0.loss_cls: 0.2016, decode.d0.loss_mask: 0.2579, decode.d0.loss_dice: 0.5094, decode.d1.loss_cls: 0.0581, decode.d1.loss_mask: 0.2572, decode.d1.loss_dice: 0.5001, decode.d2.loss_cls: 0.0346, decode.d2.loss_mask: 0.2546, decode.d2.loss_dice: 0.4950, decode.d3.loss_cls: 0.0315, decode.d3.loss_mask: 0.2546, decode.d3.loss_dice: 0.4986, decode.d4.loss_cls: 0.0410, decode.d4.loss_mask: 0.2563, decode.d4.loss_dice: 0.4980, decode.d5.loss_cls: 0.0392, decode.d5.loss_mask: 0.2564, decode.d5.loss_dice: 0.4950, decode.d6.loss_cls: 0.0304, decode.d6.loss_mask: 0.2563, decode.d6.loss_dice: 0.5029, decode.d7.loss_cls: 0.0304, decode.d7.loss_mask: 0.2558, decode.d7.loss_dice: 0.4969, decode.d8.loss_cls: 0.0288, decode.d8.loss_mask: 0.2560, decode.d8.loss_dice: 0.4888, loss: 8.0620
2023-09-29 15:19:33,492 - mmseg - INFO - Iter [35350/40000]	lr: 1.669e-07, eta: 4:00:41, time: 2.273, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0436, decode.loss_mask: 0.2490, decode.loss_dice: 0.5157, decode.d0.loss_cls: 0.2316, decode.d0.loss_mask: 0.2512, decode.d0.loss_dice: 0.5315, decode.d1.loss_cls: 0.0629, decode.d1.loss_mask: 0.2499, decode.d1.loss_dice: 0.5125, decode.d2.loss_cls: 0.0606, decode.d2.loss_mask: 0.2478, decode.d2.loss_dice: 0.5205, decode.d3.loss_cls: 0.0437, decode.d3.loss_mask: 0.2482, decode.d3.loss_dice: 0.5127, decode.d4.loss_cls: 0.0444, decode.d4.loss_mask: 0.2475, decode.d4.loss_dice: 0.5167, decode.d5.loss_cls: 0.0597, decode.d5.loss_mask: 0.2479, decode.d5.loss_dice: 0.5137, decode.d6.loss_cls: 0.0495, decode.d6.loss_mask: 0.2493, decode.d6.loss_dice: 0.5224, decode.d7.loss_cls: 0.0521, decode.d7.loss_mask: 0.2480, decode.d7.loss_dice: 0.5151, decode.d8.loss_cls: 0.0589, decode.d8.loss_mask: 0.2481, decode.d8.loss_dice: 0.5182, loss: 8.3730
2023-09-29 15:21:26,891 - mmseg - INFO - Iter [35400/40000]	lr: 1.652e-07, eta: 3:58:01, time: 2.268, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0658, decode.loss_mask: 0.2382, decode.loss_dice: 0.5304, decode.d0.loss_cls: 0.2065, decode.d0.loss_mask: 0.2410, decode.d0.loss_dice: 0.5441, decode.d1.loss_cls: 0.0826, decode.d1.loss_mask: 0.2387, decode.d1.loss_dice: 0.5240, decode.d2.loss_cls: 0.0670, decode.d2.loss_mask: 0.2374, decode.d2.loss_dice: 0.5303, decode.d3.loss_cls: 0.0616, decode.d3.loss_mask: 0.2372, decode.d3.loss_dice: 0.5174, decode.d4.loss_cls: 0.0690, decode.d4.loss_mask: 0.2367, decode.d4.loss_dice: 0.5218, decode.d5.loss_cls: 0.0633, decode.d5.loss_mask: 0.2378, decode.d5.loss_dice: 0.5315, decode.d6.loss_cls: 0.0651, decode.d6.loss_mask: 0.2364, decode.d6.loss_dice: 0.5205, decode.d7.loss_cls: 0.0686, decode.d7.loss_mask: 0.2373, decode.d7.loss_dice: 0.5199, decode.d8.loss_cls: 0.0793, decode.d8.loss_mask: 0.2376, decode.d8.loss_dice: 0.5209, loss: 8.4679
2023-09-29 15:23:19,988 - mmseg - INFO - Iter [35450/40000]	lr: 1.634e-07, eta: 3:55:20, time: 2.262, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0281, decode.loss_mask: 0.2458, decode.loss_dice: 0.4964, decode.d0.loss_cls: 0.1936, decode.d0.loss_mask: 0.2501, decode.d0.loss_dice: 0.4994, decode.d1.loss_cls: 0.0306, decode.d1.loss_mask: 0.2459, decode.d1.loss_dice: 0.5067, decode.d2.loss_cls: 0.0357, decode.d2.loss_mask: 0.2480, decode.d2.loss_dice: 0.4918, decode.d3.loss_cls: 0.0311, decode.d3.loss_mask: 0.2460, decode.d3.loss_dice: 0.4861, decode.d4.loss_cls: 0.0339, decode.d4.loss_mask: 0.2480, decode.d4.loss_dice: 0.4845, decode.d5.loss_cls: 0.0247, decode.d5.loss_mask: 0.2470, decode.d5.loss_dice: 0.4968, decode.d6.loss_cls: 0.0279, decode.d6.loss_mask: 0.2454, decode.d6.loss_dice: 0.4889, decode.d7.loss_cls: 0.0340, decode.d7.loss_mask: 0.2460, decode.d7.loss_dice: 0.4992, decode.d8.loss_cls: 0.0320, decode.d8.loss_mask: 0.2465, decode.d8.loss_dice: 0.4928, loss: 7.8829
2023-09-29 15:25:12,528 - mmseg - INFO - Iter [35500/40000]	lr: 1.616e-07, eta: 3:52:39, time: 2.251, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0748, decode.loss_mask: 0.2110, decode.loss_dice: 0.4883, decode.d0.loss_cls: 0.2163, decode.d0.loss_mask: 0.2127, decode.d0.loss_dice: 0.5140, decode.d1.loss_cls: 0.1066, decode.d1.loss_mask: 0.2116, decode.d1.loss_dice: 0.4978, decode.d2.loss_cls: 0.0904, decode.d2.loss_mask: 0.2093, decode.d2.loss_dice: 0.4814, decode.d3.loss_cls: 0.0873, decode.d3.loss_mask: 0.2107, decode.d3.loss_dice: 0.4932, decode.d4.loss_cls: 0.0737, decode.d4.loss_mask: 0.2113, decode.d4.loss_dice: 0.5029, decode.d5.loss_cls: 0.0806, decode.d5.loss_mask: 0.2131, decode.d5.loss_dice: 0.4938, decode.d6.loss_cls: 0.0884, decode.d6.loss_mask: 0.2105, decode.d6.loss_dice: 0.4948, decode.d7.loss_cls: 0.0874, decode.d7.loss_mask: 0.2106, decode.d7.loss_dice: 0.4943, decode.d8.loss_cls: 0.0848, decode.d8.loss_mask: 0.2101, decode.d8.loss_dice: 0.4908, loss: 8.0524
2023-09-29 15:27:05,612 - mmseg - INFO - Iter [35550/40000]	lr: 1.598e-07, eta: 3:49:59, time: 2.262, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0546, decode.loss_mask: 0.2606, decode.loss_dice: 0.5017, decode.d0.loss_cls: 0.2239, decode.d0.loss_mask: 0.2653, decode.d0.loss_dice: 0.5075, decode.d1.loss_cls: 0.0458, decode.d1.loss_mask: 0.2626, decode.d1.loss_dice: 0.4982, decode.d2.loss_cls: 0.0529, decode.d2.loss_mask: 0.2626, decode.d2.loss_dice: 0.4968, decode.d3.loss_cls: 0.0484, decode.d3.loss_mask: 0.2623, decode.d3.loss_dice: 0.5015, decode.d4.loss_cls: 0.0534, decode.d4.loss_mask: 0.2686, decode.d4.loss_dice: 0.4968, decode.d5.loss_cls: 0.0474, decode.d5.loss_mask: 0.2613, decode.d5.loss_dice: 0.5065, decode.d6.loss_cls: 0.0683, decode.d6.loss_mask: 0.2624, decode.d6.loss_dice: 0.5018, decode.d7.loss_cls: 0.0598, decode.d7.loss_mask: 0.2603, decode.d7.loss_dice: 0.5004, decode.d8.loss_cls: 0.0435, decode.d8.loss_mask: 0.2631, decode.d8.loss_dice: 0.5059, loss: 8.3442
2023-09-29 15:28:58,363 - mmseg - INFO - Iter [35600/40000]	lr: 1.580e-07, eta: 3:47:19, time: 2.255, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0916, decode.loss_mask: 0.2373, decode.loss_dice: 0.5344, decode.d0.loss_cls: 0.2635, decode.d0.loss_mask: 0.2407, decode.d0.loss_dice: 0.5446, decode.d1.loss_cls: 0.0764, decode.d1.loss_mask: 0.2389, decode.d1.loss_dice: 0.5416, decode.d2.loss_cls: 0.0856, decode.d2.loss_mask: 0.2375, decode.d2.loss_dice: 0.5406, decode.d3.loss_cls: 0.0815, decode.d3.loss_mask: 0.2375, decode.d3.loss_dice: 0.5303, decode.d4.loss_cls: 0.0953, decode.d4.loss_mask: 0.2379, decode.d4.loss_dice: 0.5383, decode.d5.loss_cls: 0.0816, decode.d5.loss_mask: 0.2377, decode.d5.loss_dice: 0.5285, decode.d6.loss_cls: 0.0983, decode.d6.loss_mask: 0.2377, decode.d6.loss_dice: 0.5408, decode.d7.loss_cls: 0.0854, decode.d7.loss_mask: 0.2381, decode.d7.loss_dice: 0.5352, decode.d8.loss_cls: 0.0729, decode.d8.loss_mask: 0.2385, decode.d8.loss_dice: 0.5420, loss: 8.7902
2023-09-29 15:30:50,781 - mmseg - INFO - Iter [35650/40000]	lr: 1.562e-07, eta: 3:44:38, time: 2.248, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0565, decode.loss_mask: 0.2515, decode.loss_dice: 0.5154, decode.d0.loss_cls: 0.2174, decode.d0.loss_mask: 0.2550, decode.d0.loss_dice: 0.5251, decode.d1.loss_cls: 0.0526, decode.d1.loss_mask: 0.2522, decode.d1.loss_dice: 0.5089, decode.d2.loss_cls: 0.0479, decode.d2.loss_mask: 0.2508, decode.d2.loss_dice: 0.5126, decode.d3.loss_cls: 0.0653, decode.d3.loss_mask: 0.2507, decode.d3.loss_dice: 0.5043, decode.d4.loss_cls: 0.0584, decode.d4.loss_mask: 0.2504, decode.d4.loss_dice: 0.5045, decode.d5.loss_cls: 0.0651, decode.d5.loss_mask: 0.2502, decode.d5.loss_dice: 0.5116, decode.d6.loss_cls: 0.0472, decode.d6.loss_mask: 0.2506, decode.d6.loss_dice: 0.5025, decode.d7.loss_cls: 0.0515, decode.d7.loss_mask: 0.2509, decode.d7.loss_dice: 0.5043, decode.d8.loss_cls: 0.0642, decode.d8.loss_mask: 0.2519, decode.d8.loss_dice: 0.5043, loss: 8.3340
2023-09-29 15:32:43,738 - mmseg - INFO - Iter [35700/40000]	lr: 1.544e-07, eta: 3:41:58, time: 2.259, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0580, decode.loss_mask: 0.2558, decode.loss_dice: 0.4987, decode.d0.loss_cls: 0.2168, decode.d0.loss_mask: 0.2630, decode.d0.loss_dice: 0.5263, decode.d1.loss_cls: 0.0775, decode.d1.loss_mask: 0.2573, decode.d1.loss_dice: 0.5006, decode.d2.loss_cls: 0.0627, decode.d2.loss_mask: 0.2550, decode.d2.loss_dice: 0.4937, decode.d3.loss_cls: 0.0559, decode.d3.loss_mask: 0.2555, decode.d3.loss_dice: 0.5042, decode.d4.loss_cls: 0.0672, decode.d4.loss_mask: 0.2560, decode.d4.loss_dice: 0.5068, decode.d5.loss_cls: 0.0659, decode.d5.loss_mask: 0.2552, decode.d5.loss_dice: 0.4950, decode.d6.loss_cls: 0.0736, decode.d6.loss_mask: 0.2552, decode.d6.loss_dice: 0.5000, decode.d7.loss_cls: 0.0617, decode.d7.loss_mask: 0.2554, decode.d7.loss_dice: 0.4991, decode.d8.loss_cls: 0.0556, decode.d8.loss_mask: 0.2556, decode.d8.loss_dice: 0.5022, loss: 8.3855
2023-09-29 15:34:36,403 - mmseg - INFO - Iter [35750/40000]	lr: 1.526e-07, eta: 3:39:19, time: 2.253, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0405, decode.loss_mask: 0.2496, decode.loss_dice: 0.4933, decode.d0.loss_cls: 0.2212, decode.d0.loss_mask: 0.2523, decode.d0.loss_dice: 0.5049, decode.d1.loss_cls: 0.0521, decode.d1.loss_mask: 0.2503, decode.d1.loss_dice: 0.4817, decode.d2.loss_cls: 0.0466, decode.d2.loss_mask: 0.2488, decode.d2.loss_dice: 0.4827, decode.d3.loss_cls: 0.0712, decode.d3.loss_mask: 0.2489, decode.d3.loss_dice: 0.4887, decode.d4.loss_cls: 0.0568, decode.d4.loss_mask: 0.2483, decode.d4.loss_dice: 0.4881, decode.d5.loss_cls: 0.0513, decode.d5.loss_mask: 0.2478, decode.d5.loss_dice: 0.4877, decode.d6.loss_cls: 0.0609, decode.d6.loss_mask: 0.2489, decode.d6.loss_dice: 0.4762, decode.d7.loss_cls: 0.0667, decode.d7.loss_mask: 0.2486, decode.d7.loss_dice: 0.4805, decode.d8.loss_cls: 0.0534, decode.d8.loss_mask: 0.2482, decode.d8.loss_dice: 0.4768, loss: 8.0729
2023-09-29 15:36:29,068 - mmseg - INFO - Iter [35800/40000]	lr: 1.508e-07, eta: 3:36:39, time: 2.253, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0648, decode.loss_mask: 0.2610, decode.loss_dice: 0.5270, decode.d0.loss_cls: 0.2183, decode.d0.loss_mask: 0.2654, decode.d0.loss_dice: 0.5410, decode.d1.loss_cls: 0.0746, decode.d1.loss_mask: 0.2600, decode.d1.loss_dice: 0.5254, decode.d2.loss_cls: 0.0809, decode.d2.loss_mask: 0.2576, decode.d2.loss_dice: 0.5132, decode.d3.loss_cls: 0.0974, decode.d3.loss_mask: 0.2594, decode.d3.loss_dice: 0.5256, decode.d4.loss_cls: 0.0694, decode.d4.loss_mask: 0.2598, decode.d4.loss_dice: 0.5288, decode.d5.loss_cls: 0.0634, decode.d5.loss_mask: 0.2596, decode.d5.loss_dice: 0.5200, decode.d6.loss_cls: 0.0578, decode.d6.loss_mask: 0.2612, decode.d6.loss_dice: 0.5144, decode.d7.loss_cls: 0.0692, decode.d7.loss_mask: 0.2597, decode.d7.loss_dice: 0.5213, decode.d8.loss_cls: 0.0785, decode.d8.loss_mask: 0.2607, decode.d8.loss_dice: 0.5195, loss: 8.7150
2023-09-29 15:38:21,773 - mmseg - INFO - Iter [35850/40000]	lr: 1.490e-07, eta: 3:33:59, time: 2.254, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0615, decode.loss_mask: 0.2313, decode.loss_dice: 0.4971, decode.d0.loss_cls: 0.2434, decode.d0.loss_mask: 0.2319, decode.d0.loss_dice: 0.4977, decode.d1.loss_cls: 0.0867, decode.d1.loss_mask: 0.2319, decode.d1.loss_dice: 0.4861, decode.d2.loss_cls: 0.0567, decode.d2.loss_mask: 0.2314, decode.d2.loss_dice: 0.4927, decode.d3.loss_cls: 0.0607, decode.d3.loss_mask: 0.2318, decode.d3.loss_dice: 0.4896, decode.d4.loss_cls: 0.0467, decode.d4.loss_mask: 0.2306, decode.d4.loss_dice: 0.4931, decode.d5.loss_cls: 0.0606, decode.d5.loss_mask: 0.2309, decode.d5.loss_dice: 0.4840, decode.d6.loss_cls: 0.0641, decode.d6.loss_mask: 0.2306, decode.d6.loss_dice: 0.4912, decode.d7.loss_cls: 0.0476, decode.d7.loss_mask: 0.2304, decode.d7.loss_dice: 0.4956, decode.d8.loss_cls: 0.0580, decode.d8.loss_mask: 0.2305, decode.d8.loss_dice: 0.4852, loss: 8.0099
2023-09-29 15:40:19,385 - mmseg - INFO - Iter [35900/40000]	lr: 1.472e-07, eta: 3:31:20, time: 2.352, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0536, decode.loss_mask: 0.2966, decode.loss_dice: 0.5435, decode.d0.loss_cls: 0.2191, decode.d0.loss_mask: 0.2947, decode.d0.loss_dice: 0.5714, decode.d1.loss_cls: 0.0865, decode.d1.loss_mask: 0.2943, decode.d1.loss_dice: 0.5468, decode.d2.loss_cls: 0.0732, decode.d2.loss_mask: 0.2972, decode.d2.loss_dice: 0.5537, decode.d3.loss_cls: 0.0711, decode.d3.loss_mask: 0.2975, decode.d3.loss_dice: 0.5467, decode.d4.loss_cls: 0.0600, decode.d4.loss_mask: 0.2990, decode.d4.loss_dice: 0.5585, decode.d5.loss_cls: 0.0664, decode.d5.loss_mask: 0.2969, decode.d5.loss_dice: 0.5491, decode.d6.loss_cls: 0.0602, decode.d6.loss_mask: 0.2976, decode.d6.loss_dice: 0.5453, decode.d7.loss_cls: 0.0711, decode.d7.loss_mask: 0.2990, decode.d7.loss_dice: 0.5442, decode.d8.loss_cls: 0.0489, decode.d8.loss_mask: 0.2979, decode.d8.loss_dice: 0.5508, loss: 9.2911
2023-09-29 15:42:11,985 - mmseg - INFO - Iter [35950/40000]	lr: 1.454e-07, eta: 3:28:41, time: 2.253, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0774, decode.loss_mask: 0.2754, decode.loss_dice: 0.5230, decode.d0.loss_cls: 0.2352, decode.d0.loss_mask: 0.2823, decode.d0.loss_dice: 0.5336, decode.d1.loss_cls: 0.0853, decode.d1.loss_mask: 0.2778, decode.d1.loss_dice: 0.5385, decode.d2.loss_cls: 0.0730, decode.d2.loss_mask: 0.2778, decode.d2.loss_dice: 0.5303, decode.d3.loss_cls: 0.0595, decode.d3.loss_mask: 0.2765, decode.d3.loss_dice: 0.5206, decode.d4.loss_cls: 0.0740, decode.d4.loss_mask: 0.2782, decode.d4.loss_dice: 0.5196, decode.d5.loss_cls: 0.0605, decode.d5.loss_mask: 0.2774, decode.d5.loss_dice: 0.5275, decode.d6.loss_cls: 0.0781, decode.d6.loss_mask: 0.2775, decode.d6.loss_dice: 0.5307, decode.d7.loss_cls: 0.0749, decode.d7.loss_mask: 0.2757, decode.d7.loss_dice: 0.5284, decode.d8.loss_cls: 0.0696, decode.d8.loss_mask: 0.2769, decode.d8.loss_dice: 0.5231, loss: 8.9383
2023-09-29 15:44:04,913 - mmseg - INFO - Saving checkpoint at 36000 iterations
2023-09-29 15:44:24,899 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 15:44:24,899 - mmseg - INFO - Iter [36000/40000]	lr: 1.436e-07, eta: 3:26:04, time: 2.658, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0592, decode.loss_mask: 0.2390, decode.loss_dice: 0.5128, decode.d0.loss_cls: 0.2308, decode.d0.loss_mask: 0.2422, decode.d0.loss_dice: 0.5297, decode.d1.loss_cls: 0.1033, decode.d1.loss_mask: 0.2389, decode.d1.loss_dice: 0.5201, decode.d2.loss_cls: 0.0777, decode.d2.loss_mask: 0.2383, decode.d2.loss_dice: 0.5137, decode.d3.loss_cls: 0.0685, decode.d3.loss_mask: 0.2384, decode.d3.loss_dice: 0.5209, decode.d4.loss_cls: 0.0717, decode.d4.loss_mask: 0.2378, decode.d4.loss_dice: 0.5235, decode.d5.loss_cls: 0.0752, decode.d5.loss_mask: 0.2384, decode.d5.loss_dice: 0.5159, decode.d6.loss_cls: 0.0716, decode.d6.loss_mask: 0.2386, decode.d6.loss_dice: 0.5153, decode.d7.loss_cls: 0.0781, decode.d7.loss_mask: 0.2389, decode.d7.loss_dice: 0.5200, decode.d8.loss_cls: 0.0740, decode.d8.loss_mask: 0.2386, decode.d8.loss_dice: 0.5142, loss: 8.4854
2023-09-29 16:01:40,225 - mmseg - INFO - per class results:
2023-09-29 16:01:40,226 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 92.83 | 97.11 |
|    Sidewalk   |  69.3 | 81.95 |
|  Construction | 82.26 | 94.29 |
|     Fence     | 33.96 | 37.81 |
|      Pole     | 57.91 |  69.9 |
| Traffic Light | 67.69 | 78.09 |
|  Traffic Sign | 72.36 | 80.51 |
|     Nature    | 88.49 | 93.62 |
|      Sky      | 96.63 | 98.04 |
|     Person    | 33.63 | 36.09 |
|     Rider     |  8.63 | 72.74 |
|      Car      | 91.56 | 94.67 |
|   background  | 96.12 | 97.64 |
+---------------+-------+-------+
2023-09-29 16:01:40,226 - mmseg - INFO - Summary:
2023-09-29 16:01:40,226 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.47 | 68.57 | 79.42 |
+-------+-------+-------+
2023-09-29 16:01:40,229 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 16:01:40,230 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9447, mIoU: 0.6857, mAcc: 0.7942, IoU.Road: 0.9283, IoU.Sidewalk: 0.6930, IoU.Construction: 0.8226, IoU.Fence: 0.3396, IoU.Pole: 0.5791, IoU.Traffic Light: 0.6769, IoU.Traffic Sign: 0.7236, IoU.Nature: 0.8849, IoU.Sky: 0.9663, IoU.Person: 0.3363, IoU.Rider: 0.0863, IoU.Car: 0.9156, IoU.background: 0.9612, Acc.Road: 0.9711, Acc.Sidewalk: 0.8195, Acc.Construction: 0.9429, Acc.Fence: 0.3781, Acc.Pole: 0.6990, Acc.Traffic Light: 0.7809, Acc.Traffic Sign: 0.8051, Acc.Nature: 0.9362, Acc.Sky: 0.9804, Acc.Person: 0.3609, Acc.Rider: 0.7274, Acc.Car: 0.9467, Acc.background: 0.9764
2023-09-29 16:03:32,897 - mmseg - INFO - Iter [36050/40000]	lr: 1.418e-07, eta: 3:25:18, time: 22.960, data_time: 20.738, memory: 21542, decode.loss_cls: 0.0351, decode.loss_mask: 0.2380, decode.loss_dice: 0.5515, decode.d0.loss_cls: 0.1967, decode.d0.loss_mask: 0.2392, decode.d0.loss_dice: 0.5631, decode.d1.loss_cls: 0.0483, decode.d1.loss_mask: 0.2380, decode.d1.loss_dice: 0.5548, decode.d2.loss_cls: 0.0430, decode.d2.loss_mask: 0.2387, decode.d2.loss_dice: 0.5525, decode.d3.loss_cls: 0.0372, decode.d3.loss_mask: 0.2388, decode.d3.loss_dice: 0.5454, decode.d4.loss_cls: 0.0388, decode.d4.loss_mask: 0.2387, decode.d4.loss_dice: 0.5548, decode.d5.loss_cls: 0.0467, decode.d5.loss_mask: 0.2380, decode.d5.loss_dice: 0.5539, decode.d6.loss_cls: 0.0450, decode.d6.loss_mask: 0.2380, decode.d6.loss_dice: 0.5512, decode.d7.loss_cls: 0.0469, decode.d7.loss_mask: 0.2393, decode.d7.loss_dice: 0.5508, decode.d8.loss_cls: 0.0391, decode.d8.loss_mask: 0.2377, decode.d8.loss_dice: 0.5573, loss: 8.4964
2023-09-29 16:05:26,239 - mmseg - INFO - Iter [36100/40000]	lr: 1.400e-07, eta: 3:22:38, time: 2.267, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0382, decode.loss_mask: 0.2663, decode.loss_dice: 0.5005, decode.d0.loss_cls: 0.2006, decode.d0.loss_mask: 0.2712, decode.d0.loss_dice: 0.4952, decode.d1.loss_cls: 0.0517, decode.d1.loss_mask: 0.2640, decode.d1.loss_dice: 0.4953, decode.d2.loss_cls: 0.0273, decode.d2.loss_mask: 0.2644, decode.d2.loss_dice: 0.4894, decode.d3.loss_cls: 0.0425, decode.d3.loss_mask: 0.2655, decode.d3.loss_dice: 0.4951, decode.d4.loss_cls: 0.0379, decode.d4.loss_mask: 0.2649, decode.d4.loss_dice: 0.4980, decode.d5.loss_cls: 0.0281, decode.d5.loss_mask: 0.2645, decode.d5.loss_dice: 0.4896, decode.d6.loss_cls: 0.0410, decode.d6.loss_mask: 0.2654, decode.d6.loss_dice: 0.5007, decode.d7.loss_cls: 0.0443, decode.d7.loss_mask: 0.2644, decode.d7.loss_dice: 0.5013, decode.d8.loss_cls: 0.0360, decode.d8.loss_mask: 0.2656, decode.d8.loss_dice: 0.4944, loss: 8.1635
2023-09-29 16:07:18,787 - mmseg - INFO - Iter [36150/40000]	lr: 1.382e-07, eta: 3:19:57, time: 2.251, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0536, decode.loss_mask: 0.2434, decode.loss_dice: 0.5310, decode.d0.loss_cls: 0.2026, decode.d0.loss_mask: 0.2461, decode.d0.loss_dice: 0.5404, decode.d1.loss_cls: 0.0741, decode.d1.loss_mask: 0.2443, decode.d1.loss_dice: 0.5264, decode.d2.loss_cls: 0.0511, decode.d2.loss_mask: 0.2445, decode.d2.loss_dice: 0.5265, decode.d3.loss_cls: 0.0578, decode.d3.loss_mask: 0.2440, decode.d3.loss_dice: 0.5216, decode.d4.loss_cls: 0.0446, decode.d4.loss_mask: 0.2448, decode.d4.loss_dice: 0.5244, decode.d5.loss_cls: 0.0582, decode.d5.loss_mask: 0.2452, decode.d5.loss_dice: 0.5240, decode.d6.loss_cls: 0.0494, decode.d6.loss_mask: 0.2437, decode.d6.loss_dice: 0.5310, decode.d7.loss_cls: 0.0565, decode.d7.loss_mask: 0.2452, decode.d7.loss_dice: 0.5233, decode.d8.loss_cls: 0.0495, decode.d8.loss_mask: 0.2440, decode.d8.loss_dice: 0.5267, loss: 8.4179
2023-09-29 16:09:11,011 - mmseg - INFO - Iter [36200/40000]	lr: 1.364e-07, eta: 3:17:17, time: 2.244, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0554, decode.loss_mask: 0.2634, decode.loss_dice: 0.5495, decode.d0.loss_cls: 0.2133, decode.d0.loss_mask: 0.2650, decode.d0.loss_dice: 0.5492, decode.d1.loss_cls: 0.0645, decode.d1.loss_mask: 0.2633, decode.d1.loss_dice: 0.5454, decode.d2.loss_cls: 0.0563, decode.d2.loss_mask: 0.2621, decode.d2.loss_dice: 0.5399, decode.d3.loss_cls: 0.0671, decode.d3.loss_mask: 0.2632, decode.d3.loss_dice: 0.5429, decode.d4.loss_cls: 0.0580, decode.d4.loss_mask: 0.2643, decode.d4.loss_dice: 0.5508, decode.d5.loss_cls: 0.0449, decode.d5.loss_mask: 0.2635, decode.d5.loss_dice: 0.5404, decode.d6.loss_cls: 0.0664, decode.d6.loss_mask: 0.2633, decode.d6.loss_dice: 0.5513, decode.d7.loss_cls: 0.0427, decode.d7.loss_mask: 0.2637, decode.d7.loss_dice: 0.5435, decode.d8.loss_cls: 0.0421, decode.d8.loss_mask: 0.2615, decode.d8.loss_dice: 0.5462, loss: 8.8032
2023-09-29 16:11:06,694 - mmseg - INFO - Iter [36250/40000]	lr: 1.346e-07, eta: 3:14:37, time: 2.314, data_time: 0.085, memory: 21542, decode.loss_cls: 0.0534, decode.loss_mask: 0.2558, decode.loss_dice: 0.5259, decode.d0.loss_cls: 0.2421, decode.d0.loss_mask: 0.2583, decode.d0.loss_dice: 0.5378, decode.d1.loss_cls: 0.0675, decode.d1.loss_mask: 0.2545, decode.d1.loss_dice: 0.5270, decode.d2.loss_cls: 0.0726, decode.d2.loss_mask: 0.2530, decode.d2.loss_dice: 0.5240, decode.d3.loss_cls: 0.0492, decode.d3.loss_mask: 0.2556, decode.d3.loss_dice: 0.5252, decode.d4.loss_cls: 0.0592, decode.d4.loss_mask: 0.2555, decode.d4.loss_dice: 0.5263, decode.d5.loss_cls: 0.0586, decode.d5.loss_mask: 0.2552, decode.d5.loss_dice: 0.5212, decode.d6.loss_cls: 0.0510, decode.d6.loss_mask: 0.2569, decode.d6.loss_dice: 0.5312, decode.d7.loss_cls: 0.0453, decode.d7.loss_mask: 0.2564, decode.d7.loss_dice: 0.5324, decode.d8.loss_cls: 0.0459, decode.d8.loss_mask: 0.2562, decode.d8.loss_dice: 0.5266, loss: 8.5800
2023-09-29 16:12:59,309 - mmseg - INFO - Iter [36300/40000]	lr: 1.328e-07, eta: 3:11:57, time: 2.252, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0446, decode.loss_mask: 0.2331, decode.loss_dice: 0.4965, decode.d0.loss_cls: 0.2240, decode.d0.loss_mask: 0.2363, decode.d0.loss_dice: 0.5127, decode.d1.loss_cls: 0.0617, decode.d1.loss_mask: 0.2351, decode.d1.loss_dice: 0.4968, decode.d2.loss_cls: 0.0431, decode.d2.loss_mask: 0.2344, decode.d2.loss_dice: 0.4857, decode.d3.loss_cls: 0.0439, decode.d3.loss_mask: 0.2329, decode.d3.loss_dice: 0.5035, decode.d4.loss_cls: 0.0560, decode.d4.loss_mask: 0.2342, decode.d4.loss_dice: 0.5031, decode.d5.loss_cls: 0.0422, decode.d5.loss_mask: 0.2345, decode.d5.loss_dice: 0.5015, decode.d6.loss_cls: 0.0400, decode.d6.loss_mask: 0.2326, decode.d6.loss_dice: 0.4866, decode.d7.loss_cls: 0.0500, decode.d7.loss_mask: 0.2327, decode.d7.loss_dice: 0.4987, decode.d8.loss_cls: 0.0464, decode.d8.loss_mask: 0.2331, decode.d8.loss_dice: 0.4855, loss: 7.9614
2023-09-29 16:14:52,506 - mmseg - INFO - Iter [36350/40000]	lr: 1.311e-07, eta: 3:09:17, time: 2.264, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0678, decode.loss_mask: 0.2285, decode.loss_dice: 0.5317, decode.d0.loss_cls: 0.2208, decode.d0.loss_mask: 0.2315, decode.d0.loss_dice: 0.5266, decode.d1.loss_cls: 0.1057, decode.d1.loss_mask: 0.2280, decode.d1.loss_dice: 0.5314, decode.d2.loss_cls: 0.0753, decode.d2.loss_mask: 0.2283, decode.d2.loss_dice: 0.5239, decode.d3.loss_cls: 0.0551, decode.d3.loss_mask: 0.2283, decode.d3.loss_dice: 0.5281, decode.d4.loss_cls: 0.0529, decode.d4.loss_mask: 0.2295, decode.d4.loss_dice: 0.5262, decode.d5.loss_cls: 0.0725, decode.d5.loss_mask: 0.2286, decode.d5.loss_dice: 0.5312, decode.d6.loss_cls: 0.0634, decode.d6.loss_mask: 0.2297, decode.d6.loss_dice: 0.5262, decode.d7.loss_cls: 0.0690, decode.d7.loss_mask: 0.2288, decode.d7.loss_dice: 0.5280, decode.d8.loss_cls: 0.0546, decode.d8.loss_mask: 0.2286, decode.d8.loss_dice: 0.5267, loss: 8.4069
2023-09-29 16:16:45,623 - mmseg - INFO - Iter [36400/40000]	lr: 1.293e-07, eta: 3:06:37, time: 2.262, data_time: 0.025, memory: 21542, decode.loss_cls: 0.0556, decode.loss_mask: 0.2657, decode.loss_dice: 0.4604, decode.d0.loss_cls: 0.1980, decode.d0.loss_mask: 0.2778, decode.d0.loss_dice: 0.4838, decode.d1.loss_cls: 0.0602, decode.d1.loss_mask: 0.2726, decode.d1.loss_dice: 0.4783, decode.d2.loss_cls: 0.0590, decode.d2.loss_mask: 0.2669, decode.d2.loss_dice: 0.4666, decode.d3.loss_cls: 0.0618, decode.d3.loss_mask: 0.2664, decode.d3.loss_dice: 0.4558, decode.d4.loss_cls: 0.0536, decode.d4.loss_mask: 0.2684, decode.d4.loss_dice: 0.4666, decode.d5.loss_cls: 0.0525, decode.d5.loss_mask: 0.2695, decode.d5.loss_dice: 0.4711, decode.d6.loss_cls: 0.0536, decode.d6.loss_mask: 0.2673, decode.d6.loss_dice: 0.4671, decode.d7.loss_cls: 0.0640, decode.d7.loss_mask: 0.2692, decode.d7.loss_dice: 0.4663, decode.d8.loss_cls: 0.0589, decode.d8.loss_mask: 0.2664, decode.d8.loss_dice: 0.4650, loss: 8.0884
2023-09-29 16:18:38,567 - mmseg - INFO - Iter [36450/40000]	lr: 1.275e-07, eta: 3:03:57, time: 2.259, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0582, decode.loss_mask: 0.2522, decode.loss_dice: 0.5146, decode.d0.loss_cls: 0.2184, decode.d0.loss_mask: 0.2583, decode.d0.loss_dice: 0.5274, decode.d1.loss_cls: 0.0778, decode.d1.loss_mask: 0.2558, decode.d1.loss_dice: 0.5172, decode.d2.loss_cls: 0.0789, decode.d2.loss_mask: 0.2539, decode.d2.loss_dice: 0.5240, decode.d3.loss_cls: 0.0695, decode.d3.loss_mask: 0.2525, decode.d3.loss_dice: 0.5147, decode.d4.loss_cls: 0.0897, decode.d4.loss_mask: 0.2609, decode.d4.loss_dice: 0.5242, decode.d5.loss_cls: 0.0691, decode.d5.loss_mask: 0.2525, decode.d5.loss_dice: 0.5158, decode.d6.loss_cls: 0.0736, decode.d6.loss_mask: 0.2539, decode.d6.loss_dice: 0.5121, decode.d7.loss_cls: 0.0766, decode.d7.loss_mask: 0.2521, decode.d7.loss_dice: 0.5168, decode.d8.loss_cls: 0.0759, decode.d8.loss_mask: 0.2527, decode.d8.loss_dice: 0.5226, loss: 8.6216
2023-09-29 16:20:31,330 - mmseg - INFO - Iter [36500/40000]	lr: 1.257e-07, eta: 3:01:18, time: 2.255, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0721, decode.loss_mask: 0.2417, decode.loss_dice: 0.4962, decode.d0.loss_cls: 0.1976, decode.d0.loss_mask: 0.2461, decode.d0.loss_dice: 0.5251, decode.d1.loss_cls: 0.0624, decode.d1.loss_mask: 0.2435, decode.d1.loss_dice: 0.5096, decode.d2.loss_cls: 0.0760, decode.d2.loss_mask: 0.2420, decode.d2.loss_dice: 0.5073, decode.d3.loss_cls: 0.0686, decode.d3.loss_mask: 0.2412, decode.d3.loss_dice: 0.5055, decode.d4.loss_cls: 0.0691, decode.d4.loss_mask: 0.2422, decode.d4.loss_dice: 0.5064, decode.d5.loss_cls: 0.0728, decode.d5.loss_mask: 0.2429, decode.d5.loss_dice: 0.5124, decode.d6.loss_cls: 0.0671, decode.d6.loss_mask: 0.2421, decode.d6.loss_dice: 0.5002, decode.d7.loss_cls: 0.0566, decode.d7.loss_mask: 0.2425, decode.d7.loss_dice: 0.5059, decode.d8.loss_cls: 0.0598, decode.d8.loss_mask: 0.2426, decode.d8.loss_dice: 0.5149, loss: 8.3121
2023-09-29 16:22:24,576 - mmseg - INFO - Iter [36550/40000]	lr: 1.239e-07, eta: 2:58:39, time: 2.265, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0643, decode.loss_mask: 0.2734, decode.loss_dice: 0.5174, decode.d0.loss_cls: 0.2297, decode.d0.loss_mask: 0.2807, decode.d0.loss_dice: 0.5263, decode.d1.loss_cls: 0.0753, decode.d1.loss_mask: 0.2779, decode.d1.loss_dice: 0.5304, decode.d2.loss_cls: 0.0693, decode.d2.loss_mask: 0.2738, decode.d2.loss_dice: 0.5075, decode.d3.loss_cls: 0.0665, decode.d3.loss_mask: 0.2727, decode.d3.loss_dice: 0.5178, decode.d4.loss_cls: 0.0858, decode.d4.loss_mask: 0.2731, decode.d4.loss_dice: 0.5184, decode.d5.loss_cls: 0.0842, decode.d5.loss_mask: 0.2733, decode.d5.loss_dice: 0.5179, decode.d6.loss_cls: 0.0648, decode.d6.loss_mask: 0.2747, decode.d6.loss_dice: 0.5153, decode.d7.loss_cls: 0.0646, decode.d7.loss_mask: 0.2753, decode.d7.loss_dice: 0.5138, decode.d8.loss_cls: 0.0645, decode.d8.loss_mask: 0.2742, decode.d8.loss_dice: 0.5075, loss: 8.7905
2023-09-29 16:24:17,390 - mmseg - INFO - Iter [36600/40000]	lr: 1.221e-07, eta: 2:55:59, time: 2.256, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0480, decode.loss_mask: 0.2578, decode.loss_dice: 0.5119, decode.d0.loss_cls: 0.2044, decode.d0.loss_mask: 0.2635, decode.d0.loss_dice: 0.5157, decode.d1.loss_cls: 0.1062, decode.d1.loss_mask: 0.2585, decode.d1.loss_dice: 0.5077, decode.d2.loss_cls: 0.0562, decode.d2.loss_mask: 0.2588, decode.d2.loss_dice: 0.5167, decode.d3.loss_cls: 0.0502, decode.d3.loss_mask: 0.2591, decode.d3.loss_dice: 0.5027, decode.d4.loss_cls: 0.0447, decode.d4.loss_mask: 0.2591, decode.d4.loss_dice: 0.5069, decode.d5.loss_cls: 0.0500, decode.d5.loss_mask: 0.2592, decode.d5.loss_dice: 0.5162, decode.d6.loss_cls: 0.0373, decode.d6.loss_mask: 0.2579, decode.d6.loss_dice: 0.5148, decode.d7.loss_cls: 0.0392, decode.d7.loss_mask: 0.2584, decode.d7.loss_dice: 0.5091, decode.d8.loss_cls: 0.0478, decode.d8.loss_mask: 0.2586, decode.d8.loss_dice: 0.5145, loss: 8.3909
2023-09-29 16:26:09,879 - mmseg - INFO - Iter [36650/40000]	lr: 1.203e-07, eta: 2:53:20, time: 2.250, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0447, decode.loss_mask: 0.2500, decode.loss_dice: 0.5433, decode.d0.loss_cls: 0.2183, decode.d0.loss_mask: 0.2498, decode.d0.loss_dice: 0.5393, decode.d1.loss_cls: 0.0800, decode.d1.loss_mask: 0.2502, decode.d1.loss_dice: 0.5517, decode.d2.loss_cls: 0.0358, decode.d2.loss_mask: 0.2518, decode.d2.loss_dice: 0.5456, decode.d3.loss_cls: 0.0385, decode.d3.loss_mask: 0.2500, decode.d3.loss_dice: 0.5434, decode.d4.loss_cls: 0.0527, decode.d4.loss_mask: 0.2500, decode.d4.loss_dice: 0.5417, decode.d5.loss_cls: 0.0462, decode.d5.loss_mask: 0.2509, decode.d5.loss_dice: 0.5439, decode.d6.loss_cls: 0.0387, decode.d6.loss_mask: 0.2508, decode.d6.loss_dice: 0.5455, decode.d7.loss_cls: 0.0338, decode.d7.loss_mask: 0.2510, decode.d7.loss_dice: 0.5484, decode.d8.loss_cls: 0.0278, decode.d8.loss_mask: 0.2500, decode.d8.loss_dice: 0.5399, loss: 8.5639
2023-09-29 16:28:02,942 - mmseg - INFO - Iter [36700/40000]	lr: 1.185e-07, eta: 2:50:41, time: 2.261, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0324, decode.loss_mask: 0.2621, decode.loss_dice: 0.5130, decode.d0.loss_cls: 0.2033, decode.d0.loss_mask: 0.2677, decode.d0.loss_dice: 0.5184, decode.d1.loss_cls: 0.0471, decode.d1.loss_mask: 0.2658, decode.d1.loss_dice: 0.5096, decode.d2.loss_cls: 0.0497, decode.d2.loss_mask: 0.2639, decode.d2.loss_dice: 0.5048, decode.d3.loss_cls: 0.0446, decode.d3.loss_mask: 0.2644, decode.d3.loss_dice: 0.5074, decode.d4.loss_cls: 0.0487, decode.d4.loss_mask: 0.2636, decode.d4.loss_dice: 0.5169, decode.d5.loss_cls: 0.0487, decode.d5.loss_mask: 0.2620, decode.d5.loss_dice: 0.5135, decode.d6.loss_cls: 0.0486, decode.d6.loss_mask: 0.2637, decode.d6.loss_dice: 0.5092, decode.d7.loss_cls: 0.0408, decode.d7.loss_mask: 0.2639, decode.d7.loss_dice: 0.5147, decode.d8.loss_cls: 0.0445, decode.d8.loss_mask: 0.2624, decode.d8.loss_dice: 0.5137, loss: 8.3692
2023-09-29 16:29:55,810 - mmseg - INFO - Iter [36750/40000]	lr: 1.167e-07, eta: 2:48:02, time: 2.257, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0649, decode.loss_mask: 0.2264, decode.loss_dice: 0.4843, decode.d0.loss_cls: 0.2163, decode.d0.loss_mask: 0.2307, decode.d0.loss_dice: 0.5011, decode.d1.loss_cls: 0.0596, decode.d1.loss_mask: 0.2281, decode.d1.loss_dice: 0.5016, decode.d2.loss_cls: 0.0813, decode.d2.loss_mask: 0.2271, decode.d2.loss_dice: 0.4772, decode.d3.loss_cls: 0.0866, decode.d3.loss_mask: 0.2265, decode.d3.loss_dice: 0.4868, decode.d4.loss_cls: 0.0895, decode.d4.loss_mask: 0.2274, decode.d4.loss_dice: 0.4972, decode.d5.loss_cls: 0.0747, decode.d5.loss_mask: 0.2275, decode.d5.loss_dice: 0.4954, decode.d6.loss_cls: 0.0686, decode.d6.loss_mask: 0.2277, decode.d6.loss_dice: 0.4996, decode.d7.loss_cls: 0.0688, decode.d7.loss_mask: 0.2271, decode.d7.loss_dice: 0.4921, decode.d8.loss_cls: 0.0874, decode.d8.loss_mask: 0.2270, decode.d8.loss_dice: 0.4923, loss: 8.1007
2023-09-29 16:31:47,953 - mmseg - INFO - Iter [36800/40000]	lr: 1.149e-07, eta: 2:45:23, time: 2.243, data_time: 0.034, memory: 21542, decode.loss_cls: 0.0544, decode.loss_mask: 0.2375, decode.loss_dice: 0.4946, decode.d0.loss_cls: 0.2122, decode.d0.loss_mask: 0.2448, decode.d0.loss_dice: 0.4967, decode.d1.loss_cls: 0.0807, decode.d1.loss_mask: 0.2398, decode.d1.loss_dice: 0.4900, decode.d2.loss_cls: 0.0639, decode.d2.loss_mask: 0.2381, decode.d2.loss_dice: 0.4908, decode.d3.loss_cls: 0.0674, decode.d3.loss_mask: 0.2382, decode.d3.loss_dice: 0.4883, decode.d4.loss_cls: 0.0638, decode.d4.loss_mask: 0.2402, decode.d4.loss_dice: 0.4897, decode.d5.loss_cls: 0.0593, decode.d5.loss_mask: 0.2399, decode.d5.loss_dice: 0.4815, decode.d6.loss_cls: 0.0583, decode.d6.loss_mask: 0.2388, decode.d6.loss_dice: 0.4827, decode.d7.loss_cls: 0.0625, decode.d7.loss_mask: 0.2378, decode.d7.loss_dice: 0.4872, decode.d8.loss_cls: 0.0630, decode.d8.loss_mask: 0.2387, decode.d8.loss_dice: 0.4827, loss: 8.0634
2023-09-29 16:33:40,555 - mmseg - INFO - Iter [36850/40000]	lr: 1.131e-07, eta: 2:42:45, time: 2.252, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0527, decode.loss_mask: 0.2411, decode.loss_dice: 0.5321, decode.d0.loss_cls: 0.2044, decode.d0.loss_mask: 0.2429, decode.d0.loss_dice: 0.5333, decode.d1.loss_cls: 0.0491, decode.d1.loss_mask: 0.2429, decode.d1.loss_dice: 0.5398, decode.d2.loss_cls: 0.0389, decode.d2.loss_mask: 0.2429, decode.d2.loss_dice: 0.5354, decode.d3.loss_cls: 0.0484, decode.d3.loss_mask: 0.2423, decode.d3.loss_dice: 0.5265, decode.d4.loss_cls: 0.0568, decode.d4.loss_mask: 0.2431, decode.d4.loss_dice: 0.5257, decode.d5.loss_cls: 0.0417, decode.d5.loss_mask: 0.2416, decode.d5.loss_dice: 0.5284, decode.d6.loss_cls: 0.0364, decode.d6.loss_mask: 0.2435, decode.d6.loss_dice: 0.5284, decode.d7.loss_cls: 0.0348, decode.d7.loss_mask: 0.2428, decode.d7.loss_dice: 0.5321, decode.d8.loss_cls: 0.0405, decode.d8.loss_mask: 0.2423, decode.d8.loss_dice: 0.5352, loss: 8.3457
2023-09-29 16:35:32,988 - mmseg - INFO - Iter [36900/40000]	lr: 1.113e-07, eta: 2:40:06, time: 2.249, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0324, decode.loss_mask: 0.2372, decode.loss_dice: 0.4613, decode.d0.loss_cls: 0.1843, decode.d0.loss_mask: 0.2401, decode.d0.loss_dice: 0.4687, decode.d1.loss_cls: 0.0605, decode.d1.loss_mask: 0.2381, decode.d1.loss_dice: 0.4757, decode.d2.loss_cls: 0.0498, decode.d2.loss_mask: 0.2385, decode.d2.loss_dice: 0.4742, decode.d3.loss_cls: 0.0496, decode.d3.loss_mask: 0.2363, decode.d3.loss_dice: 0.4659, decode.d4.loss_cls: 0.0448, decode.d4.loss_mask: 0.2375, decode.d4.loss_dice: 0.4665, decode.d5.loss_cls: 0.0418, decode.d5.loss_mask: 0.2375, decode.d5.loss_dice: 0.4686, decode.d6.loss_cls: 0.0476, decode.d6.loss_mask: 0.2368, decode.d6.loss_dice: 0.4656, decode.d7.loss_cls: 0.0506, decode.d7.loss_mask: 0.2369, decode.d7.loss_dice: 0.4732, decode.d8.loss_cls: 0.0594, decode.d8.loss_mask: 0.2368, decode.d8.loss_dice: 0.4630, loss: 7.6790
2023-09-29 16:37:25,610 - mmseg - INFO - Iter [36950/40000]	lr: 1.095e-07, eta: 2:37:28, time: 2.252, data_time: 0.035, memory: 21542, decode.loss_cls: 0.0923, decode.loss_mask: 0.2753, decode.loss_dice: 0.5571, decode.d0.loss_cls: 0.2130, decode.d0.loss_mask: 0.2797, decode.d0.loss_dice: 0.5858, decode.d1.loss_cls: 0.0902, decode.d1.loss_mask: 0.2755, decode.d1.loss_dice: 0.5636, decode.d2.loss_cls: 0.0789, decode.d2.loss_mask: 0.2744, decode.d2.loss_dice: 0.5599, decode.d3.loss_cls: 0.0709, decode.d3.loss_mask: 0.2747, decode.d3.loss_dice: 0.5554, decode.d4.loss_cls: 0.0827, decode.d4.loss_mask: 0.2759, decode.d4.loss_dice: 0.5687, decode.d5.loss_cls: 0.1066, decode.d5.loss_mask: 0.2739, decode.d5.loss_dice: 0.5539, decode.d6.loss_cls: 0.0836, decode.d6.loss_mask: 0.2737, decode.d6.loss_dice: 0.5596, decode.d7.loss_cls: 0.0715, decode.d7.loss_mask: 0.2744, decode.d7.loss_dice: 0.5617, decode.d8.loss_cls: 0.0763, decode.d8.loss_mask: 0.2748, decode.d8.loss_dice: 0.5626, loss: 9.3464
2023-09-29 16:39:18,452 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 16:39:18,453 - mmseg - INFO - Iter [37000/40000]	lr: 1.077e-07, eta: 2:34:49, time: 2.257, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0444, decode.loss_mask: 0.2549, decode.loss_dice: 0.4923, decode.d0.loss_cls: 0.2083, decode.d0.loss_mask: 0.2591, decode.d0.loss_dice: 0.4915, decode.d1.loss_cls: 0.0669, decode.d1.loss_mask: 0.2536, decode.d1.loss_dice: 0.4838, decode.d2.loss_cls: 0.0629, decode.d2.loss_mask: 0.2550, decode.d2.loss_dice: 0.4844, decode.d3.loss_cls: 0.0527, decode.d3.loss_mask: 0.2529, decode.d3.loss_dice: 0.4801, decode.d4.loss_cls: 0.0492, decode.d4.loss_mask: 0.2544, decode.d4.loss_dice: 0.4860, decode.d5.loss_cls: 0.0659, decode.d5.loss_mask: 0.2552, decode.d5.loss_dice: 0.4861, decode.d6.loss_cls: 0.0400, decode.d6.loss_mask: 0.2533, decode.d6.loss_dice: 0.4842, decode.d7.loss_cls: 0.0529, decode.d7.loss_mask: 0.2542, decode.d7.loss_dice: 0.4914, decode.d8.loss_cls: 0.0553, decode.d8.loss_mask: 0.2526, decode.d8.loss_dice: 0.4811, loss: 8.1048
2023-09-29 16:41:10,805 - mmseg - INFO - Iter [37050/40000]	lr: 1.059e-07, eta: 2:32:11, time: 2.247, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0516, decode.loss_mask: 0.2407, decode.loss_dice: 0.5258, decode.d0.loss_cls: 0.2068, decode.d0.loss_mask: 0.2426, decode.d0.loss_dice: 0.5361, decode.d1.loss_cls: 0.0589, decode.d1.loss_mask: 0.2414, decode.d1.loss_dice: 0.5265, decode.d2.loss_cls: 0.0523, decode.d2.loss_mask: 0.2414, decode.d2.loss_dice: 0.5153, decode.d3.loss_cls: 0.0574, decode.d3.loss_mask: 0.2405, decode.d3.loss_dice: 0.5126, decode.d4.loss_cls: 0.0554, decode.d4.loss_mask: 0.2414, decode.d4.loss_dice: 0.5278, decode.d5.loss_cls: 0.0507, decode.d5.loss_mask: 0.2410, decode.d5.loss_dice: 0.5194, decode.d6.loss_cls: 0.0485, decode.d6.loss_mask: 0.2413, decode.d6.loss_dice: 0.5250, decode.d7.loss_cls: 0.0563, decode.d7.loss_mask: 0.2414, decode.d7.loss_dice: 0.5256, decode.d8.loss_cls: 0.0447, decode.d8.loss_mask: 0.2413, decode.d8.loss_dice: 0.5276, loss: 8.3374
2023-09-29 16:43:03,106 - mmseg - INFO - Iter [37100/40000]	lr: 1.041e-07, eta: 2:29:33, time: 2.246, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0648, decode.loss_mask: 0.2340, decode.loss_dice: 0.4801, decode.d0.loss_cls: 0.2150, decode.d0.loss_mask: 0.2369, decode.d0.loss_dice: 0.4971, decode.d1.loss_cls: 0.0580, decode.d1.loss_mask: 0.2346, decode.d1.loss_dice: 0.4919, decode.d2.loss_cls: 0.0533, decode.d2.loss_mask: 0.2339, decode.d2.loss_dice: 0.4899, decode.d3.loss_cls: 0.0566, decode.d3.loss_mask: 0.2343, decode.d3.loss_dice: 0.4792, decode.d4.loss_cls: 0.0615, decode.d4.loss_mask: 0.2351, decode.d4.loss_dice: 0.5028, decode.d5.loss_cls: 0.0694, decode.d5.loss_mask: 0.2340, decode.d5.loss_dice: 0.4901, decode.d6.loss_cls: 0.0624, decode.d6.loss_mask: 0.2337, decode.d6.loss_dice: 0.4846, decode.d7.loss_cls: 0.0491, decode.d7.loss_mask: 0.2344, decode.d7.loss_dice: 0.4943, decode.d8.loss_cls: 0.0585, decode.d8.loss_mask: 0.2344, decode.d8.loss_dice: 0.4916, loss: 7.9956
2023-09-29 16:44:55,456 - mmseg - INFO - Iter [37150/40000]	lr: 1.023e-07, eta: 2:26:55, time: 2.247, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0768, decode.loss_mask: 0.2267, decode.loss_dice: 0.5080, decode.d0.loss_cls: 0.2305, decode.d0.loss_mask: 0.2294, decode.d0.loss_dice: 0.5307, decode.d1.loss_cls: 0.0893, decode.d1.loss_mask: 0.2291, decode.d1.loss_dice: 0.5035, decode.d2.loss_cls: 0.0855, decode.d2.loss_mask: 0.2276, decode.d2.loss_dice: 0.5041, decode.d3.loss_cls: 0.0696, decode.d3.loss_mask: 0.2275, decode.d3.loss_dice: 0.5030, decode.d4.loss_cls: 0.0711, decode.d4.loss_mask: 0.2291, decode.d4.loss_dice: 0.5206, decode.d5.loss_cls: 0.0591, decode.d5.loss_mask: 0.2286, decode.d5.loss_dice: 0.5156, decode.d6.loss_cls: 0.0683, decode.d6.loss_mask: 0.2278, decode.d6.loss_dice: 0.5164, decode.d7.loss_cls: 0.0692, decode.d7.loss_mask: 0.2274, decode.d7.loss_dice: 0.5105, decode.d8.loss_cls: 0.0568, decode.d8.loss_mask: 0.2286, decode.d8.loss_dice: 0.5182, loss: 8.2887
2023-09-29 16:46:47,623 - mmseg - INFO - Iter [37200/40000]	lr: 1.005e-07, eta: 2:24:17, time: 2.244, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0754, decode.loss_mask: 0.2479, decode.loss_dice: 0.5188, decode.d0.loss_cls: 0.2308, decode.d0.loss_mask: 0.2492, decode.d0.loss_dice: 0.5213, decode.d1.loss_cls: 0.0930, decode.d1.loss_mask: 0.2482, decode.d1.loss_dice: 0.5309, decode.d2.loss_cls: 0.0698, decode.d2.loss_mask: 0.2477, decode.d2.loss_dice: 0.5249, decode.d3.loss_cls: 0.0797, decode.d3.loss_mask: 0.2453, decode.d3.loss_dice: 0.5143, decode.d4.loss_cls: 0.0743, decode.d4.loss_mask: 0.2457, decode.d4.loss_dice: 0.5094, decode.d5.loss_cls: 0.0845, decode.d5.loss_mask: 0.2456, decode.d5.loss_dice: 0.5182, decode.d6.loss_cls: 0.0658, decode.d6.loss_mask: 0.2452, decode.d6.loss_dice: 0.5148, decode.d7.loss_cls: 0.0715, decode.d7.loss_mask: 0.2462, decode.d7.loss_dice: 0.5161, decode.d8.loss_cls: 0.0673, decode.d8.loss_mask: 0.2462, decode.d8.loss_dice: 0.5131, loss: 8.5612
2023-09-29 16:48:40,480 - mmseg - INFO - Iter [37250/40000]	lr: 9.875e-08, eta: 2:21:39, time: 2.257, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0396, decode.loss_mask: 0.2552, decode.loss_dice: 0.4943, decode.d0.loss_cls: 0.2196, decode.d0.loss_mask: 0.2595, decode.d0.loss_dice: 0.5142, decode.d1.loss_cls: 0.0554, decode.d1.loss_mask: 0.2571, decode.d1.loss_dice: 0.4930, decode.d2.loss_cls: 0.0473, decode.d2.loss_mask: 0.2553, decode.d2.loss_dice: 0.5003, decode.d3.loss_cls: 0.0492, decode.d3.loss_mask: 0.2544, decode.d3.loss_dice: 0.4959, decode.d4.loss_cls: 0.0287, decode.d4.loss_mask: 0.2559, decode.d4.loss_dice: 0.5028, decode.d5.loss_cls: 0.0408, decode.d5.loss_mask: 0.2553, decode.d5.loss_dice: 0.4956, decode.d6.loss_cls: 0.0422, decode.d6.loss_mask: 0.2540, decode.d6.loss_dice: 0.4950, decode.d7.loss_cls: 0.0366, decode.d7.loss_mask: 0.2563, decode.d7.loss_dice: 0.5017, decode.d8.loss_cls: 0.0364, decode.d8.loss_mask: 0.2552, decode.d8.loss_dice: 0.4967, loss: 8.1436
2023-09-29 16:50:35,549 - mmseg - INFO - Iter [37300/40000]	lr: 9.695e-08, eta: 2:19:02, time: 2.301, data_time: 0.078, memory: 21542, decode.loss_cls: 0.0558, decode.loss_mask: 0.2269, decode.loss_dice: 0.4674, decode.d0.loss_cls: 0.2355, decode.d0.loss_mask: 0.2322, decode.d0.loss_dice: 0.4563, decode.d1.loss_cls: 0.0537, decode.d1.loss_mask: 0.2249, decode.d1.loss_dice: 0.4683, decode.d2.loss_cls: 0.0515, decode.d2.loss_mask: 0.2264, decode.d2.loss_dice: 0.4690, decode.d3.loss_cls: 0.0404, decode.d3.loss_mask: 0.2260, decode.d3.loss_dice: 0.4638, decode.d4.loss_cls: 0.0574, decode.d4.loss_mask: 0.2255, decode.d4.loss_dice: 0.4619, decode.d5.loss_cls: 0.0510, decode.d5.loss_mask: 0.2265, decode.d5.loss_dice: 0.4655, decode.d6.loss_cls: 0.0449, decode.d6.loss_mask: 0.2257, decode.d6.loss_dice: 0.4719, decode.d7.loss_cls: 0.0558, decode.d7.loss_mask: 0.2267, decode.d7.loss_dice: 0.4624, decode.d8.loss_cls: 0.0784, decode.d8.loss_mask: 0.2268, decode.d8.loss_dice: 0.4664, loss: 7.6450
2023-09-29 16:52:27,688 - mmseg - INFO - Iter [37350/40000]	lr: 9.516e-08, eta: 2:16:25, time: 2.243, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0594, decode.loss_mask: 0.2353, decode.loss_dice: 0.5305, decode.d0.loss_cls: 0.2400, decode.d0.loss_mask: 0.2379, decode.d0.loss_dice: 0.5307, decode.d1.loss_cls: 0.0864, decode.d1.loss_mask: 0.2363, decode.d1.loss_dice: 0.5117, decode.d2.loss_cls: 0.0549, decode.d2.loss_mask: 0.2352, decode.d2.loss_dice: 0.5300, decode.d3.loss_cls: 0.0792, decode.d3.loss_mask: 0.2351, decode.d3.loss_dice: 0.5229, decode.d4.loss_cls: 0.0664, decode.d4.loss_mask: 0.2360, decode.d4.loss_dice: 0.5263, decode.d5.loss_cls: 0.0590, decode.d5.loss_mask: 0.2359, decode.d5.loss_dice: 0.5221, decode.d6.loss_cls: 0.0585, decode.d6.loss_mask: 0.2361, decode.d6.loss_dice: 0.5131, decode.d7.loss_cls: 0.0543, decode.d7.loss_mask: 0.2355, decode.d7.loss_dice: 0.5116, decode.d8.loss_cls: 0.0615, decode.d8.loss_mask: 0.2357, decode.d8.loss_dice: 0.5126, loss: 8.3904
2023-09-29 16:54:20,686 - mmseg - INFO - Iter [37400/40000]	lr: 9.336e-08, eta: 2:13:47, time: 2.260, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0549, decode.loss_mask: 0.2248, decode.loss_dice: 0.4829, decode.d0.loss_cls: 0.2356, decode.d0.loss_mask: 0.2255, decode.d0.loss_dice: 0.4985, decode.d1.loss_cls: 0.0518, decode.d1.loss_mask: 0.2259, decode.d1.loss_dice: 0.4852, decode.d2.loss_cls: 0.0703, decode.d2.loss_mask: 0.2247, decode.d2.loss_dice: 0.4854, decode.d3.loss_cls: 0.0596, decode.d3.loss_mask: 0.2237, decode.d3.loss_dice: 0.4793, decode.d4.loss_cls: 0.0734, decode.d4.loss_mask: 0.2252, decode.d4.loss_dice: 0.4895, decode.d5.loss_cls: 0.0635, decode.d5.loss_mask: 0.2255, decode.d5.loss_dice: 0.4807, decode.d6.loss_cls: 0.0658, decode.d6.loss_mask: 0.2255, decode.d6.loss_dice: 0.4900, decode.d7.loss_cls: 0.0623, decode.d7.loss_mask: 0.2243, decode.d7.loss_dice: 0.4827, decode.d8.loss_cls: 0.0659, decode.d8.loss_mask: 0.2258, decode.d8.loss_dice: 0.4903, loss: 7.9185
2023-09-29 16:56:13,793 - mmseg - INFO - Iter [37450/40000]	lr: 9.157e-08, eta: 2:11:10, time: 2.260, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0539, decode.loss_mask: 0.2499, decode.loss_dice: 0.4943, decode.d0.loss_cls: 0.2111, decode.d0.loss_mask: 0.2530, decode.d0.loss_dice: 0.5055, decode.d1.loss_cls: 0.0628, decode.d1.loss_mask: 0.2487, decode.d1.loss_dice: 0.4986, decode.d2.loss_cls: 0.0594, decode.d2.loss_mask: 0.2495, decode.d2.loss_dice: 0.4999, decode.d3.loss_cls: 0.0712, decode.d3.loss_mask: 0.2517, decode.d3.loss_dice: 0.5033, decode.d4.loss_cls: 0.0473, decode.d4.loss_mask: 0.2510, decode.d4.loss_dice: 0.5064, decode.d5.loss_cls: 0.0487, decode.d5.loss_mask: 0.2496, decode.d5.loss_dice: 0.5063, decode.d6.loss_cls: 0.0528, decode.d6.loss_mask: 0.2499, decode.d6.loss_dice: 0.5010, decode.d7.loss_cls: 0.0464, decode.d7.loss_mask: 0.2500, decode.d7.loss_dice: 0.4986, decode.d8.loss_cls: 0.0464, decode.d8.loss_mask: 0.2502, decode.d8.loss_dice: 0.5071, loss: 8.2243
2023-09-29 16:58:06,352 - mmseg - INFO - Iter [37500/40000]	lr: 8.977e-08, eta: 2:08:33, time: 2.253, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0426, decode.loss_mask: 0.2319, decode.loss_dice: 0.4727, decode.d0.loss_cls: 0.2120, decode.d0.loss_mask: 0.2316, decode.d0.loss_dice: 0.4821, decode.d1.loss_cls: 0.0388, decode.d1.loss_mask: 0.2311, decode.d1.loss_dice: 0.4657, decode.d2.loss_cls: 0.0376, decode.d2.loss_mask: 0.2312, decode.d2.loss_dice: 0.4642, decode.d3.loss_cls: 0.0449, decode.d3.loss_mask: 0.2320, decode.d3.loss_dice: 0.4770, decode.d4.loss_cls: 0.0370, decode.d4.loss_mask: 0.2316, decode.d4.loss_dice: 0.4663, decode.d5.loss_cls: 0.0402, decode.d5.loss_mask: 0.2341, decode.d5.loss_dice: 0.4742, decode.d6.loss_cls: 0.0467, decode.d6.loss_mask: 0.2332, decode.d6.loss_dice: 0.4699, decode.d7.loss_cls: 0.0431, decode.d7.loss_mask: 0.2335, decode.d7.loss_dice: 0.4744, decode.d8.loss_cls: 0.0483, decode.d8.loss_mask: 0.2318, decode.d8.loss_dice: 0.4705, loss: 7.6303
2023-09-29 16:59:59,009 - mmseg - INFO - Iter [37550/40000]	lr: 8.798e-08, eta: 2:05:56, time: 2.253, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0367, decode.loss_mask: 0.2200, decode.loss_dice: 0.4704, decode.d0.loss_cls: 0.2106, decode.d0.loss_mask: 0.2222, decode.d0.loss_dice: 0.4864, decode.d1.loss_cls: 0.0532, decode.d1.loss_mask: 0.2206, decode.d1.loss_dice: 0.4729, decode.d2.loss_cls: 0.0367, decode.d2.loss_mask: 0.2209, decode.d2.loss_dice: 0.4736, decode.d3.loss_cls: 0.0482, decode.d3.loss_mask: 0.2203, decode.d3.loss_dice: 0.4769, decode.d4.loss_cls: 0.0401, decode.d4.loss_mask: 0.2199, decode.d4.loss_dice: 0.4744, decode.d5.loss_cls: 0.0498, decode.d5.loss_mask: 0.2201, decode.d5.loss_dice: 0.4784, decode.d6.loss_cls: 0.0521, decode.d6.loss_mask: 0.2192, decode.d6.loss_dice: 0.4789, decode.d7.loss_cls: 0.0506, decode.d7.loss_mask: 0.2204, decode.d7.loss_dice: 0.4707, decode.d8.loss_cls: 0.0370, decode.d8.loss_mask: 0.2204, decode.d8.loss_dice: 0.4703, loss: 7.5720
2023-09-29 17:01:51,935 - mmseg - INFO - Iter [37600/40000]	lr: 8.618e-08, eta: 2:03:19, time: 2.258, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0654, decode.loss_mask: 0.2519, decode.loss_dice: 0.4858, decode.d0.loss_cls: 0.2084, decode.d0.loss_mask: 0.2533, decode.d0.loss_dice: 0.5011, decode.d1.loss_cls: 0.0520, decode.d1.loss_mask: 0.2535, decode.d1.loss_dice: 0.4886, decode.d2.loss_cls: 0.0575, decode.d2.loss_mask: 0.2532, decode.d2.loss_dice: 0.4926, decode.d3.loss_cls: 0.0543, decode.d3.loss_mask: 0.2529, decode.d3.loss_dice: 0.4918, decode.d4.loss_cls: 0.0527, decode.d4.loss_mask: 0.2532, decode.d4.loss_dice: 0.4946, decode.d5.loss_cls: 0.0642, decode.d5.loss_mask: 0.2530, decode.d5.loss_dice: 0.4895, decode.d6.loss_cls: 0.0553, decode.d6.loss_mask: 0.2532, decode.d6.loss_dice: 0.4890, decode.d7.loss_cls: 0.0683, decode.d7.loss_mask: 0.2525, decode.d7.loss_dice: 0.4900, decode.d8.loss_cls: 0.0769, decode.d8.loss_mask: 0.2526, decode.d8.loss_dice: 0.4987, loss: 8.2060
2023-09-29 17:03:44,360 - mmseg - INFO - Iter [37650/40000]	lr: 8.439e-08, eta: 2:00:42, time: 2.249, data_time: 0.025, memory: 21542, decode.loss_cls: 0.0689, decode.loss_mask: 0.2520, decode.loss_dice: 0.4836, decode.d0.loss_cls: 0.1923, decode.d0.loss_mask: 0.2558, decode.d0.loss_dice: 0.4890, decode.d1.loss_cls: 0.0490, decode.d1.loss_mask: 0.2524, decode.d1.loss_dice: 0.4746, decode.d2.loss_cls: 0.0642, decode.d2.loss_mask: 0.2521, decode.d2.loss_dice: 0.4702, decode.d3.loss_cls: 0.0628, decode.d3.loss_mask: 0.2516, decode.d3.loss_dice: 0.4763, decode.d4.loss_cls: 0.0608, decode.d4.loss_mask: 0.2502, decode.d4.loss_dice: 0.4783, decode.d5.loss_cls: 0.0596, decode.d5.loss_mask: 0.2512, decode.d5.loss_dice: 0.4752, decode.d6.loss_cls: 0.0562, decode.d6.loss_mask: 0.2522, decode.d6.loss_dice: 0.4826, decode.d7.loss_cls: 0.0558, decode.d7.loss_mask: 0.2497, decode.d7.loss_dice: 0.4777, decode.d8.loss_cls: 0.0533, decode.d8.loss_mask: 0.2520, decode.d8.loss_dice: 0.4752, loss: 8.0246
2023-09-29 17:05:37,436 - mmseg - INFO - Iter [37700/40000]	lr: 8.259e-08, eta: 1:58:06, time: 2.261, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0472, decode.loss_mask: 0.2463, decode.loss_dice: 0.5172, decode.d0.loss_cls: 0.2123, decode.d0.loss_mask: 0.2504, decode.d0.loss_dice: 0.5446, decode.d1.loss_cls: 0.0884, decode.d1.loss_mask: 0.2462, decode.d1.loss_dice: 0.5157, decode.d2.loss_cls: 0.0551, decode.d2.loss_mask: 0.2462, decode.d2.loss_dice: 0.5325, decode.d3.loss_cls: 0.0545, decode.d3.loss_mask: 0.2469, decode.d3.loss_dice: 0.5166, decode.d4.loss_cls: 0.0521, decode.d4.loss_mask: 0.2465, decode.d4.loss_dice: 0.5182, decode.d5.loss_cls: 0.0537, decode.d5.loss_mask: 0.2471, decode.d5.loss_dice: 0.5283, decode.d6.loss_cls: 0.0535, decode.d6.loss_mask: 0.2459, decode.d6.loss_dice: 0.5254, decode.d7.loss_cls: 0.0701, decode.d7.loss_mask: 0.2462, decode.d7.loss_dice: 0.5160, decode.d8.loss_cls: 0.0490, decode.d8.loss_mask: 0.2456, decode.d8.loss_dice: 0.5257, loss: 8.4436
2023-09-29 17:07:30,308 - mmseg - INFO - Iter [37750/40000]	lr: 8.080e-08, eta: 1:55:29, time: 2.257, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0496, decode.loss_mask: 0.2298, decode.loss_dice: 0.4944, decode.d0.loss_cls: 0.2242, decode.d0.loss_mask: 0.2315, decode.d0.loss_dice: 0.5047, decode.d1.loss_cls: 0.0748, decode.d1.loss_mask: 0.2285, decode.d1.loss_dice: 0.5074, decode.d2.loss_cls: 0.0580, decode.d2.loss_mask: 0.2289, decode.d2.loss_dice: 0.4888, decode.d3.loss_cls: 0.0582, decode.d3.loss_mask: 0.2304, decode.d3.loss_dice: 0.4929, decode.d4.loss_cls: 0.0593, decode.d4.loss_mask: 0.2305, decode.d4.loss_dice: 0.4861, decode.d5.loss_cls: 0.0642, decode.d5.loss_mask: 0.2298, decode.d5.loss_dice: 0.4961, decode.d6.loss_cls: 0.0597, decode.d6.loss_mask: 0.2292, decode.d6.loss_dice: 0.4949, decode.d7.loss_cls: 0.0499, decode.d7.loss_mask: 0.2286, decode.d7.loss_dice: 0.4928, decode.d8.loss_cls: 0.0496, decode.d8.loss_mask: 0.2287, decode.d8.loss_dice: 0.5056, loss: 8.0073
2023-09-29 17:09:22,800 - mmseg - INFO - Iter [37800/40000]	lr: 7.900e-08, eta: 1:52:53, time: 2.250, data_time: 0.025, memory: 21542, decode.loss_cls: 0.0585, decode.loss_mask: 0.2946, decode.loss_dice: 0.4994, decode.d0.loss_cls: 0.2264, decode.d0.loss_mask: 0.3024, decode.d0.loss_dice: 0.5195, decode.d1.loss_cls: 0.0849, decode.d1.loss_mask: 0.2955, decode.d1.loss_dice: 0.5067, decode.d2.loss_cls: 0.0663, decode.d2.loss_mask: 0.2945, decode.d2.loss_dice: 0.5030, decode.d3.loss_cls: 0.0565, decode.d3.loss_mask: 0.2959, decode.d3.loss_dice: 0.4931, decode.d4.loss_cls: 0.0632, decode.d4.loss_mask: 0.2950, decode.d4.loss_dice: 0.4985, decode.d5.loss_cls: 0.0626, decode.d5.loss_mask: 0.2965, decode.d5.loss_dice: 0.5025, decode.d6.loss_cls: 0.0529, decode.d6.loss_mask: 0.2965, decode.d6.loss_dice: 0.5020, decode.d7.loss_cls: 0.0565, decode.d7.loss_mask: 0.2947, decode.d7.loss_dice: 0.5008, decode.d8.loss_cls: 0.0475, decode.d8.loss_mask: 0.2957, decode.d8.loss_dice: 0.5034, loss: 8.7657
2023-09-29 17:11:15,159 - mmseg - INFO - Iter [37850/40000]	lr: 7.721e-08, eta: 1:50:17, time: 2.247, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0645, decode.loss_mask: 0.2690, decode.loss_dice: 0.5114, decode.d0.loss_cls: 0.2121, decode.d0.loss_mask: 0.2754, decode.d0.loss_dice: 0.5160, decode.d1.loss_cls: 0.0788, decode.d1.loss_mask: 0.2703, decode.d1.loss_dice: 0.5141, decode.d2.loss_cls: 0.0738, decode.d2.loss_mask: 0.2706, decode.d2.loss_dice: 0.5085, decode.d3.loss_cls: 0.0692, decode.d3.loss_mask: 0.2692, decode.d3.loss_dice: 0.5152, decode.d4.loss_cls: 0.0781, decode.d4.loss_mask: 0.2691, decode.d4.loss_dice: 0.5116, decode.d5.loss_cls: 0.0717, decode.d5.loss_mask: 0.2710, decode.d5.loss_dice: 0.5134, decode.d6.loss_cls: 0.0517, decode.d6.loss_mask: 0.2690, decode.d6.loss_dice: 0.5145, decode.d7.loss_cls: 0.0630, decode.d7.loss_mask: 0.2702, decode.d7.loss_dice: 0.5095, decode.d8.loss_cls: 0.0704, decode.d8.loss_mask: 0.2690, decode.d8.loss_dice: 0.5066, loss: 8.6570
2023-09-29 17:13:07,227 - mmseg - INFO - Iter [37900/40000]	lr: 7.542e-08, eta: 1:47:40, time: 2.241, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0511, decode.loss_mask: 0.2476, decode.loss_dice: 0.4884, decode.d0.loss_cls: 0.2126, decode.d0.loss_mask: 0.2489, decode.d0.loss_dice: 0.5010, decode.d1.loss_cls: 0.0560, decode.d1.loss_mask: 0.2469, decode.d1.loss_dice: 0.4939, decode.d2.loss_cls: 0.0507, decode.d2.loss_mask: 0.2471, decode.d2.loss_dice: 0.4836, decode.d3.loss_cls: 0.0562, decode.d3.loss_mask: 0.2470, decode.d3.loss_dice: 0.4888, decode.d4.loss_cls: 0.0555, decode.d4.loss_mask: 0.2471, decode.d4.loss_dice: 0.4879, decode.d5.loss_cls: 0.0475, decode.d5.loss_mask: 0.2477, decode.d5.loss_dice: 0.4864, decode.d6.loss_cls: 0.0439, decode.d6.loss_mask: 0.2476, decode.d6.loss_dice: 0.4830, decode.d7.loss_cls: 0.0462, decode.d7.loss_mask: 0.2462, decode.d7.loss_dice: 0.4767, decode.d8.loss_cls: 0.0486, decode.d8.loss_mask: 0.2473, decode.d8.loss_dice: 0.4773, loss: 8.0088
2023-09-29 17:14:59,725 - mmseg - INFO - Iter [37950/40000]	lr: 7.362e-08, eta: 1:45:04, time: 2.251, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0610, decode.loss_mask: 0.2570, decode.loss_dice: 0.5436, decode.d0.loss_cls: 0.2295, decode.d0.loss_mask: 0.2596, decode.d0.loss_dice: 0.5538, decode.d1.loss_cls: 0.0978, decode.d1.loss_mask: 0.2587, decode.d1.loss_dice: 0.5406, decode.d2.loss_cls: 0.0924, decode.d2.loss_mask: 0.2569, decode.d2.loss_dice: 0.5256, decode.d3.loss_cls: 0.0832, decode.d3.loss_mask: 0.2579, decode.d3.loss_dice: 0.5333, decode.d4.loss_cls: 0.0800, decode.d4.loss_mask: 0.2581, decode.d4.loss_dice: 0.5376, decode.d5.loss_cls: 0.0914, decode.d5.loss_mask: 0.2576, decode.d5.loss_dice: 0.5397, decode.d6.loss_cls: 0.0653, decode.d6.loss_mask: 0.2564, decode.d6.loss_dice: 0.5390, decode.d7.loss_cls: 0.0740, decode.d7.loss_mask: 0.2578, decode.d7.loss_dice: 0.5451, decode.d8.loss_cls: 0.0644, decode.d8.loss_mask: 0.2583, decode.d8.loss_dice: 0.5473, loss: 8.9228
2023-09-29 17:16:52,772 - mmseg - INFO - Saving checkpoint at 38000 iterations
2023-09-29 17:17:13,459 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 17:17:13,460 - mmseg - INFO - Iter [38000/40000]	lr: 7.183e-08, eta: 1:42:29, time: 2.675, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0544, decode.loss_mask: 0.2906, decode.loss_dice: 0.5497, decode.d0.loss_cls: 0.2151, decode.d0.loss_mask: 0.2972, decode.d0.loss_dice: 0.5591, decode.d1.loss_cls: 0.0748, decode.d1.loss_mask: 0.2877, decode.d1.loss_dice: 0.5457, decode.d2.loss_cls: 0.0650, decode.d2.loss_mask: 0.2887, decode.d2.loss_dice: 0.5441, decode.d3.loss_cls: 0.0515, decode.d3.loss_mask: 0.2910, decode.d3.loss_dice: 0.5486, decode.d4.loss_cls: 0.0544, decode.d4.loss_mask: 0.2898, decode.d4.loss_dice: 0.5464, decode.d5.loss_cls: 0.0548, decode.d5.loss_mask: 0.2889, decode.d5.loss_dice: 0.5559, decode.d6.loss_cls: 0.0768, decode.d6.loss_mask: 0.2896, decode.d6.loss_dice: 0.5461, decode.d7.loss_cls: 0.0563, decode.d7.loss_mask: 0.2910, decode.d7.loss_dice: 0.5414, decode.d8.loss_cls: 0.0530, decode.d8.loss_mask: 0.2899, decode.d8.loss_dice: 0.5539, loss: 9.1513
2023-09-29 17:34:28,107 - mmseg - INFO - per class results:
2023-09-29 17:34:28,109 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     |  92.9 | 96.84 |
|    Sidewalk   | 69.51 | 81.83 |
|  Construction | 82.32 | 94.36 |
|     Fence     | 33.44 | 37.03 |
|      Pole     | 57.45 | 68.82 |
| Traffic Light | 67.81 | 78.81 |
|  Traffic Sign | 72.47 | 79.87 |
|     Nature    | 88.62 | 93.88 |
|      Sky      | 96.64 | 98.01 |
|     Person    | 33.17 | 35.49 |
|     Rider     |  9.11 | 70.89 |
|      Car      | 91.57 | 94.93 |
|   background  | 96.04 | 97.87 |
+---------------+-------+-------+
2023-09-29 17:34:28,109 - mmseg - INFO - Summary:
2023-09-29 17:34:28,109 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.49 | 68.54 | 79.13 |
+-------+-------+-------+
2023-09-29 17:34:28,113 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 17:34:28,114 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9449, mIoU: 0.6854, mAcc: 0.7913, IoU.Road: 0.9290, IoU.Sidewalk: 0.6951, IoU.Construction: 0.8232, IoU.Fence: 0.3344, IoU.Pole: 0.5745, IoU.Traffic Light: 0.6781, IoU.Traffic Sign: 0.7247, IoU.Nature: 0.8862, IoU.Sky: 0.9664, IoU.Person: 0.3317, IoU.Rider: 0.0911, IoU.Car: 0.9157, IoU.background: 0.9604, Acc.Road: 0.9684, Acc.Sidewalk: 0.8183, Acc.Construction: 0.9436, Acc.Fence: 0.3703, Acc.Pole: 0.6882, Acc.Traffic Light: 0.7881, Acc.Traffic Sign: 0.7987, Acc.Nature: 0.9388, Acc.Sky: 0.9801, Acc.Person: 0.3549, Acc.Rider: 0.7089, Acc.Car: 0.9493, Acc.background: 0.9787
2023-09-29 17:36:21,823 - mmseg - INFO - Iter [38050/40000]	lr: 7.003e-08, eta: 1:40:47, time: 22.967, data_time: 20.722, memory: 21542, decode.loss_cls: 0.0683, decode.loss_mask: 0.2584, decode.loss_dice: 0.5070, decode.d0.loss_cls: 0.2366, decode.d0.loss_mask: 0.2656, decode.d0.loss_dice: 0.5220, decode.d1.loss_cls: 0.0848, decode.d1.loss_mask: 0.2593, decode.d1.loss_dice: 0.5029, decode.d2.loss_cls: 0.0782, decode.d2.loss_mask: 0.2587, decode.d2.loss_dice: 0.4917, decode.d3.loss_cls: 0.0672, decode.d3.loss_mask: 0.2589, decode.d3.loss_dice: 0.5041, decode.d4.loss_cls: 0.0690, decode.d4.loss_mask: 0.2593, decode.d4.loss_dice: 0.5023, decode.d5.loss_cls: 0.0804, decode.d5.loss_mask: 0.2611, decode.d5.loss_dice: 0.4973, decode.d6.loss_cls: 0.0660, decode.d6.loss_mask: 0.2582, decode.d6.loss_dice: 0.5008, decode.d7.loss_cls: 0.0571, decode.d7.loss_mask: 0.2597, decode.d7.loss_dice: 0.5065, decode.d8.loss_cls: 0.0812, decode.d8.loss_mask: 0.2591, decode.d8.loss_dice: 0.4960, loss: 8.5177
2023-09-29 17:38:14,809 - mmseg - INFO - Iter [38100/40000]	lr: 6.824e-08, eta: 1:38:09, time: 2.260, data_time: 0.033, memory: 21542, decode.loss_cls: 0.0618, decode.loss_mask: 0.2596, decode.loss_dice: 0.5325, decode.d0.loss_cls: 0.2535, decode.d0.loss_mask: 0.2659, decode.d0.loss_dice: 0.5396, decode.d1.loss_cls: 0.1022, decode.d1.loss_mask: 0.2611, decode.d1.loss_dice: 0.5242, decode.d2.loss_cls: 0.0606, decode.d2.loss_mask: 0.2601, decode.d2.loss_dice: 0.5338, decode.d3.loss_cls: 0.0685, decode.d3.loss_mask: 0.2619, decode.d3.loss_dice: 0.5364, decode.d4.loss_cls: 0.0533, decode.d4.loss_mask: 0.2613, decode.d4.loss_dice: 0.5399, decode.d5.loss_cls: 0.0632, decode.d5.loss_mask: 0.2613, decode.d5.loss_dice: 0.5297, decode.d6.loss_cls: 0.0494, decode.d6.loss_mask: 0.2615, decode.d6.loss_dice: 0.5400, decode.d7.loss_cls: 0.0579, decode.d7.loss_mask: 0.2607, decode.d7.loss_dice: 0.5266, decode.d8.loss_cls: 0.0516, decode.d8.loss_mask: 0.2604, decode.d8.loss_dice: 0.5299, loss: 8.7684
2023-09-29 17:40:07,057 - mmseg - INFO - Iter [38150/40000]	lr: 6.644e-08, eta: 1:35:32, time: 2.245, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0511, decode.loss_mask: 0.2504, decode.loss_dice: 0.5015, decode.d0.loss_cls: 0.2287, decode.d0.loss_mask: 0.2534, decode.d0.loss_dice: 0.5064, decode.d1.loss_cls: 0.0972, decode.d1.loss_mask: 0.2481, decode.d1.loss_dice: 0.4948, decode.d2.loss_cls: 0.0614, decode.d2.loss_mask: 0.2507, decode.d2.loss_dice: 0.4951, decode.d3.loss_cls: 0.0610, decode.d3.loss_mask: 0.2508, decode.d3.loss_dice: 0.5143, decode.d4.loss_cls: 0.0482, decode.d4.loss_mask: 0.2513, decode.d4.loss_dice: 0.4969, decode.d5.loss_cls: 0.0467, decode.d5.loss_mask: 0.2491, decode.d5.loss_dice: 0.5123, decode.d6.loss_cls: 0.0509, decode.d6.loss_mask: 0.2492, decode.d6.loss_dice: 0.4948, decode.d7.loss_cls: 0.0576, decode.d7.loss_mask: 0.2497, decode.d7.loss_dice: 0.4954, decode.d8.loss_cls: 0.0542, decode.d8.loss_mask: 0.2495, decode.d8.loss_dice: 0.5027, loss: 8.2735
2023-09-29 17:42:00,233 - mmseg - INFO - Iter [38200/40000]	lr: 6.465e-08, eta: 1:32:55, time: 2.263, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0732, decode.loss_mask: 0.2650, decode.loss_dice: 0.5324, decode.d0.loss_cls: 0.2118, decode.d0.loss_mask: 0.2657, decode.d0.loss_dice: 0.5339, decode.d1.loss_cls: 0.0670, decode.d1.loss_mask: 0.2656, decode.d1.loss_dice: 0.5372, decode.d2.loss_cls: 0.0889, decode.d2.loss_mask: 0.2644, decode.d2.loss_dice: 0.5379, decode.d3.loss_cls: 0.0807, decode.d3.loss_mask: 0.2675, decode.d3.loss_dice: 0.5384, decode.d4.loss_cls: 0.0676, decode.d4.loss_mask: 0.2654, decode.d4.loss_dice: 0.5330, decode.d5.loss_cls: 0.0664, decode.d5.loss_mask: 0.2654, decode.d5.loss_dice: 0.5302, decode.d6.loss_cls: 0.0662, decode.d6.loss_mask: 0.2666, decode.d6.loss_dice: 0.5300, decode.d7.loss_cls: 0.0698, decode.d7.loss_mask: 0.2641, decode.d7.loss_dice: 0.5309, decode.d8.loss_cls: 0.0739, decode.d8.loss_mask: 0.2651, decode.d8.loss_dice: 0.5274, loss: 8.8517
2023-09-29 17:43:53,089 - mmseg - INFO - Iter [38250/40000]	lr: 6.285e-08, eta: 1:30:19, time: 2.257, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0562, decode.loss_mask: 0.2740, decode.loss_dice: 0.5475, decode.d0.loss_cls: 0.2101, decode.d0.loss_mask: 0.2774, decode.d0.loss_dice: 0.5434, decode.d1.loss_cls: 0.0441, decode.d1.loss_mask: 0.2743, decode.d1.loss_dice: 0.5497, decode.d2.loss_cls: 0.0546, decode.d2.loss_mask: 0.2739, decode.d2.loss_dice: 0.5350, decode.d3.loss_cls: 0.0535, decode.d3.loss_mask: 0.2724, decode.d3.loss_dice: 0.5422, decode.d4.loss_cls: 0.0558, decode.d4.loss_mask: 0.2745, decode.d4.loss_dice: 0.5507, decode.d5.loss_cls: 0.0543, decode.d5.loss_mask: 0.2733, decode.d5.loss_dice: 0.5370, decode.d6.loss_cls: 0.0505, decode.d6.loss_mask: 0.2722, decode.d6.loss_dice: 0.5424, decode.d7.loss_cls: 0.0551, decode.d7.loss_mask: 0.2732, decode.d7.loss_dice: 0.5476, decode.d8.loss_cls: 0.0498, decode.d8.loss_mask: 0.2737, decode.d8.loss_dice: 0.5441, loss: 8.8626
2023-09-29 17:45:46,352 - mmseg - INFO - Iter [38300/40000]	lr: 6.106e-08, eta: 1:27:42, time: 2.265, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0471, decode.loss_mask: 0.2392, decode.loss_dice: 0.5236, decode.d0.loss_cls: 0.2189, decode.d0.loss_mask: 0.2397, decode.d0.loss_dice: 0.5206, decode.d1.loss_cls: 0.0721, decode.d1.loss_mask: 0.2425, decode.d1.loss_dice: 0.5249, decode.d2.loss_cls: 0.0688, decode.d2.loss_mask: 0.2411, decode.d2.loss_dice: 0.5221, decode.d3.loss_cls: 0.0471, decode.d3.loss_mask: 0.2394, decode.d3.loss_dice: 0.5068, decode.d4.loss_cls: 0.0478, decode.d4.loss_mask: 0.2410, decode.d4.loss_dice: 0.5160, decode.d5.loss_cls: 0.0642, decode.d5.loss_mask: 0.2396, decode.d5.loss_dice: 0.5137, decode.d6.loss_cls: 0.0507, decode.d6.loss_mask: 0.2397, decode.d6.loss_dice: 0.5126, decode.d7.loss_cls: 0.0478, decode.d7.loss_mask: 0.2399, decode.d7.loss_dice: 0.5114, decode.d8.loss_cls: 0.0432, decode.d8.loss_mask: 0.2395, decode.d8.loss_dice: 0.5041, loss: 8.2652
2023-09-29 17:47:39,731 - mmseg - INFO - Iter [38350/40000]	lr: 5.926e-08, eta: 1:25:05, time: 2.267, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0723, decode.loss_mask: 0.2584, decode.loss_dice: 0.5465, decode.d0.loss_cls: 0.2222, decode.d0.loss_mask: 0.2677, decode.d0.loss_dice: 0.5593, decode.d1.loss_cls: 0.0937, decode.d1.loss_mask: 0.2609, decode.d1.loss_dice: 0.5602, decode.d2.loss_cls: 0.0799, decode.d2.loss_mask: 0.2601, decode.d2.loss_dice: 0.5597, decode.d3.loss_cls: 0.0762, decode.d3.loss_mask: 0.2601, decode.d3.loss_dice: 0.5385, decode.d4.loss_cls: 0.0639, decode.d4.loss_mask: 0.2622, decode.d4.loss_dice: 0.5661, decode.d5.loss_cls: 0.0713, decode.d5.loss_mask: 0.2604, decode.d5.loss_dice: 0.5508, decode.d6.loss_cls: 0.0688, decode.d6.loss_mask: 0.2602, decode.d6.loss_dice: 0.5625, decode.d7.loss_cls: 0.0679, decode.d7.loss_mask: 0.2604, decode.d7.loss_dice: 0.5561, decode.d8.loss_cls: 0.0679, decode.d8.loss_mask: 0.2587, decode.d8.loss_dice: 0.5525, loss: 9.0454
2023-09-29 17:49:35,138 - mmseg - INFO - Iter [38400/40000]	lr: 5.747e-08, eta: 1:22:29, time: 2.308, data_time: 0.081, memory: 21542, decode.loss_cls: 0.0483, decode.loss_mask: 0.2445, decode.loss_dice: 0.5407, decode.d0.loss_cls: 0.2073, decode.d0.loss_mask: 0.2445, decode.d0.loss_dice: 0.5600, decode.d1.loss_cls: 0.0796, decode.d1.loss_mask: 0.2371, decode.d1.loss_dice: 0.5358, decode.d2.loss_cls: 0.0834, decode.d2.loss_mask: 0.2373, decode.d2.loss_dice: 0.5355, decode.d3.loss_cls: 0.0561, decode.d3.loss_mask: 0.2378, decode.d3.loss_dice: 0.5398, decode.d4.loss_cls: 0.0710, decode.d4.loss_mask: 0.2378, decode.d4.loss_dice: 0.5249, decode.d5.loss_cls: 0.0794, decode.d5.loss_mask: 0.2400, decode.d5.loss_dice: 0.5285, decode.d6.loss_cls: 0.0718, decode.d6.loss_mask: 0.2411, decode.d6.loss_dice: 0.5367, decode.d7.loss_cls: 0.0859, decode.d7.loss_mask: 0.2378, decode.d7.loss_dice: 0.5363, decode.d8.loss_cls: 0.0733, decode.d8.loss_mask: 0.2383, decode.d8.loss_dice: 0.5239, loss: 8.6143
2023-09-29 17:51:28,219 - mmseg - INFO - Iter [38450/40000]	lr: 5.567e-08, eta: 1:19:53, time: 2.262, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0340, decode.loss_mask: 0.2469, decode.loss_dice: 0.5059, decode.d0.loss_cls: 0.1947, decode.d0.loss_mask: 0.2525, decode.d0.loss_dice: 0.5084, decode.d1.loss_cls: 0.0602, decode.d1.loss_mask: 0.2488, decode.d1.loss_dice: 0.5106, decode.d2.loss_cls: 0.0495, decode.d2.loss_mask: 0.2481, decode.d2.loss_dice: 0.5027, decode.d3.loss_cls: 0.0479, decode.d3.loss_mask: 0.2482, decode.d3.loss_dice: 0.5090, decode.d4.loss_cls: 0.0594, decode.d4.loss_mask: 0.2481, decode.d4.loss_dice: 0.5026, decode.d5.loss_cls: 0.0619, decode.d5.loss_mask: 0.2472, decode.d5.loss_dice: 0.5047, decode.d6.loss_cls: 0.0340, decode.d6.loss_mask: 0.2472, decode.d6.loss_dice: 0.5037, decode.d7.loss_cls: 0.0404, decode.d7.loss_mask: 0.2474, decode.d7.loss_dice: 0.5116, decode.d8.loss_cls: 0.0388, decode.d8.loss_mask: 0.2474, decode.d8.loss_dice: 0.5078, loss: 8.1697
2023-09-29 17:53:20,926 - mmseg - INFO - Iter [38500/40000]	lr: 5.388e-08, eta: 1:17:16, time: 2.254, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0466, decode.loss_mask: 0.2299, decode.loss_dice: 0.5088, decode.d0.loss_cls: 0.1958, decode.d0.loss_mask: 0.2314, decode.d0.loss_dice: 0.5290, decode.d1.loss_cls: 0.0517, decode.d1.loss_mask: 0.2304, decode.d1.loss_dice: 0.5187, decode.d2.loss_cls: 0.0584, decode.d2.loss_mask: 0.2302, decode.d2.loss_dice: 0.5049, decode.d3.loss_cls: 0.0485, decode.d3.loss_mask: 0.2300, decode.d3.loss_dice: 0.5083, decode.d4.loss_cls: 0.0422, decode.d4.loss_mask: 0.2299, decode.d4.loss_dice: 0.5078, decode.d5.loss_cls: 0.0491, decode.d5.loss_mask: 0.2316, decode.d5.loss_dice: 0.5219, decode.d6.loss_cls: 0.0426, decode.d6.loss_mask: 0.2281, decode.d6.loss_dice: 0.5022, decode.d7.loss_cls: 0.0416, decode.d7.loss_mask: 0.2288, decode.d7.loss_dice: 0.5065, decode.d8.loss_cls: 0.0421, decode.d8.loss_mask: 0.2303, decode.d8.loss_dice: 0.5098, loss: 8.0371
2023-09-29 17:55:14,301 - mmseg - INFO - Iter [38550/40000]	lr: 5.208e-08, eta: 1:14:40, time: 2.267, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0712, decode.loss_mask: 0.2511, decode.loss_dice: 0.5166, decode.d0.loss_cls: 0.2030, decode.d0.loss_mask: 0.2541, decode.d0.loss_dice: 0.5277, decode.d1.loss_cls: 0.0921, decode.d1.loss_mask: 0.2515, decode.d1.loss_dice: 0.5116, decode.d2.loss_cls: 0.0608, decode.d2.loss_mask: 0.2518, decode.d2.loss_dice: 0.5039, decode.d3.loss_cls: 0.0618, decode.d3.loss_mask: 0.2525, decode.d3.loss_dice: 0.5228, decode.d4.loss_cls: 0.0662, decode.d4.loss_mask: 0.2518, decode.d4.loss_dice: 0.5197, decode.d5.loss_cls: 0.0634, decode.d5.loss_mask: 0.2516, decode.d5.loss_dice: 0.5108, decode.d6.loss_cls: 0.0525, decode.d6.loss_mask: 0.2512, decode.d6.loss_dice: 0.5117, decode.d7.loss_cls: 0.0536, decode.d7.loss_mask: 0.2514, decode.d7.loss_dice: 0.5165, decode.d8.loss_cls: 0.0541, decode.d8.loss_mask: 0.2505, decode.d8.loss_dice: 0.5194, loss: 8.4569
2023-09-29 17:57:08,119 - mmseg - INFO - Iter [38600/40000]	lr: 5.029e-08, eta: 1:12:04, time: 2.277, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0429, decode.loss_mask: 0.2449, decode.loss_dice: 0.5044, decode.d0.loss_cls: 0.2008, decode.d0.loss_mask: 0.2485, decode.d0.loss_dice: 0.5210, decode.d1.loss_cls: 0.0577, decode.d1.loss_mask: 0.2444, decode.d1.loss_dice: 0.5139, decode.d2.loss_cls: 0.0462, decode.d2.loss_mask: 0.2443, decode.d2.loss_dice: 0.5030, decode.d3.loss_cls: 0.0523, decode.d3.loss_mask: 0.2407, decode.d3.loss_dice: 0.4986, decode.d4.loss_cls: 0.0410, decode.d4.loss_mask: 0.2445, decode.d4.loss_dice: 0.5049, decode.d5.loss_cls: 0.0486, decode.d5.loss_mask: 0.2440, decode.d5.loss_dice: 0.5010, decode.d6.loss_cls: 0.0448, decode.d6.loss_mask: 0.2414, decode.d6.loss_dice: 0.4929, decode.d7.loss_cls: 0.0428, decode.d7.loss_mask: 0.2440, decode.d7.loss_dice: 0.4975, decode.d8.loss_cls: 0.0420, decode.d8.loss_mask: 0.2432, decode.d8.loss_dice: 0.5023, loss: 8.0983
2023-09-29 17:59:00,796 - mmseg - INFO - Iter [38650/40000]	lr: 4.849e-08, eta: 1:09:28, time: 2.254, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0323, decode.loss_mask: 0.2349, decode.loss_dice: 0.4963, decode.d0.loss_cls: 0.2001, decode.d0.loss_mask: 0.2372, decode.d0.loss_dice: 0.5025, decode.d1.loss_cls: 0.0482, decode.d1.loss_mask: 0.2354, decode.d1.loss_dice: 0.4957, decode.d2.loss_cls: 0.0429, decode.d2.loss_mask: 0.2348, decode.d2.loss_dice: 0.4933, decode.d3.loss_cls: 0.0400, decode.d3.loss_mask: 0.2336, decode.d3.loss_dice: 0.4939, decode.d4.loss_cls: 0.0473, decode.d4.loss_mask: 0.2332, decode.d4.loss_dice: 0.4903, decode.d5.loss_cls: 0.0526, decode.d5.loss_mask: 0.2350, decode.d5.loss_dice: 0.4947, decode.d6.loss_cls: 0.0337, decode.d6.loss_mask: 0.2342, decode.d6.loss_dice: 0.4901, decode.d7.loss_cls: 0.0434, decode.d7.loss_mask: 0.2338, decode.d7.loss_dice: 0.4953, decode.d8.loss_cls: 0.0395, decode.d8.loss_mask: 0.2332, decode.d8.loss_dice: 0.4926, loss: 7.8699
2023-09-29 18:00:53,914 - mmseg - INFO - Iter [38700/40000]	lr: 4.670e-08, eta: 1:06:53, time: 2.262, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0516, decode.loss_mask: 0.2441, decode.loss_dice: 0.5168, decode.d0.loss_cls: 0.1905, decode.d0.loss_mask: 0.2458, decode.d0.loss_dice: 0.5332, decode.d1.loss_cls: 0.0750, decode.d1.loss_mask: 0.2471, decode.d1.loss_dice: 0.5218, decode.d2.loss_cls: 0.0481, decode.d2.loss_mask: 0.2467, decode.d2.loss_dice: 0.5204, decode.d3.loss_cls: 0.0617, decode.d3.loss_mask: 0.2457, decode.d3.loss_dice: 0.5328, decode.d4.loss_cls: 0.0535, decode.d4.loss_mask: 0.2470, decode.d4.loss_dice: 0.5248, decode.d5.loss_cls: 0.0436, decode.d5.loss_mask: 0.2467, decode.d5.loss_dice: 0.5195, decode.d6.loss_cls: 0.0528, decode.d6.loss_mask: 0.2467, decode.d6.loss_dice: 0.5281, decode.d7.loss_cls: 0.0562, decode.d7.loss_mask: 0.2461, decode.d7.loss_dice: 0.5258, decode.d8.loss_cls: 0.0472, decode.d8.loss_mask: 0.2452, decode.d8.loss_dice: 0.5184, loss: 8.3829
2023-09-29 18:02:46,878 - mmseg - INFO - Iter [38750/40000]	lr: 4.490e-08, eta: 1:04:17, time: 2.259, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0670, decode.loss_mask: 0.2513, decode.loss_dice: 0.5191, decode.d0.loss_cls: 0.2222, decode.d0.loss_mask: 0.2541, decode.d0.loss_dice: 0.5401, decode.d1.loss_cls: 0.0721, decode.d1.loss_mask: 0.2537, decode.d1.loss_dice: 0.5302, decode.d2.loss_cls: 0.0493, decode.d2.loss_mask: 0.2511, decode.d2.loss_dice: 0.5321, decode.d3.loss_cls: 0.0556, decode.d3.loss_mask: 0.2517, decode.d3.loss_dice: 0.5320, decode.d4.loss_cls: 0.0559, decode.d4.loss_mask: 0.2518, decode.d4.loss_dice: 0.5276, decode.d5.loss_cls: 0.0550, decode.d5.loss_mask: 0.2507, decode.d5.loss_dice: 0.5326, decode.d6.loss_cls: 0.0442, decode.d6.loss_mask: 0.2517, decode.d6.loss_dice: 0.5261, decode.d7.loss_cls: 0.0528, decode.d7.loss_mask: 0.2507, decode.d7.loss_dice: 0.5219, decode.d8.loss_cls: 0.0525, decode.d8.loss_mask: 0.2503, decode.d8.loss_dice: 0.5269, loss: 8.5323
2023-09-29 18:04:40,059 - mmseg - INFO - Iter [38800/40000]	lr: 4.311e-08, eta: 1:01:41, time: 2.264, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0434, decode.loss_mask: 0.2380, decode.loss_dice: 0.5292, decode.d0.loss_cls: 0.1932, decode.d0.loss_mask: 0.2407, decode.d0.loss_dice: 0.5386, decode.d1.loss_cls: 0.0472, decode.d1.loss_mask: 0.2394, decode.d1.loss_dice: 0.5238, decode.d2.loss_cls: 0.0492, decode.d2.loss_mask: 0.2386, decode.d2.loss_dice: 0.5301, decode.d3.loss_cls: 0.0479, decode.d3.loss_mask: 0.2376, decode.d3.loss_dice: 0.5296, decode.d4.loss_cls: 0.0561, decode.d4.loss_mask: 0.2383, decode.d4.loss_dice: 0.5186, decode.d5.loss_cls: 0.0495, decode.d5.loss_mask: 0.2380, decode.d5.loss_dice: 0.5250, decode.d6.loss_cls: 0.0405, decode.d6.loss_mask: 0.2370, decode.d6.loss_dice: 0.5198, decode.d7.loss_cls: 0.0478, decode.d7.loss_mask: 0.2379, decode.d7.loss_dice: 0.5217, decode.d8.loss_cls: 0.0486, decode.d8.loss_mask: 0.2379, decode.d8.loss_dice: 0.5246, loss: 8.2677
2023-09-29 18:06:32,886 - mmseg - INFO - Iter [38850/40000]	lr: 4.132e-08, eta: 0:59:06, time: 2.257, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0642, decode.loss_mask: 0.2619, decode.loss_dice: 0.5135, decode.d0.loss_cls: 0.2353, decode.d0.loss_mask: 0.2679, decode.d0.loss_dice: 0.5362, decode.d1.loss_cls: 0.0798, decode.d1.loss_mask: 0.2623, decode.d1.loss_dice: 0.5194, decode.d2.loss_cls: 0.0684, decode.d2.loss_mask: 0.2615, decode.d2.loss_dice: 0.5191, decode.d3.loss_cls: 0.0652, decode.d3.loss_mask: 0.2621, decode.d3.loss_dice: 0.5232, decode.d4.loss_cls: 0.0707, decode.d4.loss_mask: 0.2627, decode.d4.loss_dice: 0.5097, decode.d5.loss_cls: 0.0780, decode.d5.loss_mask: 0.2622, decode.d5.loss_dice: 0.5102, decode.d6.loss_cls: 0.0651, decode.d6.loss_mask: 0.2619, decode.d6.loss_dice: 0.5221, decode.d7.loss_cls: 0.0674, decode.d7.loss_mask: 0.2611, decode.d7.loss_dice: 0.5173, decode.d8.loss_cls: 0.0743, decode.d8.loss_mask: 0.2624, decode.d8.loss_dice: 0.5165, loss: 8.6814
2023-09-29 18:08:25,633 - mmseg - INFO - Iter [38900/40000]	lr: 3.952e-08, eta: 0:56:31, time: 2.255, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0559, decode.loss_mask: 0.2488, decode.loss_dice: 0.5064, decode.d0.loss_cls: 0.2248, decode.d0.loss_mask: 0.2546, decode.d0.loss_dice: 0.5105, decode.d1.loss_cls: 0.0654, decode.d1.loss_mask: 0.2487, decode.d1.loss_dice: 0.4970, decode.d2.loss_cls: 0.0501, decode.d2.loss_mask: 0.2481, decode.d2.loss_dice: 0.5036, decode.d3.loss_cls: 0.0509, decode.d3.loss_mask: 0.2479, decode.d3.loss_dice: 0.4965, decode.d4.loss_cls: 0.0731, decode.d4.loss_mask: 0.2473, decode.d4.loss_dice: 0.5012, decode.d5.loss_cls: 0.0723, decode.d5.loss_mask: 0.2480, decode.d5.loss_dice: 0.5011, decode.d6.loss_cls: 0.0586, decode.d6.loss_mask: 0.2476, decode.d6.loss_dice: 0.5045, decode.d7.loss_cls: 0.0600, decode.d7.loss_mask: 0.2481, decode.d7.loss_dice: 0.5054, decode.d8.loss_cls: 0.0421, decode.d8.loss_mask: 0.2478, decode.d8.loss_dice: 0.5013, loss: 8.2677
2023-09-29 18:10:18,106 - mmseg - INFO - Iter [38950/40000]	lr: 3.773e-08, eta: 0:53:55, time: 2.249, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0333, decode.loss_mask: 0.2428, decode.loss_dice: 0.5320, decode.d0.loss_cls: 0.2340, decode.d0.loss_mask: 0.2440, decode.d0.loss_dice: 0.5367, decode.d1.loss_cls: 0.0791, decode.d1.loss_mask: 0.2413, decode.d1.loss_dice: 0.5185, decode.d2.loss_cls: 0.0671, decode.d2.loss_mask: 0.2417, decode.d2.loss_dice: 0.5226, decode.d3.loss_cls: 0.0430, decode.d3.loss_mask: 0.2426, decode.d3.loss_dice: 0.5132, decode.d4.loss_cls: 0.0501, decode.d4.loss_mask: 0.2422, decode.d4.loss_dice: 0.5252, decode.d5.loss_cls: 0.0375, decode.d5.loss_mask: 0.2426, decode.d5.loss_dice: 0.5163, decode.d6.loss_cls: 0.0486, decode.d6.loss_mask: 0.2403, decode.d6.loss_dice: 0.5210, decode.d7.loss_cls: 0.0480, decode.d7.loss_mask: 0.2409, decode.d7.loss_dice: 0.5230, decode.d8.loss_cls: 0.0486, decode.d8.loss_mask: 0.2412, decode.d8.loss_dice: 0.5215, loss: 8.3390
2023-09-29 18:12:10,533 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 18:12:10,533 - mmseg - INFO - Iter [39000/40000]	lr: 3.593e-08, eta: 0:51:20, time: 2.249, data_time: 0.032, memory: 21542, decode.loss_cls: 0.0561, decode.loss_mask: 0.2536, decode.loss_dice: 0.4805, decode.d0.loss_cls: 0.2174, decode.d0.loss_mask: 0.2576, decode.d0.loss_dice: 0.4895, decode.d1.loss_cls: 0.0731, decode.d1.loss_mask: 0.2553, decode.d1.loss_dice: 0.4727, decode.d2.loss_cls: 0.0791, decode.d2.loss_mask: 0.2546, decode.d2.loss_dice: 0.4848, decode.d3.loss_cls: 0.0616, decode.d3.loss_mask: 0.2537, decode.d3.loss_dice: 0.4891, decode.d4.loss_cls: 0.0604, decode.d4.loss_mask: 0.2534, decode.d4.loss_dice: 0.4907, decode.d5.loss_cls: 0.0527, decode.d5.loss_mask: 0.2527, decode.d5.loss_dice: 0.4863, decode.d6.loss_cls: 0.0694, decode.d6.loss_mask: 0.2528, decode.d6.loss_dice: 0.4848, decode.d7.loss_cls: 0.0563, decode.d7.loss_mask: 0.2539, decode.d7.loss_dice: 0.4917, decode.d8.loss_cls: 0.0729, decode.d8.loss_mask: 0.2544, decode.d8.loss_dice: 0.4831, loss: 8.1941
2023-09-29 18:14:03,102 - mmseg - INFO - Iter [39050/40000]	lr: 3.414e-08, eta: 0:48:45, time: 2.251, data_time: 0.035, memory: 21542, decode.loss_cls: 0.0374, decode.loss_mask: 0.2618, decode.loss_dice: 0.5464, decode.d0.loss_cls: 0.2188, decode.d0.loss_mask: 0.2647, decode.d0.loss_dice: 0.5499, decode.d1.loss_cls: 0.0642, decode.d1.loss_mask: 0.2648, decode.d1.loss_dice: 0.5507, decode.d2.loss_cls: 0.0589, decode.d2.loss_mask: 0.2627, decode.d2.loss_dice: 0.5499, decode.d3.loss_cls: 0.0566, decode.d3.loss_mask: 0.2624, decode.d3.loss_dice: 0.5456, decode.d4.loss_cls: 0.0549, decode.d4.loss_mask: 0.2626, decode.d4.loss_dice: 0.5465, decode.d5.loss_cls: 0.0430, decode.d5.loss_mask: 0.2630, decode.d5.loss_dice: 0.5538, decode.d6.loss_cls: 0.0338, decode.d6.loss_mask: 0.2615, decode.d6.loss_dice: 0.5503, decode.d7.loss_cls: 0.0557, decode.d7.loss_mask: 0.2638, decode.d7.loss_dice: 0.5471, decode.d8.loss_cls: 0.0443, decode.d8.loss_mask: 0.2624, decode.d8.loss_dice: 0.5479, loss: 8.7856
2023-09-29 18:15:54,970 - mmseg - INFO - Iter [39100/40000]	lr: 3.234e-08, eta: 0:46:10, time: 2.237, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0774, decode.loss_mask: 0.2407, decode.loss_dice: 0.4789, decode.d0.loss_cls: 0.2263, decode.d0.loss_mask: 0.2417, decode.d0.loss_dice: 0.4911, decode.d1.loss_cls: 0.0945, decode.d1.loss_mask: 0.2431, decode.d1.loss_dice: 0.4878, decode.d2.loss_cls: 0.0747, decode.d2.loss_mask: 0.2386, decode.d2.loss_dice: 0.4806, decode.d3.loss_cls: 0.0892, decode.d3.loss_mask: 0.2389, decode.d3.loss_dice: 0.4787, decode.d4.loss_cls: 0.0944, decode.d4.loss_mask: 0.2406, decode.d4.loss_dice: 0.4815, decode.d5.loss_cls: 0.0706, decode.d5.loss_mask: 0.2385, decode.d5.loss_dice: 0.4811, decode.d6.loss_cls: 0.0707, decode.d6.loss_mask: 0.2378, decode.d6.loss_dice: 0.4844, decode.d7.loss_cls: 0.0614, decode.d7.loss_mask: 0.2418, decode.d7.loss_dice: 0.4895, decode.d8.loss_cls: 0.0538, decode.d8.loss_mask: 0.2415, decode.d8.loss_dice: 0.4848, loss: 8.1551
2023-09-29 18:17:47,721 - mmseg - INFO - Iter [39150/40000]	lr: 3.055e-08, eta: 0:43:35, time: 2.255, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0408, decode.loss_mask: 0.2611, decode.loss_dice: 0.5020, decode.d0.loss_cls: 0.2117, decode.d0.loss_mask: 0.2683, decode.d0.loss_dice: 0.5122, decode.d1.loss_cls: 0.0554, decode.d1.loss_mask: 0.2601, decode.d1.loss_dice: 0.4872, decode.d2.loss_cls: 0.0476, decode.d2.loss_mask: 0.2614, decode.d2.loss_dice: 0.4944, decode.d3.loss_cls: 0.0425, decode.d3.loss_mask: 0.2615, decode.d3.loss_dice: 0.4973, decode.d4.loss_cls: 0.0336, decode.d4.loss_mask: 0.2623, decode.d4.loss_dice: 0.4995, decode.d5.loss_cls: 0.0402, decode.d5.loss_mask: 0.2628, decode.d5.loss_dice: 0.4929, decode.d6.loss_cls: 0.0562, decode.d6.loss_mask: 0.2623, decode.d6.loss_dice: 0.4927, decode.d7.loss_cls: 0.0402, decode.d7.loss_mask: 0.2618, decode.d7.loss_dice: 0.4903, decode.d8.loss_cls: 0.0547, decode.d8.loss_mask: 0.2622, decode.d8.loss_dice: 0.4975, loss: 8.2129
2023-09-29 18:19:40,431 - mmseg - INFO - Iter [39200/40000]	lr: 2.875e-08, eta: 0:41:01, time: 2.254, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0663, decode.loss_mask: 0.2314, decode.loss_dice: 0.4703, decode.d0.loss_cls: 0.2284, decode.d0.loss_mask: 0.2288, decode.d0.loss_dice: 0.4957, decode.d1.loss_cls: 0.0730, decode.d1.loss_mask: 0.2303, decode.d1.loss_dice: 0.4869, decode.d2.loss_cls: 0.0688, decode.d2.loss_mask: 0.2327, decode.d2.loss_dice: 0.4681, decode.d3.loss_cls: 0.0571, decode.d3.loss_mask: 0.2319, decode.d3.loss_dice: 0.4753, decode.d4.loss_cls: 0.0661, decode.d4.loss_mask: 0.2375, decode.d4.loss_dice: 0.4843, decode.d5.loss_cls: 0.0724, decode.d5.loss_mask: 0.2346, decode.d5.loss_dice: 0.4834, decode.d6.loss_cls: 0.0610, decode.d6.loss_mask: 0.2311, decode.d6.loss_dice: 0.4795, decode.d7.loss_cls: 0.0533, decode.d7.loss_mask: 0.2288, decode.d7.loss_dice: 0.4900, decode.d8.loss_cls: 0.0599, decode.d8.loss_mask: 0.2285, decode.d8.loss_dice: 0.4718, loss: 7.9271
2023-09-29 18:21:32,936 - mmseg - INFO - Iter [39250/40000]	lr: 2.696e-08, eta: 0:38:26, time: 2.251, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0503, decode.loss_mask: 0.2387, decode.loss_dice: 0.5171, decode.d0.loss_cls: 0.2326, decode.d0.loss_mask: 0.2405, decode.d0.loss_dice: 0.5321, decode.d1.loss_cls: 0.0502, decode.d1.loss_mask: 0.2400, decode.d1.loss_dice: 0.5278, decode.d2.loss_cls: 0.0468, decode.d2.loss_mask: 0.2399, decode.d2.loss_dice: 0.5282, decode.d3.loss_cls: 0.0601, decode.d3.loss_mask: 0.2400, decode.d3.loss_dice: 0.5292, decode.d4.loss_cls: 0.0491, decode.d4.loss_mask: 0.2405, decode.d4.loss_dice: 0.5309, decode.d5.loss_cls: 0.0668, decode.d5.loss_mask: 0.2401, decode.d5.loss_dice: 0.5311, decode.d6.loss_cls: 0.0491, decode.d6.loss_mask: 0.2382, decode.d6.loss_dice: 0.5263, decode.d7.loss_cls: 0.0489, decode.d7.loss_mask: 0.2403, decode.d7.loss_dice: 0.5302, decode.d8.loss_cls: 0.0508, decode.d8.loss_mask: 0.2400, decode.d8.loss_dice: 0.5274, loss: 8.3832
2023-09-29 18:23:25,609 - mmseg - INFO - Iter [39300/40000]	lr: 2.516e-08, eta: 0:35:52, time: 2.253, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0587, decode.loss_mask: 0.2219, decode.loss_dice: 0.4804, decode.d0.loss_cls: 0.2085, decode.d0.loss_mask: 0.2268, decode.d0.loss_dice: 0.5020, decode.d1.loss_cls: 0.0528, decode.d1.loss_mask: 0.2229, decode.d1.loss_dice: 0.4878, decode.d2.loss_cls: 0.0691, decode.d2.loss_mask: 0.2223, decode.d2.loss_dice: 0.4792, decode.d3.loss_cls: 0.0668, decode.d3.loss_mask: 0.2223, decode.d3.loss_dice: 0.4885, decode.d4.loss_cls: 0.0526, decode.d4.loss_mask: 0.2225, decode.d4.loss_dice: 0.4831, decode.d5.loss_cls: 0.0708, decode.d5.loss_mask: 0.2219, decode.d5.loss_dice: 0.4778, decode.d6.loss_cls: 0.0652, decode.d6.loss_mask: 0.2226, decode.d6.loss_dice: 0.4891, decode.d7.loss_cls: 0.0555, decode.d7.loss_mask: 0.2227, decode.d7.loss_dice: 0.4895, decode.d8.loss_cls: 0.0503, decode.d8.loss_mask: 0.2226, decode.d8.loss_dice: 0.4869, loss: 7.8431
2023-09-29 18:25:18,603 - mmseg - INFO - Iter [39350/40000]	lr: 2.337e-08, eta: 0:33:17, time: 2.260, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0802, decode.loss_mask: 0.2595, decode.loss_dice: 0.5074, decode.d0.loss_cls: 0.2281, decode.d0.loss_mask: 0.2619, decode.d0.loss_dice: 0.5182, decode.d1.loss_cls: 0.0992, decode.d1.loss_mask: 0.2592, decode.d1.loss_dice: 0.5113, decode.d2.loss_cls: 0.0720, decode.d2.loss_mask: 0.2606, decode.d2.loss_dice: 0.5089, decode.d3.loss_cls: 0.1014, decode.d3.loss_mask: 0.2601, decode.d3.loss_dice: 0.4973, decode.d4.loss_cls: 0.0921, decode.d4.loss_mask: 0.2593, decode.d4.loss_dice: 0.5184, decode.d5.loss_cls: 0.0968, decode.d5.loss_mask: 0.2602, decode.d5.loss_dice: 0.5107, decode.d6.loss_cls: 0.0752, decode.d6.loss_mask: 0.2588, decode.d6.loss_dice: 0.5025, decode.d7.loss_cls: 0.0757, decode.d7.loss_mask: 0.2590, decode.d7.loss_dice: 0.5051, decode.d8.loss_cls: 0.0685, decode.d8.loss_mask: 0.2594, decode.d8.loss_dice: 0.5086, loss: 8.6757
2023-09-29 18:27:11,252 - mmseg - INFO - Iter [39400/40000]	lr: 2.157e-08, eta: 0:30:43, time: 2.253, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0685, decode.loss_mask: 0.2443, decode.loss_dice: 0.4882, decode.d0.loss_cls: 0.2223, decode.d0.loss_mask: 0.2534, decode.d0.loss_dice: 0.5109, decode.d1.loss_cls: 0.0836, decode.d1.loss_mask: 0.2476, decode.d1.loss_dice: 0.4918, decode.d2.loss_cls: 0.0793, decode.d2.loss_mask: 0.2450, decode.d2.loss_dice: 0.4895, decode.d3.loss_cls: 0.0687, decode.d3.loss_mask: 0.2466, decode.d3.loss_dice: 0.4878, decode.d4.loss_cls: 0.0677, decode.d4.loss_mask: 0.2465, decode.d4.loss_dice: 0.4874, decode.d5.loss_cls: 0.0749, decode.d5.loss_mask: 0.2463, decode.d5.loss_dice: 0.4937, decode.d6.loss_cls: 0.0873, decode.d6.loss_mask: 0.2456, decode.d6.loss_dice: 0.4830, decode.d7.loss_cls: 0.0819, decode.d7.loss_mask: 0.2465, decode.d7.loss_dice: 0.4825, decode.d8.loss_cls: 0.0786, decode.d8.loss_mask: 0.2457, decode.d8.loss_dice: 0.4788, loss: 8.2738
2023-09-29 18:29:03,854 - mmseg - INFO - Iter [39450/40000]	lr: 1.978e-08, eta: 0:28:09, time: 2.252, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0659, decode.loss_mask: 0.2569, decode.loss_dice: 0.5384, decode.d0.loss_cls: 0.2058, decode.d0.loss_mask: 0.2614, decode.d0.loss_dice: 0.5461, decode.d1.loss_cls: 0.0652, decode.d1.loss_mask: 0.2585, decode.d1.loss_dice: 0.5422, decode.d2.loss_cls: 0.0681, decode.d2.loss_mask: 0.2584, decode.d2.loss_dice: 0.5408, decode.d3.loss_cls: 0.0652, decode.d3.loss_mask: 0.2577, decode.d3.loss_dice: 0.5377, decode.d4.loss_cls: 0.0585, decode.d4.loss_mask: 0.2574, decode.d4.loss_dice: 0.5392, decode.d5.loss_cls: 0.0491, decode.d5.loss_mask: 0.2585, decode.d5.loss_dice: 0.5393, decode.d6.loss_cls: 0.0552, decode.d6.loss_mask: 0.2585, decode.d6.loss_dice: 0.5394, decode.d7.loss_cls: 0.0367, decode.d7.loss_mask: 0.2580, decode.d7.loss_dice: 0.5382, decode.d8.loss_cls: 0.0562, decode.d8.loss_mask: 0.2587, decode.d8.loss_dice: 0.5340, loss: 8.7054
2023-09-29 18:30:59,188 - mmseg - INFO - Iter [39500/40000]	lr: 1.798e-08, eta: 0:25:35, time: 2.307, data_time: 0.084, memory: 21542, decode.loss_cls: 0.0517, decode.loss_mask: 0.2491, decode.loss_dice: 0.4958, decode.d0.loss_cls: 0.2128, decode.d0.loss_mask: 0.2556, decode.d0.loss_dice: 0.4958, decode.d1.loss_cls: 0.0449, decode.d1.loss_mask: 0.2502, decode.d1.loss_dice: 0.4969, decode.d2.loss_cls: 0.0495, decode.d2.loss_mask: 0.2500, decode.d2.loss_dice: 0.4893, decode.d3.loss_cls: 0.0378, decode.d3.loss_mask: 0.2503, decode.d3.loss_dice: 0.4893, decode.d4.loss_cls: 0.0464, decode.d4.loss_mask: 0.2495, decode.d4.loss_dice: 0.4913, decode.d5.loss_cls: 0.0547, decode.d5.loss_mask: 0.2509, decode.d5.loss_dice: 0.5000, decode.d6.loss_cls: 0.0338, decode.d6.loss_mask: 0.2503, decode.d6.loss_dice: 0.4952, decode.d7.loss_cls: 0.0349, decode.d7.loss_mask: 0.2495, decode.d7.loss_dice: 0.4971, decode.d8.loss_cls: 0.0434, decode.d8.loss_mask: 0.2496, decode.d8.loss_dice: 0.4954, loss: 8.0613
2023-09-29 18:32:51,997 - mmseg - INFO - Iter [39550/40000]	lr: 1.619e-08, eta: 0:23:01, time: 2.256, data_time: 0.028, memory: 21542, decode.loss_cls: 0.0622, decode.loss_mask: 0.2340, decode.loss_dice: 0.4808, decode.d0.loss_cls: 0.2400, decode.d0.loss_mask: 0.2357, decode.d0.loss_dice: 0.4909, decode.d1.loss_cls: 0.0840, decode.d1.loss_mask: 0.2335, decode.d1.loss_dice: 0.4847, decode.d2.loss_cls: 0.0608, decode.d2.loss_mask: 0.2333, decode.d2.loss_dice: 0.4791, decode.d3.loss_cls: 0.0806, decode.d3.loss_mask: 0.2332, decode.d3.loss_dice: 0.4811, decode.d4.loss_cls: 0.0610, decode.d4.loss_mask: 0.2334, decode.d4.loss_dice: 0.4775, decode.d5.loss_cls: 0.0623, decode.d5.loss_mask: 0.2346, decode.d5.loss_dice: 0.4821, decode.d6.loss_cls: 0.0576, decode.d6.loss_mask: 0.2329, decode.d6.loss_dice: 0.4733, decode.d7.loss_cls: 0.0657, decode.d7.loss_mask: 0.2336, decode.d7.loss_dice: 0.4797, decode.d8.loss_cls: 0.0594, decode.d8.loss_mask: 0.2354, decode.d8.loss_dice: 0.4837, loss: 7.9861
2023-09-29 18:34:45,608 - mmseg - INFO - Iter [39600/40000]	lr: 1.439e-08, eta: 0:20:27, time: 2.272, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0388, decode.loss_mask: 0.2543, decode.loss_dice: 0.4914, decode.d0.loss_cls: 0.2415, decode.d0.loss_mask: 0.2606, decode.d0.loss_dice: 0.5027, decode.d1.loss_cls: 0.0659, decode.d1.loss_mask: 0.2542, decode.d1.loss_dice: 0.4934, decode.d2.loss_cls: 0.0731, decode.d2.loss_mask: 0.2547, decode.d2.loss_dice: 0.4951, decode.d3.loss_cls: 0.0636, decode.d3.loss_mask: 0.2551, decode.d3.loss_dice: 0.5093, decode.d4.loss_cls: 0.0492, decode.d4.loss_mask: 0.2565, decode.d4.loss_dice: 0.4906, decode.d5.loss_cls: 0.0499, decode.d5.loss_mask: 0.2541, decode.d5.loss_dice: 0.5007, decode.d6.loss_cls: 0.0445, decode.d6.loss_mask: 0.2552, decode.d6.loss_dice: 0.4967, decode.d7.loss_cls: 0.0454, decode.d7.loss_mask: 0.2560, decode.d7.loss_dice: 0.5074, decode.d8.loss_cls: 0.0569, decode.d8.loss_mask: 0.2538, decode.d8.loss_dice: 0.4924, loss: 8.2631
2023-09-29 18:36:39,020 - mmseg - INFO - Iter [39650/40000]	lr: 1.260e-08, eta: 0:17:53, time: 2.268, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0745, decode.loss_mask: 0.2354, decode.loss_dice: 0.4902, decode.d0.loss_cls: 0.2486, decode.d0.loss_mask: 0.2355, decode.d0.loss_dice: 0.5157, decode.d1.loss_cls: 0.0999, decode.d1.loss_mask: 0.2361, decode.d1.loss_dice: 0.5003, decode.d2.loss_cls: 0.0905, decode.d2.loss_mask: 0.2363, decode.d2.loss_dice: 0.4981, decode.d3.loss_cls: 0.1030, decode.d3.loss_mask: 0.2356, decode.d3.loss_dice: 0.4932, decode.d4.loss_cls: 0.1003, decode.d4.loss_mask: 0.2353, decode.d4.loss_dice: 0.4846, decode.d5.loss_cls: 0.0862, decode.d5.loss_mask: 0.2344, decode.d5.loss_dice: 0.4938, decode.d6.loss_cls: 0.1080, decode.d6.loss_mask: 0.2338, decode.d6.loss_dice: 0.5009, decode.d7.loss_cls: 0.1103, decode.d7.loss_mask: 0.2345, decode.d7.loss_dice: 0.4909, decode.d8.loss_cls: 0.0740, decode.d8.loss_mask: 0.2343, decode.d8.loss_dice: 0.4957, loss: 8.4100
2023-09-29 18:38:31,370 - mmseg - INFO - Iter [39700/40000]	lr: 1.080e-08, eta: 0:15:19, time: 2.247, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0422, decode.loss_mask: 0.2302, decode.loss_dice: 0.5189, decode.d0.loss_cls: 0.1880, decode.d0.loss_mask: 0.2307, decode.d0.loss_dice: 0.5428, decode.d1.loss_cls: 0.0698, decode.d1.loss_mask: 0.2291, decode.d1.loss_dice: 0.5265, decode.d2.loss_cls: 0.0574, decode.d2.loss_mask: 0.2304, decode.d2.loss_dice: 0.5281, decode.d3.loss_cls: 0.0525, decode.d3.loss_mask: 0.2290, decode.d3.loss_dice: 0.5170, decode.d4.loss_cls: 0.0447, decode.d4.loss_mask: 0.2291, decode.d4.loss_dice: 0.5302, decode.d5.loss_cls: 0.0513, decode.d5.loss_mask: 0.2293, decode.d5.loss_dice: 0.5364, decode.d6.loss_cls: 0.0431, decode.d6.loss_mask: 0.2291, decode.d6.loss_dice: 0.5333, decode.d7.loss_cls: 0.0464, decode.d7.loss_mask: 0.2301, decode.d7.loss_dice: 0.5363, decode.d8.loss_cls: 0.0565, decode.d8.loss_mask: 0.2300, decode.d8.loss_dice: 0.5365, loss: 8.2547
2023-09-29 18:40:24,742 - mmseg - INFO - Iter [39750/40000]	lr: 9.010e-09, eta: 0:12:46, time: 2.267, data_time: 0.027, memory: 21542, decode.loss_cls: 0.0427, decode.loss_mask: 0.2472, decode.loss_dice: 0.5080, decode.d0.loss_cls: 0.1970, decode.d0.loss_mask: 0.2479, decode.d0.loss_dice: 0.5232, decode.d1.loss_cls: 0.0618, decode.d1.loss_mask: 0.2468, decode.d1.loss_dice: 0.5051, decode.d2.loss_cls: 0.0517, decode.d2.loss_mask: 0.2481, decode.d2.loss_dice: 0.5080, decode.d3.loss_cls: 0.0564, decode.d3.loss_mask: 0.2482, decode.d3.loss_dice: 0.5210, decode.d4.loss_cls: 0.0371, decode.d4.loss_mask: 0.2478, decode.d4.loss_dice: 0.5085, decode.d5.loss_cls: 0.0541, decode.d5.loss_mask: 0.2473, decode.d5.loss_dice: 0.5091, decode.d6.loss_cls: 0.0515, decode.d6.loss_mask: 0.2476, decode.d6.loss_dice: 0.5128, decode.d7.loss_cls: 0.0371, decode.d7.loss_mask: 0.2470, decode.d7.loss_dice: 0.5152, decode.d8.loss_cls: 0.0413, decode.d8.loss_mask: 0.2467, decode.d8.loss_dice: 0.5059, loss: 8.2222
2023-09-29 18:42:17,932 - mmseg - INFO - Iter [39800/40000]	lr: 7.215e-09, eta: 0:10:12, time: 2.264, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0628, decode.loss_mask: 0.2786, decode.loss_dice: 0.5370, decode.d0.loss_cls: 0.2321, decode.d0.loss_mask: 0.2837, decode.d0.loss_dice: 0.5477, decode.d1.loss_cls: 0.0632, decode.d1.loss_mask: 0.2820, decode.d1.loss_dice: 0.5470, decode.d2.loss_cls: 0.0530, decode.d2.loss_mask: 0.2794, decode.d2.loss_dice: 0.5375, decode.d3.loss_cls: 0.0711, decode.d3.loss_mask: 0.2800, decode.d3.loss_dice: 0.5327, decode.d4.loss_cls: 0.0553, decode.d4.loss_mask: 0.2792, decode.d4.loss_dice: 0.5479, decode.d5.loss_cls: 0.0651, decode.d5.loss_mask: 0.2794, decode.d5.loss_dice: 0.5351, decode.d6.loss_cls: 0.0560, decode.d6.loss_mask: 0.2799, decode.d6.loss_dice: 0.5408, decode.d7.loss_cls: 0.0582, decode.d7.loss_mask: 0.2787, decode.d7.loss_dice: 0.5369, decode.d8.loss_cls: 0.0503, decode.d8.loss_mask: 0.2788, decode.d8.loss_dice: 0.5325, loss: 8.9617
2023-09-29 18:44:11,060 - mmseg - INFO - Iter [39850/40000]	lr: 5.420e-09, eta: 0:07:39, time: 2.263, data_time: 0.030, memory: 21542, decode.loss_cls: 0.0407, decode.loss_mask: 0.2222, decode.loss_dice: 0.4715, decode.d0.loss_cls: 0.2138, decode.d0.loss_mask: 0.2255, decode.d0.loss_dice: 0.4945, decode.d1.loss_cls: 0.0528, decode.d1.loss_mask: 0.2236, decode.d1.loss_dice: 0.4690, decode.d2.loss_cls: 0.0428, decode.d2.loss_mask: 0.2257, decode.d2.loss_dice: 0.4739, decode.d3.loss_cls: 0.0421, decode.d3.loss_mask: 0.2242, decode.d3.loss_dice: 0.4643, decode.d4.loss_cls: 0.0404, decode.d4.loss_mask: 0.2218, decode.d4.loss_dice: 0.4711, decode.d5.loss_cls: 0.0443, decode.d5.loss_mask: 0.2256, decode.d5.loss_dice: 0.4772, decode.d6.loss_cls: 0.0373, decode.d6.loss_mask: 0.2231, decode.d6.loss_dice: 0.4721, decode.d7.loss_cls: 0.0368, decode.d7.loss_mask: 0.2223, decode.d7.loss_dice: 0.4824, decode.d8.loss_cls: 0.0462, decode.d8.loss_mask: 0.2220, decode.d8.loss_dice: 0.4741, loss: 7.5834
2023-09-29 18:46:03,770 - mmseg - INFO - Iter [39900/40000]	lr: 3.625e-09, eta: 0:05:06, time: 2.254, data_time: 0.026, memory: 21542, decode.loss_cls: 0.0987, decode.loss_mask: 0.2428, decode.loss_dice: 0.4951, decode.d0.loss_cls: 0.2235, decode.d0.loss_mask: 0.2476, decode.d0.loss_dice: 0.5112, decode.d1.loss_cls: 0.0898, decode.d1.loss_mask: 0.2434, decode.d1.loss_dice: 0.5021, decode.d2.loss_cls: 0.0698, decode.d2.loss_mask: 0.2443, decode.d2.loss_dice: 0.5061, decode.d3.loss_cls: 0.0810, decode.d3.loss_mask: 0.2434, decode.d3.loss_dice: 0.5101, decode.d4.loss_cls: 0.0607, decode.d4.loss_mask: 0.2429, decode.d4.loss_dice: 0.5047, decode.d5.loss_cls: 0.0718, decode.d5.loss_mask: 0.2432, decode.d5.loss_dice: 0.5087, decode.d6.loss_cls: 0.0596, decode.d6.loss_mask: 0.2436, decode.d6.loss_dice: 0.5131, decode.d7.loss_cls: 0.0775, decode.d7.loss_mask: 0.2429, decode.d7.loss_dice: 0.5071, decode.d8.loss_cls: 0.0615, decode.d8.loss_mask: 0.2440, decode.d8.loss_dice: 0.5111, loss: 8.4012
2023-09-29 18:47:57,245 - mmseg - INFO - Iter [39950/40000]	lr: 1.831e-09, eta: 0:02:33, time: 2.269, data_time: 0.029, memory: 21542, decode.loss_cls: 0.0557, decode.loss_mask: 0.2798, decode.loss_dice: 0.5018, decode.d0.loss_cls: 0.2220, decode.d0.loss_mask: 0.2839, decode.d0.loss_dice: 0.5027, decode.d1.loss_cls: 0.0701, decode.d1.loss_mask: 0.2816, decode.d1.loss_dice: 0.4966, decode.d2.loss_cls: 0.0517, decode.d2.loss_mask: 0.2823, decode.d2.loss_dice: 0.5012, decode.d3.loss_cls: 0.0472, decode.d3.loss_mask: 0.2829, decode.d3.loss_dice: 0.4937, decode.d4.loss_cls: 0.0565, decode.d4.loss_mask: 0.2840, decode.d4.loss_dice: 0.5024, decode.d5.loss_cls: 0.0525, decode.d5.loss_mask: 0.2834, decode.d5.loss_dice: 0.5064, decode.d6.loss_cls: 0.0499, decode.d6.loss_mask: 0.2788, decode.d6.loss_dice: 0.4959, decode.d7.loss_cls: 0.0483, decode.d7.loss_mask: 0.2838, decode.d7.loss_dice: 0.4971, decode.d8.loss_cls: 0.0505, decode.d8.loss_mask: 0.2797, decode.d8.loss_dice: 0.4896, loss: 8.5121
2023-09-29 18:49:50,557 - mmseg - INFO - Saving checkpoint at 40000 iterations
2023-09-29 18:50:11,125 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 18:50:11,125 - mmseg - INFO - Iter [40000/40000]	lr: 3.589e-11, eta: 0:00:00, time: 2.678, data_time: 0.031, memory: 21542, decode.loss_cls: 0.0316, decode.loss_mask: 0.2530, decode.loss_dice: 0.5367, decode.d0.loss_cls: 0.1838, decode.d0.loss_mask: 0.2576, decode.d0.loss_dice: 0.5625, decode.d1.loss_cls: 0.0562, decode.d1.loss_mask: 0.2541, decode.d1.loss_dice: 0.5543, decode.d2.loss_cls: 0.0568, decode.d2.loss_mask: 0.2514, decode.d2.loss_dice: 0.5420, decode.d3.loss_cls: 0.0416, decode.d3.loss_mask: 0.2543, decode.d3.loss_dice: 0.5463, decode.d4.loss_cls: 0.0401, decode.d4.loss_mask: 0.2533, decode.d4.loss_dice: 0.5430, decode.d5.loss_cls: 0.0285, decode.d5.loss_mask: 0.2534, decode.d5.loss_dice: 0.5500, decode.d6.loss_cls: 0.0423, decode.d6.loss_mask: 0.2518, decode.d6.loss_dice: 0.5446, decode.d7.loss_cls: 0.0339, decode.d7.loss_mask: 0.2547, decode.d7.loss_dice: 0.5573, decode.d8.loss_cls: 0.0401, decode.d8.loss_mask: 0.2531, decode.d8.loss_dice: 0.5375, loss: 8.5660
2023-09-29 19:07:26,978 - mmseg - INFO - per class results:
2023-09-29 19:07:26,979 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      Road     | 92.89 | 96.97 |
|    Sidewalk   | 69.59 | 81.66 |
|  Construction | 82.31 | 94.28 |
|     Fence     | 33.69 | 37.37 |
|      Pole     | 57.64 | 68.93 |
| Traffic Light | 67.83 | 78.87 |
|  Traffic Sign | 72.76 | 80.83 |
|     Nature    | 88.57 |  93.9 |
|      Sky      | 96.61 |  98.0 |
|     Person    | 41.22 | 44.41 |
|     Rider     | 11.53 | 71.02 |
|      Car      |  91.6 | 94.84 |
|   background  | 96.12 | 97.77 |
+---------------+-------+-------+
2023-09-29 19:07:26,979 - mmseg - INFO - Summary:
2023-09-29 19:07:26,979 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.49 | 69.41 | 79.91 |
+-------+-------+-------+
2023-09-29 19:07:27,803 - mmseg - INFO - The previous best checkpoint /raid/hyundai/ViT-Adapter/segmentation/work_dirs/vit_13/best_mIoU_iter_14000.pth was removed
2023-09-29 19:07:43,970 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_40000.pth.
2023-09-29 19:07:43,971 - mmseg - INFO - Best mIoU is 0.6941 at 40000 iter.
2023-09-29 19:07:43,974 - mmseg - INFO - Exp name: vit_13class-2.py
2023-09-29 19:07:43,974 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9449, mIoU: 0.6941, mAcc: 0.7991, IoU.Road: 0.9289, IoU.Sidewalk: 0.6959, IoU.Construction: 0.8231, IoU.Fence: 0.3369, IoU.Pole: 0.5764, IoU.Traffic Light: 0.6783, IoU.Traffic Sign: 0.7276, IoU.Nature: 0.8857, IoU.Sky: 0.9661, IoU.Person: 0.4122, IoU.Rider: 0.1153, IoU.Car: 0.9160, IoU.background: 0.9612, Acc.Road: 0.9697, Acc.Sidewalk: 0.8166, Acc.Construction: 0.9428, Acc.Fence: 0.3737, Acc.Pole: 0.6893, Acc.Traffic Light: 0.7887, Acc.Traffic Sign: 0.8083, Acc.Nature: 0.9390, Acc.Sky: 0.9800, Acc.Person: 0.4441, Acc.Rider: 0.7102, Acc.Car: 0.9484, Acc.background: 0.9777
